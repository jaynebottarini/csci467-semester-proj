{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"matchups_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TEAM NO</th>\n",
       "      <th>DUNKS FG%</th>\n",
       "      <th>DUNKS SHARE</th>\n",
       "      <th>DUNKS FG%D</th>\n",
       "      <th>DUNKS D SHARE</th>\n",
       "      <th>CLOSE TWOS FG%</th>\n",
       "      <th>BADJ EM_x</th>\n",
       "      <th>BADJ O_x</th>\n",
       "      <th>BADJ D_x</th>\n",
       "      <th>...</th>\n",
       "      <th>BARTHAG_x_o</th>\n",
       "      <th>BADJ EM_y_o</th>\n",
       "      <th>BADJ O_y_o</th>\n",
       "      <th>BADJ D_y_o</th>\n",
       "      <th>BARTHAG_y_o</th>\n",
       "      <th>YEAR_o</th>\n",
       "      <th>SEED_o</th>\n",
       "      <th>CURRENT ROUND_o</th>\n",
       "      <th>GAME ID_o</th>\n",
       "      <th>UPSET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1011</td>\n",
       "      <td>88.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>85.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>60.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>121.6</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>102.4</td>\n",
       "      <td>104.4</td>\n",
       "      <td>0.445</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>979</td>\n",
       "      <td>80.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>86.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>59.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>118.1</td>\n",
       "      <td>97.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914</td>\n",
       "      <td>17.6</td>\n",
       "      <td>114.8</td>\n",
       "      <td>97.2</td>\n",
       "      <td>0.871</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>961</td>\n",
       "      <td>87.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>61.5</td>\n",
       "      <td>25.7</td>\n",
       "      <td>113.8</td>\n",
       "      <td>88.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819</td>\n",
       "      <td>9.4</td>\n",
       "      <td>108.1</td>\n",
       "      <td>98.7</td>\n",
       "      <td>0.740</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>76</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>946</td>\n",
       "      <td>89.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>81.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>60.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>110.8</td>\n",
       "      <td>91.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640</td>\n",
       "      <td>9.5</td>\n",
       "      <td>112.6</td>\n",
       "      <td>103.1</td>\n",
       "      <td>0.734</td>\n",
       "      <td>2023</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001</td>\n",
       "      <td>94.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>63.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>115.7</td>\n",
       "      <td>89.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840</td>\n",
       "      <td>15.2</td>\n",
       "      <td>113.0</td>\n",
       "      <td>97.8</td>\n",
       "      <td>0.840</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  TEAM NO  DUNKS FG%  DUNKS SHARE  DUNKS FG%D  DUNKS D SHARE  \\\n",
       "0           0     1011       88.7         13.0        85.2            5.3   \n",
       "1           1      979       80.2          6.7        86.7            5.8   \n",
       "2           2      961       87.5          7.8        75.0            5.4   \n",
       "3           3      946       89.7          9.4        81.5            5.2   \n",
       "4           4     1001       94.7         10.4        78.9            4.3   \n",
       "\n",
       "   CLOSE TWOS FG%  BADJ EM_x  BADJ O_x  BADJ D_x  ...  BARTHAG_x_o  \\\n",
       "0            60.7       33.0     121.6      88.6  ...        0.468   \n",
       "1            59.9       20.8     118.1      97.3  ...        0.914   \n",
       "2            61.5       25.7     113.8      88.1  ...        0.819   \n",
       "3            60.6       19.3     110.8      91.5  ...        0.640   \n",
       "4            63.6       26.3     115.7      89.4  ...        0.840   \n",
       "\n",
       "   BADJ EM_y_o  BADJ O_y_o  BADJ D_y_o  BARTHAG_y_o  YEAR_o  SEED_o  \\\n",
       "0         -2.0       102.4       104.4        0.445    2023      16   \n",
       "1         17.6       114.8        97.2        0.871    2023       9   \n",
       "2          9.4       108.1        98.7        0.740    2023      12   \n",
       "3          9.5       112.6       103.1        0.734    2023      13   \n",
       "4         15.2       113.0        97.8        0.840    2023      11   \n",
       "\n",
       "   CURRENT ROUND_o GAME ID_o  UPSET  \n",
       "0               64        74     -1  \n",
       "1               64        75     -1  \n",
       "2               64        76     -1  \n",
       "3               64        77      1  \n",
       "4               64        78     -1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matchups.drop(columns=['OUTCOME', \"TEAM\", \"ROUND\", \"BY YEAR NO\", \"BY ROUND NO\", \"SCORE\", \"UPSET\"])\n",
    "y = matchups['UPSET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 36)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 36)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 36)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(36,), activation='relu'))\n",
    "    model.add(Dense(128, input_shape=(128,), activation='relu'))\n",
    "    model.add(Dense(128, input_shape=(128,), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'epochs': [100, 200, 300],\n",
    "    'batch_size': [8, 16, 32, 64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(model=create_baseline, epochs=200, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "64/64 [==============================] - 4s 11ms/step - loss: 0.6870 - accuracy: 0.5391 - val_loss: 0.9207 - val_accuracy: 0.1890\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.6777 - val_loss: 0.5199 - val_accuracy: 0.1646\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6914 - val_loss: 0.1639 - val_accuracy: 0.1524\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7148 - val_loss: 0.2344 - val_accuracy: 0.1829\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7246 - val_loss: 0.5837 - val_accuracy: 0.2012\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7852 - val_loss: -0.6824 - val_accuracy: 0.1585\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7715 - val_loss: -1.2927 - val_accuracy: 0.0976\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7988 - val_loss: -1.2057 - val_accuracy: 0.1280\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7871 - val_loss: -1.2010 - val_accuracy: 0.1524\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7949 - val_loss: -1.2385 - val_accuracy: 0.1280\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8340 - val_loss: -1.6924 - val_accuracy: 0.1463\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8262 - val_loss: -2.5171 - val_accuracy: 0.0549\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8242 - val_loss: -1.3906 - val_accuracy: 0.1646\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8535 - val_loss: -1.3949 - val_accuracy: 0.1768\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8516 - val_loss: -1.0590 - val_accuracy: 0.1890\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8574 - val_loss: -1.6906 - val_accuracy: 0.1220\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8496 - val_loss: -2.6674 - val_accuracy: 0.1220\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8594 - val_loss: -2.3294 - val_accuracy: 0.1037\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8438 - val_loss: -2.5155 - val_accuracy: 0.1280\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8633 - val_loss: -1.5072 - val_accuracy: 0.1463\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.8770 - val_loss: -1.5288 - val_accuracy: 0.1829\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8809 - val_loss: -3.0256 - val_accuracy: 0.1037\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2451 - accuracy: 0.8945 - val_loss: -3.6426 - val_accuracy: 0.0854\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.9043 - val_loss: -2.8563 - val_accuracy: 0.1402\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2371 - accuracy: 0.9023 - val_loss: -3.6726 - val_accuracy: 0.1098\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.8926 - val_loss: -2.2104 - val_accuracy: 0.1585\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2609 - accuracy: 0.8965 - val_loss: -3.0445 - val_accuracy: 0.1098\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2119 - accuracy: 0.9160 - val_loss: -3.9572 - val_accuracy: 0.0915\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9316 - val_loss: -4.3989 - val_accuracy: 0.0732\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9043 - val_loss: -3.6061 - val_accuracy: 0.1159\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1768 - accuracy: 0.9375 - val_loss: -3.3928 - val_accuracy: 0.1463\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2319 - accuracy: 0.9121 - val_loss: -1.1162 - val_accuracy: 0.1280\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9102 - val_loss: -2.4302 - val_accuracy: 0.1524\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9316 - val_loss: -4.2420 - val_accuracy: 0.0793\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9258 - val_loss: -2.8125 - val_accuracy: 0.1159\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1770 - accuracy: 0.9277 - val_loss: -4.5355 - val_accuracy: 0.0915\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1819 - accuracy: 0.9238 - val_loss: -3.8770 - val_accuracy: 0.1098\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9414 - val_loss: -4.5749 - val_accuracy: 0.0915\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.9453 - val_loss: -4.3720 - val_accuracy: 0.0915\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9590 - val_loss: -5.0546 - val_accuracy: 0.1220\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.9590 - val_loss: -2.8453 - val_accuracy: 0.1585\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9590 - val_loss: -6.6046 - val_accuracy: 0.0793\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1291 - accuracy: 0.9453 - val_loss: -6.7104 - val_accuracy: 0.0854\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1752 - accuracy: 0.9355 - val_loss: -4.4706 - val_accuracy: 0.1280\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9590 - val_loss: -4.1054 - val_accuracy: 0.1341\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9707 - val_loss: -6.7255 - val_accuracy: 0.0793\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9785 - val_loss: -6.2151 - val_accuracy: 0.0732\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9785 - val_loss: -6.3256 - val_accuracy: 0.1037\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9746 - val_loss: -6.9601 - val_accuracy: 0.0915\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9668 - val_loss: -7.6864 - val_accuracy: 0.0549\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9688 - val_loss: -5.8865 - val_accuracy: 0.1280\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9316 - val_loss: -5.3909 - val_accuracy: 0.1220\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9746 - val_loss: -5.2179 - val_accuracy: 0.1159\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9434 - val_loss: -6.2702 - val_accuracy: 0.0793\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9785 - val_loss: -6.6483 - val_accuracy: 0.0732\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: -5.4135 - val_accuracy: 0.1220\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9902 - val_loss: -7.0117 - val_accuracy: 0.0793\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9941 - val_loss: -6.7833 - val_accuracy: 0.1098\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9805 - val_loss: -5.6257 - val_accuracy: 0.1037\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9707 - val_loss: -6.7987 - val_accuracy: 0.0854\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9668 - val_loss: -6.5032 - val_accuracy: 0.0976\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.9238 - val_loss: -5.0329 - val_accuracy: 0.1220\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.8965 - val_loss: -5.5364 - val_accuracy: 0.1280\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9570 - val_loss: -6.1518 - val_accuracy: 0.1037\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9902 - val_loss: -7.0050 - val_accuracy: 0.1098\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9961 - val_loss: -7.3495 - val_accuracy: 0.1159\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9980 - val_loss: -8.4914 - val_accuracy: 0.1037\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9961 - val_loss: -7.7061 - val_accuracy: 0.1098\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: -9.4822 - val_accuracy: 0.0793\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9980 - val_loss: -9.0662 - val_accuracy: 0.0976\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: -6.5542 - val_accuracy: 0.1159\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9883 - val_loss: -9.0773 - val_accuracy: 0.0915\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: -9.1796 - val_accuracy: 0.0915\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9922 - val_loss: -9.3966 - val_accuracy: 0.0732\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9727 - val_loss: -9.3430 - val_accuracy: 0.0854\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9375 - val_loss: -4.6480 - val_accuracy: 0.1402\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9492 - val_loss: -6.0994 - val_accuracy: 0.1037\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9883 - val_loss: -7.5876 - val_accuracy: 0.0793\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: -8.3074 - val_accuracy: 0.0854\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: -9.3705 - val_accuracy: 0.0671\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: -8.6456 - val_accuracy: 0.0976\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -8.6656 - val_accuracy: 0.1037\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -9.1670 - val_accuracy: 0.1037\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -9.3426 - val_accuracy: 0.1037\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -9.5329 - val_accuracy: 0.0976\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.5284 - val_accuracy: 0.1098\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.8035 - val_accuracy: 0.0915\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.7010 - val_accuracy: 0.1037\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.8356 - val_accuracy: 0.0976\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.1435 - val_accuracy: 0.1037\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.8157 - val_accuracy: 0.1037\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.1469 - val_accuracy: 0.1037\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.4169 - val_accuracy: 0.1037\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.9207e-04 - accuracy: 1.0000 - val_loss: -10.2418 - val_accuracy: 0.0915\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.9185e-04 - accuracy: 1.0000 - val_loss: -10.2733 - val_accuracy: 0.1037\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.5383e-04 - accuracy: 1.0000 - val_loss: -10.5162 - val_accuracy: 0.1037\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.9872e-04 - accuracy: 1.0000 - val_loss: -10.5814 - val_accuracy: 0.1037\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.6432e-04 - accuracy: 1.0000 - val_loss: -10.5722 - val_accuracy: 0.1037\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.9714e-04 - accuracy: 1.0000 - val_loss: -10.7586 - val_accuracy: 0.1037\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 6.6373e-04 - accuracy: 1.0000 - val_loss: -10.6491 - val_accuracy: 0.1037\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.5332 - val_loss: 0.8488 - val_accuracy: 0.1951\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5938 - val_loss: 0.3313 - val_accuracy: 0.0915\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6183 - accuracy: 0.6582 - val_loss: 0.7178 - val_accuracy: 0.1829\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.6855 - val_loss: 0.6216 - val_accuracy: 0.1829\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7188 - val_loss: -0.8930 - val_accuracy: 0.0549\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7188 - val_loss: -0.5314 - val_accuracy: 0.1159\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7188 - val_loss: -0.7843 - val_accuracy: 0.0732\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7344 - val_loss: -0.0103 - val_accuracy: 0.1707\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7773 - val_loss: -1.4907 - val_accuracy: 0.0915\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7637 - val_loss: -0.0890 - val_accuracy: 0.1768\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7754 - val_loss: -0.4458 - val_accuracy: 0.1585\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7793 - val_loss: -0.7314 - val_accuracy: 0.1524\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7852 - val_loss: -0.8642 - val_accuracy: 0.1463\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7891 - val_loss: -1.0358 - val_accuracy: 0.1463\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.7871 - val_loss: -0.9163 - val_accuracy: 0.1707\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8223 - val_loss: -0.2308 - val_accuracy: 0.1768\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8359 - val_loss: -1.2342 - val_accuracy: 0.1463\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8047 - val_loss: -1.2993 - val_accuracy: 0.1098\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8398 - val_loss: -1.0134 - val_accuracy: 0.1463\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8379 - val_loss: -1.7011 - val_accuracy: 0.1402\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8379 - val_loss: -1.9492 - val_accuracy: 0.1341\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8535 - val_loss: -1.2468 - val_accuracy: 0.1402\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8574 - val_loss: -2.5307 - val_accuracy: 0.0976\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8516 - val_loss: -1.8812 - val_accuracy: 0.1524\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8730 - val_loss: -2.4233 - val_accuracy: 0.1280\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.8867 - val_loss: -2.6927 - val_accuracy: 0.1159\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8730 - val_loss: -1.3564 - val_accuracy: 0.1220\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.9043 - val_loss: -1.7759 - val_accuracy: 0.1159\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2358 - accuracy: 0.9043 - val_loss: -3.0007 - val_accuracy: 0.1037\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9141 - val_loss: -4.7124 - val_accuracy: 0.0549\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8574 - val_loss: -3.4094 - val_accuracy: 0.0976\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2096 - accuracy: 0.9258 - val_loss: -2.8054 - val_accuracy: 0.0915\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2095 - accuracy: 0.9102 - val_loss: -2.9207 - val_accuracy: 0.1280\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9316 - val_loss: -2.8795 - val_accuracy: 0.1159\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9121 - val_loss: -3.8018 - val_accuracy: 0.0915\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2176 - accuracy: 0.9219 - val_loss: -2.9241 - val_accuracy: 0.0915\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9199 - val_loss: -3.8104 - val_accuracy: 0.0915\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.9258 - val_loss: -2.5069 - val_accuracy: 0.1220\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9512 - val_loss: -3.9407 - val_accuracy: 0.1098\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1853 - accuracy: 0.9355 - val_loss: -3.1336 - val_accuracy: 0.1220\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1640 - accuracy: 0.9355 - val_loss: -3.3103 - val_accuracy: 0.1037\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9453 - val_loss: -2.6787 - val_accuracy: 0.1220\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9082 - val_loss: -1.6653 - val_accuracy: 0.0976\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1631 - accuracy: 0.9297 - val_loss: -4.0569 - val_accuracy: 0.0976\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9688 - val_loss: -5.0633 - val_accuracy: 0.0854\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9668 - val_loss: -4.6505 - val_accuracy: 0.1220\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9512 - val_loss: -4.6369 - val_accuracy: 0.1037\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9668 - val_loss: -4.4322 - val_accuracy: 0.1098\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9707 - val_loss: -3.7768 - val_accuracy: 0.1159\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9414 - val_loss: -0.5229 - val_accuracy: 0.1585\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9102 - val_loss: -4.8262 - val_accuracy: 0.0915\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9473 - val_loss: -3.7061 - val_accuracy: 0.1159\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.9551 - val_loss: -4.5148 - val_accuracy: 0.1037\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9648 - val_loss: -4.5966 - val_accuracy: 0.0854\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9844 - val_loss: -4.7971 - val_accuracy: 0.0915\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: -5.4322 - val_accuracy: 0.0854\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9785 - val_loss: -5.0657 - val_accuracy: 0.1037\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9863 - val_loss: -4.9270 - val_accuracy: 0.1098\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9785 - val_loss: -5.6256 - val_accuracy: 0.0732\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: -5.1132 - val_accuracy: 0.1220\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9805 - val_loss: -6.9966 - val_accuracy: 0.0732\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9473 - val_loss: -5.3015 - val_accuracy: 0.0732\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9727 - val_loss: -6.5723 - val_accuracy: 0.0732\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9727 - val_loss: -5.2522 - val_accuracy: 0.0915\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9902 - val_loss: -4.1382 - val_accuracy: 0.1098\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9863 - val_loss: -6.1927 - val_accuracy: 0.0793\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.9258 - val_loss: -3.2922 - val_accuracy: 0.1220\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9434 - val_loss: -3.3725 - val_accuracy: 0.1159\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9766 - val_loss: -3.7261 - val_accuracy: 0.1159\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9922 - val_loss: -4.5508 - val_accuracy: 0.0915\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9980 - val_loss: -4.6516 - val_accuracy: 0.1098\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: -5.0957 - val_accuracy: 0.0976\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9746 - val_loss: -4.6411 - val_accuracy: 0.0854\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9668 - val_loss: -4.7308 - val_accuracy: 0.0854\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9590 - val_loss: -3.4833 - val_accuracy: 0.0915\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9648 - val_loss: -4.8405 - val_accuracy: 0.1037\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: -4.7691 - val_accuracy: 0.0793\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9902 - val_loss: -4.7559 - val_accuracy: 0.0976\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9980 - val_loss: -4.3048 - val_accuracy: 0.1037\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: -4.8762 - val_accuracy: 0.0976\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: -5.6850 - val_accuracy: 0.0793\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: -4.5629 - val_accuracy: 0.0976\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9902 - val_loss: -5.5475 - val_accuracy: 0.0854\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: -4.3754 - val_accuracy: 0.0976\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: -5.8791 - val_accuracy: 0.0854\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: -4.9913 - val_accuracy: 0.0854\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: -5.6651 - val_accuracy: 0.0854\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -5.2341 - val_accuracy: 0.0915\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -5.5288 - val_accuracy: 0.0854\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -5.7988 - val_accuracy: 0.0854\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9961 - val_loss: -6.1613 - val_accuracy: 0.0854\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9922 - val_loss: -4.3281 - val_accuracy: 0.1098\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.9160 - val_loss: -4.2399 - val_accuracy: 0.1098\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1973 - accuracy: 0.9219 - val_loss: -3.4650 - val_accuracy: 0.1159\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9590 - val_loss: -5.1952 - val_accuracy: 0.0976\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9707 - val_loss: -5.1004 - val_accuracy: 0.0915\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: -4.8632 - val_accuracy: 0.0915\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: -5.2647 - val_accuracy: 0.0854\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: -5.3880 - val_accuracy: 0.0915\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: -5.3546 - val_accuracy: 0.0915\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 2s 6ms/step - loss: 0.6822 - accuracy: 0.5527 - val_loss: 0.8389 - val_accuracy: 0.1951\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6562 - val_loss: -0.0826 - val_accuracy: 0.0488\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6895 - val_loss: 0.4399 - val_accuracy: 0.1829\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7383 - val_loss: -0.4429 - val_accuracy: 0.1524\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7188 - val_loss: 0.6692 - val_accuracy: 0.1951\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7676 - val_loss: -1.0530 - val_accuracy: 0.1341\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7617 - val_loss: -0.9738 - val_accuracy: 0.1524\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7715 - val_loss: -0.7486 - val_accuracy: 0.1829\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7754 - val_loss: -0.8796 - val_accuracy: 0.1646\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7793 - val_loss: -0.6773 - val_accuracy: 0.2012\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8125 - val_loss: -0.6888 - val_accuracy: 0.1524\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7930 - val_loss: -0.9923 - val_accuracy: 0.1951\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7871 - val_loss: -1.8811 - val_accuracy: 0.1402\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8145 - val_loss: -1.7479 - val_accuracy: 0.1524\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8340 - val_loss: -1.8783 - val_accuracy: 0.1524\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8184 - val_loss: -0.6872 - val_accuracy: 0.2073\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8262 - val_loss: -2.2122 - val_accuracy: 0.1585\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8516 - val_loss: -1.7880 - val_accuracy: 0.1707\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8164 - val_loss: -2.9220 - val_accuracy: 0.1220\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8398 - val_loss: -1.1931 - val_accuracy: 0.1890\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8301 - val_loss: -2.3792 - val_accuracy: 0.1402\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8594 - val_loss: -2.6445 - val_accuracy: 0.0976\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8652 - val_loss: -0.4620 - val_accuracy: 0.1585\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8262 - val_loss: -1.9822 - val_accuracy: 0.1646\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8828 - val_loss: -2.8201 - val_accuracy: 0.1220\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8516 - val_loss: -0.8509 - val_accuracy: 0.1646\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8672 - val_loss: -2.5383 - val_accuracy: 0.1524\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8770 - val_loss: -2.9135 - val_accuracy: 0.1280\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8828 - val_loss: -3.2651 - val_accuracy: 0.1159\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.8984 - val_loss: -4.3039 - val_accuracy: 0.0732\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.9141 - val_loss: -2.9768 - val_accuracy: 0.1402\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.9004 - val_loss: -5.0329 - val_accuracy: 0.0427\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8594 - val_loss: -2.1985 - val_accuracy: 0.1646\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9160 - val_loss: -2.4213 - val_accuracy: 0.1585\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9180 - val_loss: -3.2294 - val_accuracy: 0.1463\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9355 - val_loss: -3.4451 - val_accuracy: 0.1220\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9062 - val_loss: -3.7059 - val_accuracy: 0.0976\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9199 - val_loss: -2.4330 - val_accuracy: 0.1768\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.8965 - val_loss: -4.9519 - val_accuracy: 0.0854\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9414 - val_loss: -4.3228 - val_accuracy: 0.1220\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.9297 - val_loss: -4.8320 - val_accuracy: 0.0976\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9395 - val_loss: -3.1181 - val_accuracy: 0.1463\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9121 - val_loss: -5.1413 - val_accuracy: 0.0854\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9355 - val_loss: -4.0327 - val_accuracy: 0.1707\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9297 - val_loss: -3.9955 - val_accuracy: 0.1220\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9375 - val_loss: -4.2761 - val_accuracy: 0.1220\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9316 - val_loss: -6.2604 - val_accuracy: 0.0976\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1359 - accuracy: 0.9551 - val_loss: -5.4510 - val_accuracy: 0.1220\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9648 - val_loss: -5.1539 - val_accuracy: 0.1402\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9629 - val_loss: -5.9244 - val_accuracy: 0.0915\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9492 - val_loss: -4.8527 - val_accuracy: 0.1037\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9473 - val_loss: -3.4785 - val_accuracy: 0.1707\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9473 - val_loss: -5.7890 - val_accuracy: 0.1037\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9668 - val_loss: -5.1218 - val_accuracy: 0.1341\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9629 - val_loss: -6.7441 - val_accuracy: 0.0732\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9648 - val_loss: -7.6896 - val_accuracy: 0.0732\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9590 - val_loss: -3.9419 - val_accuracy: 0.1585\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9590 - val_loss: -6.5859 - val_accuracy: 0.0915\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9512 - val_loss: -6.3038 - val_accuracy: 0.0976\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9531 - val_loss: -4.7474 - val_accuracy: 0.1402\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9609 - val_loss: -6.7954 - val_accuracy: 0.0915\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9746 - val_loss: -6.7889 - val_accuracy: 0.1037\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9551 - val_loss: -4.0949 - val_accuracy: 0.1646\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1410 - accuracy: 0.9355 - val_loss: -4.9969 - val_accuracy: 0.1098\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9570 - val_loss: -7.1461 - val_accuracy: 0.0915\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9688 - val_loss: -5.6750 - val_accuracy: 0.1098\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9746 - val_loss: -6.6272 - val_accuracy: 0.1098\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9707 - val_loss: -7.8156 - val_accuracy: 0.0915\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9785 - val_loss: -6.7689 - val_accuracy: 0.1159\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9766 - val_loss: -7.5665 - val_accuracy: 0.1220\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9863 - val_loss: -5.1907 - val_accuracy: 0.1159\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9902 - val_loss: -7.7402 - val_accuracy: 0.0976\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9863 - val_loss: -5.9019 - val_accuracy: 0.1098\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9668 - val_loss: -1.9088 - val_accuracy: 0.1646\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9297 - val_loss: -5.6098 - val_accuracy: 0.1463\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9629 - val_loss: -6.6762 - val_accuracy: 0.1220\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9453 - val_loss: -7.8096 - val_accuracy: 0.0976\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: -5.7311 - val_accuracy: 0.1402\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9785 - val_loss: -6.4113 - val_accuracy: 0.1159\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9785 - val_loss: -8.3284 - val_accuracy: 0.0793\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9902 - val_loss: -6.9779 - val_accuracy: 0.1159\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9941 - val_loss: -8.1308 - val_accuracy: 0.0915\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: -8.3366 - val_accuracy: 0.1098\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: -8.5370 - val_accuracy: 0.1037\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9980 - val_loss: -9.0458 - val_accuracy: 0.0732\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: -7.6702 - val_accuracy: 0.1220\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: -7.3799 - val_accuracy: 0.1220\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: -10.0463 - val_accuracy: 0.0854\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: -9.5898 - val_accuracy: 0.0976\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9648 - val_loss: -7.1617 - val_accuracy: 0.0854\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8613 - val_loss: -3.5621 - val_accuracy: 0.1280\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9375 - val_loss: -6.5194 - val_accuracy: 0.0976\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: -8.3440 - val_accuracy: 0.0854\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9824 - val_loss: -7.3456 - val_accuracy: 0.1037\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: -7.8007 - val_accuracy: 0.0915\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: -7.2108 - val_accuracy: 0.1159\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: -8.0037 - val_accuracy: 0.0976\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: -8.3077 - val_accuracy: 0.0854\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: -8.3985 - val_accuracy: 0.1098\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: -8.9934 - val_accuracy: 0.0854\n",
      "32/32 [==============================] - 0s 923us/step\n",
      "Epoch 1/200\n",
      "64/64 [==============================] - 1s 6ms/step - loss: 0.6779 - accuracy: 0.5508 - val_loss: 0.6711 - val_accuracy: 0.1524\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6387 - val_loss: 0.5970 - val_accuracy: 0.1585\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.6934 - val_loss: 0.2246 - val_accuracy: 0.1768\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7383 - val_loss: -0.5072 - val_accuracy: 0.1341\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7656 - val_loss: -0.0468 - val_accuracy: 0.1768\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7910 - val_loss: -0.5050 - val_accuracy: 0.1768\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7988 - val_loss: -0.6365 - val_accuracy: 0.1829\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8125 - val_loss: -0.4258 - val_accuracy: 0.1646\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8086 - val_loss: -1.4608 - val_accuracy: 0.1402\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8184 - val_loss: -0.5743 - val_accuracy: 0.1951\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8047 - val_loss: -0.6765 - val_accuracy: 0.1829\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8066 - val_loss: -1.4449 - val_accuracy: 0.1768\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8301 - val_loss: -2.0131 - val_accuracy: 0.1220\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8379 - val_loss: -1.8106 - val_accuracy: 0.1524\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8223 - val_loss: -2.4039 - val_accuracy: 0.1037\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8203 - val_loss: -2.6963 - val_accuracy: 0.1159\n",
      "Epoch 17/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8379 - val_loss: -3.8067 - val_accuracy: 0.0366\n",
      "Epoch 18/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8418 - val_loss: -1.3308 - val_accuracy: 0.1280\n",
      "Epoch 19/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8164 - val_loss: -2.7555 - val_accuracy: 0.1098\n",
      "Epoch 20/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8477 - val_loss: -2.2105 - val_accuracy: 0.1341\n",
      "Epoch 21/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8574 - val_loss: -2.5101 - val_accuracy: 0.1220\n",
      "Epoch 22/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8574 - val_loss: -2.8042 - val_accuracy: 0.1159\n",
      "Epoch 23/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8535 - val_loss: -3.4263 - val_accuracy: 0.0854\n",
      "Epoch 24/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8730 - val_loss: -2.9256 - val_accuracy: 0.1159\n",
      "Epoch 25/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.8555 - val_loss: -2.4638 - val_accuracy: 0.1402\n",
      "Epoch 26/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8691 - val_loss: -3.3873 - val_accuracy: 0.1037\n",
      "Epoch 27/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8633 - val_loss: -2.4309 - val_accuracy: 0.1402\n",
      "Epoch 28/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8750 - val_loss: -2.9803 - val_accuracy: 0.1463\n",
      "Epoch 29/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.8965 - val_loss: -3.0298 - val_accuracy: 0.1402\n",
      "Epoch 30/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.9043 - val_loss: -4.7890 - val_accuracy: 0.0732\n",
      "Epoch 31/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.8945 - val_loss: -5.3809 - val_accuracy: 0.0549\n",
      "Epoch 32/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9199 - val_loss: -2.9077 - val_accuracy: 0.1280\n",
      "Epoch 33/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.8945 - val_loss: -4.5089 - val_accuracy: 0.0854\n",
      "Epoch 34/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9082 - val_loss: -2.7681 - val_accuracy: 0.1341\n",
      "Epoch 35/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9180 - val_loss: -4.0220 - val_accuracy: 0.1402\n",
      "Epoch 36/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.8945 - val_loss: -4.0647 - val_accuracy: 0.0976\n",
      "Epoch 37/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.8887 - val_loss: -5.2938 - val_accuracy: 0.1037\n",
      "Epoch 38/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9160 - val_loss: -4.3394 - val_accuracy: 0.1341\n",
      "Epoch 39/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9297 - val_loss: -4.1978 - val_accuracy: 0.1220\n",
      "Epoch 40/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9082 - val_loss: -4.4774 - val_accuracy: 0.1159\n",
      "Epoch 41/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9258 - val_loss: -4.9525 - val_accuracy: 0.1159\n",
      "Epoch 42/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.8984 - val_loss: -2.7670 - val_accuracy: 0.2012\n",
      "Epoch 43/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9258 - val_loss: -4.5655 - val_accuracy: 0.1220\n",
      "Epoch 44/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9199 - val_loss: -4.8363 - val_accuracy: 0.1220\n",
      "Epoch 45/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1627 - accuracy: 0.9375 - val_loss: -4.5527 - val_accuracy: 0.1341\n",
      "Epoch 46/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1631 - accuracy: 0.9375 - val_loss: -5.7630 - val_accuracy: 0.1159\n",
      "Epoch 47/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9395 - val_loss: -6.9814 - val_accuracy: 0.0976\n",
      "Epoch 48/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.9277 - val_loss: -6.7640 - val_accuracy: 0.1037\n",
      "Epoch 49/200\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1496 - accuracy: 0.9453 - val_loss: -5.4446 - val_accuracy: 0.1220\n",
      "Epoch 50/200\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1739 - accuracy: 0.9355 - val_loss: -6.9816 - val_accuracy: 0.0854\n",
      "Epoch 51/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.9453 - val_loss: -6.5412 - val_accuracy: 0.0976\n",
      "Epoch 52/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1607 - accuracy: 0.9277 - val_loss: -7.2617 - val_accuracy: 0.0793\n",
      "Epoch 53/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9492 - val_loss: -7.1533 - val_accuracy: 0.1098\n",
      "Epoch 54/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9414 - val_loss: -5.0574 - val_accuracy: 0.1524\n",
      "Epoch 55/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9492 - val_loss: -7.9408 - val_accuracy: 0.0915\n",
      "Epoch 56/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9531 - val_loss: -6.7671 - val_accuracy: 0.1037\n",
      "Epoch 57/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9688 - val_loss: -8.3811 - val_accuracy: 0.0793\n",
      "Epoch 58/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9570 - val_loss: -5.7183 - val_accuracy: 0.1524\n",
      "Epoch 59/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9570 - val_loss: -8.7525 - val_accuracy: 0.0854\n",
      "Epoch 60/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9590 - val_loss: -8.1847 - val_accuracy: 0.0976\n",
      "Epoch 61/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9629 - val_loss: -7.6139 - val_accuracy: 0.1098\n",
      "Epoch 62/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9668 - val_loss: -7.0414 - val_accuracy: 0.1463\n",
      "Epoch 63/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9707 - val_loss: -8.6448 - val_accuracy: 0.1159\n",
      "Epoch 64/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 0.9766 - val_loss: -7.8750 - val_accuracy: 0.1280\n",
      "Epoch 65/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9707 - val_loss: -8.2806 - val_accuracy: 0.1220\n",
      "Epoch 66/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9648 - val_loss: -8.6586 - val_accuracy: 0.1098\n",
      "Epoch 67/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 0.9434 - val_loss: -7.7139 - val_accuracy: 0.1159\n",
      "Epoch 68/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9395 - val_loss: -6.0709 - val_accuracy: 0.1280\n",
      "Epoch 69/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9688 - val_loss: -7.0315 - val_accuracy: 0.1220\n",
      "Epoch 70/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9824 - val_loss: -8.4980 - val_accuracy: 0.1037\n",
      "Epoch 71/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9746 - val_loss: -9.9220 - val_accuracy: 0.0854\n",
      "Epoch 72/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9531 - val_loss: -7.9922 - val_accuracy: 0.1220\n",
      "Epoch 73/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9785 - val_loss: -7.8443 - val_accuracy: 0.1037\n",
      "Epoch 74/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9746 - val_loss: -8.1332 - val_accuracy: 0.1341\n",
      "Epoch 75/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9766 - val_loss: -7.3216 - val_accuracy: 0.1280\n",
      "Epoch 76/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9883 - val_loss: -9.9663 - val_accuracy: 0.1098\n",
      "Epoch 77/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1375 - accuracy: 0.9590 - val_loss: -5.8132 - val_accuracy: 0.1524\n",
      "Epoch 78/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.9238 - val_loss: -6.9082 - val_accuracy: 0.1220\n",
      "Epoch 79/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9648 - val_loss: -7.7844 - val_accuracy: 0.1159\n",
      "Epoch 80/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: -9.0355 - val_accuracy: 0.0915\n",
      "Epoch 81/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9805 - val_loss: -8.2356 - val_accuracy: 0.1098\n",
      "Epoch 82/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: -9.0134 - val_accuracy: 0.1098\n",
      "Epoch 83/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: -10.7616 - val_accuracy: 0.1037\n",
      "Epoch 84/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9805 - val_loss: -8.2709 - val_accuracy: 0.1402\n",
      "Epoch 85/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9785 - val_loss: -11.9166 - val_accuracy: 0.0610\n",
      "Epoch 86/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9941 - val_loss: -10.2582 - val_accuracy: 0.1037\n",
      "Epoch 87/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: -10.0036 - val_accuracy: 0.1159\n",
      "Epoch 88/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: -10.6613 - val_accuracy: 0.1098\n",
      "Epoch 89/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9941 - val_loss: -9.5147 - val_accuracy: 0.1280\n",
      "Epoch 90/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9863 - val_loss: -10.2985 - val_accuracy: 0.1341\n",
      "Epoch 91/200\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1394 - accuracy: 0.9473 - val_loss: -7.4496 - val_accuracy: 0.1159\n",
      "Epoch 92/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9512 - val_loss: -6.6574 - val_accuracy: 0.1159\n",
      "Epoch 93/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9473 - val_loss: -7.4286 - val_accuracy: 0.1220\n",
      "Epoch 94/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9766 - val_loss: -8.6437 - val_accuracy: 0.1220\n",
      "Epoch 95/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9922 - val_loss: -8.6334 - val_accuracy: 0.1159\n",
      "Epoch 96/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: -10.2920 - val_accuracy: 0.0915\n",
      "Epoch 97/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: -10.8127 - val_accuracy: 0.1037\n",
      "Epoch 98/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -9.7019 - val_accuracy: 0.0976\n",
      "Epoch 99/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: -10.9958 - val_accuracy: 0.1037\n",
      "Epoch 100/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -11.5097 - val_accuracy: 0.0976\n",
      "Epoch 101/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -11.2404 - val_accuracy: 0.0976\n",
      "Epoch 102/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -11.1327 - val_accuracy: 0.0976\n",
      "Epoch 103/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -11.8921 - val_accuracy: 0.0976\n",
      "Epoch 104/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -11.6040 - val_accuracy: 0.0976\n",
      "Epoch 105/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -11.8712 - val_accuracy: 0.0976\n",
      "Epoch 106/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -12.5530 - val_accuracy: 0.1037\n",
      "Epoch 107/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -12.3909 - val_accuracy: 0.0976\n",
      "Epoch 108/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -12.4104 - val_accuracy: 0.0976\n",
      "Epoch 109/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -12.5477 - val_accuracy: 0.0976\n",
      "Epoch 110/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -12.7758 - val_accuracy: 0.0976\n",
      "Epoch 111/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -12.8809 - val_accuracy: 0.0976\n",
      "Epoch 112/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -12.7538 - val_accuracy: 0.0976\n",
      "Epoch 113/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.8189e-04 - accuracy: 1.0000 - val_loss: -13.0623 - val_accuracy: 0.0976\n",
      "Epoch 114/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.4714e-04 - accuracy: 1.0000 - val_loss: -12.6308 - val_accuracy: 0.0976\n",
      "Epoch 115/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.1006e-04 - accuracy: 1.0000 - val_loss: -13.1350 - val_accuracy: 0.0976\n",
      "Epoch 116/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.1896e-04 - accuracy: 1.0000 - val_loss: -13.1907 - val_accuracy: 0.0976\n",
      "Epoch 117/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.6367e-04 - accuracy: 1.0000 - val_loss: -12.9788 - val_accuracy: 0.0976\n",
      "Epoch 118/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 7.3008e-04 - accuracy: 1.0000 - val_loss: -13.2855 - val_accuracy: 0.0976\n",
      "Epoch 119/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.1147e-04 - accuracy: 1.0000 - val_loss: -13.3618 - val_accuracy: 0.0976\n",
      "Epoch 120/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.5362e-04 - accuracy: 1.0000 - val_loss: -13.5629 - val_accuracy: 0.0976\n",
      "Epoch 121/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.3871e-04 - accuracy: 1.0000 - val_loss: -13.6528 - val_accuracy: 0.0976\n",
      "Epoch 122/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.6479e-04 - accuracy: 1.0000 - val_loss: -13.3386 - val_accuracy: 0.0976\n",
      "Epoch 123/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 5.7142e-04 - accuracy: 1.0000 - val_loss: -13.5025 - val_accuracy: 0.0976\n",
      "Epoch 124/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.1781e-04 - accuracy: 1.0000 - val_loss: -13.4182 - val_accuracy: 0.0976\n",
      "Epoch 125/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.0328e-04 - accuracy: 1.0000 - val_loss: -13.7543 - val_accuracy: 0.0976\n",
      "Epoch 126/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.6052e-04 - accuracy: 1.0000 - val_loss: -13.7007 - val_accuracy: 0.0976\n",
      "Epoch 127/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 4.5614e-04 - accuracy: 1.0000 - val_loss: -13.7331 - val_accuracy: 0.0976\n",
      "Epoch 128/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.2105e-04 - accuracy: 1.0000 - val_loss: -13.7276 - val_accuracy: 0.0976\n",
      "Epoch 129/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.1127e-04 - accuracy: 1.0000 - val_loss: -14.0979 - val_accuracy: 0.0976\n",
      "Epoch 130/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.0268e-04 - accuracy: 1.0000 - val_loss: -13.7425 - val_accuracy: 0.0976\n",
      "Epoch 131/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.8639e-04 - accuracy: 1.0000 - val_loss: -13.9020 - val_accuracy: 0.0976\n",
      "Epoch 132/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.5118e-04 - accuracy: 1.0000 - val_loss: -14.0312 - val_accuracy: 0.0976\n",
      "Epoch 133/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.3928e-04 - accuracy: 1.0000 - val_loss: -14.1678 - val_accuracy: 0.0976\n",
      "Epoch 134/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.2808e-04 - accuracy: 1.0000 - val_loss: -14.1818 - val_accuracy: 0.0976\n",
      "Epoch 135/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.0629e-04 - accuracy: 1.0000 - val_loss: -14.1568 - val_accuracy: 0.0976\n",
      "Epoch 136/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.0177e-04 - accuracy: 1.0000 - val_loss: -14.1379 - val_accuracy: 0.0976\n",
      "Epoch 137/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9153e-04 - accuracy: 1.0000 - val_loss: -14.2879 - val_accuracy: 0.0976\n",
      "Epoch 138/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.7106e-04 - accuracy: 1.0000 - val_loss: -14.5343 - val_accuracy: 0.0976\n",
      "Epoch 139/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.6897e-04 - accuracy: 1.0000 - val_loss: -14.3552 - val_accuracy: 0.0976\n",
      "Epoch 140/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.5770e-04 - accuracy: 1.0000 - val_loss: -14.4360 - val_accuracy: 0.0976\n",
      "Epoch 141/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.3492e-04 - accuracy: 1.0000 - val_loss: -14.5403 - val_accuracy: 0.0976\n",
      "Epoch 142/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1964e-04 - accuracy: 1.0000 - val_loss: -14.5486 - val_accuracy: 0.0976\n",
      "Epoch 143/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1730e-04 - accuracy: 1.0000 - val_loss: -14.7311 - val_accuracy: 0.0976\n",
      "Epoch 144/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.2058e-04 - accuracy: 1.0000 - val_loss: -14.7508 - val_accuracy: 0.0976\n",
      "Epoch 145/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9753e-04 - accuracy: 1.0000 - val_loss: -14.8044 - val_accuracy: 0.0976\n",
      "Epoch 146/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8962e-04 - accuracy: 1.0000 - val_loss: -14.9907 - val_accuracy: 0.0976\n",
      "Epoch 147/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8014e-04 - accuracy: 1.0000 - val_loss: -14.7663 - val_accuracy: 0.0976\n",
      "Epoch 148/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8303e-04 - accuracy: 1.0000 - val_loss: -14.9046 - val_accuracy: 0.0976\n",
      "Epoch 149/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6647e-04 - accuracy: 1.0000 - val_loss: -15.0689 - val_accuracy: 0.0976\n",
      "Epoch 150/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6274e-04 - accuracy: 1.0000 - val_loss: -15.0364 - val_accuracy: 0.0976\n",
      "Epoch 151/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.5490e-04 - accuracy: 1.0000 - val_loss: -15.1870 - val_accuracy: 0.0976\n",
      "Epoch 152/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4917e-04 - accuracy: 1.0000 - val_loss: -15.2946 - val_accuracy: 0.0976\n",
      "Epoch 153/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4933e-04 - accuracy: 1.0000 - val_loss: -15.3255 - val_accuracy: 0.0976\n",
      "Epoch 154/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.5445e-04 - accuracy: 1.0000 - val_loss: -15.5475 - val_accuracy: 0.0976\n",
      "Epoch 155/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4342e-04 - accuracy: 1.0000 - val_loss: -15.3550 - val_accuracy: 0.0976\n",
      "Epoch 156/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3575e-04 - accuracy: 1.0000 - val_loss: -15.3336 - val_accuracy: 0.1037\n",
      "Epoch 157/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2044e-04 - accuracy: 1.0000 - val_loss: -15.3290 - val_accuracy: 0.1037\n",
      "Epoch 158/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.2454e-04 - accuracy: 1.0000 - val_loss: -15.5355 - val_accuracy: 0.0976\n",
      "Epoch 159/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1767e-04 - accuracy: 1.0000 - val_loss: -15.4745 - val_accuracy: 0.1037\n",
      "Epoch 160/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.0950e-04 - accuracy: 1.0000 - val_loss: -15.6170 - val_accuracy: 0.1037\n",
      "Epoch 161/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0387e-04 - accuracy: 1.0000 - val_loss: -15.6707 - val_accuracy: 0.0976\n",
      "Epoch 162/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.0300e-04 - accuracy: 1.0000 - val_loss: -15.8462 - val_accuracy: 0.0976\n",
      "Epoch 163/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.3882e-05 - accuracy: 1.0000 - val_loss: -15.6405 - val_accuracy: 0.0976\n",
      "Epoch 164/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.0411e-05 - accuracy: 1.0000 - val_loss: -15.8714 - val_accuracy: 0.1037\n",
      "Epoch 165/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.8036e-05 - accuracy: 1.0000 - val_loss: -15.6085 - val_accuracy: 0.1037\n",
      "Epoch 166/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.0470e-05 - accuracy: 1.0000 - val_loss: -15.7917 - val_accuracy: 0.0976\n",
      "Epoch 167/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 8.2897e-05 - accuracy: 1.0000 - val_loss: -15.7486 - val_accuracy: 0.1037\n",
      "Epoch 168/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.0840e-05 - accuracy: 1.0000 - val_loss: -16.0558 - val_accuracy: 0.1037\n",
      "Epoch 169/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.5270e-05 - accuracy: 1.0000 - val_loss: -16.1938 - val_accuracy: 0.1037\n",
      "Epoch 170/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.7729e-05 - accuracy: 1.0000 - val_loss: -16.0868 - val_accuracy: 0.1037\n",
      "Epoch 171/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.8768e-05 - accuracy: 1.0000 - val_loss: -16.1805 - val_accuracy: 0.1037\n",
      "Epoch 172/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.6706e-05 - accuracy: 1.0000 - val_loss: -16.1606 - val_accuracy: 0.1037\n",
      "Epoch 173/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.4354e-05 - accuracy: 1.0000 - val_loss: -16.1629 - val_accuracy: 0.1037\n",
      "Epoch 174/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.0642e-05 - accuracy: 1.0000 - val_loss: -16.2594 - val_accuracy: 0.1037\n",
      "Epoch 175/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.8558e-05 - accuracy: 1.0000 - val_loss: -16.4093 - val_accuracy: 0.1037\n",
      "Epoch 176/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.7913e-05 - accuracy: 1.0000 - val_loss: -16.4401 - val_accuracy: 0.1037\n",
      "Epoch 177/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.7120e-05 - accuracy: 1.0000 - val_loss: -16.4735 - val_accuracy: 0.0976\n",
      "Epoch 178/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.7045e-05 - accuracy: 1.0000 - val_loss: -16.4369 - val_accuracy: 0.1037\n",
      "Epoch 179/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.2169e-05 - accuracy: 1.0000 - val_loss: -16.4917 - val_accuracy: 0.1037\n",
      "Epoch 180/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.8287e-05 - accuracy: 1.0000 - val_loss: -16.6638 - val_accuracy: 0.1037\n",
      "Epoch 181/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.6533e-05 - accuracy: 1.0000 - val_loss: -16.5254 - val_accuracy: 0.1037\n",
      "Epoch 182/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.7156e-05 - accuracy: 1.0000 - val_loss: -16.5185 - val_accuracy: 0.1037\n",
      "Epoch 183/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.3974e-05 - accuracy: 1.0000 - val_loss: -16.5538 - val_accuracy: 0.1037\n",
      "Epoch 184/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.3527e-05 - accuracy: 1.0000 - val_loss: -16.5004 - val_accuracy: 0.1037\n",
      "Epoch 185/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.0341e-05 - accuracy: 1.0000 - val_loss: -16.8883 - val_accuracy: 0.1037\n",
      "Epoch 186/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.7897e-05 - accuracy: 1.0000 - val_loss: -16.7180 - val_accuracy: 0.1037\n",
      "Epoch 187/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.6637e-05 - accuracy: 1.0000 - val_loss: -16.8468 - val_accuracy: 0.1037\n",
      "Epoch 188/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5293e-05 - accuracy: 1.0000 - val_loss: -16.9593 - val_accuracy: 0.1037\n",
      "Epoch 189/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.4467e-05 - accuracy: 1.0000 - val_loss: -17.0326 - val_accuracy: 0.1037\n",
      "Epoch 190/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.3703e-05 - accuracy: 1.0000 - val_loss: -16.8991 - val_accuracy: 0.1037\n",
      "Epoch 191/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.3381e-05 - accuracy: 1.0000 - val_loss: -17.1144 - val_accuracy: 0.1037\n",
      "Epoch 192/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.0968e-05 - accuracy: 1.0000 - val_loss: -17.1012 - val_accuracy: 0.1037\n",
      "Epoch 193/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9430e-05 - accuracy: 1.0000 - val_loss: -17.1428 - val_accuracy: 0.1037\n",
      "Epoch 194/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.8451e-05 - accuracy: 1.0000 - val_loss: -16.8608 - val_accuracy: 0.1037\n",
      "Epoch 195/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.9529e-05 - accuracy: 1.0000 - val_loss: -17.1386 - val_accuracy: 0.1037\n",
      "Epoch 196/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.7133e-05 - accuracy: 1.0000 - val_loss: -17.2838 - val_accuracy: 0.1037\n",
      "Epoch 197/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6298e-05 - accuracy: 1.0000 - val_loss: -17.2829 - val_accuracy: 0.1037\n",
      "Epoch 198/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.5232e-05 - accuracy: 1.0000 - val_loss: -17.2885 - val_accuracy: 0.1037\n",
      "Epoch 199/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.3568e-05 - accuracy: 1.0000 - val_loss: -17.5483 - val_accuracy: 0.1037\n",
      "Epoch 200/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2312e-05 - accuracy: 1.0000 - val_loss: -17.3855 - val_accuracy: 0.1037\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "64/64 [==============================] - 1s 5ms/step - loss: 0.6845 - accuracy: 0.5664 - val_loss: 0.9390 - val_accuracy: 0.2073\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6562 - val_loss: 0.6878 - val_accuracy: 0.1707\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6582 - val_loss: -0.1217 - val_accuracy: 0.0976\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7090 - val_loss: -0.4187 - val_accuracy: 0.1341\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7305 - val_loss: -0.7670 - val_accuracy: 0.0793\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7480 - val_loss: -0.2855 - val_accuracy: 0.1829\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7285 - val_loss: -0.1836 - val_accuracy: 0.1890\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7578 - val_loss: -0.8225 - val_accuracy: 0.1463\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7656 - val_loss: 0.0493 - val_accuracy: 0.1829\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7930 - val_loss: -0.6491 - val_accuracy: 0.1829\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7852 - val_loss: -1.1280 - val_accuracy: 0.1402\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7832 - val_loss: -0.3648 - val_accuracy: 0.1829\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7910 - val_loss: -1.4784 - val_accuracy: 0.1402\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8066 - val_loss: -0.5172 - val_accuracy: 0.1829\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8047 - val_loss: -1.1129 - val_accuracy: 0.1768\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7773 - val_loss: -1.6676 - val_accuracy: 0.1402\n",
      "Epoch 17/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7754 - val_loss: -1.0029 - val_accuracy: 0.1463\n",
      "Epoch 18/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8066 - val_loss: -2.0829 - val_accuracy: 0.1341\n",
      "Epoch 19/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8262 - val_loss: -2.5054 - val_accuracy: 0.1098\n",
      "Epoch 20/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8398 - val_loss: -1.8205 - val_accuracy: 0.1402\n",
      "Epoch 21/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8438 - val_loss: -1.6841 - val_accuracy: 0.1280\n",
      "Epoch 22/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8594 - val_loss: -1.8541 - val_accuracy: 0.1463\n",
      "Epoch 23/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8516 - val_loss: -1.6769 - val_accuracy: 0.1524\n",
      "Epoch 24/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8574 - val_loss: -2.4140 - val_accuracy: 0.1280\n",
      "Epoch 25/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8789 - val_loss: -2.9485 - val_accuracy: 0.0976\n",
      "Epoch 26/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8789 - val_loss: -1.4834 - val_accuracy: 0.1768\n",
      "Epoch 27/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8809 - val_loss: -3.0789 - val_accuracy: 0.1159\n",
      "Epoch 28/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9121 - val_loss: -3.2994 - val_accuracy: 0.1220\n",
      "Epoch 29/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9023 - val_loss: -3.0891 - val_accuracy: 0.1402\n",
      "Epoch 30/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.9043 - val_loss: -3.8245 - val_accuracy: 0.1098\n",
      "Epoch 31/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9180 - val_loss: -2.4373 - val_accuracy: 0.1280\n",
      "Epoch 32/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9062 - val_loss: -2.8656 - val_accuracy: 0.1585\n",
      "Epoch 33/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9004 - val_loss: -3.6288 - val_accuracy: 0.1220\n",
      "Epoch 34/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.8633 - val_loss: -2.8415 - val_accuracy: 0.1220\n",
      "Epoch 35/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8750 - val_loss: -2.6750 - val_accuracy: 0.1220\n",
      "Epoch 36/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2080 - accuracy: 0.9219 - val_loss: -3.6866 - val_accuracy: 0.1098\n",
      "Epoch 37/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9258 - val_loss: -3.5634 - val_accuracy: 0.1037\n",
      "Epoch 38/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9434 - val_loss: -3.6783 - val_accuracy: 0.1280\n",
      "Epoch 39/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.8926 - val_loss: -2.7331 - val_accuracy: 0.1402\n",
      "Epoch 40/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.8965 - val_loss: -1.3273 - val_accuracy: 0.1585\n",
      "Epoch 41/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9316 - val_loss: -3.6506 - val_accuracy: 0.1280\n",
      "Epoch 42/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9434 - val_loss: -4.6629 - val_accuracy: 0.0915\n",
      "Epoch 43/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9570 - val_loss: -4.8729 - val_accuracy: 0.1098\n",
      "Epoch 44/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1306 - accuracy: 0.9590 - val_loss: -3.8616 - val_accuracy: 0.1037\n",
      "Epoch 45/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9414 - val_loss: -3.9524 - val_accuracy: 0.1341\n",
      "Epoch 46/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9453 - val_loss: -3.9635 - val_accuracy: 0.1159\n",
      "Epoch 47/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9395 - val_loss: -4.9695 - val_accuracy: 0.1098\n",
      "Epoch 48/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9395 - val_loss: -4.2264 - val_accuracy: 0.1037\n",
      "Epoch 49/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9551 - val_loss: -3.0509 - val_accuracy: 0.1280\n",
      "Epoch 50/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9590 - val_loss: -4.0281 - val_accuracy: 0.1098\n",
      "Epoch 51/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9688 - val_loss: -4.7178 - val_accuracy: 0.1098\n",
      "Epoch 52/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9355 - val_loss: -6.0211 - val_accuracy: 0.0793\n",
      "Epoch 53/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9531 - val_loss: -3.9120 - val_accuracy: 0.1037\n",
      "Epoch 54/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9707 - val_loss: -4.4526 - val_accuracy: 0.1098\n",
      "Epoch 55/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9688 - val_loss: -5.8097 - val_accuracy: 0.0854\n",
      "Epoch 56/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9785 - val_loss: -4.0710 - val_accuracy: 0.1159\n",
      "Epoch 57/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: -4.8553 - val_accuracy: 0.1220\n",
      "Epoch 58/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9688 - val_loss: -5.0682 - val_accuracy: 0.0915\n",
      "Epoch 59/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9590 - val_loss: -3.1838 - val_accuracy: 0.1463\n",
      "Epoch 60/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9668 - val_loss: -5.7531 - val_accuracy: 0.0976\n",
      "Epoch 61/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9844 - val_loss: -5.3149 - val_accuracy: 0.1220\n",
      "Epoch 62/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9844 - val_loss: -4.5692 - val_accuracy: 0.1159\n",
      "Epoch 63/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9688 - val_loss: -5.0043 - val_accuracy: 0.1037\n",
      "Epoch 64/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9336 - val_loss: -4.7047 - val_accuracy: 0.1220\n",
      "Epoch 65/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9766 - val_loss: -4.1741 - val_accuracy: 0.1098\n",
      "Epoch 66/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9844 - val_loss: -3.8253 - val_accuracy: 0.1159\n",
      "Epoch 67/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9766 - val_loss: -5.4266 - val_accuracy: 0.1159\n",
      "Epoch 68/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9824 - val_loss: -6.7342 - val_accuracy: 0.1037\n",
      "Epoch 69/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9863 - val_loss: -5.5379 - val_accuracy: 0.1037\n",
      "Epoch 70/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9844 - val_loss: -7.6753 - val_accuracy: 0.0793\n",
      "Epoch 71/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: -6.1291 - val_accuracy: 0.1220\n",
      "Epoch 72/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: -6.8057 - val_accuracy: 0.0976\n",
      "Epoch 73/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: -6.8323 - val_accuracy: 0.1098\n",
      "Epoch 74/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: -6.2128 - val_accuracy: 0.1098\n",
      "Epoch 75/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: -7.3209 - val_accuracy: 0.1037\n",
      "Epoch 76/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: -6.5121 - val_accuracy: 0.1280\n",
      "Epoch 77/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9883 - val_loss: -2.1741 - val_accuracy: 0.1463\n",
      "Epoch 78/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8789 - val_loss: -5.8958 - val_accuracy: 0.0915\n",
      "Epoch 79/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.8906 - val_loss: -4.5101 - val_accuracy: 0.1037\n",
      "Epoch 80/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: -3.9389 - val_accuracy: 0.1220\n",
      "Epoch 81/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9863 - val_loss: -6.2969 - val_accuracy: 0.0854\n",
      "Epoch 82/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9902 - val_loss: -5.1000 - val_accuracy: 0.1037\n",
      "Epoch 83/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9863 - val_loss: -5.5863 - val_accuracy: 0.0976\n",
      "Epoch 84/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9961 - val_loss: -6.1214 - val_accuracy: 0.1037\n",
      "Epoch 85/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: -7.0156 - val_accuracy: 0.0793\n",
      "Epoch 86/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9844 - val_loss: -5.5116 - val_accuracy: 0.1159\n",
      "Epoch 87/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: -6.2930 - val_accuracy: 0.1037\n",
      "Epoch 88/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9805 - val_loss: -7.7050 - val_accuracy: 0.1098\n",
      "Epoch 89/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9785 - val_loss: -8.2862 - val_accuracy: 0.0915\n",
      "Epoch 90/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9785 - val_loss: -1.6397 - val_accuracy: 0.1220\n",
      "Epoch 91/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9551 - val_loss: -6.4340 - val_accuracy: 0.1037\n",
      "Epoch 92/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: -7.5746 - val_accuracy: 0.0854\n",
      "Epoch 93/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: -7.7664 - val_accuracy: 0.0854\n",
      "Epoch 94/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9941 - val_loss: -6.9468 - val_accuracy: 0.0976\n",
      "Epoch 95/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: -7.3469 - val_accuracy: 0.0915\n",
      "Epoch 96/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -7.0766 - val_accuracy: 0.0976\n",
      "Epoch 97/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.3323 - val_accuracy: 0.0915\n",
      "Epoch 98/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.7904 - val_accuracy: 0.0854\n",
      "Epoch 99/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.5490 - val_accuracy: 0.0976\n",
      "Epoch 100/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.5816 - val_accuracy: 0.0976\n",
      "Epoch 101/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.7360 - val_accuracy: 0.0976\n",
      "Epoch 102/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.6258 - val_accuracy: 0.0976\n",
      "Epoch 103/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7486 - val_accuracy: 0.0976\n",
      "Epoch 104/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7398 - val_accuracy: 0.0976\n",
      "Epoch 105/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.7755 - val_accuracy: 0.0976\n",
      "Epoch 106/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.9399e-04 - accuracy: 1.0000 - val_loss: -7.9053 - val_accuracy: 0.0976\n",
      "Epoch 107/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.2694e-04 - accuracy: 1.0000 - val_loss: -7.8834 - val_accuracy: 0.0976\n",
      "Epoch 108/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.6326e-04 - accuracy: 1.0000 - val_loss: -8.0095 - val_accuracy: 0.0976\n",
      "Epoch 109/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.2833e-04 - accuracy: 1.0000 - val_loss: -7.9128 - val_accuracy: 0.0915\n",
      "Epoch 110/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.4930e-04 - accuracy: 1.0000 - val_loss: -8.0937 - val_accuracy: 0.0915\n",
      "Epoch 111/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.2425e-04 - accuracy: 1.0000 - val_loss: -8.0646 - val_accuracy: 0.0915\n",
      "Epoch 112/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.8428e-04 - accuracy: 1.0000 - val_loss: -8.0924 - val_accuracy: 0.0976\n",
      "Epoch 113/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.6888e-04 - accuracy: 1.0000 - val_loss: -8.0959 - val_accuracy: 0.0915\n",
      "Epoch 114/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.3113e-04 - accuracy: 1.0000 - val_loss: -8.1571 - val_accuracy: 0.0915\n",
      "Epoch 115/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.0661e-04 - accuracy: 1.0000 - val_loss: -8.3174 - val_accuracy: 0.0915\n",
      "Epoch 116/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.5231e-04 - accuracy: 1.0000 - val_loss: -8.1614 - val_accuracy: 0.0915\n",
      "Epoch 117/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.3240e-04 - accuracy: 1.0000 - val_loss: -8.2831 - val_accuracy: 0.0976\n",
      "Epoch 118/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.2612e-04 - accuracy: 1.0000 - val_loss: -8.3733 - val_accuracy: 0.0915\n",
      "Epoch 119/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.8045e-04 - accuracy: 1.0000 - val_loss: -8.3671 - val_accuracy: 0.0915\n",
      "Epoch 120/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.7143e-04 - accuracy: 1.0000 - val_loss: -8.4060 - val_accuracy: 0.0915\n",
      "Epoch 121/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.4376e-04 - accuracy: 1.0000 - val_loss: -8.4832 - val_accuracy: 0.0915\n",
      "Epoch 122/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.2555e-04 - accuracy: 1.0000 - val_loss: -8.5563 - val_accuracy: 0.0915\n",
      "Epoch 123/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.0659e-04 - accuracy: 1.0000 - val_loss: -8.4908 - val_accuracy: 0.0915\n",
      "Epoch 124/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.9595e-04 - accuracy: 1.0000 - val_loss: -8.5844 - val_accuracy: 0.0915\n",
      "Epoch 125/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.6798e-04 - accuracy: 1.0000 - val_loss: -8.5065 - val_accuracy: 0.0915\n",
      "Epoch 126/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.6204e-04 - accuracy: 1.0000 - val_loss: -8.6961 - val_accuracy: 0.0915\n",
      "Epoch 127/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2755e-04 - accuracy: 1.0000 - val_loss: -8.5825 - val_accuracy: 0.0915\n",
      "Epoch 128/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.3029e-04 - accuracy: 1.0000 - val_loss: -8.7423 - val_accuracy: 0.0915\n",
      "Epoch 129/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.1355e-04 - accuracy: 1.0000 - val_loss: -8.7659 - val_accuracy: 0.0915\n",
      "Epoch 130/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.0853e-04 - accuracy: 1.0000 - val_loss: -8.9108 - val_accuracy: 0.0915\n",
      "Epoch 131/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.8332e-04 - accuracy: 1.0000 - val_loss: -8.7822 - val_accuracy: 0.0915\n",
      "Epoch 132/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.6880e-04 - accuracy: 1.0000 - val_loss: -8.6573 - val_accuracy: 0.0976\n",
      "Epoch 133/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.6194e-04 - accuracy: 1.0000 - val_loss: -8.8769 - val_accuracy: 0.0915\n",
      "Epoch 134/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.4912e-04 - accuracy: 1.0000 - val_loss: -8.9141 - val_accuracy: 0.0915\n",
      "Epoch 135/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.3709e-04 - accuracy: 1.0000 - val_loss: -8.9229 - val_accuracy: 0.0915\n",
      "Epoch 136/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2847e-04 - accuracy: 1.0000 - val_loss: -8.9877 - val_accuracy: 0.0915\n",
      "Epoch 137/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1730e-04 - accuracy: 1.0000 - val_loss: -8.9384 - val_accuracy: 0.0915\n",
      "Epoch 138/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1079e-04 - accuracy: 1.0000 - val_loss: -9.0264 - val_accuracy: 0.0915\n",
      "Epoch 139/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.0256e-04 - accuracy: 1.0000 - val_loss: -8.9218 - val_accuracy: 0.0915\n",
      "Epoch 140/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9826e-04 - accuracy: 1.0000 - val_loss: -8.9697 - val_accuracy: 0.0976\n",
      "Epoch 141/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.8376e-04 - accuracy: 1.0000 - val_loss: -9.0437 - val_accuracy: 0.0915\n",
      "Epoch 142/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.7477e-04 - accuracy: 1.0000 - val_loss: -9.0375 - val_accuracy: 0.0915\n",
      "Epoch 143/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.6839e-04 - accuracy: 1.0000 - val_loss: -8.9789 - val_accuracy: 0.0976\n",
      "Epoch 144/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6492e-04 - accuracy: 1.0000 - val_loss: -9.0722 - val_accuracy: 0.0976\n",
      "Epoch 145/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.5742e-04 - accuracy: 1.0000 - val_loss: -9.2921 - val_accuracy: 0.0915\n",
      "Epoch 146/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4669e-04 - accuracy: 1.0000 - val_loss: -9.0447 - val_accuracy: 0.0976\n",
      "Epoch 147/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4546e-04 - accuracy: 1.0000 - val_loss: -9.0686 - val_accuracy: 0.0976\n",
      "Epoch 148/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.4332e-04 - accuracy: 1.0000 - val_loss: -9.3217 - val_accuracy: 0.0915\n",
      "Epoch 149/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3618e-04 - accuracy: 1.0000 - val_loss: -9.3141 - val_accuracy: 0.0915\n",
      "Epoch 150/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.2524e-04 - accuracy: 1.0000 - val_loss: -9.1606 - val_accuracy: 0.0976\n",
      "Epoch 151/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.2384e-04 - accuracy: 1.0000 - val_loss: -9.4198 - val_accuracy: 0.0915\n",
      "Epoch 152/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1769e-04 - accuracy: 1.0000 - val_loss: -9.3001 - val_accuracy: 0.0976\n",
      "Epoch 153/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1361e-04 - accuracy: 1.0000 - val_loss: -9.2149 - val_accuracy: 0.0976\n",
      "Epoch 154/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1266e-04 - accuracy: 1.0000 - val_loss: -9.3702 - val_accuracy: 0.0976\n",
      "Epoch 155/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0765e-04 - accuracy: 1.0000 - val_loss: -9.3850 - val_accuracy: 0.0915\n",
      "Epoch 156/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.7752e-05 - accuracy: 1.0000 - val_loss: -9.3806 - val_accuracy: 0.0976\n",
      "Epoch 157/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.5936e-05 - accuracy: 1.0000 - val_loss: -9.5065 - val_accuracy: 0.0915\n",
      "Epoch 158/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.2636e-05 - accuracy: 1.0000 - val_loss: -9.5575 - val_accuracy: 0.0915\n",
      "Epoch 159/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.9816e-05 - accuracy: 1.0000 - val_loss: -9.4316 - val_accuracy: 0.0976\n",
      "Epoch 160/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.7355e-05 - accuracy: 1.0000 - val_loss: -9.5884 - val_accuracy: 0.0915\n",
      "Epoch 161/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.5963e-05 - accuracy: 1.0000 - val_loss: -9.6389 - val_accuracy: 0.0915\n",
      "Epoch 162/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 7.9303e-05 - accuracy: 1.0000 - val_loss: -9.7152 - val_accuracy: 0.0915\n",
      "Epoch 163/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.7001e-05 - accuracy: 1.0000 - val_loss: -9.5611 - val_accuracy: 0.0915\n",
      "Epoch 164/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.4601e-05 - accuracy: 1.0000 - val_loss: -9.6101 - val_accuracy: 0.0976\n",
      "Epoch 165/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.0836e-05 - accuracy: 1.0000 - val_loss: -9.7569 - val_accuracy: 0.0915\n",
      "Epoch 166/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.7051e-05 - accuracy: 1.0000 - val_loss: -9.7634 - val_accuracy: 0.0915\n",
      "Epoch 167/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.2409e-05 - accuracy: 1.0000 - val_loss: -9.6477 - val_accuracy: 0.0976\n",
      "Epoch 168/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.0807e-05 - accuracy: 1.0000 - val_loss: -9.9707 - val_accuracy: 0.0915\n",
      "Epoch 169/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.0196e-05 - accuracy: 1.0000 - val_loss: -9.7895 - val_accuracy: 0.0915\n",
      "Epoch 170/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.8270e-05 - accuracy: 1.0000 - val_loss: -9.8870 - val_accuracy: 0.0915\n",
      "Epoch 171/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.5799e-05 - accuracy: 1.0000 - val_loss: -9.8337 - val_accuracy: 0.0915\n",
      "Epoch 172/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.2119e-05 - accuracy: 1.0000 - val_loss: -10.0979 - val_accuracy: 0.0915\n",
      "Epoch 173/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.1591e-05 - accuracy: 1.0000 - val_loss: -9.9970 - val_accuracy: 0.0915\n",
      "Epoch 174/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.8998e-05 - accuracy: 1.0000 - val_loss: -9.9809 - val_accuracy: 0.0915\n",
      "Epoch 175/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.8569e-05 - accuracy: 1.0000 - val_loss: -10.1288 - val_accuracy: 0.0915\n",
      "Epoch 176/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.5330e-05 - accuracy: 1.0000 - val_loss: -10.1340 - val_accuracy: 0.0915\n",
      "Epoch 177/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.2578e-05 - accuracy: 1.0000 - val_loss: -9.9704 - val_accuracy: 0.0915\n",
      "Epoch 178/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.3303e-05 - accuracy: 1.0000 - val_loss: -10.0965 - val_accuracy: 0.0915\n",
      "Epoch 179/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.9607e-05 - accuracy: 1.0000 - val_loss: -10.1938 - val_accuracy: 0.0915\n",
      "Epoch 180/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.9025e-05 - accuracy: 1.0000 - val_loss: -10.0483 - val_accuracy: 0.0915\n",
      "Epoch 181/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.7223e-05 - accuracy: 1.0000 - val_loss: -10.0264 - val_accuracy: 0.0915\n",
      "Epoch 182/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.6617e-05 - accuracy: 1.0000 - val_loss: -10.2425 - val_accuracy: 0.0915\n",
      "Epoch 183/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.4712e-05 - accuracy: 1.0000 - val_loss: -10.2212 - val_accuracy: 0.0915\n",
      "Epoch 184/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.2510e-05 - accuracy: 1.0000 - val_loss: -10.1957 - val_accuracy: 0.0915\n",
      "Epoch 185/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.1869e-05 - accuracy: 1.0000 - val_loss: -10.3358 - val_accuracy: 0.0915\n",
      "Epoch 186/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.0685e-05 - accuracy: 1.0000 - val_loss: -10.1524 - val_accuracy: 0.0915\n",
      "Epoch 187/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.0112e-05 - accuracy: 1.0000 - val_loss: -10.4042 - val_accuracy: 0.0915\n",
      "Epoch 188/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9083e-05 - accuracy: 1.0000 - val_loss: -10.2748 - val_accuracy: 0.0915\n",
      "Epoch 189/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7140e-05 - accuracy: 1.0000 - val_loss: -10.3737 - val_accuracy: 0.0915\n",
      "Epoch 190/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.7002e-05 - accuracy: 1.0000 - val_loss: -10.3846 - val_accuracy: 0.0915\n",
      "Epoch 191/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6125e-05 - accuracy: 1.0000 - val_loss: -10.4904 - val_accuracy: 0.0915\n",
      "Epoch 192/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.5803e-05 - accuracy: 1.0000 - val_loss: -10.4114 - val_accuracy: 0.0915\n",
      "Epoch 193/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.3838e-05 - accuracy: 1.0000 - val_loss: -10.3183 - val_accuracy: 0.0915\n",
      "Epoch 194/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.4093e-05 - accuracy: 1.0000 - val_loss: -10.6659 - val_accuracy: 0.0915\n",
      "Epoch 195/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1996e-05 - accuracy: 1.0000 - val_loss: -10.4537 - val_accuracy: 0.0915\n",
      "Epoch 196/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1350e-05 - accuracy: 1.0000 - val_loss: -10.5546 - val_accuracy: 0.0915\n",
      "Epoch 197/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.0088e-05 - accuracy: 1.0000 - val_loss: -10.4562 - val_accuracy: 0.0915\n",
      "Epoch 198/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.9762e-05 - accuracy: 1.0000 - val_loss: -10.9832 - val_accuracy: 0.0915\n",
      "Epoch 199/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.8457e-05 - accuracy: 1.0000 - val_loss: -10.5953 - val_accuracy: 0.0915\n",
      "Epoch 200/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8702e-05 - accuracy: 1.0000 - val_loss: -10.7923 - val_accuracy: 0.0915\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "64/64 [==============================] - 1s 6ms/step - loss: 0.6923 - accuracy: 0.4941 - val_loss: 0.7439 - val_accuracy: 0.1951\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6504 - val_loss: 0.5750 - val_accuracy: 0.1646\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6543 - val_loss: 0.3959 - val_accuracy: 0.1829\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7266 - val_loss: -0.7076 - val_accuracy: 0.0976\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7715 - val_loss: -0.8788 - val_accuracy: 0.1280\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7598 - val_loss: -1.5099 - val_accuracy: 0.1037\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7734 - val_loss: -0.9667 - val_accuracy: 0.1646\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: -0.6774 - val_accuracy: 0.2012\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7695 - val_loss: -1.4671 - val_accuracy: 0.1159\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7969 - val_loss: -0.7674 - val_accuracy: 0.1829\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8086 - val_loss: -0.8543 - val_accuracy: 0.1402\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8066 - val_loss: -0.8383 - val_accuracy: 0.1646\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8047 - val_loss: -1.8159 - val_accuracy: 0.1646\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8242 - val_loss: -1.7600 - val_accuracy: 0.1707\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8145 - val_loss: -2.1258 - val_accuracy: 0.1402\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8164 - val_loss: -1.3317 - val_accuracy: 0.1585\n",
      "Epoch 17/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8340 - val_loss: -1.7746 - val_accuracy: 0.1463\n",
      "Epoch 18/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8398 - val_loss: -2.4911 - val_accuracy: 0.1524\n",
      "Epoch 19/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8125 - val_loss: -1.6193 - val_accuracy: 0.1829\n",
      "Epoch 20/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8340 - val_loss: -2.9070 - val_accuracy: 0.1037\n",
      "Epoch 21/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8496 - val_loss: -2.0445 - val_accuracy: 0.1951\n",
      "Epoch 22/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8750 - val_loss: -1.9130 - val_accuracy: 0.1463\n",
      "Epoch 23/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8633 - val_loss: -2.7445 - val_accuracy: 0.1646\n",
      "Epoch 24/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8633 - val_loss: -2.7686 - val_accuracy: 0.1341\n",
      "Epoch 25/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3155 - accuracy: 0.8672 - val_loss: -1.3010 - val_accuracy: 0.1707\n",
      "Epoch 26/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8691 - val_loss: -2.1700 - val_accuracy: 0.1585\n",
      "Epoch 27/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8906 - val_loss: -3.6017 - val_accuracy: 0.1280\n",
      "Epoch 28/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8867 - val_loss: -3.1409 - val_accuracy: 0.1280\n",
      "Epoch 29/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2702 - accuracy: 0.8809 - val_loss: -2.1672 - val_accuracy: 0.1220\n",
      "Epoch 30/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8750 - val_loss: -3.1502 - val_accuracy: 0.1646\n",
      "Epoch 31/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8672 - val_loss: -3.2511 - val_accuracy: 0.1524\n",
      "Epoch 32/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9004 - val_loss: -3.0883 - val_accuracy: 0.1280\n",
      "Epoch 33/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9043 - val_loss: -3.7197 - val_accuracy: 0.1159\n",
      "Epoch 34/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9102 - val_loss: -4.0508 - val_accuracy: 0.1098\n",
      "Epoch 35/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9277 - val_loss: -5.0186 - val_accuracy: 0.0976\n",
      "Epoch 36/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.9375 - val_loss: -5.1717 - val_accuracy: 0.1280\n",
      "Epoch 37/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.9199 - val_loss: -4.0406 - val_accuracy: 0.1098\n",
      "Epoch 38/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9062 - val_loss: -2.9995 - val_accuracy: 0.1098\n",
      "Epoch 39/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9277 - val_loss: -3.5170 - val_accuracy: 0.1646\n",
      "Epoch 40/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9434 - val_loss: -3.3055 - val_accuracy: 0.1707\n",
      "Epoch 41/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9258 - val_loss: -4.6404 - val_accuracy: 0.1463\n",
      "Epoch 42/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2225 - accuracy: 0.9062 - val_loss: -4.7079 - val_accuracy: 0.1463\n",
      "Epoch 43/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9219 - val_loss: -4.9292 - val_accuracy: 0.1220\n",
      "Epoch 44/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9336 - val_loss: -4.2160 - val_accuracy: 0.1463\n",
      "Epoch 45/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9492 - val_loss: -5.3154 - val_accuracy: 0.0671\n",
      "Epoch 46/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9375 - val_loss: -4.3899 - val_accuracy: 0.1402\n",
      "Epoch 47/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9395 - val_loss: -3.9104 - val_accuracy: 0.1524\n",
      "Epoch 48/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9492 - val_loss: -4.0565 - val_accuracy: 0.1585\n",
      "Epoch 49/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9609 - val_loss: -5.7501 - val_accuracy: 0.0976\n",
      "Epoch 50/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9434 - val_loss: -5.6447 - val_accuracy: 0.1220\n",
      "Epoch 51/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9297 - val_loss: -6.1785 - val_accuracy: 0.1159\n",
      "Epoch 52/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9551 - val_loss: -6.9513 - val_accuracy: 0.1098\n",
      "Epoch 53/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9648 - val_loss: -7.1889 - val_accuracy: 0.1220\n",
      "Epoch 54/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9648 - val_loss: -8.1684 - val_accuracy: 0.1098\n",
      "Epoch 55/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9648 - val_loss: -8.4988 - val_accuracy: 0.1037\n",
      "Epoch 56/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9707 - val_loss: -7.2647 - val_accuracy: 0.1280\n",
      "Epoch 57/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9570 - val_loss: -5.8686 - val_accuracy: 0.1463\n",
      "Epoch 58/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9609 - val_loss: -7.3711 - val_accuracy: 0.1159\n",
      "Epoch 59/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9785 - val_loss: -6.6825 - val_accuracy: 0.1463\n",
      "Epoch 60/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9824 - val_loss: -7.5998 - val_accuracy: 0.1098\n",
      "Epoch 61/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9609 - val_loss: -7.3214 - val_accuracy: 0.0976\n",
      "Epoch 62/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9707 - val_loss: -7.7681 - val_accuracy: 0.0976\n",
      "Epoch 63/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9766 - val_loss: -8.7024 - val_accuracy: 0.0854\n",
      "Epoch 64/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9688 - val_loss: -9.5298 - val_accuracy: 0.0976\n",
      "Epoch 65/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9629 - val_loss: -7.7025 - val_accuracy: 0.0793\n",
      "Epoch 66/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9355 - val_loss: -7.6593 - val_accuracy: 0.1220\n",
      "Epoch 67/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9492 - val_loss: -7.0666 - val_accuracy: 0.1220\n",
      "Epoch 68/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9844 - val_loss: -6.4888 - val_accuracy: 0.1280\n",
      "Epoch 69/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9766 - val_loss: -7.6215 - val_accuracy: 0.1280\n",
      "Epoch 70/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9766 - val_loss: -7.9007 - val_accuracy: 0.0793\n",
      "Epoch 71/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: -7.1311 - val_accuracy: 0.1341\n",
      "Epoch 72/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9766 - val_loss: -8.1444 - val_accuracy: 0.1280\n",
      "Epoch 73/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9766 - val_loss: -6.5294 - val_accuracy: 0.1220\n",
      "Epoch 74/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9922 - val_loss: -7.3847 - val_accuracy: 0.1280\n",
      "Epoch 75/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: -7.8130 - val_accuracy: 0.1280\n",
      "Epoch 76/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9844 - val_loss: -7.9488 - val_accuracy: 0.1220\n",
      "Epoch 77/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9941 - val_loss: -8.1919 - val_accuracy: 0.1098\n",
      "Epoch 78/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: -7.7155 - val_accuracy: 0.1159\n",
      "Epoch 79/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9766 - val_loss: -9.1712 - val_accuracy: 0.1159\n",
      "Epoch 80/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9551 - val_loss: -8.1136 - val_accuracy: 0.1402\n",
      "Epoch 81/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9199 - val_loss: -4.7226 - val_accuracy: 0.1159\n",
      "Epoch 82/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9297 - val_loss: -6.6394 - val_accuracy: 0.1220\n",
      "Epoch 83/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9473 - val_loss: -7.7554 - val_accuracy: 0.1341\n",
      "Epoch 84/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9785 - val_loss: -8.5701 - val_accuracy: 0.1098\n",
      "Epoch 85/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: -7.7765 - val_accuracy: 0.0976\n",
      "Epoch 86/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: -8.9635 - val_accuracy: 0.1098\n",
      "Epoch 87/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9766 - val_loss: -8.7908 - val_accuracy: 0.1280\n",
      "Epoch 88/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: -9.3581 - val_accuracy: 0.1220\n",
      "Epoch 89/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9922 - val_loss: -7.3089 - val_accuracy: 0.1402\n",
      "Epoch 90/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9824 - val_loss: -8.0980 - val_accuracy: 0.1220\n",
      "Epoch 91/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: -9.0295 - val_accuracy: 0.1098\n",
      "Epoch 92/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: -9.4644 - val_accuracy: 0.0976\n",
      "Epoch 93/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: -10.1707 - val_accuracy: 0.0976\n",
      "Epoch 94/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: -9.9947 - val_accuracy: 0.0915\n",
      "Epoch 95/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: -9.3009 - val_accuracy: 0.0915\n",
      "Epoch 96/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: -9.2190 - val_accuracy: 0.0915\n",
      "Epoch 97/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: -9.0674 - val_accuracy: 0.1037\n",
      "Epoch 98/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: -9.5978 - val_accuracy: 0.0976\n",
      "Epoch 99/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: -10.2986 - val_accuracy: 0.0976\n",
      "Epoch 100/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: -10.1089 - val_accuracy: 0.0915\n",
      "Epoch 101/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -9.1192 - val_accuracy: 0.1098\n",
      "Epoch 102/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: -9.5536 - val_accuracy: 0.1037\n",
      "Epoch 103/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -9.3081 - val_accuracy: 0.1037\n",
      "Epoch 104/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -10.6241 - val_accuracy: 0.0915\n",
      "Epoch 105/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -9.6514 - val_accuracy: 0.0976\n",
      "Epoch 106/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -9.8035 - val_accuracy: 0.0915\n",
      "Epoch 107/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -9.9481 - val_accuracy: 0.0915\n",
      "Epoch 108/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -9.8035 - val_accuracy: 0.0915\n",
      "Epoch 109/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.7340 - val_accuracy: 0.0976\n",
      "Epoch 110/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.7510 - val_accuracy: 0.0915\n",
      "Epoch 111/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.5819 - val_accuracy: 0.0976\n",
      "Epoch 112/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.5296 - val_accuracy: 0.0976\n",
      "Epoch 113/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.3373 - val_accuracy: 0.1037\n",
      "Epoch 114/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.5195 - val_accuracy: 0.0976\n",
      "Epoch 115/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.4294 - val_accuracy: 0.0976\n",
      "Epoch 116/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.4158 - val_accuracy: 0.0976\n",
      "Epoch 117/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.9560 - val_accuracy: 0.0976\n",
      "Epoch 118/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.0348 - val_accuracy: 0.1098\n",
      "Epoch 119/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.0355 - val_accuracy: 0.0976\n",
      "Epoch 120/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 8.0393e-04 - accuracy: 1.0000 - val_loss: -9.8979 - val_accuracy: 0.0976\n",
      "Epoch 121/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.8750e-04 - accuracy: 1.0000 - val_loss: -10.0276 - val_accuracy: 0.0915\n",
      "Epoch 122/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.6694e-04 - accuracy: 1.0000 - val_loss: -10.2582 - val_accuracy: 0.0915\n",
      "Epoch 123/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.0293e-04 - accuracy: 1.0000 - val_loss: -9.5897 - val_accuracy: 0.0976\n",
      "Epoch 124/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.9063e-04 - accuracy: 1.0000 - val_loss: -10.2062 - val_accuracy: 0.0976\n",
      "Epoch 125/200\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 5.3514e-04 - accuracy: 1.0000 - val_loss: -9.8293 - val_accuracy: 0.0976\n",
      "Epoch 126/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 4.8270e-04 - accuracy: 1.0000 - val_loss: -9.8115 - val_accuracy: 0.0976\n",
      "Epoch 127/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.9121e-04 - accuracy: 1.0000 - val_loss: -9.7643 - val_accuracy: 0.0976\n",
      "Epoch 128/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.6188e-04 - accuracy: 1.0000 - val_loss: -9.9057 - val_accuracy: 0.0976\n",
      "Epoch 129/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.2681e-04 - accuracy: 1.0000 - val_loss: -10.1214 - val_accuracy: 0.0976\n",
      "Epoch 130/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.8497e-04 - accuracy: 1.0000 - val_loss: -10.0418 - val_accuracy: 0.0976\n",
      "Epoch 131/200\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 3.9540e-04 - accuracy: 1.0000 - val_loss: -10.0615 - val_accuracy: 0.0976\n",
      "Epoch 132/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.7367e-04 - accuracy: 1.0000 - val_loss: -10.1237 - val_accuracy: 0.0976\n",
      "Epoch 133/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.1917e-04 - accuracy: 1.0000 - val_loss: -9.8066 - val_accuracy: 0.1037\n",
      "Epoch 134/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.3702e-04 - accuracy: 1.0000 - val_loss: -10.4897 - val_accuracy: 0.0915\n",
      "Epoch 135/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.6465e-04 - accuracy: 1.0000 - val_loss: -10.2341 - val_accuracy: 0.0915\n",
      "Epoch 136/200\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 3.1715e-04 - accuracy: 1.0000 - val_loss: -10.3376 - val_accuracy: 0.0976\n",
      "Epoch 137/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.0637e-04 - accuracy: 1.0000 - val_loss: -10.3055 - val_accuracy: 0.0976\n",
      "Epoch 138/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.6464e-04 - accuracy: 1.0000 - val_loss: -10.3512 - val_accuracy: 0.0976\n",
      "Epoch 139/200\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 2.4612e-04 - accuracy: 1.0000 - val_loss: -10.5861 - val_accuracy: 0.0915\n",
      "Epoch 140/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.5622e-04 - accuracy: 1.0000 - val_loss: -10.4360 - val_accuracy: 0.0976\n",
      "Epoch 141/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2075e-04 - accuracy: 1.0000 - val_loss: -10.3475 - val_accuracy: 0.0976\n",
      "Epoch 142/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.4461e-04 - accuracy: 1.0000 - val_loss: -10.4244 - val_accuracy: 0.0976\n",
      "Epoch 143/200\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 2.1039e-04 - accuracy: 1.0000 - val_loss: -10.3509 - val_accuracy: 0.0976\n",
      "Epoch 144/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.0884e-04 - accuracy: 1.0000 - val_loss: -10.6399 - val_accuracy: 0.0976\n",
      "Epoch 145/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9264e-04 - accuracy: 1.0000 - val_loss: -10.4604 - val_accuracy: 0.0976\n",
      "Epoch 146/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.9192e-04 - accuracy: 1.0000 - val_loss: -10.4836 - val_accuracy: 0.0976\n",
      "Epoch 147/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8154e-04 - accuracy: 1.0000 - val_loss: -10.7294 - val_accuracy: 0.0976\n",
      "Epoch 148/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7181e-04 - accuracy: 1.0000 - val_loss: -10.5831 - val_accuracy: 0.0976\n",
      "Epoch 149/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6252e-04 - accuracy: 1.0000 - val_loss: -10.4360 - val_accuracy: 0.0976\n",
      "Epoch 150/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.4893e-04 - accuracy: 1.0000 - val_loss: -10.7252 - val_accuracy: 0.0976\n",
      "Epoch 151/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.3776e-04 - accuracy: 1.0000 - val_loss: -10.4761 - val_accuracy: 0.0976\n",
      "Epoch 152/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.4047e-04 - accuracy: 1.0000 - val_loss: -10.6085 - val_accuracy: 0.0976\n",
      "Epoch 153/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3380e-04 - accuracy: 1.0000 - val_loss: -10.7820 - val_accuracy: 0.0976\n",
      "Epoch 154/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3305e-04 - accuracy: 1.0000 - val_loss: -10.9728 - val_accuracy: 0.0976\n",
      "Epoch 155/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2570e-04 - accuracy: 1.0000 - val_loss: -10.7701 - val_accuracy: 0.0976\n",
      "Epoch 156/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1733e-04 - accuracy: 1.0000 - val_loss: -11.0050 - val_accuracy: 0.0976\n",
      "Epoch 157/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.0640e-04 - accuracy: 1.0000 - val_loss: -10.6960 - val_accuracy: 0.0976\n",
      "Epoch 158/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0376e-04 - accuracy: 1.0000 - val_loss: -10.8372 - val_accuracy: 0.0976\n",
      "Epoch 159/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0110e-04 - accuracy: 1.0000 - val_loss: -10.7899 - val_accuracy: 0.0976\n",
      "Epoch 160/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.4043e-05 - accuracy: 1.0000 - val_loss: -11.1095 - val_accuracy: 0.0976\n",
      "Epoch 161/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.8650e-05 - accuracy: 1.0000 - val_loss: -10.9210 - val_accuracy: 0.0976\n",
      "Epoch 162/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.3848e-05 - accuracy: 1.0000 - val_loss: -10.7953 - val_accuracy: 0.1037\n",
      "Epoch 163/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.6157e-05 - accuracy: 1.0000 - val_loss: -10.9766 - val_accuracy: 0.0976\n",
      "Epoch 164/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 8.0719e-05 - accuracy: 1.0000 - val_loss: -11.0178 - val_accuracy: 0.0976\n",
      "Epoch 165/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.6351e-05 - accuracy: 1.0000 - val_loss: -11.5131 - val_accuracy: 0.0976\n",
      "Epoch 166/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.1754e-05 - accuracy: 1.0000 - val_loss: -11.0463 - val_accuracy: 0.0976\n",
      "Epoch 167/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.9993e-05 - accuracy: 1.0000 - val_loss: -11.2447 - val_accuracy: 0.0976\n",
      "Epoch 168/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.1815e-05 - accuracy: 1.0000 - val_loss: -11.3514 - val_accuracy: 0.0976\n",
      "Epoch 169/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.5498e-05 - accuracy: 1.0000 - val_loss: -11.0701 - val_accuracy: 0.1037\n",
      "Epoch 170/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.8911e-05 - accuracy: 1.0000 - val_loss: -11.1983 - val_accuracy: 0.1037\n",
      "Epoch 171/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.5753e-05 - accuracy: 1.0000 - val_loss: -11.5286 - val_accuracy: 0.0976\n",
      "Epoch 172/200\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 6.6702e-05 - accuracy: 1.0000 - val_loss: -11.3535 - val_accuracy: 0.0976\n",
      "Epoch 173/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.3195e-05 - accuracy: 1.0000 - val_loss: -11.1387 - val_accuracy: 0.1037\n",
      "Epoch 174/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.2809e-05 - accuracy: 1.0000 - val_loss: -11.2782 - val_accuracy: 0.0976\n",
      "Epoch 175/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.9959e-05 - accuracy: 1.0000 - val_loss: -11.3401 - val_accuracy: 0.0976\n",
      "Epoch 176/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.6604e-05 - accuracy: 1.0000 - val_loss: -11.2763 - val_accuracy: 0.0976\n",
      "Epoch 177/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.7000e-05 - accuracy: 1.0000 - val_loss: -11.2930 - val_accuracy: 0.1037\n",
      "Epoch 178/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.1531e-05 - accuracy: 1.0000 - val_loss: -11.6583 - val_accuracy: 0.0976\n",
      "Epoch 179/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.6580e-05 - accuracy: 1.0000 - val_loss: -11.6764 - val_accuracy: 0.0976\n",
      "Epoch 180/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.2847e-05 - accuracy: 1.0000 - val_loss: -11.2542 - val_accuracy: 0.1037\n",
      "Epoch 181/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.8128e-05 - accuracy: 1.0000 - val_loss: -11.3104 - val_accuracy: 0.1037\n",
      "Epoch 182/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.6672e-05 - accuracy: 1.0000 - val_loss: -11.3809 - val_accuracy: 0.1037\n",
      "Epoch 183/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5058e-05 - accuracy: 1.0000 - val_loss: -11.4057 - val_accuracy: 0.1037\n",
      "Epoch 184/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.4095e-05 - accuracy: 1.0000 - val_loss: -11.4896 - val_accuracy: 0.1037\n",
      "Epoch 185/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.1563e-05 - accuracy: 1.0000 - val_loss: -11.2435 - val_accuracy: 0.1037\n",
      "Epoch 186/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.1737e-05 - accuracy: 1.0000 - val_loss: -11.5177 - val_accuracy: 0.0976\n",
      "Epoch 187/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.0542e-05 - accuracy: 1.0000 - val_loss: -11.7020 - val_accuracy: 0.1037\n",
      "Epoch 188/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.9662e-05 - accuracy: 1.0000 - val_loss: -11.5836 - val_accuracy: 0.1037\n",
      "Epoch 189/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.7873e-05 - accuracy: 1.0000 - val_loss: -11.6232 - val_accuracy: 0.1037\n",
      "Epoch 190/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.6617e-05 - accuracy: 1.0000 - val_loss: -11.6986 - val_accuracy: 0.1037\n",
      "Epoch 191/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.4808e-05 - accuracy: 1.0000 - val_loss: -11.5397 - val_accuracy: 0.1037\n",
      "Epoch 192/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.5833e-05 - accuracy: 1.0000 - val_loss: -12.0461 - val_accuracy: 0.1037\n",
      "Epoch 193/200\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.6711e-05 - accuracy: 1.0000 - val_loss: -11.6175 - val_accuracy: 0.1037\n",
      "Epoch 194/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.2744e-05 - accuracy: 1.0000 - val_loss: -11.7456 - val_accuracy: 0.1037\n",
      "Epoch 195/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1042e-05 - accuracy: 1.0000 - val_loss: -11.7593 - val_accuracy: 0.1037\n",
      "Epoch 196/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9731e-05 - accuracy: 1.0000 - val_loss: -11.4511 - val_accuracy: 0.1159\n",
      "Epoch 197/200\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.3166e-05 - accuracy: 1.0000 - val_loss: -11.9806 - val_accuracy: 0.1037\n",
      "Epoch 198/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.1158e-05 - accuracy: 1.0000 - val_loss: -11.9902 - val_accuracy: 0.1037\n",
      "Epoch 199/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.6983e-05 - accuracy: 1.0000 - val_loss: -11.4966 - val_accuracy: 0.1159\n",
      "Epoch 200/200\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.8130e-05 - accuracy: 1.0000 - val_loss: -11.8464 - val_accuracy: 0.1037\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 1/300\n",
      "64/64 [==============================] - 1s 4ms/step - loss: 0.6841 - accuracy: 0.5586 - val_loss: 0.4741 - val_accuracy: 0.0976\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6406 - val_loss: 0.0633 - val_accuracy: 0.1220\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7305 - val_loss: 0.0221 - val_accuracy: 0.1463\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7305 - val_loss: -0.7429 - val_accuracy: 0.0976\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7617 - val_loss: -0.6274 - val_accuracy: 0.1159\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7930 - val_loss: 0.0973 - val_accuracy: 0.1890\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7559 - val_loss: -1.0149 - val_accuracy: 0.1037\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.8008 - val_loss: -0.4439 - val_accuracy: 0.1829\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8066 - val_loss: -1.1404 - val_accuracy: 0.1220\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7930 - val_loss: -1.1263 - val_accuracy: 0.1524\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8203 - val_loss: -1.9515 - val_accuracy: 0.1037\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7891 - val_loss: -0.9540 - val_accuracy: 0.1280\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8320 - val_loss: -1.0638 - val_accuracy: 0.1463\n",
      "Epoch 14/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8281 - val_loss: -1.7785 - val_accuracy: 0.1098\n",
      "Epoch 15/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8477 - val_loss: -1.9898 - val_accuracy: 0.1463\n",
      "Epoch 16/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8555 - val_loss: -2.0412 - val_accuracy: 0.1220\n",
      "Epoch 17/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8496 - val_loss: -1.6800 - val_accuracy: 0.1585\n",
      "Epoch 18/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8301 - val_loss: -2.5942 - val_accuracy: 0.1098\n",
      "Epoch 19/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8398 - val_loss: -2.0173 - val_accuracy: 0.1402\n",
      "Epoch 20/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8711 - val_loss: -1.0925 - val_accuracy: 0.1646\n",
      "Epoch 21/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8730 - val_loss: -3.0442 - val_accuracy: 0.1220\n",
      "Epoch 22/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8848 - val_loss: -3.1447 - val_accuracy: 0.1098\n",
      "Epoch 23/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8379 - val_loss: -2.6696 - val_accuracy: 0.0976\n",
      "Epoch 24/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8555 - val_loss: -1.2050 - val_accuracy: 0.1646\n",
      "Epoch 25/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8730 - val_loss: -2.3942 - val_accuracy: 0.1402\n",
      "Epoch 26/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.9004 - val_loss: -2.9593 - val_accuracy: 0.1220\n",
      "Epoch 27/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.8945 - val_loss: -3.5312 - val_accuracy: 0.1220\n",
      "Epoch 28/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9062 - val_loss: -1.9540 - val_accuracy: 0.1585\n",
      "Epoch 29/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9023 - val_loss: -2.7862 - val_accuracy: 0.1220\n",
      "Epoch 30/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9180 - val_loss: -4.9959 - val_accuracy: 0.0854\n",
      "Epoch 31/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9219 - val_loss: -3.3922 - val_accuracy: 0.1402\n",
      "Epoch 32/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2134 - accuracy: 0.9180 - val_loss: -4.0031 - val_accuracy: 0.1220\n",
      "Epoch 33/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9336 - val_loss: -4.8601 - val_accuracy: 0.0976\n",
      "Epoch 34/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2266 - accuracy: 0.9082 - val_loss: -4.3297 - val_accuracy: 0.1341\n",
      "Epoch 35/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.8965 - val_loss: -3.8553 - val_accuracy: 0.1098\n",
      "Epoch 36/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: -4.6141 - val_accuracy: 0.1159\n",
      "Epoch 37/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9297 - val_loss: -4.7818 - val_accuracy: 0.0976\n",
      "Epoch 38/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9355 - val_loss: -4.5294 - val_accuracy: 0.1220\n",
      "Epoch 39/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1524 - accuracy: 0.9414 - val_loss: -4.8711 - val_accuracy: 0.1098\n",
      "Epoch 40/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9160 - val_loss: -5.3553 - val_accuracy: 0.1098\n",
      "Epoch 41/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9121 - val_loss: -5.4307 - val_accuracy: 0.0549\n",
      "Epoch 42/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9395 - val_loss: -5.0410 - val_accuracy: 0.1280\n",
      "Epoch 43/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9512 - val_loss: -5.9013 - val_accuracy: 0.0976\n",
      "Epoch 44/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9355 - val_loss: -6.0870 - val_accuracy: 0.0976\n",
      "Epoch 45/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9414 - val_loss: -4.6302 - val_accuracy: 0.1220\n",
      "Epoch 46/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9414 - val_loss: -5.6360 - val_accuracy: 0.0976\n",
      "Epoch 47/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9570 - val_loss: -3.7792 - val_accuracy: 0.1524\n",
      "Epoch 48/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9570 - val_loss: -6.4043 - val_accuracy: 0.1037\n",
      "Epoch 49/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9512 - val_loss: -3.1954 - val_accuracy: 0.1768\n",
      "Epoch 50/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9316 - val_loss: -7.9632 - val_accuracy: 0.0671\n",
      "Epoch 51/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9492 - val_loss: -4.9673 - val_accuracy: 0.1463\n",
      "Epoch 52/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9590 - val_loss: -6.1375 - val_accuracy: 0.1341\n",
      "Epoch 53/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9688 - val_loss: -7.2616 - val_accuracy: 0.1037\n",
      "Epoch 54/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9629 - val_loss: -7.8676 - val_accuracy: 0.0732\n",
      "Epoch 55/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9434 - val_loss: -7.2370 - val_accuracy: 0.1159\n",
      "Epoch 56/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9297 - val_loss: -4.5838 - val_accuracy: 0.1585\n",
      "Epoch 57/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9609 - val_loss: -5.3995 - val_accuracy: 0.1402\n",
      "Epoch 58/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9590 - val_loss: -8.0884 - val_accuracy: 0.0488\n",
      "Epoch 59/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9590 - val_loss: -6.9895 - val_accuracy: 0.1098\n",
      "Epoch 60/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9707 - val_loss: -5.8285 - val_accuracy: 0.1220\n",
      "Epoch 61/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9629 - val_loss: -7.1615 - val_accuracy: 0.1280\n",
      "Epoch 62/300\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.1250 - accuracy: 0.9570 - val_loss: -5.8603 - val_accuracy: 0.1585\n",
      "Epoch 63/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9727 - val_loss: -5.2515 - val_accuracy: 0.1341\n",
      "Epoch 64/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9844 - val_loss: -6.7805 - val_accuracy: 0.1402\n",
      "Epoch 65/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9766 - val_loss: -8.7007 - val_accuracy: 0.1037\n",
      "Epoch 66/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1770 - accuracy: 0.9258 - val_loss: -6.7983 - val_accuracy: 0.1098\n",
      "Epoch 67/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9648 - val_loss: -6.2023 - val_accuracy: 0.1463\n",
      "Epoch 68/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9863 - val_loss: -8.8248 - val_accuracy: 0.0915\n",
      "Epoch 69/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9648 - val_loss: -7.1631 - val_accuracy: 0.0976\n",
      "Epoch 70/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9590 - val_loss: -7.7700 - val_accuracy: 0.1037\n",
      "Epoch 71/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9824 - val_loss: -8.2762 - val_accuracy: 0.1159\n",
      "Epoch 72/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9863 - val_loss: -7.5531 - val_accuracy: 0.0976\n",
      "Epoch 73/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9941 - val_loss: -9.3530 - val_accuracy: 0.0915\n",
      "Epoch 74/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9824 - val_loss: -9.2102 - val_accuracy: 0.0976\n",
      "Epoch 75/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: -8.9308 - val_accuracy: 0.0976\n",
      "Epoch 76/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9922 - val_loss: -8.4747 - val_accuracy: 0.1159\n",
      "Epoch 77/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9688 - val_loss: -9.0952 - val_accuracy: 0.0854\n",
      "Epoch 78/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9316 - val_loss: -8.2646 - val_accuracy: 0.1037\n",
      "Epoch 79/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9375 - val_loss: -6.6645 - val_accuracy: 0.0915\n",
      "Epoch 80/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9629 - val_loss: -9.2908 - val_accuracy: 0.0976\n",
      "Epoch 81/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9629 - val_loss: -8.0380 - val_accuracy: 0.0671\n",
      "Epoch 82/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9746 - val_loss: -8.6991 - val_accuracy: 0.0915\n",
      "Epoch 83/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: -8.7787 - val_accuracy: 0.0976\n",
      "Epoch 84/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9980 - val_loss: -8.1505 - val_accuracy: 0.1159\n",
      "Epoch 85/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: -10.1488 - val_accuracy: 0.0793\n",
      "Epoch 86/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9902 - val_loss: -9.0011 - val_accuracy: 0.1037\n",
      "Epoch 87/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: -8.7129 - val_accuracy: 0.1220\n",
      "Epoch 88/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: -9.8411 - val_accuracy: 0.1220\n",
      "Epoch 89/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: -10.0742 - val_accuracy: 0.0915\n",
      "Epoch 90/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: -9.6568 - val_accuracy: 0.1159\n",
      "Epoch 91/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -9.7168 - val_accuracy: 0.1159\n",
      "Epoch 92/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -9.3996 - val_accuracy: 0.1159\n",
      "Epoch 93/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -10.0795 - val_accuracy: 0.1159\n",
      "Epoch 94/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -10.4427 - val_accuracy: 0.1098\n",
      "Epoch 95/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -10.3951 - val_accuracy: 0.1159\n",
      "Epoch 96/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -10.6264 - val_accuracy: 0.1037\n",
      "Epoch 97/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -10.5800 - val_accuracy: 0.1098\n",
      "Epoch 98/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -10.4313 - val_accuracy: 0.1159\n",
      "Epoch 99/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -10.7401 - val_accuracy: 0.1159\n",
      "Epoch 100/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -10.9256 - val_accuracy: 0.1098\n",
      "Epoch 101/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -10.8891 - val_accuracy: 0.1098\n",
      "Epoch 102/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -10.8628 - val_accuracy: 0.1159\n",
      "Epoch 103/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.9423 - val_accuracy: 0.1280\n",
      "Epoch 104/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9863 - val_loss: -6.9755 - val_accuracy: 0.1524\n",
      "Epoch 105/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8652 - val_loss: -6.0736 - val_accuracy: 0.0915\n",
      "Epoch 106/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8965 - val_loss: -4.1308 - val_accuracy: 0.1159\n",
      "Epoch 107/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9492 - val_loss: -6.7529 - val_accuracy: 0.0854\n",
      "Epoch 108/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9492 - val_loss: -6.6711 - val_accuracy: 0.0793\n",
      "Epoch 109/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: -6.2862 - val_accuracy: 0.1402\n",
      "Epoch 110/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9707 - val_loss: -7.8303 - val_accuracy: 0.1159\n",
      "Epoch 111/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9629 - val_loss: -7.8632 - val_accuracy: 0.1159\n",
      "Epoch 112/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9941 - val_loss: -8.9232 - val_accuracy: 0.0854\n",
      "Epoch 113/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9980 - val_loss: -8.7995 - val_accuracy: 0.1098\n",
      "Epoch 114/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9805 - val_loss: -8.3387 - val_accuracy: 0.1037\n",
      "Epoch 115/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9785 - val_loss: -9.5857 - val_accuracy: 0.1037\n",
      "Epoch 116/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9883 - val_loss: -8.2281 - val_accuracy: 0.1098\n",
      "Epoch 117/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9844 - val_loss: -7.6097 - val_accuracy: 0.1220\n",
      "Epoch 118/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9922 - val_loss: -9.1895 - val_accuracy: 0.1159\n",
      "Epoch 119/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9980 - val_loss: -9.2973 - val_accuracy: 0.1037\n",
      "Epoch 120/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -10.3546 - val_accuracy: 0.0976\n",
      "Epoch 121/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -10.4144 - val_accuracy: 0.1037\n",
      "Epoch 122/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -10.5571 - val_accuracy: 0.1037\n",
      "Epoch 123/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -10.6001 - val_accuracy: 0.1098\n",
      "Epoch 124/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -10.4675 - val_accuracy: 0.1159\n",
      "Epoch 125/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.6257 - val_accuracy: 0.1098\n",
      "Epoch 126/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -10.7557 - val_accuracy: 0.1098\n",
      "Epoch 127/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.8063 - val_accuracy: 0.1098\n",
      "Epoch 128/300\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -11.2138 - val_accuracy: 0.1037\n",
      "Epoch 129/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.8719 - val_accuracy: 0.1037\n",
      "Epoch 130/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 9.5173e-04 - accuracy: 1.0000 - val_loss: -10.8285 - val_accuracy: 0.1098\n",
      "Epoch 131/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 8.7223e-04 - accuracy: 1.0000 - val_loss: -11.2709 - val_accuracy: 0.1037\n",
      "Epoch 132/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 8.3957e-04 - accuracy: 1.0000 - val_loss: -10.9673 - val_accuracy: 0.1098\n",
      "Epoch 133/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.7382e-04 - accuracy: 1.0000 - val_loss: -11.1477 - val_accuracy: 0.1098\n",
      "Epoch 134/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.3580e-04 - accuracy: 1.0000 - val_loss: -11.0885 - val_accuracy: 0.1098\n",
      "Epoch 135/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.1760e-04 - accuracy: 1.0000 - val_loss: -11.4409 - val_accuracy: 0.1037\n",
      "Epoch 136/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.0404e-04 - accuracy: 1.0000 - val_loss: -11.3124 - val_accuracy: 0.1098\n",
      "Epoch 137/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.0522e-04 - accuracy: 1.0000 - val_loss: -11.5209 - val_accuracy: 0.1037\n",
      "Epoch 138/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 5.8429e-04 - accuracy: 1.0000 - val_loss: -11.4214 - val_accuracy: 0.1037\n",
      "Epoch 139/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.4360e-04 - accuracy: 1.0000 - val_loss: -11.6981 - val_accuracy: 0.1037\n",
      "Epoch 140/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.4310e-04 - accuracy: 1.0000 - val_loss: -11.5539 - val_accuracy: 0.1037\n",
      "Epoch 141/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.1172e-04 - accuracy: 1.0000 - val_loss: -11.7176 - val_accuracy: 0.1037\n",
      "Epoch 142/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.8265e-04 - accuracy: 1.0000 - val_loss: -11.7926 - val_accuracy: 0.1037\n",
      "Epoch 143/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.5637e-04 - accuracy: 1.0000 - val_loss: -11.5308 - val_accuracy: 0.1037\n",
      "Epoch 144/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.3370e-04 - accuracy: 1.0000 - val_loss: -11.8175 - val_accuracy: 0.1037\n",
      "Epoch 145/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.2611e-04 - accuracy: 1.0000 - val_loss: -11.9184 - val_accuracy: 0.1037\n",
      "Epoch 146/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.1471e-04 - accuracy: 1.0000 - val_loss: -12.3429 - val_accuracy: 0.1037\n",
      "Epoch 147/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.9242e-04 - accuracy: 1.0000 - val_loss: -11.7501 - val_accuracy: 0.1037\n",
      "Epoch 148/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.5954e-04 - accuracy: 1.0000 - val_loss: -11.9630 - val_accuracy: 0.1037\n",
      "Epoch 149/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.4646e-04 - accuracy: 1.0000 - val_loss: -11.7560 - val_accuracy: 0.1098\n",
      "Epoch 150/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.3247e-04 - accuracy: 1.0000 - val_loss: -12.2275 - val_accuracy: 0.1037\n",
      "Epoch 151/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 3.0896e-04 - accuracy: 1.0000 - val_loss: -12.2506 - val_accuracy: 0.1037\n",
      "Epoch 152/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9068e-04 - accuracy: 1.0000 - val_loss: -11.8690 - val_accuracy: 0.1098\n",
      "Epoch 153/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.8689e-04 - accuracy: 1.0000 - val_loss: -12.1278 - val_accuracy: 0.1037\n",
      "Epoch 154/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.6255e-04 - accuracy: 1.0000 - val_loss: -12.4102 - val_accuracy: 0.1037\n",
      "Epoch 155/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.6257e-04 - accuracy: 1.0000 - val_loss: -12.0905 - val_accuracy: 0.1098\n",
      "Epoch 156/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.5702e-04 - accuracy: 1.0000 - val_loss: -12.3991 - val_accuracy: 0.1037\n",
      "Epoch 157/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.2716e-04 - accuracy: 1.0000 - val_loss: -12.3700 - val_accuracy: 0.1037\n",
      "Epoch 158/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.2524e-04 - accuracy: 1.0000 - val_loss: -12.5413 - val_accuracy: 0.1037\n",
      "Epoch 159/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.1418e-04 - accuracy: 1.0000 - val_loss: -12.5135 - val_accuracy: 0.1037\n",
      "Epoch 160/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.0093e-04 - accuracy: 1.0000 - val_loss: -12.3276 - val_accuracy: 0.1037\n",
      "Epoch 161/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9846e-04 - accuracy: 1.0000 - val_loss: -12.2820 - val_accuracy: 0.1098\n",
      "Epoch 162/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8860e-04 - accuracy: 1.0000 - val_loss: -12.5835 - val_accuracy: 0.1037\n",
      "Epoch 163/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7592e-04 - accuracy: 1.0000 - val_loss: -12.5995 - val_accuracy: 0.1037\n",
      "Epoch 164/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.6969e-04 - accuracy: 1.0000 - val_loss: -12.6838 - val_accuracy: 0.1037\n",
      "Epoch 165/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.6404e-04 - accuracy: 1.0000 - val_loss: -12.8948 - val_accuracy: 0.1037\n",
      "Epoch 166/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.5370e-04 - accuracy: 1.0000 - val_loss: -12.6451 - val_accuracy: 0.1098\n",
      "Epoch 167/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.5666e-04 - accuracy: 1.0000 - val_loss: -13.1633 - val_accuracy: 0.1037\n",
      "Epoch 168/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4670e-04 - accuracy: 1.0000 - val_loss: -12.8153 - val_accuracy: 0.1037\n",
      "Epoch 169/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.3908e-04 - accuracy: 1.0000 - val_loss: -12.9438 - val_accuracy: 0.1037\n",
      "Epoch 170/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.3037e-04 - accuracy: 1.0000 - val_loss: -12.7312 - val_accuracy: 0.1098\n",
      "Epoch 171/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2979e-04 - accuracy: 1.0000 - val_loss: -12.7258 - val_accuracy: 0.1098\n",
      "Epoch 172/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2204e-04 - accuracy: 1.0000 - val_loss: -12.8314 - val_accuracy: 0.1037\n",
      "Epoch 173/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1032e-04 - accuracy: 1.0000 - val_loss: -13.2455 - val_accuracy: 0.1037\n",
      "Epoch 174/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1238e-04 - accuracy: 1.0000 - val_loss: -12.9504 - val_accuracy: 0.1098\n",
      "Epoch 175/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0676e-04 - accuracy: 1.0000 - val_loss: -13.1302 - val_accuracy: 0.1037\n",
      "Epoch 176/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.0028e-04 - accuracy: 1.0000 - val_loss: -13.1360 - val_accuracy: 0.1037\n",
      "Epoch 177/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.6629e-05 - accuracy: 1.0000 - val_loss: -13.4064 - val_accuracy: 0.1037\n",
      "Epoch 178/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.4046e-05 - accuracy: 1.0000 - val_loss: -13.2203 - val_accuracy: 0.1098\n",
      "Epoch 179/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.9339e-05 - accuracy: 1.0000 - val_loss: -13.0855 - val_accuracy: 0.1098\n",
      "Epoch 180/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.7664e-05 - accuracy: 1.0000 - val_loss: -13.1982 - val_accuracy: 0.1098\n",
      "Epoch 181/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.7794e-05 - accuracy: 1.0000 - val_loss: -13.5048 - val_accuracy: 0.1037\n",
      "Epoch 182/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.8629e-05 - accuracy: 1.0000 - val_loss: -13.4306 - val_accuracy: 0.1037\n",
      "Epoch 183/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.1533e-05 - accuracy: 1.0000 - val_loss: -13.2826 - val_accuracy: 0.1098\n",
      "Epoch 184/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.9329e-05 - accuracy: 1.0000 - val_loss: -13.7021 - val_accuracy: 0.1037\n",
      "Epoch 185/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.7432e-05 - accuracy: 1.0000 - val_loss: -13.4203 - val_accuracy: 0.1098\n",
      "Epoch 186/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.3301e-05 - accuracy: 1.0000 - val_loss: -13.6040 - val_accuracy: 0.1037\n",
      "Epoch 187/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.5042e-05 - accuracy: 1.0000 - val_loss: -13.5207 - val_accuracy: 0.1037\n",
      "Epoch 188/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.7197e-05 - accuracy: 1.0000 - val_loss: -13.2349 - val_accuracy: 0.1098\n",
      "Epoch 189/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 5.9863e-05 - accuracy: 1.0000 - val_loss: -13.6705 - val_accuracy: 0.1037\n",
      "Epoch 190/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.4318e-05 - accuracy: 1.0000 - val_loss: -13.6484 - val_accuracy: 0.1037\n",
      "Epoch 191/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 5.0935e-05 - accuracy: 1.0000 - val_loss: -13.8546 - val_accuracy: 0.1037\n",
      "Epoch 192/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 4.8083e-05 - accuracy: 1.0000 - val_loss: -13.6952 - val_accuracy: 0.1098\n",
      "Epoch 193/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.8022e-05 - accuracy: 1.0000 - val_loss: -13.7847 - val_accuracy: 0.1098\n",
      "Epoch 194/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 4.5329e-05 - accuracy: 1.0000 - val_loss: -13.8855 - val_accuracy: 0.1037\n",
      "Epoch 195/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.3364e-05 - accuracy: 1.0000 - val_loss: -13.7898 - val_accuracy: 0.1098\n",
      "Epoch 196/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.2502e-05 - accuracy: 1.0000 - val_loss: -14.1371 - val_accuracy: 0.1037\n",
      "Epoch 197/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.1758e-05 - accuracy: 1.0000 - val_loss: -14.1008 - val_accuracy: 0.1037\n",
      "Epoch 198/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.0132e-05 - accuracy: 1.0000 - val_loss: -13.8755 - val_accuracy: 0.1098\n",
      "Epoch 199/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.6949e-05 - accuracy: 1.0000 - val_loss: -13.9219 - val_accuracy: 0.1098\n",
      "Epoch 200/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.6337e-05 - accuracy: 1.0000 - val_loss: -14.1539 - val_accuracy: 0.1037\n",
      "Epoch 201/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2678e-05 - accuracy: 1.0000 - val_loss: -13.8505 - val_accuracy: 0.1098\n",
      "Epoch 202/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.4183e-05 - accuracy: 1.0000 - val_loss: -13.8798 - val_accuracy: 0.1098\n",
      "Epoch 203/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.2383e-05 - accuracy: 1.0000 - val_loss: -14.2026 - val_accuracy: 0.1037\n",
      "Epoch 204/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.0536e-05 - accuracy: 1.0000 - val_loss: -14.2329 - val_accuracy: 0.1037\n",
      "Epoch 205/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.8125e-05 - accuracy: 1.0000 - val_loss: -14.2597 - val_accuracy: 0.1098\n",
      "Epoch 206/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.7658e-05 - accuracy: 1.0000 - val_loss: -14.2364 - val_accuracy: 0.1098\n",
      "Epoch 207/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6233e-05 - accuracy: 1.0000 - val_loss: -14.2024 - val_accuracy: 0.1098\n",
      "Epoch 208/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.5679e-05 - accuracy: 1.0000 - val_loss: -14.3198 - val_accuracy: 0.1037\n",
      "Epoch 209/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.4575e-05 - accuracy: 1.0000 - val_loss: -14.5008 - val_accuracy: 0.1037\n",
      "Epoch 210/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.3154e-05 - accuracy: 1.0000 - val_loss: -14.3776 - val_accuracy: 0.1098\n",
      "Epoch 211/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2088e-05 - accuracy: 1.0000 - val_loss: -14.3746 - val_accuracy: 0.1098\n",
      "Epoch 212/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2322e-05 - accuracy: 1.0000 - val_loss: -14.4696 - val_accuracy: 0.1098\n",
      "Epoch 213/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9926e-05 - accuracy: 1.0000 - val_loss: -14.5774 - val_accuracy: 0.1098\n",
      "Epoch 214/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.0521e-05 - accuracy: 1.0000 - val_loss: -14.6467 - val_accuracy: 0.1037\n",
      "Epoch 215/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.9838e-05 - accuracy: 1.0000 - val_loss: -14.6902 - val_accuracy: 0.1098\n",
      "Epoch 216/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9092e-05 - accuracy: 1.0000 - val_loss: -14.5820 - val_accuracy: 0.1098\n",
      "Epoch 217/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.7360e-05 - accuracy: 1.0000 - val_loss: -14.6701 - val_accuracy: 0.1098\n",
      "Epoch 218/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.7372e-05 - accuracy: 1.0000 - val_loss: -14.4317 - val_accuracy: 0.1098\n",
      "Epoch 219/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.6139e-05 - accuracy: 1.0000 - val_loss: -14.8149 - val_accuracy: 0.1098\n",
      "Epoch 220/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.5170e-05 - accuracy: 1.0000 - val_loss: -14.7354 - val_accuracy: 0.1098\n",
      "Epoch 221/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.4618e-05 - accuracy: 1.0000 - val_loss: -14.9957 - val_accuracy: 0.1037\n",
      "Epoch 222/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.4014e-05 - accuracy: 1.0000 - val_loss: -14.7317 - val_accuracy: 0.1098\n",
      "Epoch 223/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3779e-05 - accuracy: 1.0000 - val_loss: -14.8600 - val_accuracy: 0.1098\n",
      "Epoch 224/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.3367e-05 - accuracy: 1.0000 - val_loss: -14.8967 - val_accuracy: 0.1098\n",
      "Epoch 225/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.2167e-05 - accuracy: 1.0000 - val_loss: -14.8950 - val_accuracy: 0.1098\n",
      "Epoch 226/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2053e-05 - accuracy: 1.0000 - val_loss: -14.9536 - val_accuracy: 0.1098\n",
      "Epoch 227/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1998e-05 - accuracy: 1.0000 - val_loss: -15.0191 - val_accuracy: 0.1098\n",
      "Epoch 228/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1382e-05 - accuracy: 1.0000 - val_loss: -15.0210 - val_accuracy: 0.1098\n",
      "Epoch 229/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0754e-05 - accuracy: 1.0000 - val_loss: -15.1886 - val_accuracy: 0.1098\n",
      "Epoch 230/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1324e-05 - accuracy: 1.0000 - val_loss: -15.0323 - val_accuracy: 0.1098\n",
      "Epoch 231/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.0057e-05 - accuracy: 1.0000 - val_loss: -15.2483 - val_accuracy: 0.1037\n",
      "Epoch 232/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.8455e-06 - accuracy: 1.0000 - val_loss: -15.2580 - val_accuracy: 0.1098\n",
      "Epoch 233/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.1900e-06 - accuracy: 1.0000 - val_loss: -15.1316 - val_accuracy: 0.1098\n",
      "Epoch 234/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.8160e-06 - accuracy: 1.0000 - val_loss: -15.1564 - val_accuracy: 0.1098\n",
      "Epoch 235/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.3811e-06 - accuracy: 1.0000 - val_loss: -15.2136 - val_accuracy: 0.1098\n",
      "Epoch 236/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.8887e-06 - accuracy: 1.0000 - val_loss: -15.4270 - val_accuracy: 0.1098\n",
      "Epoch 237/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.8717e-06 - accuracy: 1.0000 - val_loss: -15.3201 - val_accuracy: 0.1098\n",
      "Epoch 238/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.7749e-06 - accuracy: 1.0000 - val_loss: -15.4516 - val_accuracy: 0.1098\n",
      "Epoch 239/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.4588e-06 - accuracy: 1.0000 - val_loss: -15.4129 - val_accuracy: 0.1098\n",
      "Epoch 240/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.8087e-06 - accuracy: 1.0000 - val_loss: -15.4284 - val_accuracy: 0.1098\n",
      "Epoch 241/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.5483e-06 - accuracy: 1.0000 - val_loss: -15.3148 - val_accuracy: 0.1098\n",
      "Epoch 242/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.3112e-06 - accuracy: 1.0000 - val_loss: -15.4722 - val_accuracy: 0.1098\n",
      "Epoch 243/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 6.0889e-06 - accuracy: 1.0000 - val_loss: -15.5093 - val_accuracy: 0.1098\n",
      "Epoch 244/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.0887e-06 - accuracy: 1.0000 - val_loss: -15.8551 - val_accuracy: 0.1037\n",
      "Epoch 245/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.1926e-06 - accuracy: 1.0000 - val_loss: -15.4798 - val_accuracy: 0.1098\n",
      "Epoch 246/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.2792e-06 - accuracy: 1.0000 - val_loss: -15.5792 - val_accuracy: 0.1098\n",
      "Epoch 247/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.5642e-06 - accuracy: 1.0000 - val_loss: -15.4051 - val_accuracy: 0.1098\n",
      "Epoch 248/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.2013e-06 - accuracy: 1.0000 - val_loss: -15.6116 - val_accuracy: 0.1098\n",
      "Epoch 249/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 4.7051e-06 - accuracy: 1.0000 - val_loss: -15.4817 - val_accuracy: 0.1098\n",
      "Epoch 250/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.5718e-06 - accuracy: 1.0000 - val_loss: -15.7325 - val_accuracy: 0.1098\n",
      "Epoch 251/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.3252e-06 - accuracy: 1.0000 - val_loss: -15.7006 - val_accuracy: 0.1098\n",
      "Epoch 252/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.3112e-06 - accuracy: 1.0000 - val_loss: -15.8779 - val_accuracy: 0.1098\n",
      "Epoch 253/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.2500e-06 - accuracy: 1.0000 - val_loss: -16.0608 - val_accuracy: 0.1037\n",
      "Epoch 254/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.2381e-06 - accuracy: 1.0000 - val_loss: -15.9699 - val_accuracy: 0.1037\n",
      "Epoch 255/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.8313e-06 - accuracy: 1.0000 - val_loss: -15.7353 - val_accuracy: 0.1098\n",
      "Epoch 256/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5255e-06 - accuracy: 1.0000 - val_loss: -15.9408 - val_accuracy: 0.1098\n",
      "Epoch 257/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.6096e-06 - accuracy: 1.0000 - val_loss: -15.9717 - val_accuracy: 0.1098\n",
      "Epoch 258/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.3123e-06 - accuracy: 1.0000 - val_loss: -15.9872 - val_accuracy: 0.1098\n",
      "Epoch 259/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2683e-06 - accuracy: 1.0000 - val_loss: -15.7827 - val_accuracy: 0.1098\n",
      "Epoch 260/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.0839e-06 - accuracy: 1.0000 - val_loss: -16.0112 - val_accuracy: 0.1098\n",
      "Epoch 261/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9168e-06 - accuracy: 1.0000 - val_loss: -15.9045 - val_accuracy: 0.1098\n",
      "Epoch 262/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.8662e-06 - accuracy: 1.0000 - val_loss: -16.0209 - val_accuracy: 0.1098\n",
      "Epoch 263/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.8504e-06 - accuracy: 1.0000 - val_loss: -16.0917 - val_accuracy: 0.1098\n",
      "Epoch 264/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.5994e-06 - accuracy: 1.0000 - val_loss: -16.1639 - val_accuracy: 0.1098\n",
      "Epoch 265/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6051e-06 - accuracy: 1.0000 - val_loss: -16.1398 - val_accuracy: 0.1098\n",
      "Epoch 266/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6088e-06 - accuracy: 1.0000 - val_loss: -16.1595 - val_accuracy: 0.1098\n",
      "Epoch 267/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.4973e-06 - accuracy: 1.0000 - val_loss: -16.0412 - val_accuracy: 0.1098\n",
      "Epoch 268/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.3216e-06 - accuracy: 1.0000 - val_loss: -16.1010 - val_accuracy: 0.1098\n",
      "Epoch 269/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1809e-06 - accuracy: 1.0000 - val_loss: -16.4179 - val_accuracy: 0.1098\n",
      "Epoch 270/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.1845e-06 - accuracy: 1.0000 - val_loss: -16.1019 - val_accuracy: 0.1098\n",
      "Epoch 271/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.0667e-06 - accuracy: 1.0000 - val_loss: -16.2114 - val_accuracy: 0.1098\n",
      "Epoch 272/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8992e-06 - accuracy: 1.0000 - val_loss: -16.4250 - val_accuracy: 0.1098\n",
      "Epoch 273/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9451e-06 - accuracy: 1.0000 - val_loss: -16.4109 - val_accuracy: 0.1098\n",
      "Epoch 274/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.9169e-06 - accuracy: 1.0000 - val_loss: -16.6160 - val_accuracy: 0.1098\n",
      "Epoch 275/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8591e-06 - accuracy: 1.0000 - val_loss: -16.5992 - val_accuracy: 0.1098\n",
      "Epoch 276/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.7477e-06 - accuracy: 1.0000 - val_loss: -16.6083 - val_accuracy: 0.1098\n",
      "Epoch 277/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6403e-06 - accuracy: 1.0000 - val_loss: -16.6169 - val_accuracy: 0.1098\n",
      "Epoch 278/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.5430e-06 - accuracy: 1.0000 - val_loss: -16.4353 - val_accuracy: 0.1098\n",
      "Epoch 279/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.5274e-06 - accuracy: 1.0000 - val_loss: -16.3404 - val_accuracy: 0.1098\n",
      "Epoch 280/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.4428e-06 - accuracy: 1.0000 - val_loss: -16.5503 - val_accuracy: 0.1098\n",
      "Epoch 281/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.3954e-06 - accuracy: 1.0000 - val_loss: -16.5568 - val_accuracy: 0.1098\n",
      "Epoch 282/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.3302e-06 - accuracy: 1.0000 - val_loss: -16.7038 - val_accuracy: 0.1098\n",
      "Epoch 283/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3115e-06 - accuracy: 1.0000 - val_loss: -16.6003 - val_accuracy: 0.1098\n",
      "Epoch 284/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.2355e-06 - accuracy: 1.0000 - val_loss: -16.7566 - val_accuracy: 0.1098\n",
      "Epoch 285/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1934e-06 - accuracy: 1.0000 - val_loss: -16.7425 - val_accuracy: 0.1098\n",
      "Epoch 286/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.1575e-06 - accuracy: 1.0000 - val_loss: -16.8603 - val_accuracy: 0.1098\n",
      "Epoch 287/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1015e-06 - accuracy: 1.0000 - val_loss: -16.4967 - val_accuracy: 0.1098\n",
      "Epoch 288/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1878e-06 - accuracy: 1.0000 - val_loss: -16.8118 - val_accuracy: 0.1098\n",
      "Epoch 289/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.9767e-07 - accuracy: 1.0000 - val_loss: -16.7204 - val_accuracy: 0.1098\n",
      "Epoch 290/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.0234e-06 - accuracy: 1.0000 - val_loss: -16.9376 - val_accuracy: 0.1098\n",
      "Epoch 291/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.7664e-07 - accuracy: 1.0000 - val_loss: -16.9151 - val_accuracy: 0.1098\n",
      "Epoch 292/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.7607e-07 - accuracy: 1.0000 - val_loss: -16.8954 - val_accuracy: 0.1098\n",
      "Epoch 293/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.2565e-07 - accuracy: 1.0000 - val_loss: -17.0474 - val_accuracy: 0.1098\n",
      "Epoch 294/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.9586e-07 - accuracy: 1.0000 - val_loss: -16.9611 - val_accuracy: 0.1098\n",
      "Epoch 295/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.1586e-07 - accuracy: 1.0000 - val_loss: -17.2907 - val_accuracy: 0.1098\n",
      "Epoch 296/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.8290e-07 - accuracy: 1.0000 - val_loss: -17.2458 - val_accuracy: 0.1098\n",
      "Epoch 297/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.8702e-07 - accuracy: 1.0000 - val_loss: -16.9765 - val_accuracy: 0.1098\n",
      "Epoch 298/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.5035e-07 - accuracy: 1.0000 - val_loss: -17.0197 - val_accuracy: 0.1098\n",
      "Epoch 299/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.1344e-07 - accuracy: 1.0000 - val_loss: -16.9675 - val_accuracy: 0.1098\n",
      "Epoch 300/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.8340e-07 - accuracy: 1.0000 - val_loss: -17.3026 - val_accuracy: 0.1098\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/300\n",
      "64/64 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.5508 - val_loss: 0.7568 - val_accuracy: 0.2134\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5547 - val_loss: 0.3832 - val_accuracy: 0.0671\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6543 - val_loss: 0.5151 - val_accuracy: 0.1463\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7070 - val_loss: 0.4050 - val_accuracy: 0.1890\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7441 - val_loss: -0.7462 - val_accuracy: 0.0854\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7500 - val_loss: -0.6106 - val_accuracy: 0.1463\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7539 - val_loss: -0.8958 - val_accuracy: 0.0976\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7539 - val_loss: -0.9981 - val_accuracy: 0.1220\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7598 - val_loss: -1.4196 - val_accuracy: 0.0854\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7793 - val_loss: -1.1494 - val_accuracy: 0.1463\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7715 - val_loss: -1.2367 - val_accuracy: 0.1585\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7910 - val_loss: -1.3578 - val_accuracy: 0.1463\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7773 - val_loss: -1.6868 - val_accuracy: 0.1220\n",
      "Epoch 14/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7891 - val_loss: -1.7254 - val_accuracy: 0.1280\n",
      "Epoch 15/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7949 - val_loss: -1.2857 - val_accuracy: 0.1707\n",
      "Epoch 16/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8066 - val_loss: -1.2628 - val_accuracy: 0.1341\n",
      "Epoch 17/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.8027 - val_loss: -1.5808 - val_accuracy: 0.1402\n",
      "Epoch 18/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: -0.4246 - val_accuracy: 0.1768\n",
      "Epoch 19/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8262 - val_loss: -1.1766 - val_accuracy: 0.1646\n",
      "Epoch 20/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8438 - val_loss: -1.2245 - val_accuracy: 0.1463\n",
      "Epoch 21/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8418 - val_loss: -3.1370 - val_accuracy: 0.0854\n",
      "Epoch 22/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8516 - val_loss: -1.8164 - val_accuracy: 0.1402\n",
      "Epoch 23/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8555 - val_loss: -2.0941 - val_accuracy: 0.1402\n",
      "Epoch 24/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8535 - val_loss: -1.6182 - val_accuracy: 0.1524\n",
      "Epoch 25/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.8555 - val_loss: -2.5096 - val_accuracy: 0.1402\n",
      "Epoch 26/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8711 - val_loss: -1.3014 - val_accuracy: 0.1280\n",
      "Epoch 27/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.9004 - val_loss: -2.3184 - val_accuracy: 0.1341\n",
      "Epoch 28/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9004 - val_loss: -2.5479 - val_accuracy: 0.1463\n",
      "Epoch 29/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.8984 - val_loss: -3.7003 - val_accuracy: 0.1159\n",
      "Epoch 30/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8828 - val_loss: -3.6795 - val_accuracy: 0.1220\n",
      "Epoch 31/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8828 - val_loss: -2.5516 - val_accuracy: 0.1280\n",
      "Epoch 32/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.9082 - val_loss: -2.6297 - val_accuracy: 0.1098\n",
      "Epoch 33/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9316 - val_loss: -3.1440 - val_accuracy: 0.1220\n",
      "Epoch 34/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.8926 - val_loss: -3.2945 - val_accuracy: 0.1280\n",
      "Epoch 35/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.8906 - val_loss: -3.2227 - val_accuracy: 0.1159\n",
      "Epoch 36/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9277 - val_loss: -4.6336 - val_accuracy: 0.1098\n",
      "Epoch 37/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9258 - val_loss: -4.1187 - val_accuracy: 0.1159\n",
      "Epoch 38/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9160 - val_loss: -3.8541 - val_accuracy: 0.1280\n",
      "Epoch 39/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1795 - accuracy: 0.9297 - val_loss: -4.2090 - val_accuracy: 0.1037\n",
      "Epoch 40/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.9238 - val_loss: -3.7176 - val_accuracy: 0.1098\n",
      "Epoch 41/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9570 - val_loss: -3.4248 - val_accuracy: 0.1280\n",
      "Epoch 42/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9375 - val_loss: -2.9858 - val_accuracy: 0.1220\n",
      "Epoch 43/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9434 - val_loss: -3.0345 - val_accuracy: 0.1402\n",
      "Epoch 44/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9707 - val_loss: -4.5180 - val_accuracy: 0.1037\n",
      "Epoch 45/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9609 - val_loss: -3.0685 - val_accuracy: 0.1280\n",
      "Epoch 46/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9492 - val_loss: -4.1680 - val_accuracy: 0.1098\n",
      "Epoch 47/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9570 - val_loss: -5.1098 - val_accuracy: 0.0854\n",
      "Epoch 48/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9473 - val_loss: -5.5426 - val_accuracy: 0.1098\n",
      "Epoch 49/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9668 - val_loss: -4.9876 - val_accuracy: 0.0915\n",
      "Epoch 50/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9785 - val_loss: -1.7401 - val_accuracy: 0.1524\n",
      "Epoch 51/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9453 - val_loss: -3.3455 - val_accuracy: 0.1098\n",
      "Epoch 52/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9688 - val_loss: -5.8882 - val_accuracy: 0.1159\n",
      "Epoch 53/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9766 - val_loss: -5.7070 - val_accuracy: 0.1037\n",
      "Epoch 54/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9863 - val_loss: -6.5992 - val_accuracy: 0.0793\n",
      "Epoch 55/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9590 - val_loss: -5.8720 - val_accuracy: 0.1037\n",
      "Epoch 56/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9375 - val_loss: -2.2738 - val_accuracy: 0.1402\n",
      "Epoch 57/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9297 - val_loss: -4.7478 - val_accuracy: 0.1220\n",
      "Epoch 58/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9414 - val_loss: -4.6464 - val_accuracy: 0.1220\n",
      "Epoch 59/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9727 - val_loss: -6.9583 - val_accuracy: 0.0793\n",
      "Epoch 60/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9746 - val_loss: -6.5248 - val_accuracy: 0.0549\n",
      "Epoch 61/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9902 - val_loss: -4.1970 - val_accuracy: 0.1159\n",
      "Epoch 62/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9883 - val_loss: -5.0787 - val_accuracy: 0.1341\n",
      "Epoch 63/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9941 - val_loss: -4.6418 - val_accuracy: 0.1220\n",
      "Epoch 64/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9883 - val_loss: -4.8904 - val_accuracy: 0.0976\n",
      "Epoch 65/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9922 - val_loss: -7.6355 - val_accuracy: 0.0671\n",
      "Epoch 66/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9863 - val_loss: -7.6914 - val_accuracy: 0.0610\n",
      "Epoch 67/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9922 - val_loss: -7.9755 - val_accuracy: 0.0732\n",
      "Epoch 68/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: -6.7277 - val_accuracy: 0.1037\n",
      "Epoch 69/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9883 - val_loss: -6.6323 - val_accuracy: 0.0793\n",
      "Epoch 70/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: -6.6199 - val_accuracy: 0.0915\n",
      "Epoch 71/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: -7.0421 - val_accuracy: 0.0915\n",
      "Epoch 72/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: -7.0717 - val_accuracy: 0.0854\n",
      "Epoch 73/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: -6.8268 - val_accuracy: 0.0976\n",
      "Epoch 74/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9941 - val_loss: -6.2760 - val_accuracy: 0.0976\n",
      "Epoch 75/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -6.7551 - val_accuracy: 0.0976\n",
      "Epoch 76/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -7.4808 - val_accuracy: 0.0976\n",
      "Epoch 77/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -8.3648 - val_accuracy: 0.0793\n",
      "Epoch 78/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: -8.1815 - val_accuracy: 0.0671\n",
      "Epoch 79/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: -8.0078 - val_accuracy: 0.0854\n",
      "Epoch 80/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: -6.3717 - val_accuracy: 0.0976\n",
      "Epoch 81/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: -5.2153 - val_accuracy: 0.1098\n",
      "Epoch 82/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9824 - val_loss: -11.6571 - val_accuracy: 0.0610\n",
      "Epoch 83/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.8145 - val_loss: -4.2804 - val_accuracy: 0.1037\n",
      "Epoch 84/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9102 - val_loss: -6.3220 - val_accuracy: 0.1098\n",
      "Epoch 85/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9531 - val_loss: -5.5965 - val_accuracy: 0.1098\n",
      "Epoch 86/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: -5.8190 - val_accuracy: 0.0915\n",
      "Epoch 87/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9824 - val_loss: -6.2532 - val_accuracy: 0.1098\n",
      "Epoch 88/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9922 - val_loss: -7.1384 - val_accuracy: 0.0793\n",
      "Epoch 89/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9961 - val_loss: -5.9957 - val_accuracy: 0.1280\n",
      "Epoch 90/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9590 - val_loss: -6.1034 - val_accuracy: 0.1159\n",
      "Epoch 91/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9414 - val_loss: -5.9610 - val_accuracy: 0.1098\n",
      "Epoch 92/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9609 - val_loss: -7.7079 - val_accuracy: 0.0793\n",
      "Epoch 93/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9844 - val_loss: -7.6107 - val_accuracy: 0.0854\n",
      "Epoch 94/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: -6.9741 - val_accuracy: 0.1037\n",
      "Epoch 95/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: -7.5639 - val_accuracy: 0.0854\n",
      "Epoch 96/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: -8.0744 - val_accuracy: 0.0793\n",
      "Epoch 97/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: -7.4803 - val_accuracy: 0.1037\n",
      "Epoch 98/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: -7.3146 - val_accuracy: 0.0976\n",
      "Epoch 99/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -7.7026 - val_accuracy: 0.0976\n",
      "Epoch 100/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: -7.8938 - val_accuracy: 0.0915\n",
      "Epoch 101/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: -7.4962 - val_accuracy: 0.0915\n",
      "Epoch 102/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -7.4154 - val_accuracy: 0.1037\n",
      "Epoch 103/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -7.1452 - val_accuracy: 0.1037\n",
      "Epoch 104/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -7.9373 - val_accuracy: 0.0915\n",
      "Epoch 105/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.9447 - val_accuracy: 0.0915\n",
      "Epoch 106/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -7.7330 - val_accuracy: 0.0915\n",
      "Epoch 107/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.1194 - val_accuracy: 0.0915\n",
      "Epoch 108/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.8394 - val_accuracy: 0.0915\n",
      "Epoch 109/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.7275 - val_accuracy: 0.0915\n",
      "Epoch 110/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.0923 - val_accuracy: 0.0915\n",
      "Epoch 111/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.9237 - val_accuracy: 0.0915\n",
      "Epoch 112/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.3042 - val_accuracy: 0.0915\n",
      "Epoch 113/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.1824 - val_accuracy: 0.0915\n",
      "Epoch 114/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 9.5695e-04 - accuracy: 1.0000 - val_loss: -8.1414 - val_accuracy: 0.0915\n",
      "Epoch 115/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.6769e-04 - accuracy: 1.0000 - val_loss: -8.2865 - val_accuracy: 0.0915\n",
      "Epoch 116/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.0483e-04 - accuracy: 1.0000 - val_loss: -8.3718 - val_accuracy: 0.0915\n",
      "Epoch 117/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.7679e-04 - accuracy: 1.0000 - val_loss: -8.2222 - val_accuracy: 0.0915\n",
      "Epoch 118/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.4241e-04 - accuracy: 1.0000 - val_loss: -8.0348 - val_accuracy: 0.0915\n",
      "Epoch 119/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.1228e-04 - accuracy: 1.0000 - val_loss: -8.0746 - val_accuracy: 0.0915\n",
      "Epoch 120/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.9138e-04 - accuracy: 1.0000 - val_loss: -8.3813 - val_accuracy: 0.0915\n",
      "Epoch 121/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.4416e-04 - accuracy: 1.0000 - val_loss: -8.3369 - val_accuracy: 0.0915\n",
      "Epoch 122/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.3764e-04 - accuracy: 1.0000 - val_loss: -8.5788 - val_accuracy: 0.0915\n",
      "Epoch 123/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.1993e-04 - accuracy: 1.0000 - val_loss: -8.3029 - val_accuracy: 0.0915\n",
      "Epoch 124/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.3300e-04 - accuracy: 1.0000 - val_loss: -8.3421 - val_accuracy: 0.0915\n",
      "Epoch 125/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.1987e-04 - accuracy: 1.0000 - val_loss: -8.4743 - val_accuracy: 0.0915\n",
      "Epoch 126/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.2196e-04 - accuracy: 1.0000 - val_loss: -8.5547 - val_accuracy: 0.0915\n",
      "Epoch 127/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.6049e-04 - accuracy: 1.0000 - val_loss: -8.1683 - val_accuracy: 0.0915\n",
      "Epoch 128/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.5253e-04 - accuracy: 1.0000 - val_loss: -8.6790 - val_accuracy: 0.0915\n",
      "Epoch 129/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.3244e-04 - accuracy: 1.0000 - val_loss: -8.3385 - val_accuracy: 0.0915\n",
      "Epoch 130/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.0802e-04 - accuracy: 1.0000 - val_loss: -8.3491 - val_accuracy: 0.0915\n",
      "Epoch 131/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.3542e-04 - accuracy: 1.0000 - val_loss: -8.7107 - val_accuracy: 0.0915\n",
      "Epoch 132/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.6208e-04 - accuracy: 1.0000 - val_loss: -8.1205 - val_accuracy: 0.0915\n",
      "Epoch 133/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5933e-04 - accuracy: 1.0000 - val_loss: -8.8139 - val_accuracy: 0.0915\n",
      "Epoch 134/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.4681e-04 - accuracy: 1.0000 - val_loss: -8.9573 - val_accuracy: 0.0915\n",
      "Epoch 135/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2386e-04 - accuracy: 1.0000 - val_loss: -8.8066 - val_accuracy: 0.0915\n",
      "Epoch 136/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.1416e-04 - accuracy: 1.0000 - val_loss: -8.7499 - val_accuracy: 0.0915\n",
      "Epoch 137/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.3879e-04 - accuracy: 1.0000 - val_loss: -8.8585 - val_accuracy: 0.0915\n",
      "Epoch 138/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.8228e-04 - accuracy: 1.0000 - val_loss: -8.6243 - val_accuracy: 0.0915\n",
      "Epoch 139/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.5858e-04 - accuracy: 1.0000 - val_loss: -8.8762 - val_accuracy: 0.0915\n",
      "Epoch 140/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9511e-04 - accuracy: 1.0000 - val_loss: -8.8702 - val_accuracy: 0.0915\n",
      "Epoch 141/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.1415e-04 - accuracy: 1.0000 - val_loss: -8.8855 - val_accuracy: 0.0915\n",
      "Epoch 142/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.3016e-04 - accuracy: 1.0000 - val_loss: -8.6359 - val_accuracy: 0.0915\n",
      "Epoch 143/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.3561e-04 - accuracy: 1.0000 - val_loss: -8.7397 - val_accuracy: 0.0915\n",
      "Epoch 144/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1744e-04 - accuracy: 1.0000 - val_loss: -8.7517 - val_accuracy: 0.0915\n",
      "Epoch 145/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1649e-04 - accuracy: 1.0000 - val_loss: -8.8951 - val_accuracy: 0.0915\n",
      "Epoch 146/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.9824e-04 - accuracy: 1.0000 - val_loss: -9.0269 - val_accuracy: 0.0915\n",
      "Epoch 147/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.0162e-04 - accuracy: 1.0000 - val_loss: -9.0837 - val_accuracy: 0.0915\n",
      "Epoch 148/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.9499e-04 - accuracy: 1.0000 - val_loss: -8.9506 - val_accuracy: 0.0915\n",
      "Epoch 149/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6577e-04 - accuracy: 1.0000 - val_loss: -8.8007 - val_accuracy: 0.0915\n",
      "Epoch 150/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7999e-04 - accuracy: 1.0000 - val_loss: -8.8535 - val_accuracy: 0.0915\n",
      "Epoch 151/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.4984e-04 - accuracy: 1.0000 - val_loss: -9.2828 - val_accuracy: 0.0915\n",
      "Epoch 152/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.5056e-04 - accuracy: 1.0000 - val_loss: -9.0242 - val_accuracy: 0.0915\n",
      "Epoch 153/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.4044e-04 - accuracy: 1.0000 - val_loss: -9.3301 - val_accuracy: 0.0915\n",
      "Epoch 154/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.3729e-04 - accuracy: 1.0000 - val_loss: -9.0496 - val_accuracy: 0.0915\n",
      "Epoch 155/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.2983e-04 - accuracy: 1.0000 - val_loss: -8.9207 - val_accuracy: 0.0915\n",
      "Epoch 156/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3700e-04 - accuracy: 1.0000 - val_loss: -9.1247 - val_accuracy: 0.0915\n",
      "Epoch 157/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1920e-04 - accuracy: 1.0000 - val_loss: -9.1861 - val_accuracy: 0.0915\n",
      "Epoch 158/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1712e-04 - accuracy: 1.0000 - val_loss: -9.0124 - val_accuracy: 0.0915\n",
      "Epoch 159/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.1686e-04 - accuracy: 1.0000 - val_loss: -9.2370 - val_accuracy: 0.0915\n",
      "Epoch 160/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.0537e-04 - accuracy: 1.0000 - val_loss: -9.3653 - val_accuracy: 0.0915\n",
      "Epoch 161/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.8667e-05 - accuracy: 1.0000 - val_loss: -9.4199 - val_accuracy: 0.0915\n",
      "Epoch 162/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.2710e-05 - accuracy: 1.0000 - val_loss: -9.2892 - val_accuracy: 0.0915\n",
      "Epoch 163/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.1490e-05 - accuracy: 1.0000 - val_loss: -9.3892 - val_accuracy: 0.0915\n",
      "Epoch 164/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.0756e-05 - accuracy: 1.0000 - val_loss: -9.3885 - val_accuracy: 0.0915\n",
      "Epoch 165/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.3551e-05 - accuracy: 1.0000 - val_loss: -9.4259 - val_accuracy: 0.0915\n",
      "Epoch 166/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.1276e-05 - accuracy: 1.0000 - val_loss: -9.3266 - val_accuracy: 0.0915\n",
      "Epoch 167/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.0926e-05 - accuracy: 1.0000 - val_loss: -9.5274 - val_accuracy: 0.0915\n",
      "Epoch 168/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.9460e-05 - accuracy: 1.0000 - val_loss: -9.4137 - val_accuracy: 0.0915\n",
      "Epoch 169/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.9529e-05 - accuracy: 1.0000 - val_loss: -9.3022 - val_accuracy: 0.0915\n",
      "Epoch 170/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.8856e-05 - accuracy: 1.0000 - val_loss: -9.6630 - val_accuracy: 0.0915\n",
      "Epoch 171/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.6921e-05 - accuracy: 1.0000 - val_loss: -9.6271 - val_accuracy: 0.0915\n",
      "Epoch 172/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.4752e-05 - accuracy: 1.0000 - val_loss: -9.2926 - val_accuracy: 0.0915\n",
      "Epoch 173/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.2452e-05 - accuracy: 1.0000 - val_loss: -9.5408 - val_accuracy: 0.0915\n",
      "Epoch 174/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.8379e-05 - accuracy: 1.0000 - val_loss: -9.4305 - val_accuracy: 0.0915\n",
      "Epoch 175/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.7570e-05 - accuracy: 1.0000 - val_loss: -9.4297 - val_accuracy: 0.0915\n",
      "Epoch 176/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.3403e-05 - accuracy: 1.0000 - val_loss: -9.7052 - val_accuracy: 0.0915\n",
      "Epoch 177/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.2744e-05 - accuracy: 1.0000 - val_loss: -9.5297 - val_accuracy: 0.0915\n",
      "Epoch 178/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.9147e-05 - accuracy: 1.0000 - val_loss: -9.8955 - val_accuracy: 0.0915\n",
      "Epoch 179/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.6569e-05 - accuracy: 1.0000 - val_loss: -9.4206 - val_accuracy: 0.0915\n",
      "Epoch 180/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.7873e-05 - accuracy: 1.0000 - val_loss: -9.5618 - val_accuracy: 0.0915\n",
      "Epoch 181/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.3779e-05 - accuracy: 1.0000 - val_loss: -9.5538 - val_accuracy: 0.0915\n",
      "Epoch 182/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.4485e-05 - accuracy: 1.0000 - val_loss: -9.7940 - val_accuracy: 0.0915\n",
      "Epoch 183/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.1268e-05 - accuracy: 1.0000 - val_loss: -9.8099 - val_accuracy: 0.0915\n",
      "Epoch 184/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.0343e-05 - accuracy: 1.0000 - val_loss: -9.6662 - val_accuracy: 0.0915\n",
      "Epoch 185/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.7961e-05 - accuracy: 1.0000 - val_loss: -9.6876 - val_accuracy: 0.0915\n",
      "Epoch 186/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5685e-05 - accuracy: 1.0000 - val_loss: -9.9486 - val_accuracy: 0.0915\n",
      "Epoch 187/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.5919e-05 - accuracy: 1.0000 - val_loss: -9.7540 - val_accuracy: 0.0915\n",
      "Epoch 188/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2536e-05 - accuracy: 1.0000 - val_loss: -9.6345 - val_accuracy: 0.0915\n",
      "Epoch 189/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.4077e-05 - accuracy: 1.0000 - val_loss: -10.1161 - val_accuracy: 0.0915\n",
      "Epoch 190/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.3267e-05 - accuracy: 1.0000 - val_loss: -9.8268 - val_accuracy: 0.0915\n",
      "Epoch 191/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.0057e-05 - accuracy: 1.0000 - val_loss: -9.7881 - val_accuracy: 0.0915\n",
      "Epoch 192/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.8646e-05 - accuracy: 1.0000 - val_loss: -9.8447 - val_accuracy: 0.0915\n",
      "Epoch 193/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.7930e-05 - accuracy: 1.0000 - val_loss: -9.9314 - val_accuracy: 0.0915\n",
      "Epoch 194/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.7129e-05 - accuracy: 1.0000 - val_loss: -10.0280 - val_accuracy: 0.0915\n",
      "Epoch 195/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.6073e-05 - accuracy: 1.0000 - val_loss: -9.9925 - val_accuracy: 0.0915\n",
      "Epoch 196/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.4909e-05 - accuracy: 1.0000 - val_loss: -10.0644 - val_accuracy: 0.0915\n",
      "Epoch 197/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2681e-05 - accuracy: 1.0000 - val_loss: -9.8875 - val_accuracy: 0.0915\n",
      "Epoch 198/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.3714e-05 - accuracy: 1.0000 - val_loss: -10.0325 - val_accuracy: 0.0915\n",
      "Epoch 199/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.1672e-05 - accuracy: 1.0000 - val_loss: -10.1112 - val_accuracy: 0.0915\n",
      "Epoch 200/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.0941e-05 - accuracy: 1.0000 - val_loss: -10.0288 - val_accuracy: 0.0915\n",
      "Epoch 201/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.1441e-05 - accuracy: 1.0000 - val_loss: -10.2543 - val_accuracy: 0.0915\n",
      "Epoch 202/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.9478e-05 - accuracy: 1.0000 - val_loss: -10.0507 - val_accuracy: 0.0915\n",
      "Epoch 203/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.9433e-05 - accuracy: 1.0000 - val_loss: -10.0610 - val_accuracy: 0.0915\n",
      "Epoch 204/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8492e-05 - accuracy: 1.0000 - val_loss: -10.1207 - val_accuracy: 0.0915\n",
      "Epoch 205/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.7335e-05 - accuracy: 1.0000 - val_loss: -10.1414 - val_accuracy: 0.0915\n",
      "Epoch 206/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6668e-05 - accuracy: 1.0000 - val_loss: -10.0562 - val_accuracy: 0.0915\n",
      "Epoch 207/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7080e-05 - accuracy: 1.0000 - val_loss: -10.2152 - val_accuracy: 0.0915\n",
      "Epoch 208/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.5490e-05 - accuracy: 1.0000 - val_loss: -10.3438 - val_accuracy: 0.0915\n",
      "Epoch 209/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.4952e-05 - accuracy: 1.0000 - val_loss: -10.1134 - val_accuracy: 0.0915\n",
      "Epoch 210/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6137e-05 - accuracy: 1.0000 - val_loss: -10.1327 - val_accuracy: 0.0915\n",
      "Epoch 211/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.4111e-05 - accuracy: 1.0000 - val_loss: -10.3422 - val_accuracy: 0.0915\n",
      "Epoch 212/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3882e-05 - accuracy: 1.0000 - val_loss: -10.2729 - val_accuracy: 0.0915\n",
      "Epoch 213/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3412e-05 - accuracy: 1.0000 - val_loss: -10.3753 - val_accuracy: 0.0915\n",
      "Epoch 214/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2517e-05 - accuracy: 1.0000 - val_loss: -10.4470 - val_accuracy: 0.0915\n",
      "Epoch 215/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1791e-05 - accuracy: 1.0000 - val_loss: -10.4529 - val_accuracy: 0.0915\n",
      "Epoch 216/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2785e-05 - accuracy: 1.0000 - val_loss: -10.3169 - val_accuracy: 0.0915\n",
      "Epoch 217/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1398e-05 - accuracy: 1.0000 - val_loss: -10.5200 - val_accuracy: 0.0915\n",
      "Epoch 218/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0889e-05 - accuracy: 1.0000 - val_loss: -10.1797 - val_accuracy: 0.0915\n",
      "Epoch 219/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0788e-05 - accuracy: 1.0000 - val_loss: -10.5982 - val_accuracy: 0.0915\n",
      "Epoch 220/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.2808e-05 - accuracy: 1.0000 - val_loss: -10.8900 - val_accuracy: 0.0854\n",
      "Epoch 221/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.0447e-05 - accuracy: 1.0000 - val_loss: -10.7471 - val_accuracy: 0.0915\n",
      "Epoch 222/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.9604e-06 - accuracy: 1.0000 - val_loss: -10.6754 - val_accuracy: 0.0915\n",
      "Epoch 223/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.1104e-06 - accuracy: 1.0000 - val_loss: -10.4573 - val_accuracy: 0.0915\n",
      "Epoch 224/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.5390e-06 - accuracy: 1.0000 - val_loss: -10.6443 - val_accuracy: 0.0915\n",
      "Epoch 225/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.2053e-06 - accuracy: 1.0000 - val_loss: -10.8330 - val_accuracy: 0.0915\n",
      "Epoch 226/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.9689e-06 - accuracy: 1.0000 - val_loss: -10.8044 - val_accuracy: 0.0915\n",
      "Epoch 227/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.9183e-06 - accuracy: 1.0000 - val_loss: -10.8430 - val_accuracy: 0.0915\n",
      "Epoch 228/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.4557e-06 - accuracy: 1.0000 - val_loss: -10.5799 - val_accuracy: 0.0915\n",
      "Epoch 229/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.7595e-06 - accuracy: 1.0000 - val_loss: -10.7779 - val_accuracy: 0.0915\n",
      "Epoch 230/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.8608e-06 - accuracy: 1.0000 - val_loss: -10.8039 - val_accuracy: 0.0915\n",
      "Epoch 231/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.5028e-06 - accuracy: 1.0000 - val_loss: -10.8679 - val_accuracy: 0.0915\n",
      "Epoch 232/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.3113e-06 - accuracy: 1.0000 - val_loss: -10.8086 - val_accuracy: 0.0915\n",
      "Epoch 233/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.0182e-06 - accuracy: 1.0000 - val_loss: -10.7248 - val_accuracy: 0.0915\n",
      "Epoch 234/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.7727e-06 - accuracy: 1.0000 - val_loss: -10.9205 - val_accuracy: 0.0915\n",
      "Epoch 235/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.6233e-06 - accuracy: 1.0000 - val_loss: -10.8030 - val_accuracy: 0.0915\n",
      "Epoch 236/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.5978e-06 - accuracy: 1.0000 - val_loss: -10.9639 - val_accuracy: 0.0915\n",
      "Epoch 237/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.1232e-06 - accuracy: 1.0000 - val_loss: -10.8567 - val_accuracy: 0.0915\n",
      "Epoch 238/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.0735e-06 - accuracy: 1.0000 - val_loss: -10.9148 - val_accuracy: 0.0915\n",
      "Epoch 239/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.8925e-06 - accuracy: 1.0000 - val_loss: -10.9863 - val_accuracy: 0.0915\n",
      "Epoch 240/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.6382e-06 - accuracy: 1.0000 - val_loss: -10.8924 - val_accuracy: 0.0915\n",
      "Epoch 241/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.4213e-06 - accuracy: 1.0000 - val_loss: -11.0820 - val_accuracy: 0.0915\n",
      "Epoch 242/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.4784e-06 - accuracy: 1.0000 - val_loss: -11.1108 - val_accuracy: 0.0915\n",
      "Epoch 243/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.2915e-06 - accuracy: 1.0000 - val_loss: -11.0534 - val_accuracy: 0.0915\n",
      "Epoch 244/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.0626e-06 - accuracy: 1.0000 - val_loss: -10.9890 - val_accuracy: 0.0915\n",
      "Epoch 245/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.0883e-06 - accuracy: 1.0000 - val_loss: -11.3666 - val_accuracy: 0.0915\n",
      "Epoch 246/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.6468e-06 - accuracy: 1.0000 - val_loss: -10.9545 - val_accuracy: 0.0915\n",
      "Epoch 247/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5881e-06 - accuracy: 1.0000 - val_loss: -11.4709 - val_accuracy: 0.0915\n",
      "Epoch 248/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.4270e-06 - accuracy: 1.0000 - val_loss: -10.9745 - val_accuracy: 0.0915\n",
      "Epoch 249/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.8613e-06 - accuracy: 1.0000 - val_loss: -11.2445 - val_accuracy: 0.0915\n",
      "Epoch 250/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.1911e-06 - accuracy: 1.0000 - val_loss: -11.1758 - val_accuracy: 0.0915\n",
      "Epoch 251/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2136e-06 - accuracy: 1.0000 - val_loss: -11.2025 - val_accuracy: 0.0915\n",
      "Epoch 252/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.9777e-06 - accuracy: 1.0000 - val_loss: -11.2875 - val_accuracy: 0.0915\n",
      "Epoch 253/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9408e-06 - accuracy: 1.0000 - val_loss: -11.4370 - val_accuracy: 0.0915\n",
      "Epoch 254/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9312e-06 - accuracy: 1.0000 - val_loss: -11.1064 - val_accuracy: 0.0915\n",
      "Epoch 255/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6328e-06 - accuracy: 1.0000 - val_loss: -11.3658 - val_accuracy: 0.0915\n",
      "Epoch 256/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.6034e-06 - accuracy: 1.0000 - val_loss: -11.3978 - val_accuracy: 0.0915\n",
      "Epoch 257/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.4255e-06 - accuracy: 1.0000 - val_loss: -11.3427 - val_accuracy: 0.0915\n",
      "Epoch 258/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.6852e-06 - accuracy: 1.0000 - val_loss: -11.3415 - val_accuracy: 0.0915\n",
      "Epoch 259/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 2.1838e-06 - accuracy: 1.0000 - val_loss: -11.1904 - val_accuracy: 0.0915\n",
      "Epoch 260/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.1621e-06 - accuracy: 1.0000 - val_loss: -11.4628 - val_accuracy: 0.0915\n",
      "Epoch 261/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.0034e-06 - accuracy: 1.0000 - val_loss: -11.3797 - val_accuracy: 0.0915\n",
      "Epoch 262/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.9642e-06 - accuracy: 1.0000 - val_loss: -11.3970 - val_accuracy: 0.0915\n",
      "Epoch 263/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8781e-06 - accuracy: 1.0000 - val_loss: -11.1356 - val_accuracy: 0.0915\n",
      "Epoch 264/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.9530e-06 - accuracy: 1.0000 - val_loss: -11.3717 - val_accuracy: 0.0915\n",
      "Epoch 265/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8118e-06 - accuracy: 1.0000 - val_loss: -11.4327 - val_accuracy: 0.0915\n",
      "Epoch 266/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.7265e-06 - accuracy: 1.0000 - val_loss: -11.6070 - val_accuracy: 0.0915\n",
      "Epoch 267/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7169e-06 - accuracy: 1.0000 - val_loss: -11.6016 - val_accuracy: 0.0915\n",
      "Epoch 268/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.6764e-06 - accuracy: 1.0000 - val_loss: -11.5765 - val_accuracy: 0.0915\n",
      "Epoch 269/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7038e-06 - accuracy: 1.0000 - val_loss: -11.3459 - val_accuracy: 0.0915\n",
      "Epoch 270/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.5384e-06 - accuracy: 1.0000 - val_loss: -11.3669 - val_accuracy: 0.0915\n",
      "Epoch 271/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.4603e-06 - accuracy: 1.0000 - val_loss: -11.6597 - val_accuracy: 0.0915\n",
      "Epoch 272/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.3730e-06 - accuracy: 1.0000 - val_loss: -11.5400 - val_accuracy: 0.0915\n",
      "Epoch 273/300\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 1.3774e-06 - accuracy: 1.0000 - val_loss: -11.4655 - val_accuracy: 0.0915\n",
      "Epoch 274/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.2798e-06 - accuracy: 1.0000 - val_loss: -11.7018 - val_accuracy: 0.0915\n",
      "Epoch 275/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.2615e-06 - accuracy: 1.0000 - val_loss: -11.5954 - val_accuracy: 0.0915\n",
      "Epoch 276/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.1784e-06 - accuracy: 1.0000 - val_loss: -11.7405 - val_accuracy: 0.0915\n",
      "Epoch 277/300\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 1.2233e-06 - accuracy: 1.0000 - val_loss: -11.7580 - val_accuracy: 0.0915\n",
      "Epoch 278/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.0936e-06 - accuracy: 1.0000 - val_loss: -11.7158 - val_accuracy: 0.0915\n",
      "Epoch 279/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.1184e-06 - accuracy: 1.0000 - val_loss: -11.9024 - val_accuracy: 0.0915\n",
      "Epoch 280/300\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 1.0256e-06 - accuracy: 1.0000 - val_loss: -11.7138 - val_accuracy: 0.0915\n",
      "Epoch 281/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.0493e-06 - accuracy: 1.0000 - val_loss: -11.5681 - val_accuracy: 0.0915\n",
      "Epoch 282/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.0567e-06 - accuracy: 1.0000 - val_loss: -11.6517 - val_accuracy: 0.0915\n",
      "Epoch 283/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 9.2032e-07 - accuracy: 1.0000 - val_loss: -11.7146 - val_accuracy: 0.0915\n",
      "Epoch 284/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 8.9221e-07 - accuracy: 1.0000 - val_loss: -11.6113 - val_accuracy: 0.0915\n",
      "Epoch 285/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 8.7475e-07 - accuracy: 1.0000 - val_loss: -11.7781 - val_accuracy: 0.0915\n",
      "Epoch 286/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.0024e-07 - accuracy: 1.0000 - val_loss: -11.8767 - val_accuracy: 0.0915\n",
      "Epoch 287/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.9525e-07 - accuracy: 1.0000 - val_loss: -11.7240 - val_accuracy: 0.0915\n",
      "Epoch 288/300\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 7.7122e-07 - accuracy: 1.0000 - val_loss: -11.6364 - val_accuracy: 0.0915\n",
      "Epoch 289/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.9515e-07 - accuracy: 1.0000 - val_loss: -11.9348 - val_accuracy: 0.0915\n",
      "Epoch 290/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.9352e-07 - accuracy: 1.0000 - val_loss: -11.9069 - val_accuracy: 0.0915\n",
      "Epoch 291/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6413e-07 - accuracy: 1.0000 - val_loss: -12.1273 - val_accuracy: 0.0915\n",
      "Epoch 292/300\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 6.6194e-07 - accuracy: 1.0000 - val_loss: -12.2656 - val_accuracy: 0.0915\n",
      "Epoch 293/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.3983e-07 - accuracy: 1.0000 - val_loss: -12.1296 - val_accuracy: 0.0915\n",
      "Epoch 294/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.0975e-07 - accuracy: 1.0000 - val_loss: -11.9115 - val_accuracy: 0.0915\n",
      "Epoch 295/300\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 5.8957e-07 - accuracy: 1.0000 - val_loss: -12.0125 - val_accuracy: 0.0915\n",
      "Epoch 296/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 5.4924e-07 - accuracy: 1.0000 - val_loss: -12.0720 - val_accuracy: 0.0915\n",
      "Epoch 297/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 5.5900e-07 - accuracy: 1.0000 - val_loss: -12.0695 - val_accuracy: 0.0915\n",
      "Epoch 298/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 5.4412e-07 - accuracy: 1.0000 - val_loss: -12.1772 - val_accuracy: 0.0915\n",
      "Epoch 299/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.3638e-07 - accuracy: 1.0000 - val_loss: -12.1738 - val_accuracy: 0.0915\n",
      "Epoch 300/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.1102e-07 - accuracy: 1.0000 - val_loss: -11.9484 - val_accuracy: 0.0915\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "64/64 [==============================] - 2s 8ms/step - loss: 0.6860 - accuracy: 0.5684 - val_loss: 0.7524 - val_accuracy: 0.1707\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6465 - val_loss: 0.5754 - val_accuracy: 0.1463\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6738 - val_loss: 0.8883 - val_accuracy: 0.1951\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.6953 - val_loss: 0.1247 - val_accuracy: 0.1890\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7344 - val_loss: -0.6032 - val_accuracy: 0.1220\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7598 - val_loss: -1.0254 - val_accuracy: 0.1341\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.7656 - val_loss: -1.0737 - val_accuracy: 0.1585\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.8008 - val_loss: -1.0175 - val_accuracy: 0.1768\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.4619 - accuracy: 0.7852 - val_loss: -1.4324 - val_accuracy: 0.1280\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7734 - val_loss: -1.0001 - val_accuracy: 0.1341\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8027 - val_loss: -0.2345 - val_accuracy: 0.1951\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.8066 - val_loss: -1.8755 - val_accuracy: 0.0854\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: -0.0605 - val_accuracy: 0.1951\n",
      "Epoch 14/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8359 - val_loss: -1.6065 - val_accuracy: 0.1098\n",
      "Epoch 15/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8340 - val_loss: -1.6028 - val_accuracy: 0.1646\n",
      "Epoch 16/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8086 - val_loss: -1.6234 - val_accuracy: 0.1585\n",
      "Epoch 17/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8398 - val_loss: -2.6261 - val_accuracy: 0.1220\n",
      "Epoch 18/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8184 - val_loss: -0.5541 - val_accuracy: 0.1951\n",
      "Epoch 19/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8340 - val_loss: -2.1483 - val_accuracy: 0.1220\n",
      "Epoch 20/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.3550 - accuracy: 0.8457 - val_loss: -1.4820 - val_accuracy: 0.1951\n",
      "Epoch 21/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8066 - val_loss: -2.4103 - val_accuracy: 0.1159\n",
      "Epoch 22/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8555 - val_loss: -1.1700 - val_accuracy: 0.1890\n",
      "Epoch 23/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8301 - val_loss: -2.1484 - val_accuracy: 0.1402\n",
      "Epoch 24/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8652 - val_loss: -3.1901 - val_accuracy: 0.1098\n",
      "Epoch 25/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8555 - val_loss: -0.9536 - val_accuracy: 0.1890\n",
      "Epoch 26/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8574 - val_loss: -3.0305 - val_accuracy: 0.1280\n",
      "Epoch 27/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.2897 - accuracy: 0.8984 - val_loss: -2.2249 - val_accuracy: 0.1524\n",
      "Epoch 28/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.2885 - accuracy: 0.8867 - val_loss: -3.1106 - val_accuracy: 0.0915\n",
      "Epoch 29/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.8594 - val_loss: -3.4638 - val_accuracy: 0.1159\n",
      "Epoch 30/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2658 - accuracy: 0.8945 - val_loss: -2.7657 - val_accuracy: 0.1768\n",
      "Epoch 31/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2598 - accuracy: 0.9004 - val_loss: -3.0580 - val_accuracy: 0.1646\n",
      "Epoch 32/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.2670 - accuracy: 0.8945 - val_loss: -2.0213 - val_accuracy: 0.1402\n",
      "Epoch 33/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2442 - accuracy: 0.9082 - val_loss: -2.1421 - val_accuracy: 0.1585\n",
      "Epoch 34/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.2119 - accuracy: 0.9219 - val_loss: -2.9832 - val_accuracy: 0.1402\n",
      "Epoch 35/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.2366 - accuracy: 0.9004 - val_loss: -3.0241 - val_accuracy: 0.1098\n",
      "Epoch 36/300\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.2472 - accuracy: 0.9043 - val_loss: -2.8242 - val_accuracy: 0.1646\n",
      "Epoch 37/300\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2113 - accuracy: 0.9199 - val_loss: -3.2638 - val_accuracy: 0.1402\n",
      "Epoch 38/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1888 - accuracy: 0.9375 - val_loss: -4.6532 - val_accuracy: 0.0854\n",
      "Epoch 39/300\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.2161 - accuracy: 0.9141 - val_loss: -5.0211 - val_accuracy: 0.0793\n",
      "Epoch 40/300\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1784 - accuracy: 0.9355 - val_loss: -3.5662 - val_accuracy: 0.1646\n",
      "Epoch 41/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.2310 - accuracy: 0.8945 - val_loss: -3.9622 - val_accuracy: 0.1280\n",
      "Epoch 42/300\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 0.2431 - accuracy: 0.8926 - val_loss: -5.7552 - val_accuracy: 0.0793\n",
      "Epoch 43/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9355 - val_loss: -4.6701 - val_accuracy: 0.1220\n",
      "Epoch 44/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9492 - val_loss: -6.4648 - val_accuracy: 0.0976\n",
      "Epoch 45/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9453 - val_loss: -3.5358 - val_accuracy: 0.1585\n",
      "Epoch 46/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.9414 - val_loss: -4.6326 - val_accuracy: 0.1159\n",
      "Epoch 47/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9551 - val_loss: -4.8675 - val_accuracy: 0.1402\n",
      "Epoch 48/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9551 - val_loss: -5.2420 - val_accuracy: 0.1159\n",
      "Epoch 49/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9609 - val_loss: -5.7724 - val_accuracy: 0.1402\n",
      "Epoch 50/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9512 - val_loss: -6.4282 - val_accuracy: 0.1037\n",
      "Epoch 51/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9492 - val_loss: -6.4375 - val_accuracy: 0.1159\n",
      "Epoch 52/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9551 - val_loss: -5.5128 - val_accuracy: 0.1646\n",
      "Epoch 53/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9609 - val_loss: -6.1196 - val_accuracy: 0.1402\n",
      "Epoch 54/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9727 - val_loss: -6.9838 - val_accuracy: 0.1037\n",
      "Epoch 55/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1048 - accuracy: 0.9551 - val_loss: -0.8302 - val_accuracy: 0.1402\n",
      "Epoch 56/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9453 - val_loss: -6.3947 - val_accuracy: 0.1220\n",
      "Epoch 57/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9746 - val_loss: -7.0030 - val_accuracy: 0.1280\n",
      "Epoch 58/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9766 - val_loss: -7.5021 - val_accuracy: 0.1220\n",
      "Epoch 59/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9785 - val_loss: -7.3930 - val_accuracy: 0.1037\n",
      "Epoch 60/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9883 - val_loss: -7.4807 - val_accuracy: 0.1220\n",
      "Epoch 61/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9785 - val_loss: -8.5417 - val_accuracy: 0.0732\n",
      "Epoch 62/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9824 - val_loss: -8.0620 - val_accuracy: 0.0854\n",
      "Epoch 63/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9727 - val_loss: -7.5309 - val_accuracy: 0.1098\n",
      "Epoch 64/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9531 - val_loss: -8.2000 - val_accuracy: 0.0854\n",
      "Epoch 65/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9688 - val_loss: -8.1216 - val_accuracy: 0.1098\n",
      "Epoch 66/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9590 - val_loss: -6.9624 - val_accuracy: 0.1402\n",
      "Epoch 67/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9668 - val_loss: -6.0861 - val_accuracy: 0.1159\n",
      "Epoch 68/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9629 - val_loss: -7.5585 - val_accuracy: 0.1098\n",
      "Epoch 69/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9707 - val_loss: -7.7656 - val_accuracy: 0.1037\n",
      "Epoch 70/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9707 - val_loss: -8.2378 - val_accuracy: 0.1159\n",
      "Epoch 71/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9727 - val_loss: -8.0317 - val_accuracy: 0.1280\n",
      "Epoch 72/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: -7.6015 - val_accuracy: 0.1402\n",
      "Epoch 73/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9902 - val_loss: -8.5360 - val_accuracy: 0.1037\n",
      "Epoch 74/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9785 - val_loss: -8.7198 - val_accuracy: 0.1098\n",
      "Epoch 75/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9785 - val_loss: -9.3197 - val_accuracy: 0.1220\n",
      "Epoch 76/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9785 - val_loss: -10.0363 - val_accuracy: 0.0793\n",
      "Epoch 77/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9961 - val_loss: -9.3572 - val_accuracy: 0.1280\n",
      "Epoch 78/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9961 - val_loss: -9.9464 - val_accuracy: 0.0976\n",
      "Epoch 79/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: -9.2784 - val_accuracy: 0.1098\n",
      "Epoch 80/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: -9.2996 - val_accuracy: 0.1037\n",
      "Epoch 81/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9961 - val_loss: -9.9575 - val_accuracy: 0.1159\n",
      "Epoch 82/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 0.9980 - val_loss: -10.0658 - val_accuracy: 0.0793\n",
      "Epoch 83/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: -10.4431 - val_accuracy: 0.1098\n",
      "Epoch 84/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9668 - val_loss: -10.7048 - val_accuracy: 0.0976\n",
      "Epoch 85/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2228 - accuracy: 0.9297 - val_loss: -8.4328 - val_accuracy: 0.1402\n",
      "Epoch 86/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9238 - val_loss: -8.0027 - val_accuracy: 0.0488\n",
      "Epoch 87/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9590 - val_loss: -9.7242 - val_accuracy: 0.1220\n",
      "Epoch 88/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9824 - val_loss: -8.6137 - val_accuracy: 0.1037\n",
      "Epoch 89/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: -10.6160 - val_accuracy: 0.0793\n",
      "Epoch 90/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9805 - val_loss: -8.5642 - val_accuracy: 0.1159\n",
      "Epoch 91/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0767 - accuracy: 0.9688 - val_loss: -9.5488 - val_accuracy: 0.1098\n",
      "Epoch 92/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: -9.2023 - val_accuracy: 0.1341\n",
      "Epoch 93/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: -8.4523 - val_accuracy: 0.1463\n",
      "Epoch 94/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9883 - val_loss: -11.3399 - val_accuracy: 0.1037\n",
      "Epoch 95/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: -10.0940 - val_accuracy: 0.1402\n",
      "Epoch 96/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9941 - val_loss: -10.6425 - val_accuracy: 0.1037\n",
      "Epoch 97/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: -10.0031 - val_accuracy: 0.1220\n",
      "Epoch 98/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9961 - val_loss: -10.1008 - val_accuracy: 0.1159\n",
      "Epoch 99/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: -9.3912 - val_accuracy: 0.1098\n",
      "Epoch 100/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9941 - val_loss: -9.2784 - val_accuracy: 0.1341\n",
      "Epoch 101/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9941 - val_loss: -11.4917 - val_accuracy: 0.0793\n",
      "Epoch 102/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: -11.5376 - val_accuracy: 0.0915\n",
      "Epoch 103/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9941 - val_loss: -9.9772 - val_accuracy: 0.1220\n",
      "Epoch 104/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9961 - val_loss: -11.1776 - val_accuracy: 0.1159\n",
      "Epoch 105/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: -11.0785 - val_accuracy: 0.1159\n",
      "Epoch 106/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: -11.1521 - val_accuracy: 0.1098\n",
      "Epoch 107/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: -11.0838 - val_accuracy: 0.1098\n",
      "Epoch 108/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9961 - val_loss: -11.3159 - val_accuracy: 0.1037\n",
      "Epoch 109/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9961 - val_loss: -11.1955 - val_accuracy: 0.1037\n",
      "Epoch 110/300\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9980 - val_loss: -11.5684 - val_accuracy: 0.0976\n",
      "Epoch 111/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: -11.3831 - val_accuracy: 0.1037\n",
      "Epoch 112/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9980 - val_loss: -11.4423 - val_accuracy: 0.0976\n",
      "Epoch 113/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: -11.3219 - val_accuracy: 0.1037\n",
      "Epoch 114/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: -11.5646 - val_accuracy: 0.1037\n",
      "Epoch 115/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: -11.3452 - val_accuracy: 0.1037\n",
      "Epoch 116/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9961 - val_loss: -11.1034 - val_accuracy: 0.0976\n",
      "Epoch 117/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9980 - val_loss: -11.9081 - val_accuracy: 0.1037\n",
      "Epoch 118/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: -11.7596 - val_accuracy: 0.1037\n",
      "Epoch 119/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9961 - val_loss: -12.0167 - val_accuracy: 0.0976\n",
      "Epoch 120/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -11.6042 - val_accuracy: 0.0976\n",
      "Epoch 121/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -11.6752 - val_accuracy: 0.0976\n",
      "Epoch 122/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -11.8593 - val_accuracy: 0.0976\n",
      "Epoch 123/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9980 - val_loss: -11.5141 - val_accuracy: 0.1037\n",
      "Epoch 124/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: -11.3101 - val_accuracy: 0.1037\n",
      "Epoch 125/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: -11.3988 - val_accuracy: 0.1037\n",
      "Epoch 126/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: -11.3105 - val_accuracy: 0.0915\n",
      "Epoch 127/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5240 - accuracy: 0.8555 - val_loss: -8.4387 - val_accuracy: 0.1951\n",
      "Epoch 128/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8574 - val_loss: -7.0536 - val_accuracy: 0.1402\n",
      "Epoch 129/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9141 - val_loss: -10.3581 - val_accuracy: 0.1220\n",
      "Epoch 130/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9180 - val_loss: -4.6611 - val_accuracy: 0.1341\n",
      "Epoch 131/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9473 - val_loss: -7.4355 - val_accuracy: 0.1280\n",
      "Epoch 132/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9590 - val_loss: -8.3675 - val_accuracy: 0.0854\n",
      "Epoch 133/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9824 - val_loss: -10.4469 - val_accuracy: 0.0915\n",
      "Epoch 134/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9805 - val_loss: -7.9049 - val_accuracy: 0.1463\n",
      "Epoch 135/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9590 - val_loss: -10.1917 - val_accuracy: 0.0854\n",
      "Epoch 136/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9922 - val_loss: -8.3891 - val_accuracy: 0.1220\n",
      "Epoch 137/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: -8.0075 - val_accuracy: 0.1585\n",
      "Epoch 138/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9512 - val_loss: -7.3224 - val_accuracy: 0.1280\n",
      "Epoch 139/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9492 - val_loss: -10.3044 - val_accuracy: 0.1341\n",
      "Epoch 140/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9551 - val_loss: -7.6658 - val_accuracy: 0.0976\n",
      "Epoch 141/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8906 - val_loss: -4.1253 - val_accuracy: 0.1829\n",
      "Epoch 142/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 0.9434 - val_loss: -8.4376 - val_accuracy: 0.1098\n",
      "Epoch 143/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9883 - val_loss: -9.2787 - val_accuracy: 0.0915\n",
      "Epoch 144/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: -8.8298 - val_accuracy: 0.1098\n",
      "Epoch 145/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: -10.6167 - val_accuracy: 0.0976\n",
      "Epoch 146/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9961 - val_loss: -10.2116 - val_accuracy: 0.1037\n",
      "Epoch 147/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: -10.3860 - val_accuracy: 0.1098\n",
      "Epoch 148/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: -9.9389 - val_accuracy: 0.1220\n",
      "Epoch 149/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: -10.4571 - val_accuracy: 0.1159\n",
      "Epoch 150/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: -10.9001 - val_accuracy: 0.1098\n",
      "Epoch 151/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: -10.7187 - val_accuracy: 0.1098\n",
      "Epoch 152/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: -10.6866 - val_accuracy: 0.1220\n",
      "Epoch 153/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: -10.8346 - val_accuracy: 0.1037\n",
      "Epoch 154/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -11.0323 - val_accuracy: 0.1098\n",
      "Epoch 155/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -11.2431 - val_accuracy: 0.0976\n",
      "Epoch 156/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -11.2222 - val_accuracy: 0.1220\n",
      "Epoch 157/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: -11.4709 - val_accuracy: 0.0976\n",
      "Epoch 158/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -11.4461 - val_accuracy: 0.1037\n",
      "Epoch 159/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -11.3124 - val_accuracy: 0.1098\n",
      "Epoch 160/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9980 - val_loss: -11.6341 - val_accuracy: 0.1037\n",
      "Epoch 161/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: -11.4639 - val_accuracy: 0.1037\n",
      "Epoch 162/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9961 - val_loss: -11.2029 - val_accuracy: 0.1037\n",
      "Epoch 163/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: -11.0161 - val_accuracy: 0.0915\n",
      "Epoch 164/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9961 - val_loss: -11.3289 - val_accuracy: 0.0976\n",
      "Epoch 165/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -11.3496 - val_accuracy: 0.1159\n",
      "Epoch 166/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -11.4702 - val_accuracy: 0.1037\n",
      "Epoch 167/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -11.5330 - val_accuracy: 0.1037\n",
      "Epoch 168/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -11.7469 - val_accuracy: 0.0976\n",
      "Epoch 169/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -11.5418 - val_accuracy: 0.1037\n",
      "Epoch 170/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -11.8634 - val_accuracy: 0.0976\n",
      "Epoch 171/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -11.7694 - val_accuracy: 0.0976\n",
      "Epoch 172/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -11.7500 - val_accuracy: 0.0976\n",
      "Epoch 173/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -11.6247 - val_accuracy: 0.1098\n",
      "Epoch 174/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9980 - val_loss: -11.6656 - val_accuracy: 0.1037\n",
      "Epoch 175/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: -12.1803 - val_accuracy: 0.0915\n",
      "Epoch 176/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9316 - val_loss: -9.3778 - val_accuracy: 0.1341\n",
      "Epoch 177/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9277 - val_loss: -8.9934 - val_accuracy: 0.1037\n",
      "Epoch 178/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9473 - val_loss: -7.4883 - val_accuracy: 0.0732\n",
      "Epoch 179/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9707 - val_loss: -8.9931 - val_accuracy: 0.0915\n",
      "Epoch 180/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9961 - val_loss: -9.2446 - val_accuracy: 0.0854\n",
      "Epoch 181/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: -9.0727 - val_accuracy: 0.1098\n",
      "Epoch 182/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: -9.5026 - val_accuracy: 0.0976\n",
      "Epoch 183/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: -9.5281 - val_accuracy: 0.0976\n",
      "Epoch 184/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9961 - val_loss: -8.8916 - val_accuracy: 0.1098\n",
      "Epoch 185/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: -9.4224 - val_accuracy: 0.0976\n",
      "Epoch 186/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: -9.4420 - val_accuracy: 0.0976\n",
      "Epoch 187/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -9.5352 - val_accuracy: 0.0976\n",
      "Epoch 188/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: -9.8375 - val_accuracy: 0.0976\n",
      "Epoch 189/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -9.9081 - val_accuracy: 0.0915\n",
      "Epoch 190/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: -9.8374 - val_accuracy: 0.1098\n",
      "Epoch 191/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9961 - val_loss: -10.1379 - val_accuracy: 0.0854\n",
      "Epoch 192/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9961 - val_loss: -10.0218 - val_accuracy: 0.0915\n",
      "Epoch 193/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -10.2618 - val_accuracy: 0.0915\n",
      "Epoch 194/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -10.1338 - val_accuracy: 0.0915\n",
      "Epoch 195/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -10.3320 - val_accuracy: 0.0915\n",
      "Epoch 196/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -10.4738 - val_accuracy: 0.0915\n",
      "Epoch 197/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -10.7879 - val_accuracy: 0.0915\n",
      "Epoch 198/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9961 - val_loss: -9.6344 - val_accuracy: 0.1037\n",
      "Epoch 199/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.9121 - val_loss: -10.0456 - val_accuracy: 0.1280\n",
      "Epoch 200/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2228 - accuracy: 0.9180 - val_loss: -9.2987 - val_accuracy: 0.0793\n",
      "Epoch 201/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9707 - val_loss: -9.8620 - val_accuracy: 0.0854\n",
      "Epoch 202/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9961 - val_loss: -9.8752 - val_accuracy: 0.1220\n",
      "Epoch 203/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: -10.3380 - val_accuracy: 0.1220\n",
      "Epoch 204/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: -11.2068 - val_accuracy: 0.0854\n",
      "Epoch 205/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9941 - val_loss: -10.3063 - val_accuracy: 0.1220\n",
      "Epoch 206/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: -11.5441 - val_accuracy: 0.0915\n",
      "Epoch 207/300\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: -11.3590 - val_accuracy: 0.0976\n",
      "Epoch 208/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: -11.0737 - val_accuracy: 0.1220\n",
      "Epoch 209/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -10.4280 - val_accuracy: 0.1098\n",
      "Epoch 210/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -11.0066 - val_accuracy: 0.1037\n",
      "Epoch 211/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -10.9935 - val_accuracy: 0.1037\n",
      "Epoch 212/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -11.0641 - val_accuracy: 0.1037\n",
      "Epoch 213/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -11.2040 - val_accuracy: 0.1037\n",
      "Epoch 214/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: -10.3859 - val_accuracy: 0.1098\n",
      "Epoch 215/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: -10.7540 - val_accuracy: 0.1159\n",
      "Epoch 216/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: -11.1915 - val_accuracy: 0.1037\n",
      "Epoch 217/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -11.3219 - val_accuracy: 0.0976\n",
      "Epoch 218/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -11.3263 - val_accuracy: 0.0976\n",
      "Epoch 219/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -11.4390 - val_accuracy: 0.0976\n",
      "Epoch 220/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -11.4925 - val_accuracy: 0.0976\n",
      "Epoch 221/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -11.6607 - val_accuracy: 0.1037\n",
      "Epoch 222/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9961 - val_loss: -11.5392 - val_accuracy: 0.1159\n",
      "Epoch 223/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -11.5525 - val_accuracy: 0.1037\n",
      "Epoch 224/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9980 - val_loss: -11.7470 - val_accuracy: 0.1037\n",
      "Epoch 225/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: -11.7223 - val_accuracy: 0.0915\n",
      "Epoch 226/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: -11.8287 - val_accuracy: 0.0915\n",
      "Epoch 227/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.1006e-04 - accuracy: 1.0000 - val_loss: -11.8787 - val_accuracy: 0.0915\n",
      "Epoch 228/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.6510e-04 - accuracy: 1.0000 - val_loss: -11.9860 - val_accuracy: 0.0976\n",
      "Epoch 229/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.2439e-04 - accuracy: 1.0000 - val_loss: -11.9192 - val_accuracy: 0.0976\n",
      "Epoch 230/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.2753e-04 - accuracy: 1.0000 - val_loss: -11.9046 - val_accuracy: 0.0976\n",
      "Epoch 231/300\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 5.8414e-04 - accuracy: 1.0000 - val_loss: -12.0331 - val_accuracy: 0.0976\n",
      "Epoch 232/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 7.0483e-04 - accuracy: 1.0000 - val_loss: -11.9546 - val_accuracy: 0.0976\n",
      "Epoch 233/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.2719e-04 - accuracy: 1.0000 - val_loss: -12.0613 - val_accuracy: 0.1037\n",
      "Epoch 234/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.1813e-04 - accuracy: 1.0000 - val_loss: -11.9361 - val_accuracy: 0.1037\n",
      "Epoch 235/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 3.2112e-04 - accuracy: 1.0000 - val_loss: -12.0689 - val_accuracy: 0.0976\n",
      "Epoch 236/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.8570e-04 - accuracy: 1.0000 - val_loss: -11.9178 - val_accuracy: 0.1037\n",
      "Epoch 237/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.4212e-04 - accuracy: 1.0000 - val_loss: -11.9944 - val_accuracy: 0.1037\n",
      "Epoch 238/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.6275e-04 - accuracy: 1.0000 - val_loss: -11.9993 - val_accuracy: 0.1037\n",
      "Epoch 239/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2082e-04 - accuracy: 1.0000 - val_loss: -12.1457 - val_accuracy: 0.0976\n",
      "Epoch 240/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.3631e-04 - accuracy: 1.0000 - val_loss: -11.9677 - val_accuracy: 0.1037\n",
      "Epoch 241/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.0787e-04 - accuracy: 1.0000 - val_loss: -12.0846 - val_accuracy: 0.1098\n",
      "Epoch 242/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.9746e-04 - accuracy: 1.0000 - val_loss: -12.0399 - val_accuracy: 0.1037\n",
      "Epoch 243/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8883e-04 - accuracy: 1.0000 - val_loss: -12.1649 - val_accuracy: 0.1037\n",
      "Epoch 244/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.7867e-04 - accuracy: 1.0000 - val_loss: -12.0705 - val_accuracy: 0.1098\n",
      "Epoch 245/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.6281e-04 - accuracy: 1.0000 - val_loss: -12.0460 - val_accuracy: 0.1098\n",
      "Epoch 246/300\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.5044e-04 - accuracy: 1.0000 - val_loss: -12.1338 - val_accuracy: 0.1098\n",
      "Epoch 247/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.5116e-04 - accuracy: 1.0000 - val_loss: -12.2102 - val_accuracy: 0.1037\n",
      "Epoch 248/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.4005e-04 - accuracy: 1.0000 - val_loss: -12.1343 - val_accuracy: 0.1098\n",
      "Epoch 249/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.2916e-04 - accuracy: 1.0000 - val_loss: -12.2139 - val_accuracy: 0.1098\n",
      "Epoch 250/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.3167e-04 - accuracy: 1.0000 - val_loss: -12.2258 - val_accuracy: 0.1098\n",
      "Epoch 251/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3642e-04 - accuracy: 1.0000 - val_loss: -12.2737 - val_accuracy: 0.1098\n",
      "Epoch 252/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.2309e-04 - accuracy: 1.0000 - val_loss: -12.4026 - val_accuracy: 0.1098\n",
      "Epoch 253/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1313e-04 - accuracy: 1.0000 - val_loss: -12.2886 - val_accuracy: 0.1098\n",
      "Epoch 254/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0038e-04 - accuracy: 1.0000 - val_loss: -12.2741 - val_accuracy: 0.1098\n",
      "Epoch 255/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.8089e-05 - accuracy: 1.0000 - val_loss: -12.3136 - val_accuracy: 0.1098\n",
      "Epoch 256/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.5892e-05 - accuracy: 1.0000 - val_loss: -12.4021 - val_accuracy: 0.1098\n",
      "Epoch 257/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 9.2706e-05 - accuracy: 1.0000 - val_loss: -12.4614 - val_accuracy: 0.1098\n",
      "Epoch 258/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.3850e-05 - accuracy: 1.0000 - val_loss: -12.4006 - val_accuracy: 0.1098\n",
      "Epoch 259/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 8.0940e-05 - accuracy: 1.0000 - val_loss: -12.3254 - val_accuracy: 0.1098\n",
      "Epoch 260/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.8408e-05 - accuracy: 1.0000 - val_loss: -12.4825 - val_accuracy: 0.1098\n",
      "Epoch 261/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 7.3757e-05 - accuracy: 1.0000 - val_loss: -12.5031 - val_accuracy: 0.1098\n",
      "Epoch 262/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.0747e-05 - accuracy: 1.0000 - val_loss: -12.4859 - val_accuracy: 0.1098\n",
      "Epoch 263/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 6.9207e-05 - accuracy: 1.0000 - val_loss: -12.5375 - val_accuracy: 0.1098\n",
      "Epoch 264/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.6634e-05 - accuracy: 1.0000 - val_loss: -12.5047 - val_accuracy: 0.1098\n",
      "Epoch 265/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.2311e-05 - accuracy: 1.0000 - val_loss: -12.6035 - val_accuracy: 0.1098\n",
      "Epoch 266/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.9779e-05 - accuracy: 1.0000 - val_loss: -12.4695 - val_accuracy: 0.1098\n",
      "Epoch 267/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.2404e-05 - accuracy: 1.0000 - val_loss: -12.6431 - val_accuracy: 0.1098\n",
      "Epoch 268/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.9155e-05 - accuracy: 1.0000 - val_loss: -12.5724 - val_accuracy: 0.1159\n",
      "Epoch 269/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.3301e-05 - accuracy: 1.0000 - val_loss: -12.8260 - val_accuracy: 0.1098\n",
      "Epoch 270/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.1661e-05 - accuracy: 1.0000 - val_loss: -12.6436 - val_accuracy: 0.1098\n",
      "Epoch 271/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.8721e-05 - accuracy: 1.0000 - val_loss: -12.7079 - val_accuracy: 0.1159\n",
      "Epoch 272/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.7026e-05 - accuracy: 1.0000 - val_loss: -12.7781 - val_accuracy: 0.1098\n",
      "Epoch 273/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.6417e-05 - accuracy: 1.0000 - val_loss: -12.9186 - val_accuracy: 0.1098\n",
      "Epoch 274/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.7464e-05 - accuracy: 1.0000 - val_loss: -13.0217 - val_accuracy: 0.1098\n",
      "Epoch 275/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.3735e-05 - accuracy: 1.0000 - val_loss: -12.8051 - val_accuracy: 0.1159\n",
      "Epoch 276/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 4.0033e-05 - accuracy: 1.0000 - val_loss: -12.9033 - val_accuracy: 0.1159\n",
      "Epoch 277/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.8499e-05 - accuracy: 1.0000 - val_loss: -12.8867 - val_accuracy: 0.1159\n",
      "Epoch 278/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.6869e-05 - accuracy: 1.0000 - val_loss: -13.0072 - val_accuracy: 0.1098\n",
      "Epoch 279/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5758e-05 - accuracy: 1.0000 - val_loss: -12.8986 - val_accuracy: 0.1220\n",
      "Epoch 280/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.3888e-05 - accuracy: 1.0000 - val_loss: -12.9755 - val_accuracy: 0.1159\n",
      "Epoch 281/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2198e-05 - accuracy: 1.0000 - val_loss: -12.8720 - val_accuracy: 0.1220\n",
      "Epoch 282/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.2084e-05 - accuracy: 1.0000 - val_loss: -13.0757 - val_accuracy: 0.1159\n",
      "Epoch 283/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.1171e-05 - accuracy: 1.0000 - val_loss: -13.0783 - val_accuracy: 0.1159\n",
      "Epoch 284/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.9381e-05 - accuracy: 1.0000 - val_loss: -13.0756 - val_accuracy: 0.1159\n",
      "Epoch 285/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 2.9569e-05 - accuracy: 1.0000 - val_loss: -13.2864 - val_accuracy: 0.1159\n",
      "Epoch 286/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.7209e-05 - accuracy: 1.0000 - val_loss: -12.9931 - val_accuracy: 0.1280\n",
      "Epoch 287/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.5630e-05 - accuracy: 1.0000 - val_loss: -13.2030 - val_accuracy: 0.1159\n",
      "Epoch 288/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6263e-05 - accuracy: 1.0000 - val_loss: -13.1740 - val_accuracy: 0.1220\n",
      "Epoch 289/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.4358e-05 - accuracy: 1.0000 - val_loss: -13.2057 - val_accuracy: 0.1159\n",
      "Epoch 290/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.3292e-05 - accuracy: 1.0000 - val_loss: -13.0826 - val_accuracy: 0.1280\n",
      "Epoch 291/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.2614e-05 - accuracy: 1.0000 - val_loss: -13.1833 - val_accuracy: 0.1220\n",
      "Epoch 292/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.1824e-05 - accuracy: 1.0000 - val_loss: -13.2687 - val_accuracy: 0.1159\n",
      "Epoch 293/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.0825e-05 - accuracy: 1.0000 - val_loss: -13.2824 - val_accuracy: 0.1159\n",
      "Epoch 294/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.9456e-05 - accuracy: 1.0000 - val_loss: -13.3062 - val_accuracy: 0.1220\n",
      "Epoch 295/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8249e-05 - accuracy: 1.0000 - val_loss: -13.3900 - val_accuracy: 0.1159\n",
      "Epoch 296/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8073e-05 - accuracy: 1.0000 - val_loss: -13.3506 - val_accuracy: 0.1220\n",
      "Epoch 297/300\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 1.8005e-05 - accuracy: 1.0000 - val_loss: -13.3345 - val_accuracy: 0.1220\n",
      "Epoch 298/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6616e-05 - accuracy: 1.0000 - val_loss: -13.4759 - val_accuracy: 0.1159\n",
      "Epoch 299/300\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.6123e-05 - accuracy: 1.0000 - val_loss: -13.5148 - val_accuracy: 0.1159\n",
      "Epoch 300/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6491e-05 - accuracy: 1.0000 - val_loss: -13.5565 - val_accuracy: 0.1159\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 0.6773 - accuracy: 0.5586 - val_loss: 0.8020 - val_accuracy: 0.1829\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.6562 - val_loss: 0.5331 - val_accuracy: 0.1585\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.7012 - val_loss: 0.6084 - val_accuracy: 0.1646\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7383 - val_loss: 0.0918 - val_accuracy: 0.1585\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7461 - val_loss: -0.3909 - val_accuracy: 0.1463\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7051 - val_loss: -0.0093 - val_accuracy: 0.1707\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7891 - val_loss: -0.2152 - val_accuracy: 0.1707\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7891 - val_loss: -0.4949 - val_accuracy: 0.1646\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8184 - val_loss: -0.3095 - val_accuracy: 0.1768\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8320 - val_loss: -0.8275 - val_accuracy: 0.1524\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8184 - val_loss: -0.6930 - val_accuracy: 0.1646\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8535 - val_loss: -0.8133 - val_accuracy: 0.1768\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8340 - val_loss: -1.4950 - val_accuracy: 0.1341\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8594 - val_loss: -1.1058 - val_accuracy: 0.1707\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8535 - val_loss: -1.1955 - val_accuracy: 0.1646\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8320 - val_loss: -0.9399 - val_accuracy: 0.1890\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8418 - val_loss: -1.6577 - val_accuracy: 0.1402\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8672 - val_loss: -2.7428 - val_accuracy: 0.1098\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8691 - val_loss: -2.0403 - val_accuracy: 0.1280\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.9004 - val_loss: -1.6005 - val_accuracy: 0.1585\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.8887 - val_loss: -2.1876 - val_accuracy: 0.1402\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2786 - accuracy: 0.8926 - val_loss: -1.7362 - val_accuracy: 0.1707\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.9023 - val_loss: -2.9291 - val_accuracy: 0.1159\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2522 - accuracy: 0.8984 - val_loss: -3.3551 - val_accuracy: 0.0976\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.9043 - val_loss: -3.4664 - val_accuracy: 0.0915\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.9062 - val_loss: -3.0322 - val_accuracy: 0.1098\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2242 - accuracy: 0.9160 - val_loss: -3.4099 - val_accuracy: 0.1220\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2304 - accuracy: 0.9160 - val_loss: -3.2881 - val_accuracy: 0.0732\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.8848 - val_loss: -3.3295 - val_accuracy: 0.1159\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1930 - accuracy: 0.9316 - val_loss: -4.1980 - val_accuracy: 0.0854\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1943 - accuracy: 0.9297 - val_loss: -2.6342 - val_accuracy: 0.1463\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1806 - accuracy: 0.9434 - val_loss: -5.0685 - val_accuracy: 0.0427\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9316 - val_loss: -4.4618 - val_accuracy: 0.0976\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9316 - val_loss: -3.5746 - val_accuracy: 0.1341\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1893 - accuracy: 0.9316 - val_loss: -5.2269 - val_accuracy: 0.0732\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9219 - val_loss: -5.0965 - val_accuracy: 0.1098\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1921 - accuracy: 0.9258 - val_loss: -2.9288 - val_accuracy: 0.1646\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9043 - val_loss: -3.8893 - val_accuracy: 0.1159\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9414 - val_loss: -5.1616 - val_accuracy: 0.0976\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9336 - val_loss: -5.7192 - val_accuracy: 0.0915\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1344 - accuracy: 0.9531 - val_loss: -4.5199 - val_accuracy: 0.1463\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9551 - val_loss: -4.5674 - val_accuracy: 0.1220\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9531 - val_loss: -4.0983 - val_accuracy: 0.1037\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9512 - val_loss: -4.6178 - val_accuracy: 0.1280\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9551 - val_loss: -4.6727 - val_accuracy: 0.1220\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9707 - val_loss: -4.9687 - val_accuracy: 0.1098\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9668 - val_loss: -5.3402 - val_accuracy: 0.1098\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9746 - val_loss: -4.8715 - val_accuracy: 0.1463\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9492 - val_loss: -5.8154 - val_accuracy: 0.1159\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9805 - val_loss: -5.3028 - val_accuracy: 0.1280\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.9512 - val_loss: -4.8232 - val_accuracy: 0.1220\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9531 - val_loss: -6.8405 - val_accuracy: 0.0671\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.9238 - val_loss: -5.7065 - val_accuracy: 0.1280\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2102 - accuracy: 0.9316 - val_loss: -4.2061 - val_accuracy: 0.1463\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9629 - val_loss: -6.3106 - val_accuracy: 0.0976\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9785 - val_loss: -5.5999 - val_accuracy: 0.1341\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9863 - val_loss: -6.7221 - val_accuracy: 0.0915\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9844 - val_loss: -7.0237 - val_accuracy: 0.0976\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9668 - val_loss: -5.7274 - val_accuracy: 0.1098\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9629 - val_loss: -6.0359 - val_accuracy: 0.0976\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9785 - val_loss: -6.0323 - val_accuracy: 0.1159\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9863 - val_loss: -7.8465 - val_accuracy: 0.0915\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0427 - accuracy: 0.9902 - val_loss: -7.3072 - val_accuracy: 0.0976\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9883 - val_loss: -7.0994 - val_accuracy: 0.1159\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9883 - val_loss: -8.5514 - val_accuracy: 0.0915\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: -8.0426 - val_accuracy: 0.0793\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9941 - val_loss: -8.3225 - val_accuracy: 0.0976\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9961 - val_loss: -6.8215 - val_accuracy: 0.1402\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9902 - val_loss: -8.5845 - val_accuracy: 0.0915\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9941 - val_loss: -8.0839 - val_accuracy: 0.1037\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9941 - val_loss: -9.7768 - val_accuracy: 0.0732\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9922 - val_loss: -7.6187 - val_accuracy: 0.1098\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9941 - val_loss: -10.0430 - val_accuracy: 0.0854\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: -9.4414 - val_accuracy: 0.1098\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: -8.5176 - val_accuracy: 0.1098\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9961 - val_loss: -8.1120 - val_accuracy: 0.1341\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9941 - val_loss: -10.7127 - val_accuracy: 0.0671\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9902 - val_loss: -8.5928 - val_accuracy: 0.1159\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9902 - val_loss: -10.6821 - val_accuracy: 0.0732\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9629 - val_loss: -9.4645 - val_accuracy: 0.1037\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9805 - val_loss: -11.6800 - val_accuracy: 0.0488\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9473 - val_loss: -5.5180 - val_accuracy: 0.1463\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.9492 - val_loss: -9.0466 - val_accuracy: 0.0549\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9707 - val_loss: -7.0178 - val_accuracy: 0.0915\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9668 - val_loss: -9.2397 - val_accuracy: 0.0793\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9785 - val_loss: -8.8703 - val_accuracy: 0.0854\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9805 - val_loss: -7.7236 - val_accuracy: 0.1220\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9922 - val_loss: -8.7581 - val_accuracy: 0.0976\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: -8.2722 - val_accuracy: 0.1098\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: -9.5273 - val_accuracy: 0.0915\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: -9.8683 - val_accuracy: 0.0732\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: -9.0862 - val_accuracy: 0.1159\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: -9.5053 - val_accuracy: 0.1159\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: -9.8118 - val_accuracy: 0.1037\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -10.3564 - val_accuracy: 0.0793\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: -10.5874 - val_accuracy: 0.0854\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: -10.5487 - val_accuracy: 0.0854\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: -10.3521 - val_accuracy: 0.0976\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -10.2879 - val_accuracy: 0.0976\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -11.0580 - val_accuracy: 0.0854\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 15ms/step - loss: 0.6846 - accuracy: 0.5527 - val_loss: 0.4358 - val_accuracy: 0.0610\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6420 - accuracy: 0.6484 - val_loss: 0.5247 - val_accuracy: 0.1646\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.6738 - val_loss: -0.2073 - val_accuracy: 0.0915\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7090 - val_loss: 0.1207 - val_accuracy: 0.1524\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.6797 - val_loss: -0.2362 - val_accuracy: 0.1280\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7188 - val_loss: -0.0618 - val_accuracy: 0.1646\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7461 - val_loss: -0.6727 - val_accuracy: 0.1402\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7539 - val_loss: 0.2471 - val_accuracy: 0.1890\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7773 - val_loss: -0.4441 - val_accuracy: 0.1768\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7910 - val_loss: -0.9267 - val_accuracy: 0.1402\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7598 - val_loss: -0.7873 - val_accuracy: 0.1220\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7871 - val_loss: -1.2072 - val_accuracy: 0.1402\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.7891 - val_loss: -1.0425 - val_accuracy: 0.1220\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8008 - val_loss: -0.9508 - val_accuracy: 0.1646\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.7949 - val_loss: -0.5414 - val_accuracy: 0.1768\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8105 - val_loss: -1.1759 - val_accuracy: 0.1524\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8105 - val_loss: -0.5618 - val_accuracy: 0.1646\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7793 - val_loss: -0.6211 - val_accuracy: 0.1585\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3963 - accuracy: 0.8066 - val_loss: -1.5382 - val_accuracy: 0.1220\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8242 - val_loss: -1.4233 - val_accuracy: 0.1402\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8320 - val_loss: -0.1429 - val_accuracy: 0.1829\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8301 - val_loss: -0.9310 - val_accuracy: 0.1585\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8555 - val_loss: -1.3960 - val_accuracy: 0.1341\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3274 - accuracy: 0.8574 - val_loss: -1.7318 - val_accuracy: 0.1220\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8496 - val_loss: -1.7254 - val_accuracy: 0.1341\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.8848 - val_loss: -1.8231 - val_accuracy: 0.1159\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8730 - val_loss: -2.3764 - val_accuracy: 0.1098\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2795 - accuracy: 0.8730 - val_loss: -1.8135 - val_accuracy: 0.1220\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.8613 - val_loss: -0.1969 - val_accuracy: 0.1829\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8730 - val_loss: -2.2014 - val_accuracy: 0.1159\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.9023 - val_loss: -2.2467 - val_accuracy: 0.1159\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.9043 - val_loss: -1.9122 - val_accuracy: 0.1220\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.8242 - val_loss: -1.4740 - val_accuracy: 0.1524\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2540 - accuracy: 0.8926 - val_loss: -1.5048 - val_accuracy: 0.1463\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2278 - accuracy: 0.9180 - val_loss: -3.1186 - val_accuracy: 0.0854\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2319 - accuracy: 0.9082 - val_loss: -1.7735 - val_accuracy: 0.1280\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2091 - accuracy: 0.9199 - val_loss: -2.6115 - val_accuracy: 0.1159\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2249 - accuracy: 0.9160 - val_loss: -2.5621 - val_accuracy: 0.1220\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2106 - accuracy: 0.9277 - val_loss: -3.2936 - val_accuracy: 0.0793\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1835 - accuracy: 0.9355 - val_loss: -2.6791 - val_accuracy: 0.1098\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9531 - val_loss: -3.5637 - val_accuracy: 0.0854\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1709 - accuracy: 0.9238 - val_loss: -3.9288 - val_accuracy: 0.0915\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1964 - accuracy: 0.9219 - val_loss: -1.9908 - val_accuracy: 0.1159\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9336 - val_loss: -2.4444 - val_accuracy: 0.1159\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9492 - val_loss: -3.4472 - val_accuracy: 0.1098\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9609 - val_loss: -3.5383 - val_accuracy: 0.1159\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9629 - val_loss: -3.4538 - val_accuracy: 0.1037\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9707 - val_loss: -3.0588 - val_accuracy: 0.1159\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.9590 - val_loss: -2.3635 - val_accuracy: 0.1220\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9453 - val_loss: -5.4277 - val_accuracy: 0.0854\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9551 - val_loss: -4.5780 - val_accuracy: 0.0976\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.9590 - val_loss: -4.5473 - val_accuracy: 0.0793\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9688 - val_loss: -3.5063 - val_accuracy: 0.1159\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9688 - val_loss: -4.6499 - val_accuracy: 0.0976\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9746 - val_loss: -4.4051 - val_accuracy: 0.0915\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9785 - val_loss: -4.4167 - val_accuracy: 0.1037\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9844 - val_loss: -4.5326 - val_accuracy: 0.1159\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9746 - val_loss: -5.1741 - val_accuracy: 0.0915\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9727 - val_loss: -4.9914 - val_accuracy: 0.0976\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9844 - val_loss: -6.1972 - val_accuracy: 0.0915\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9668 - val_loss: -2.2556 - val_accuracy: 0.1402\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2028 - accuracy: 0.9141 - val_loss: -3.4794 - val_accuracy: 0.1220\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1311 - accuracy: 0.9609 - val_loss: -3.1451 - val_accuracy: 0.1159\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9766 - val_loss: -3.6923 - val_accuracy: 0.1280\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9727 - val_loss: -4.5145 - val_accuracy: 0.1037\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9746 - val_loss: -2.4453 - val_accuracy: 0.1402\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9395 - val_loss: -3.2231 - val_accuracy: 0.1220\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1212 - accuracy: 0.9395 - val_loss: -2.7551 - val_accuracy: 0.1220\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9688 - val_loss: -5.9258 - val_accuracy: 0.0915\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9766 - val_loss: -4.8907 - val_accuracy: 0.0976\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: -5.0032 - val_accuracy: 0.1159\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9883 - val_loss: -3.6768 - val_accuracy: 0.1220\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9824 - val_loss: -6.4335 - val_accuracy: 0.0854\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9922 - val_loss: -5.0357 - val_accuracy: 0.1098\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: -5.1792 - val_accuracy: 0.1098\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9902 - val_loss: -7.0788 - val_accuracy: 0.0854\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9941 - val_loss: -6.9581 - val_accuracy: 0.0854\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9785 - val_loss: -6.0115 - val_accuracy: 0.0976\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9805 - val_loss: -6.8103 - val_accuracy: 0.0610\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9297 - val_loss: -3.4770 - val_accuracy: 0.1280\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9492 - val_loss: -5.3333 - val_accuracy: 0.0915\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9922 - val_loss: -6.0692 - val_accuracy: 0.0915\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: -5.7326 - val_accuracy: 0.0976\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: -5.1476 - val_accuracy: 0.1037\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9863 - val_loss: -5.6356 - val_accuracy: 0.0976\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9961 - val_loss: -4.3117 - val_accuracy: 0.1220\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9590 - val_loss: -5.1128 - val_accuracy: 0.0976\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9551 - val_loss: -5.0911 - val_accuracy: 0.1159\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9805 - val_loss: -5.6583 - val_accuracy: 0.0976\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: -5.1488 - val_accuracy: 0.1159\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: -6.0784 - val_accuracy: 0.1037\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: -6.1185 - val_accuracy: 0.0915\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: -6.5802 - val_accuracy: 0.0915\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: -6.9410 - val_accuracy: 0.0793\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: -7.0548 - val_accuracy: 0.0854\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: -6.0370 - val_accuracy: 0.0976\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9961 - val_loss: -7.9569 - val_accuracy: 0.0854\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9941 - val_loss: -6.5033 - val_accuracy: 0.1037\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: -7.4411 - val_accuracy: 0.0854\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: -6.7235 - val_accuracy: 0.0915\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.6844 - accuracy: 0.5605 - val_loss: 0.7848 - val_accuracy: 0.1890\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5977 - val_loss: 0.4827 - val_accuracy: 0.1402\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6992 - val_loss: 0.2006 - val_accuracy: 0.1463\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7090 - val_loss: -0.2898 - val_accuracy: 0.1098\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7246 - val_loss: -0.3528 - val_accuracy: 0.1220\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7305 - val_loss: 0.3547 - val_accuracy: 0.1951\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4830 - accuracy: 0.7676 - val_loss: -0.5013 - val_accuracy: 0.1707\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7773 - val_loss: 0.1001 - val_accuracy: 0.2012\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7676 - val_loss: -1.1371 - val_accuracy: 0.1707\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8008 - val_loss: -1.2960 - val_accuracy: 0.1646\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8223 - val_loss: -1.3405 - val_accuracy: 0.1646\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7930 - val_loss: -0.2977 - val_accuracy: 0.1768\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8086 - val_loss: -0.6440 - val_accuracy: 0.1829\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8145 - val_loss: -1.3616 - val_accuracy: 0.1707\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8301 - val_loss: -1.5293 - val_accuracy: 0.1829\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8242 - val_loss: -1.5827 - val_accuracy: 0.1768\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8398 - val_loss: -1.5836 - val_accuracy: 0.1646\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8555 - val_loss: -3.0560 - val_accuracy: 0.0610\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3674 - accuracy: 0.8438 - val_loss: -1.5211 - val_accuracy: 0.1402\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8438 - val_loss: -2.0336 - val_accuracy: 0.1585\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8613 - val_loss: -3.4720 - val_accuracy: 0.0854\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8613 - val_loss: -1.9962 - val_accuracy: 0.1829\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.8828 - val_loss: -2.5277 - val_accuracy: 0.1402\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.8730 - val_loss: -3.1322 - val_accuracy: 0.1098\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8770 - val_loss: -2.5134 - val_accuracy: 0.1341\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2858 - accuracy: 0.8848 - val_loss: -2.7440 - val_accuracy: 0.1524\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8848 - val_loss: -2.2138 - val_accuracy: 0.1829\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.8848 - val_loss: -3.2420 - val_accuracy: 0.1463\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9141 - val_loss: -3.0394 - val_accuracy: 0.1524\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.8906 - val_loss: -3.8828 - val_accuracy: 0.1402\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.8848 - val_loss: -3.7854 - val_accuracy: 0.1280\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2749 - accuracy: 0.8828 - val_loss: -4.2039 - val_accuracy: 0.1280\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2240 - accuracy: 0.9023 - val_loss: -4.4887 - val_accuracy: 0.0915\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2100 - accuracy: 0.9238 - val_loss: -4.7989 - val_accuracy: 0.1037\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.9355 - val_loss: -4.3544 - val_accuracy: 0.1220\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9238 - val_loss: -4.1790 - val_accuracy: 0.1159\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1848 - accuracy: 0.9336 - val_loss: -4.4953 - val_accuracy: 0.1341\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9395 - val_loss: -4.5286 - val_accuracy: 0.1646\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1912 - accuracy: 0.9277 - val_loss: -4.4346 - val_accuracy: 0.1524\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9395 - val_loss: -4.5295 - val_accuracy: 0.1341\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9453 - val_loss: -4.3614 - val_accuracy: 0.1585\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.9512 - val_loss: -5.6618 - val_accuracy: 0.1159\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9238 - val_loss: -5.1743 - val_accuracy: 0.1220\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2097 - accuracy: 0.9219 - val_loss: -4.7823 - val_accuracy: 0.1402\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9473 - val_loss: -4.8619 - val_accuracy: 0.1220\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9570 - val_loss: -5.1755 - val_accuracy: 0.0976\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9551 - val_loss: -5.4472 - val_accuracy: 0.1402\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1390 - accuracy: 0.9453 - val_loss: -3.8748 - val_accuracy: 0.1646\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9414 - val_loss: -5.9175 - val_accuracy: 0.1159\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9707 - val_loss: -6.4920 - val_accuracy: 0.0915\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9551 - val_loss: -7.3523 - val_accuracy: 0.0976\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9629 - val_loss: -6.0792 - val_accuracy: 0.1098\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1190 - accuracy: 0.9531 - val_loss: -6.4510 - val_accuracy: 0.1159\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9512 - val_loss: -5.5222 - val_accuracy: 0.1159\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9492 - val_loss: -6.7842 - val_accuracy: 0.0793\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9688 - val_loss: -6.2536 - val_accuracy: 0.0976\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9746 - val_loss: -5.2651 - val_accuracy: 0.1402\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9551 - val_loss: -4.6720 - val_accuracy: 0.1707\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9668 - val_loss: -5.2588 - val_accuracy: 0.1159\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9844 - val_loss: -6.3990 - val_accuracy: 0.1341\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9746 - val_loss: -7.5157 - val_accuracy: 0.0732\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9883 - val_loss: -5.9633 - val_accuracy: 0.1220\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9785 - val_loss: -6.2581 - val_accuracy: 0.1341\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9805 - val_loss: -6.9500 - val_accuracy: 0.1280\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9883 - val_loss: -6.2944 - val_accuracy: 0.1159\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9883 - val_loss: -7.7298 - val_accuracy: 0.0915\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.9824 - val_loss: -8.0948 - val_accuracy: 0.0915\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9863 - val_loss: -8.7089 - val_accuracy: 0.0915\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9941 - val_loss: -8.3930 - val_accuracy: 0.0976\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9922 - val_loss: -9.0990 - val_accuracy: 0.1037\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9961 - val_loss: -8.9448 - val_accuracy: 0.1037\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9863 - val_loss: -8.2334 - val_accuracy: 0.1037\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1321 - accuracy: 0.9551 - val_loss: -9.7551 - val_accuracy: 0.0976\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2995 - accuracy: 0.9023 - val_loss: -5.2183 - val_accuracy: 0.1341\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2169 - accuracy: 0.9121 - val_loss: -7.0058 - val_accuracy: 0.1402\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0966 - accuracy: 0.9668 - val_loss: -7.3598 - val_accuracy: 0.0976\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: -5.9942 - val_accuracy: 0.0976\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9746 - val_loss: -9.0769 - val_accuracy: 0.0976\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9824 - val_loss: -7.9346 - val_accuracy: 0.1159\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9902 - val_loss: -9.1316 - val_accuracy: 0.0976\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9922 - val_loss: -8.2685 - val_accuracy: 0.1098\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9980 - val_loss: -10.1794 - val_accuracy: 0.0854\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.9980 - val_loss: -9.2348 - val_accuracy: 0.1159\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: -9.7284 - val_accuracy: 0.0854\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: -9.7951 - val_accuracy: 0.0915\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: -9.6653 - val_accuracy: 0.0854\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: -9.7618 - val_accuracy: 0.1037\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: -9.3348 - val_accuracy: 0.1098\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: -9.2899 - val_accuracy: 0.1159\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: -9.5589 - val_accuracy: 0.1159\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: -9.6926 - val_accuracy: 0.1037\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: -9.9898 - val_accuracy: 0.0915\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: -9.5028 - val_accuracy: 0.1098\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -9.5852 - val_accuracy: 0.1220\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -9.9970 - val_accuracy: 0.1220\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -10.0424 - val_accuracy: 0.1098\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -10.3175 - val_accuracy: 0.1037\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -10.0155 - val_accuracy: 0.1220\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -10.7040 - val_accuracy: 0.1037\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -9.4961 - val_accuracy: 0.1280\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 7ms/step - loss: 0.6697 - accuracy: 0.5840 - val_loss: 0.0402 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6621 - val_loss: 0.3344 - val_accuracy: 0.1341\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5634 - accuracy: 0.7129 - val_loss: -0.0829 - val_accuracy: 0.1220\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7285 - val_loss: 0.9968 - val_accuracy: 0.1951\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7188 - val_loss: -0.3675 - val_accuracy: 0.1159\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7793 - val_loss: -0.2569 - val_accuracy: 0.1829\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7676 - val_loss: -0.7025 - val_accuracy: 0.1646\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7891 - val_loss: -0.2249 - val_accuracy: 0.1768\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.8145 - val_loss: -0.8305 - val_accuracy: 0.1463\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8184 - val_loss: -1.4469 - val_accuracy: 0.0976\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8359 - val_loss: -0.7687 - val_accuracy: 0.1707\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8398 - val_loss: -1.4989 - val_accuracy: 0.1159\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8145 - val_loss: -1.4055 - val_accuracy: 0.1159\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3663 - accuracy: 0.8398 - val_loss: -0.8965 - val_accuracy: 0.1646\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8574 - val_loss: -1.8705 - val_accuracy: 0.1098\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8652 - val_loss: -1.8581 - val_accuracy: 0.1037\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8164 - val_loss: -1.4373 - val_accuracy: 0.1524\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8418 - val_loss: -1.6907 - val_accuracy: 0.1037\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3205 - accuracy: 0.8750 - val_loss: -2.3921 - val_accuracy: 0.0854\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2997 - accuracy: 0.8848 - val_loss: -2.3549 - val_accuracy: 0.0854\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2802 - accuracy: 0.8848 - val_loss: -2.3197 - val_accuracy: 0.0976\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2931 - accuracy: 0.8672 - val_loss: -1.8050 - val_accuracy: 0.1585\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2941 - accuracy: 0.8828 - val_loss: -2.3791 - val_accuracy: 0.0976\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2590 - accuracy: 0.8984 - val_loss: -2.4572 - val_accuracy: 0.1037\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2575 - accuracy: 0.9023 - val_loss: -2.0024 - val_accuracy: 0.1220\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2398 - accuracy: 0.9043 - val_loss: -2.8298 - val_accuracy: 0.0915\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2247 - accuracy: 0.9043 - val_loss: -2.6701 - val_accuracy: 0.1037\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2113 - accuracy: 0.9160 - val_loss: -2.8770 - val_accuracy: 0.1280\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2119 - accuracy: 0.9258 - val_loss: -2.8767 - val_accuracy: 0.0976\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2228 - accuracy: 0.9141 - val_loss: -3.4791 - val_accuracy: 0.0854\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2091 - accuracy: 0.9258 - val_loss: -2.7648 - val_accuracy: 0.1098\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1887 - accuracy: 0.9336 - val_loss: -2.5037 - val_accuracy: 0.1220\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1751 - accuracy: 0.9277 - val_loss: -3.6837 - val_accuracy: 0.0671\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.1905 - accuracy: 0.9297 - val_loss: -3.3970 - val_accuracy: 0.0915\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1596 - accuracy: 0.9336 - val_loss: -3.4800 - val_accuracy: 0.0976\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1943 - accuracy: 0.9160 - val_loss: -3.3479 - val_accuracy: 0.1098\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2119 - accuracy: 0.9102 - val_loss: -3.2344 - val_accuracy: 0.1037\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1543 - accuracy: 0.9492 - val_loss: -3.5148 - val_accuracy: 0.1037\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1214 - accuracy: 0.9551 - val_loss: -3.7882 - val_accuracy: 0.0915\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1149 - accuracy: 0.9551 - val_loss: -2.9078 - val_accuracy: 0.1463\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1375 - accuracy: 0.9473 - val_loss: -3.6020 - val_accuracy: 0.1037\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.9629 - val_loss: -5.4222 - val_accuracy: 0.0610\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1204 - accuracy: 0.9551 - val_loss: -5.4793 - val_accuracy: 0.0793\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.9277 - val_loss: -2.8305 - val_accuracy: 0.1159\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9453 - val_loss: -5.5166 - val_accuracy: 0.0793\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9805 - val_loss: -4.6906 - val_accuracy: 0.1037\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9688 - val_loss: -4.6165 - val_accuracy: 0.1098\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1040 - accuracy: 0.9668 - val_loss: -4.6013 - val_accuracy: 0.1098\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9570 - val_loss: -3.7846 - val_accuracy: 0.1159\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1686 - accuracy: 0.9316 - val_loss: -3.8899 - val_accuracy: 0.1280\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9395 - val_loss: -4.1500 - val_accuracy: 0.1159\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9648 - val_loss: -4.5511 - val_accuracy: 0.0854\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9824 - val_loss: -4.2781 - val_accuracy: 0.1037\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9824 - val_loss: -4.7961 - val_accuracy: 0.0915\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: -5.6536 - val_accuracy: 0.0732\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0807 - accuracy: 0.9629 - val_loss: -6.7552 - val_accuracy: 0.0732\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9844 - val_loss: -4.7114 - val_accuracy: 0.1037\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9844 - val_loss: -6.1062 - val_accuracy: 0.0793\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9883 - val_loss: -5.3737 - val_accuracy: 0.0793\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9922 - val_loss: -5.7862 - val_accuracy: 0.0793\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9961 - val_loss: -6.1240 - val_accuracy: 0.0793\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9941 - val_loss: -7.0971 - val_accuracy: 0.0793\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: -6.6895 - val_accuracy: 0.0793\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9902 - val_loss: -5.2540 - val_accuracy: 0.0854\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9922 - val_loss: -5.9199 - val_accuracy: 0.0915\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: -5.8409 - val_accuracy: 0.0976\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9980 - val_loss: -6.5589 - val_accuracy: 0.0854\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9961 - val_loss: -6.7670 - val_accuracy: 0.0793\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9980 - val_loss: -6.7307 - val_accuracy: 0.0915\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: -6.5193 - val_accuracy: 0.0915\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: -7.2546 - val_accuracy: 0.0549\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: -7.8607 - val_accuracy: 0.0793\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: -6.8385 - val_accuracy: 0.0915\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: -6.7400 - val_accuracy: 0.0915\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: -7.2102 - val_accuracy: 0.0854\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9922 - val_loss: -7.5609 - val_accuracy: 0.0915\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9668 - val_loss: -6.6674 - val_accuracy: 0.0976\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1207 - accuracy: 0.9551 - val_loss: -4.1568 - val_accuracy: 0.0976\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9551 - val_loss: -7.4526 - val_accuracy: 0.0671\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9512 - val_loss: -6.1446 - val_accuracy: 0.0854\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1293 - accuracy: 0.9570 - val_loss: -7.1655 - val_accuracy: 0.1037\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.9609 - val_loss: -6.8058 - val_accuracy: 0.0915\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: -5.1960 - val_accuracy: 0.1098\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.9980 - val_loss: -6.3218 - val_accuracy: 0.0915\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: -5.7722 - val_accuracy: 0.1098\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: -7.1138 - val_accuracy: 0.0854\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -7.0023 - val_accuracy: 0.0854\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -6.8503 - val_accuracy: 0.0976\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -7.0077 - val_accuracy: 0.0915\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -7.5347 - val_accuracy: 0.0854\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -6.8800 - val_accuracy: 0.0976\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.4582 - val_accuracy: 0.0976\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.6435 - val_accuracy: 0.0976\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.4756 - val_accuracy: 0.0976\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.8501 - val_accuracy: 0.0976\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.4849 - val_accuracy: 0.0976\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.6054 - val_accuracy: 0.0976\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.6322 - val_accuracy: 0.0976\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.8034 - val_accuracy: 0.0976\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.8682 - val_accuracy: 0.0976\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.7911 - val_accuracy: 0.0976\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.7608 - val_accuracy: 0.0976\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.9934 - val_accuracy: 0.0976\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.1264 - val_accuracy: 0.0976\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.9461 - val_accuracy: 0.0976\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.1685 - val_accuracy: 0.0976\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.2549 - val_accuracy: 0.0976\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.3085 - val_accuracy: 0.0976\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.1808 - val_accuracy: 0.0976\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.3527 - val_accuracy: 0.0976\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.2256 - val_accuracy: 0.0976\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 9.8633e-04 - accuracy: 1.0000 - val_loss: -8.3383 - val_accuracy: 0.0915\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.9653e-04 - accuracy: 1.0000 - val_loss: -8.4161 - val_accuracy: 0.0976\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.8929e-04 - accuracy: 1.0000 - val_loss: -8.5422 - val_accuracy: 0.0976\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.8898e-04 - accuracy: 1.0000 - val_loss: -8.4717 - val_accuracy: 0.0976\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.5645e-04 - accuracy: 1.0000 - val_loss: -8.5892 - val_accuracy: 0.0976\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2857e-04 - accuracy: 1.0000 - val_loss: -8.4892 - val_accuracy: 0.0976\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9730e-04 - accuracy: 1.0000 - val_loss: -8.6677 - val_accuracy: 0.0976\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.6643e-04 - accuracy: 1.0000 - val_loss: -8.6950 - val_accuracy: 0.0976\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3644e-04 - accuracy: 1.0000 - val_loss: -8.5497 - val_accuracy: 0.0976\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1416e-04 - accuracy: 1.0000 - val_loss: -8.7227 - val_accuracy: 0.0976\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 6.9324e-04 - accuracy: 1.0000 - val_loss: -8.7257 - val_accuracy: 0.0976\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6866e-04 - accuracy: 1.0000 - val_loss: -8.7775 - val_accuracy: 0.0976\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 6.4955e-04 - accuracy: 1.0000 - val_loss: -8.7603 - val_accuracy: 0.0976\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1722e-04 - accuracy: 1.0000 - val_loss: -8.9056 - val_accuracy: 0.0976\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.0515e-04 - accuracy: 1.0000 - val_loss: -8.9137 - val_accuracy: 0.0976\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 5.8243e-04 - accuracy: 1.0000 - val_loss: -8.9182 - val_accuracy: 0.0976\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7786e-04 - accuracy: 1.0000 - val_loss: -9.0213 - val_accuracy: 0.0976\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.6930e-04 - accuracy: 1.0000 - val_loss: -8.8468 - val_accuracy: 0.0976\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3895e-04 - accuracy: 1.0000 - val_loss: -8.8790 - val_accuracy: 0.0976\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.5069e-04 - accuracy: 1.0000 - val_loss: -8.9698 - val_accuracy: 0.0976\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0427e-04 - accuracy: 1.0000 - val_loss: -9.0426 - val_accuracy: 0.0976\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4.9047e-04 - accuracy: 1.0000 - val_loss: -9.0960 - val_accuracy: 0.0976\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8478e-04 - accuracy: 1.0000 - val_loss: -9.2065 - val_accuracy: 0.0976\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7289e-04 - accuracy: 1.0000 - val_loss: -9.1497 - val_accuracy: 0.0976\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.5202e-04 - accuracy: 1.0000 - val_loss: -9.1680 - val_accuracy: 0.0976\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.4444e-04 - accuracy: 1.0000 - val_loss: -9.0078 - val_accuracy: 0.0976\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 4.6509e-04 - accuracy: 1.0000 - val_loss: -9.1955 - val_accuracy: 0.0976\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.3037e-04 - accuracy: 1.0000 - val_loss: -9.1019 - val_accuracy: 0.0976\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0892e-04 - accuracy: 1.0000 - val_loss: -9.2318 - val_accuracy: 0.0976\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9275e-04 - accuracy: 1.0000 - val_loss: -9.2417 - val_accuracy: 0.0976\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.8594e-04 - accuracy: 1.0000 - val_loss: -9.4855 - val_accuracy: 0.0915\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7609e-04 - accuracy: 1.0000 - val_loss: -9.2745 - val_accuracy: 0.0976\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7096e-04 - accuracy: 1.0000 - val_loss: -9.5060 - val_accuracy: 0.0915\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.5686e-04 - accuracy: 1.0000 - val_loss: -9.4413 - val_accuracy: 0.0915\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.4060e-04 - accuracy: 1.0000 - val_loss: -9.4112 - val_accuracy: 0.0976\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3410e-04 - accuracy: 1.0000 - val_loss: -9.3719 - val_accuracy: 0.0976\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2179e-04 - accuracy: 1.0000 - val_loss: -9.5292 - val_accuracy: 0.0976\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0904e-04 - accuracy: 1.0000 - val_loss: -9.5320 - val_accuracy: 0.0976\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0572e-04 - accuracy: 1.0000 - val_loss: -9.4714 - val_accuracy: 0.0976\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0442e-04 - accuracy: 1.0000 - val_loss: -9.5471 - val_accuracy: 0.0976\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9081e-04 - accuracy: 1.0000 - val_loss: -9.7506 - val_accuracy: 0.0915\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8514e-04 - accuracy: 1.0000 - val_loss: -9.5563 - val_accuracy: 0.0976\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.7205e-04 - accuracy: 1.0000 - val_loss: -9.6548 - val_accuracy: 0.0915\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7595e-04 - accuracy: 1.0000 - val_loss: -9.6918 - val_accuracy: 0.0915\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.6417e-04 - accuracy: 1.0000 - val_loss: -9.7185 - val_accuracy: 0.0915\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5613e-04 - accuracy: 1.0000 - val_loss: -9.7437 - val_accuracy: 0.0915\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5251e-04 - accuracy: 1.0000 - val_loss: -9.6243 - val_accuracy: 0.0976\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5996e-04 - accuracy: 1.0000 - val_loss: -9.8045 - val_accuracy: 0.0915\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3754e-04 - accuracy: 1.0000 - val_loss: -9.7569 - val_accuracy: 0.0915\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3687e-04 - accuracy: 1.0000 - val_loss: -9.8895 - val_accuracy: 0.0915\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2.2502e-04 - accuracy: 1.0000 - val_loss: -9.7970 - val_accuracy: 0.0976\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2495e-04 - accuracy: 1.0000 - val_loss: -9.9420 - val_accuracy: 0.0915\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2363e-04 - accuracy: 1.0000 - val_loss: -9.8783 - val_accuracy: 0.0976\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1810e-04 - accuracy: 1.0000 - val_loss: -9.9569 - val_accuracy: 0.0915\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0764e-04 - accuracy: 1.0000 - val_loss: -9.9996 - val_accuracy: 0.0915\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0138e-04 - accuracy: 1.0000 - val_loss: -9.9973 - val_accuracy: 0.0915\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9544e-04 - accuracy: 1.0000 - val_loss: -9.9558 - val_accuracy: 0.0915\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9330e-04 - accuracy: 1.0000 - val_loss: -9.9608 - val_accuracy: 0.0915\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9483e-04 - accuracy: 1.0000 - val_loss: -10.2229 - val_accuracy: 0.0915\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9209e-04 - accuracy: 1.0000 - val_loss: -10.1240 - val_accuracy: 0.0915\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8421e-04 - accuracy: 1.0000 - val_loss: -10.0302 - val_accuracy: 0.0915\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7846e-04 - accuracy: 1.0000 - val_loss: -10.1909 - val_accuracy: 0.0915\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7039e-04 - accuracy: 1.0000 - val_loss: -10.0708 - val_accuracy: 0.0915\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6973e-04 - accuracy: 1.0000 - val_loss: -10.3014 - val_accuracy: 0.0915\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6313e-04 - accuracy: 1.0000 - val_loss: -10.1460 - val_accuracy: 0.0915\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6878e-04 - accuracy: 1.0000 - val_loss: -10.2667 - val_accuracy: 0.0915\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.6899e-04 - accuracy: 1.0000 - val_loss: -10.0890 - val_accuracy: 0.0976\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5771e-04 - accuracy: 1.0000 - val_loss: -10.2124 - val_accuracy: 0.0915\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4939e-04 - accuracy: 1.0000 - val_loss: -10.3985 - val_accuracy: 0.0915\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4643e-04 - accuracy: 1.0000 - val_loss: -10.2884 - val_accuracy: 0.0915\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4814e-04 - accuracy: 1.0000 - val_loss: -10.2877 - val_accuracy: 0.0915\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4771e-04 - accuracy: 1.0000 - val_loss: -10.4263 - val_accuracy: 0.0915\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3741e-04 - accuracy: 1.0000 - val_loss: -10.2668 - val_accuracy: 0.0915\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.3948e-04 - accuracy: 1.0000 - val_loss: -10.4041 - val_accuracy: 0.0915\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3392e-04 - accuracy: 1.0000 - val_loss: -10.3882 - val_accuracy: 0.0915\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2904e-04 - accuracy: 1.0000 - val_loss: -10.5205 - val_accuracy: 0.0915\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2553e-04 - accuracy: 1.0000 - val_loss: -10.4692 - val_accuracy: 0.0915\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2403e-04 - accuracy: 1.0000 - val_loss: -10.5662 - val_accuracy: 0.0915\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2737e-04 - accuracy: 1.0000 - val_loss: -10.4106 - val_accuracy: 0.0915\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1879e-04 - accuracy: 1.0000 - val_loss: -10.5507 - val_accuracy: 0.0915\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1463e-04 - accuracy: 1.0000 - val_loss: -10.7017 - val_accuracy: 0.0915\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.1287e-04 - accuracy: 1.0000 - val_loss: -10.5424 - val_accuracy: 0.0915\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1065e-04 - accuracy: 1.0000 - val_loss: -10.5956 - val_accuracy: 0.0915\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0902e-04 - accuracy: 1.0000 - val_loss: -10.8018 - val_accuracy: 0.0915\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0713e-04 - accuracy: 1.0000 - val_loss: -10.6302 - val_accuracy: 0.0915\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0715e-04 - accuracy: 1.0000 - val_loss: -10.7485 - val_accuracy: 0.0915\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.0246e-04 - accuracy: 1.0000 - val_loss: -10.6047 - val_accuracy: 0.0915\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0062e-04 - accuracy: 1.0000 - val_loss: -10.7157 - val_accuracy: 0.0915\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0044e-04 - accuracy: 1.0000 - val_loss: -10.8963 - val_accuracy: 0.0915\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 18ms/step - loss: 0.6749 - accuracy: 0.5801 - val_loss: 0.4321 - val_accuracy: 0.1037\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6113 - val_loss: 0.6698 - val_accuracy: 0.1646\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6162 - accuracy: 0.6543 - val_loss: 0.5314 - val_accuracy: 0.1646\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5678 - accuracy: 0.7129 - val_loss: 0.0555 - val_accuracy: 0.1524\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5229 - accuracy: 0.7324 - val_loss: -0.0630 - val_accuracy: 0.1829\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7500 - val_loss: -0.6319 - val_accuracy: 0.1341\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7520 - val_loss: 0.0907 - val_accuracy: 0.1829\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7812 - val_loss: -0.8042 - val_accuracy: 0.1159\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4682 - accuracy: 0.7715 - val_loss: -1.5375 - val_accuracy: 0.0610\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: -1.1577 - val_accuracy: 0.1463\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7715 - val_loss: -0.3000 - val_accuracy: 0.1646\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: -1.1879 - val_accuracy: 0.1098\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8184 - val_loss: -1.0226 - val_accuracy: 0.1524\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8184 - val_loss: -1.4061 - val_accuracy: 0.1341\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8086 - val_loss: -0.9153 - val_accuracy: 0.1707\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8340 - val_loss: -1.3312 - val_accuracy: 0.1280\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8418 - val_loss: -1.4997 - val_accuracy: 0.1341\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8418 - val_loss: -2.0724 - val_accuracy: 0.0854\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3319 - accuracy: 0.8574 - val_loss: -1.0033 - val_accuracy: 0.1646\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8066 - val_loss: -1.5806 - val_accuracy: 0.1220\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3809 - accuracy: 0.8184 - val_loss: -0.1700 - val_accuracy: 0.1951\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3551 - accuracy: 0.8574 - val_loss: -1.5733 - val_accuracy: 0.1280\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.3026 - accuracy: 0.8730 - val_loss: -1.3868 - val_accuracy: 0.1463\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3048 - accuracy: 0.8711 - val_loss: -1.6492 - val_accuracy: 0.1341\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2689 - accuracy: 0.8945 - val_loss: -2.5772 - val_accuracy: 0.0915\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2571 - accuracy: 0.9004 - val_loss: -2.0539 - val_accuracy: 0.1524\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2562 - accuracy: 0.8867 - val_loss: -1.8259 - val_accuracy: 0.1402\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2472 - accuracy: 0.8906 - val_loss: -1.7508 - val_accuracy: 0.1341\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.2380 - accuracy: 0.9004 - val_loss: -3.0612 - val_accuracy: 0.0854\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1976 - accuracy: 0.9277 - val_loss: -2.0089 - val_accuracy: 0.1098\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1925 - accuracy: 0.9258 - val_loss: -2.0840 - val_accuracy: 0.1098\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2186 - accuracy: 0.9121 - val_loss: -3.2316 - val_accuracy: 0.1037\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.2203 - accuracy: 0.9160 - val_loss: -3.0659 - val_accuracy: 0.1037\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1687 - accuracy: 0.9316 - val_loss: -3.1133 - val_accuracy: 0.0915\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1698 - accuracy: 0.9258 - val_loss: -4.6385 - val_accuracy: 0.0671\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1890 - accuracy: 0.9199 - val_loss: -3.4617 - val_accuracy: 0.1098\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1565 - accuracy: 0.9414 - val_loss: -4.5267 - val_accuracy: 0.0915\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1330 - accuracy: 0.9473 - val_loss: -2.9339 - val_accuracy: 0.1159\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1309 - accuracy: 0.9531 - val_loss: -2.1243 - val_accuracy: 0.1524\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1496 - accuracy: 0.9316 - val_loss: -4.3883 - val_accuracy: 0.0976\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.9531 - val_loss: -3.9070 - val_accuracy: 0.1037\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1086 - accuracy: 0.9590 - val_loss: -3.4635 - val_accuracy: 0.1098\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1401 - accuracy: 0.9492 - val_loss: -5.0267 - val_accuracy: 0.1098\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9707 - val_loss: -3.6888 - val_accuracy: 0.1037\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9766 - val_loss: -4.4749 - val_accuracy: 0.0976\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0715 - accuracy: 0.9805 - val_loss: -3.1046 - val_accuracy: 0.1159\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0774 - accuracy: 0.9746 - val_loss: -4.2089 - val_accuracy: 0.0854\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: -4.1831 - val_accuracy: 0.1037\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0481 - accuracy: 0.9902 - val_loss: -3.8154 - val_accuracy: 0.1098\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0802 - accuracy: 0.9648 - val_loss: -6.3888 - val_accuracy: 0.0671\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1296 - accuracy: 0.9473 - val_loss: -3.4622 - val_accuracy: 0.1098\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1458 - accuracy: 0.9297 - val_loss: -3.9955 - val_accuracy: 0.1037\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9746 - val_loss: -5.1781 - val_accuracy: 0.1037\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: -5.5316 - val_accuracy: 0.0976\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0844 - accuracy: 0.9688 - val_loss: -3.8782 - val_accuracy: 0.1220\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0798 - accuracy: 0.9746 - val_loss: -4.3938 - val_accuracy: 0.0976\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0850 - accuracy: 0.9609 - val_loss: -4.0549 - val_accuracy: 0.1037\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.9434 - val_loss: -6.4121 - val_accuracy: 0.0732\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9863 - val_loss: -5.2825 - val_accuracy: 0.0915\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9961 - val_loss: -6.0516 - val_accuracy: 0.0854\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: -5.3832 - val_accuracy: 0.0915\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: -5.3440 - val_accuracy: 0.0976\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9980 - val_loss: -5.7018 - val_accuracy: 0.1037\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: -5.6377 - val_accuracy: 0.1037\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: -6.3177 - val_accuracy: 0.0915\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9902 - val_loss: -6.5267 - val_accuracy: 0.0976\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: -5.9692 - val_accuracy: 0.0976\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: -6.4188 - val_accuracy: 0.0976\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: -5.9807 - val_accuracy: 0.0976\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: -6.4834 - val_accuracy: 0.0915\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: -7.0362 - val_accuracy: 0.0793\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -6.7323 - val_accuracy: 0.0915\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: -6.6315 - val_accuracy: 0.0915\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -6.6953 - val_accuracy: 0.0915\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -6.7793 - val_accuracy: 0.0915\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -7.0317 - val_accuracy: 0.0915\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -6.6242 - val_accuracy: 0.0976\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -5.2265 - val_accuracy: 0.1037\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -7.1527 - val_accuracy: 0.0915\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.0368 - val_accuracy: 0.0915\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -6.9546 - val_accuracy: 0.0976\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -6.5880 - val_accuracy: 0.0976\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -6.9586 - val_accuracy: 0.0976\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -6.9782 - val_accuracy: 0.0915\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -6.9190 - val_accuracy: 0.0976\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.0827 - val_accuracy: 0.0915\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -6.7972 - val_accuracy: 0.0976\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.1092 - val_accuracy: 0.0976\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.2462 - val_accuracy: 0.0915\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.3383 - val_accuracy: 0.0976\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.2595 - val_accuracy: 0.0915\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.3752 - val_accuracy: 0.0976\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.0449 - val_accuracy: 0.0976\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.4096 - val_accuracy: 0.0915\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.1303 - val_accuracy: 0.0976\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.1597 - val_accuracy: 0.0976\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.3215 - val_accuracy: 0.0976\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -7.3532 - val_accuracy: 0.0976\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.7178e-04 - accuracy: 1.0000 - val_loss: -7.3562 - val_accuracy: 0.0976\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.2595 - val_accuracy: 0.0854\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.5137 - val_accuracy: 0.0915\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4142e-04 - accuracy: 1.0000 - val_loss: -7.2620 - val_accuracy: 0.0976\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.9939e-04 - accuracy: 1.0000 - val_loss: -7.7229 - val_accuracy: 0.0915\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.5278e-04 - accuracy: 1.0000 - val_loss: -7.2900 - val_accuracy: 0.0976\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.8699e-04 - accuracy: 1.0000 - val_loss: -7.4096 - val_accuracy: 0.0976\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9950e-04 - accuracy: 1.0000 - val_loss: -7.5926 - val_accuracy: 0.0976\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3960e-04 - accuracy: 1.0000 - val_loss: -7.4209 - val_accuracy: 0.0976\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2231e-04 - accuracy: 1.0000 - val_loss: -7.9364 - val_accuracy: 0.0915\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.2778e-04 - accuracy: 1.0000 - val_loss: -7.5860 - val_accuracy: 0.0976\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7166e-04 - accuracy: 1.0000 - val_loss: -7.8327 - val_accuracy: 0.0915\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9466e-04 - accuracy: 1.0000 - val_loss: -7.6272 - val_accuracy: 0.0915\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5874e-04 - accuracy: 1.0000 - val_loss: -7.6741 - val_accuracy: 0.0915\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4999e-04 - accuracy: 1.0000 - val_loss: -7.8186 - val_accuracy: 0.0915\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1916e-04 - accuracy: 1.0000 - val_loss: -7.7964 - val_accuracy: 0.0915\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9957e-04 - accuracy: 1.0000 - val_loss: -8.0942 - val_accuracy: 0.0915\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0580e-04 - accuracy: 1.0000 - val_loss: -7.7417 - val_accuracy: 0.0915\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4978e-04 - accuracy: 1.0000 - val_loss: -8.0195 - val_accuracy: 0.0915\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3937e-04 - accuracy: 1.0000 - val_loss: -7.8681 - val_accuracy: 0.0915\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.5472e-04 - accuracy: 1.0000 - val_loss: -7.9751 - val_accuracy: 0.0915\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.0601e-04 - accuracy: 1.0000 - val_loss: -7.9484 - val_accuracy: 0.0915\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8590e-04 - accuracy: 1.0000 - val_loss: -7.9620 - val_accuracy: 0.0915\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8237e-04 - accuracy: 1.0000 - val_loss: -7.8318 - val_accuracy: 0.0915\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4330e-04 - accuracy: 1.0000 - val_loss: -7.9792 - val_accuracy: 0.0976\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.4366e-04 - accuracy: 1.0000 - val_loss: -8.0506 - val_accuracy: 0.0915\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3116e-04 - accuracy: 1.0000 - val_loss: -7.9033 - val_accuracy: 0.0976\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.2167e-04 - accuracy: 1.0000 - val_loss: -8.0663 - val_accuracy: 0.0915\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.0902e-04 - accuracy: 1.0000 - val_loss: -8.1369 - val_accuracy: 0.0976\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.1492e-04 - accuracy: 1.0000 - val_loss: -8.0838 - val_accuracy: 0.0915\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0191e-04 - accuracy: 1.0000 - val_loss: -7.9053 - val_accuracy: 0.0976\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1815e-04 - accuracy: 1.0000 - val_loss: -8.2051 - val_accuracy: 0.0915\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0142e-04 - accuracy: 1.0000 - val_loss: -8.1512 - val_accuracy: 0.0915\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.5207e-04 - accuracy: 1.0000 - val_loss: -8.3469 - val_accuracy: 0.0915\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5571e-04 - accuracy: 1.0000 - val_loss: -8.0434 - val_accuracy: 0.0976\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.5554e-04 - accuracy: 1.0000 - val_loss: -8.1872 - val_accuracy: 0.0915\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.2374e-04 - accuracy: 1.0000 - val_loss: -8.1057 - val_accuracy: 0.0976\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.1645e-04 - accuracy: 1.0000 - val_loss: -8.4215 - val_accuracy: 0.0915\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.0397e-04 - accuracy: 1.0000 - val_loss: -8.1381 - val_accuracy: 0.0976\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.9262e-04 - accuracy: 1.0000 - val_loss: -8.4424 - val_accuracy: 0.0915\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.8320e-04 - accuracy: 1.0000 - val_loss: -8.4091 - val_accuracy: 0.0915\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7392e-04 - accuracy: 1.0000 - val_loss: -8.2957 - val_accuracy: 0.0915\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7609e-04 - accuracy: 1.0000 - val_loss: -8.2098 - val_accuracy: 0.0976\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.6973e-04 - accuracy: 1.0000 - val_loss: -8.3352 - val_accuracy: 0.0976\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.7137e-04 - accuracy: 1.0000 - val_loss: -8.3210 - val_accuracy: 0.0976\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.5400e-04 - accuracy: 1.0000 - val_loss: -8.6456 - val_accuracy: 0.0915\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 2.4960e-04 - accuracy: 1.0000 - val_loss: -8.3957 - val_accuracy: 0.0976\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 2.4874e-04 - accuracy: 1.0000 - val_loss: -8.6670 - val_accuracy: 0.0915\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.4080e-04 - accuracy: 1.0000 - val_loss: -8.5567 - val_accuracy: 0.0976\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3377e-04 - accuracy: 1.0000 - val_loss: -8.6141 - val_accuracy: 0.0915\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.3438e-04 - accuracy: 1.0000 - val_loss: -8.4414 - val_accuracy: 0.0976\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1037e-04 - accuracy: 1.0000 - val_loss: -8.5034 - val_accuracy: 0.0976\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0548e-04 - accuracy: 1.0000 - val_loss: -8.7051 - val_accuracy: 0.0915\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.0245e-04 - accuracy: 1.0000 - val_loss: -8.6404 - val_accuracy: 0.0976\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9557e-04 - accuracy: 1.0000 - val_loss: -8.5167 - val_accuracy: 0.0976\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9279e-04 - accuracy: 1.0000 - val_loss: -8.6380 - val_accuracy: 0.0976\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8750e-04 - accuracy: 1.0000 - val_loss: -8.7643 - val_accuracy: 0.0915\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8236e-04 - accuracy: 1.0000 - val_loss: -8.8189 - val_accuracy: 0.0915\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7221e-04 - accuracy: 1.0000 - val_loss: -8.5058 - val_accuracy: 0.0976\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8270e-04 - accuracy: 1.0000 - val_loss: -8.8147 - val_accuracy: 0.0915\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7918e-04 - accuracy: 1.0000 - val_loss: -8.8986 - val_accuracy: 0.0915\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6212e-04 - accuracy: 1.0000 - val_loss: -8.6727 - val_accuracy: 0.0976\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6293e-04 - accuracy: 1.0000 - val_loss: -8.9463 - val_accuracy: 0.0915\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5935e-04 - accuracy: 1.0000 - val_loss: -8.7140 - val_accuracy: 0.0976\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5363e-04 - accuracy: 1.0000 - val_loss: -8.7605 - val_accuracy: 0.0915\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4712e-04 - accuracy: 1.0000 - val_loss: -8.8199 - val_accuracy: 0.0915\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4319e-04 - accuracy: 1.0000 - val_loss: -9.0420 - val_accuracy: 0.0915\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4592e-04 - accuracy: 1.0000 - val_loss: -8.6776 - val_accuracy: 0.0976\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4467e-04 - accuracy: 1.0000 - val_loss: -8.8003 - val_accuracy: 0.0976\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3374e-04 - accuracy: 1.0000 - val_loss: -8.7350 - val_accuracy: 0.0915\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3701e-04 - accuracy: 1.0000 - val_loss: -9.1243 - val_accuracy: 0.0915\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2374e-04 - accuracy: 1.0000 - val_loss: -8.9076 - val_accuracy: 0.0976\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2728e-04 - accuracy: 1.0000 - val_loss: -8.9118 - val_accuracy: 0.0915\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2076e-04 - accuracy: 1.0000 - val_loss: -9.1177 - val_accuracy: 0.0915\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1638e-04 - accuracy: 1.0000 - val_loss: -9.0087 - val_accuracy: 0.0915\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1482e-04 - accuracy: 1.0000 - val_loss: -8.7963 - val_accuracy: 0.0976\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1613e-04 - accuracy: 1.0000 - val_loss: -8.9927 - val_accuracy: 0.0915\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0777e-04 - accuracy: 1.0000 - val_loss: -9.1121 - val_accuracy: 0.0915\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0721e-04 - accuracy: 1.0000 - val_loss: -9.1187 - val_accuracy: 0.0976\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0363e-04 - accuracy: 1.0000 - val_loss: -8.9701 - val_accuracy: 0.0976\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0114e-04 - accuracy: 1.0000 - val_loss: -9.1870 - val_accuracy: 0.0915\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.7534e-05 - accuracy: 1.0000 - val_loss: -9.0633 - val_accuracy: 0.0915\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.4882e-05 - accuracy: 1.0000 - val_loss: -9.0439 - val_accuracy: 0.0976\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.4442e-05 - accuracy: 1.0000 - val_loss: -9.3617 - val_accuracy: 0.0915\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.1001e-05 - accuracy: 1.0000 - val_loss: -9.1738 - val_accuracy: 0.0976\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9062e-05 - accuracy: 1.0000 - val_loss: -9.3557 - val_accuracy: 0.0915\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.7878e-05 - accuracy: 1.0000 - val_loss: -9.3755 - val_accuracy: 0.0915\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.6106e-05 - accuracy: 1.0000 - val_loss: -9.3707 - val_accuracy: 0.0915\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.4524e-05 - accuracy: 1.0000 - val_loss: -9.3112 - val_accuracy: 0.0915\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1330e-05 - accuracy: 1.0000 - val_loss: -9.3567 - val_accuracy: 0.0915\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.9663e-05 - accuracy: 1.0000 - val_loss: -9.3487 - val_accuracy: 0.0915\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.0507e-05 - accuracy: 1.0000 - val_loss: -9.2165 - val_accuracy: 0.0976\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.8460e-05 - accuracy: 1.0000 - val_loss: -9.3865 - val_accuracy: 0.0915\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.5525e-05 - accuracy: 1.0000 - val_loss: -9.2295 - val_accuracy: 0.0976\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.4517e-05 - accuracy: 1.0000 - val_loss: -9.5070 - val_accuracy: 0.0915\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.0738e-05 - accuracy: 1.0000 - val_loss: -9.4809 - val_accuracy: 0.0915\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.8929e-05 - accuracy: 1.0000 - val_loss: -9.3722 - val_accuracy: 0.0915\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.7171e-05 - accuracy: 1.0000 - val_loss: -9.6117 - val_accuracy: 0.0915\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.6863e-05 - accuracy: 1.0000 - val_loss: -9.5507 - val_accuracy: 0.0915\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5035e-05 - accuracy: 1.0000 - val_loss: -9.2977 - val_accuracy: 0.0976\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.3398e-05 - accuracy: 1.0000 - val_loss: -9.6083 - val_accuracy: 0.0915\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2444e-05 - accuracy: 1.0000 - val_loss: -9.4900 - val_accuracy: 0.0915\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 2s 12ms/step - loss: 0.6904 - accuracy: 0.5273 - val_loss: 0.9766 - val_accuracy: 0.2134\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6641 - val_loss: 0.4989 - val_accuracy: 0.1463\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6621 - val_loss: 0.4093 - val_accuracy: 0.1402\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7031 - val_loss: 0.2597 - val_accuracy: 0.1585\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7461 - val_loss: -0.1423 - val_accuracy: 0.1402\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.7578 - val_loss: -0.2923 - val_accuracy: 0.1463\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7969 - val_loss: -1.3018 - val_accuracy: 0.0305\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7695 - val_loss: -1.2966 - val_accuracy: 0.0488\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7773 - val_loss: 0.0837 - val_accuracy: 0.1951\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.8105 - val_loss: -1.3116 - val_accuracy: 0.0915\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8047 - val_loss: -0.1390 - val_accuracy: 0.1951\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8066 - val_loss: -0.4271 - val_accuracy: 0.1890\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8066 - val_loss: -0.2817 - val_accuracy: 0.1951\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8242 - val_loss: -0.7254 - val_accuracy: 0.1585\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8301 - val_loss: -0.8197 - val_accuracy: 0.1707\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8359 - val_loss: -1.5037 - val_accuracy: 0.1341\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8340 - val_loss: -1.0709 - val_accuracy: 0.1524\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8398 - val_loss: -1.4088 - val_accuracy: 0.1524\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8574 - val_loss: -2.4331 - val_accuracy: 0.0549\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3364 - accuracy: 0.8555 - val_loss: -1.4761 - val_accuracy: 0.1524\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.8555 - val_loss: -1.8887 - val_accuracy: 0.0732\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8242 - val_loss: -1.0483 - val_accuracy: 0.1524\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3335 - accuracy: 0.8457 - val_loss: -1.5656 - val_accuracy: 0.1463\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8809 - val_loss: -1.6758 - val_accuracy: 0.1524\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.8574 - val_loss: -2.1070 - val_accuracy: 0.1220\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2842 - accuracy: 0.8828 - val_loss: -1.4436 - val_accuracy: 0.1585\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.8809 - val_loss: -2.6006 - val_accuracy: 0.0976\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8340 - val_loss: -1.5902 - val_accuracy: 0.1646\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8809 - val_loss: -1.6721 - val_accuracy: 0.1524\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2793 - accuracy: 0.8867 - val_loss: -1.5433 - val_accuracy: 0.1646\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2723 - accuracy: 0.8965 - val_loss: -2.5564 - val_accuracy: 0.0793\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9160 - val_loss: -2.7167 - val_accuracy: 0.1159\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2184 - accuracy: 0.9043 - val_loss: -2.8169 - val_accuracy: 0.0854\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9180 - val_loss: -2.8373 - val_accuracy: 0.0976\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9297 - val_loss: -1.0672 - val_accuracy: 0.1768\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1881 - accuracy: 0.9277 - val_loss: -3.3198 - val_accuracy: 0.1220\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1812 - accuracy: 0.9434 - val_loss: -2.4894 - val_accuracy: 0.1098\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9297 - val_loss: -3.0409 - val_accuracy: 0.1341\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9434 - val_loss: -3.0452 - val_accuracy: 0.1159\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1798 - accuracy: 0.9355 - val_loss: -3.5066 - val_accuracy: 0.1402\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1737 - accuracy: 0.9336 - val_loss: -1.3884 - val_accuracy: 0.1890\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2229 - accuracy: 0.9141 - val_loss: -2.5395 - val_accuracy: 0.1159\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9258 - val_loss: -2.5031 - val_accuracy: 0.1463\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1924 - accuracy: 0.9219 - val_loss: -3.7369 - val_accuracy: 0.1037\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9219 - val_loss: -2.9771 - val_accuracy: 0.1463\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1524 - accuracy: 0.9512 - val_loss: -2.2978 - val_accuracy: 0.1524\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9551 - val_loss: -2.7830 - val_accuracy: 0.1463\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9473 - val_loss: -4.6341 - val_accuracy: 0.1098\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9551 - val_loss: -4.6063 - val_accuracy: 0.1098\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.9688 - val_loss: -3.8476 - val_accuracy: 0.1524\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.9629 - val_loss: -3.6999 - val_accuracy: 0.1280\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9629 - val_loss: -6.2159 - val_accuracy: 0.0915\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1459 - accuracy: 0.9492 - val_loss: -5.5987 - val_accuracy: 0.1098\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.9473 - val_loss: -5.0059 - val_accuracy: 0.1220\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9551 - val_loss: -5.6665 - val_accuracy: 0.0793\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9707 - val_loss: -4.9377 - val_accuracy: 0.0915\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9727 - val_loss: -5.6772 - val_accuracy: 0.0793\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9766 - val_loss: -3.1524 - val_accuracy: 0.1341\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9688 - val_loss: -5.3256 - val_accuracy: 0.1098\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9766 - val_loss: -5.3728 - val_accuracy: 0.0915\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9512 - val_loss: -5.3735 - val_accuracy: 0.0976\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9453 - val_loss: -4.5755 - val_accuracy: 0.1098\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9570 - val_loss: -3.5554 - val_accuracy: 0.1463\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9609 - val_loss: -5.3074 - val_accuracy: 0.1159\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9707 - val_loss: -5.3653 - val_accuracy: 0.1159\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9785 - val_loss: -4.8281 - val_accuracy: 0.1220\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9785 - val_loss: -3.7405 - val_accuracy: 0.1280\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9727 - val_loss: -3.6727 - val_accuracy: 0.1524\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.9824 - val_loss: -6.4574 - val_accuracy: 0.0854\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9902 - val_loss: -5.6684 - val_accuracy: 0.0976\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: -5.9979 - val_accuracy: 0.1037\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: -4.6292 - val_accuracy: 0.1585\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9785 - val_loss: -5.0122 - val_accuracy: 0.1463\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9863 - val_loss: -4.1610 - val_accuracy: 0.1463\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9902 - val_loss: -5.7186 - val_accuracy: 0.1037\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9902 - val_loss: -4.9384 - val_accuracy: 0.1463\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: -6.2314 - val_accuracy: 0.0854\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9902 - val_loss: -5.5696 - val_accuracy: 0.1280\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: -5.4031 - val_accuracy: 0.1280\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: -6.6650 - val_accuracy: 0.1037\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9941 - val_loss: -7.1387 - val_accuracy: 0.1098\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9961 - val_loss: -6.9898 - val_accuracy: 0.1098\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9980 - val_loss: -6.6883 - val_accuracy: 0.1220\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9961 - val_loss: -6.4975 - val_accuracy: 0.1220\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: -8.3058 - val_accuracy: 0.0976\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9746 - val_loss: -8.1035 - val_accuracy: 0.1098\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9512 - val_loss: -3.5756 - val_accuracy: 0.1402\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9785 - val_loss: -4.7234 - val_accuracy: 0.1098\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9805 - val_loss: -5.1812 - val_accuracy: 0.1220\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9648 - val_loss: -5.2143 - val_accuracy: 0.1037\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9590 - val_loss: -5.6355 - val_accuracy: 0.1280\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.9551 - val_loss: -3.6050 - val_accuracy: 0.1037\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9766 - val_loss: -9.6142 - val_accuracy: 0.0671\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 0.9629 - val_loss: -5.7520 - val_accuracy: 0.1098\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9824 - val_loss: -6.7642 - val_accuracy: 0.0915\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9902 - val_loss: -6.6166 - val_accuracy: 0.1220\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9941 - val_loss: -6.5260 - val_accuracy: 0.1280\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: -7.4324 - val_accuracy: 0.0915\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9980 - val_loss: -7.0516 - val_accuracy: 0.1037\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: -7.2307 - val_accuracy: 0.0976\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9941 - val_loss: -7.1813 - val_accuracy: 0.0915\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: -8.0130 - val_accuracy: 0.0732\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: -7.3429 - val_accuracy: 0.0854\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: -8.4170 - val_accuracy: 0.0732\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: -7.2794 - val_accuracy: 0.0915\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: -8.6907 - val_accuracy: 0.0671\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: -5.2095 - val_accuracy: 0.1524\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 0.9863 - val_loss: -6.4493 - val_accuracy: 0.1159\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9922 - val_loss: -8.7586 - val_accuracy: 0.0671\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: -8.4824 - val_accuracy: 0.0732\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: -7.2397 - val_accuracy: 0.1098\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: -7.4374 - val_accuracy: 0.0793\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 0.9941 - val_loss: -6.7520 - val_accuracy: 0.1037\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9961 - val_loss: -7.5114 - val_accuracy: 0.0854\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9941 - val_loss: -8.6655 - val_accuracy: 0.0793\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9941 - val_loss: -7.9470 - val_accuracy: 0.0915\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9941 - val_loss: -8.6180 - val_accuracy: 0.0732\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9902 - val_loss: -4.9625 - val_accuracy: 0.1524\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: -8.4832 - val_accuracy: 0.0915\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9844 - val_loss: -6.0770 - val_accuracy: 0.1159\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1538 - accuracy: 0.9512 - val_loss: -6.0977 - val_accuracy: 0.1037\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.9414 - val_loss: -7.2852 - val_accuracy: 0.0732\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9551 - val_loss: -5.1662 - val_accuracy: 0.1402\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9551 - val_loss: -6.6162 - val_accuracy: 0.0976\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9824 - val_loss: -6.2350 - val_accuracy: 0.1280\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9883 - val_loss: -6.7068 - val_accuracy: 0.0976\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: -5.9964 - val_accuracy: 0.1098\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: -7.1703 - val_accuracy: 0.1098\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: -7.2230 - val_accuracy: 0.0976\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -7.8245 - val_accuracy: 0.0915\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: -7.8053 - val_accuracy: 0.0915\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: -7.7821 - val_accuracy: 0.0976\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -7.4756 - val_accuracy: 0.1037\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -7.7706 - val_accuracy: 0.0976\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -8.4613 - val_accuracy: 0.0854\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.9178 - val_accuracy: 0.0976\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -7.5793 - val_accuracy: 0.1098\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -8.1970 - val_accuracy: 0.0915\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.1179 - val_accuracy: 0.0915\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -8.6382 - val_accuracy: 0.0854\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.3907 - val_accuracy: 0.0976\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.5669 - val_accuracy: 0.0915\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.5528 - val_accuracy: 0.0854\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.4534 - val_accuracy: 0.0915\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.4525 - val_accuracy: 0.0915\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.6904 - val_accuracy: 0.0854\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.8673e-04 - accuracy: 1.0000 - val_loss: -8.5320 - val_accuracy: 0.0915\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.8493e-04 - accuracy: 1.0000 - val_loss: -8.5025 - val_accuracy: 0.0915\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.5901e-04 - accuracy: 1.0000 - val_loss: -8.3907 - val_accuracy: 0.0976\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.9406e-04 - accuracy: 1.0000 - val_loss: -8.8137 - val_accuracy: 0.0854\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2090e-04 - accuracy: 1.0000 - val_loss: -8.8974 - val_accuracy: 0.0854\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1992e-04 - accuracy: 1.0000 - val_loss: -8.8075 - val_accuracy: 0.0854\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.2461e-04 - accuracy: 1.0000 - val_loss: -8.6620 - val_accuracy: 0.0854\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0278e-04 - accuracy: 1.0000 - val_loss: -8.8915 - val_accuracy: 0.0854\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.6175e-04 - accuracy: 1.0000 - val_loss: -8.6811 - val_accuracy: 0.0854\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2165e-04 - accuracy: 1.0000 - val_loss: -8.8360 - val_accuracy: 0.0854\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1360e-04 - accuracy: 1.0000 - val_loss: -8.9098 - val_accuracy: 0.0854\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9173e-04 - accuracy: 1.0000 - val_loss: -8.8677 - val_accuracy: 0.0854\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4756e-04 - accuracy: 1.0000 - val_loss: -8.8443 - val_accuracy: 0.0854\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.8432e-04 - accuracy: 1.0000 - val_loss: -8.9706 - val_accuracy: 0.0854\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.0821e-04 - accuracy: 1.0000 - val_loss: -8.9480 - val_accuracy: 0.0854\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.3053e-04 - accuracy: 1.0000 - val_loss: -9.2180 - val_accuracy: 0.0854\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.1543e-04 - accuracy: 1.0000 - val_loss: -9.0161 - val_accuracy: 0.0854\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7503e-04 - accuracy: 1.0000 - val_loss: -9.1582 - val_accuracy: 0.0854\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4.9359e-04 - accuracy: 1.0000 - val_loss: -9.1144 - val_accuracy: 0.0854\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5427e-04 - accuracy: 1.0000 - val_loss: -9.0424 - val_accuracy: 0.0854\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.4868e-04 - accuracy: 1.0000 - val_loss: -9.1691 - val_accuracy: 0.0854\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.2557e-04 - accuracy: 1.0000 - val_loss: -9.0053 - val_accuracy: 0.0915\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.1996e-04 - accuracy: 1.0000 - val_loss: -9.2770 - val_accuracy: 0.0854\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0569e-04 - accuracy: 1.0000 - val_loss: -9.1744 - val_accuracy: 0.0854\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.8439e-04 - accuracy: 1.0000 - val_loss: -9.0959 - val_accuracy: 0.0854\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7980e-04 - accuracy: 1.0000 - val_loss: -9.2535 - val_accuracy: 0.0854\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.6740e-04 - accuracy: 1.0000 - val_loss: -9.1882 - val_accuracy: 0.0854\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5655e-04 - accuracy: 1.0000 - val_loss: -9.2088 - val_accuracy: 0.0854\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3698e-04 - accuracy: 1.0000 - val_loss: -9.1911 - val_accuracy: 0.0854\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3592e-04 - accuracy: 1.0000 - val_loss: -9.1812 - val_accuracy: 0.0854\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3226e-04 - accuracy: 1.0000 - val_loss: -9.3636 - val_accuracy: 0.0854\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3111e-04 - accuracy: 1.0000 - val_loss: -9.1961 - val_accuracy: 0.0915\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2563e-04 - accuracy: 1.0000 - val_loss: -9.5034 - val_accuracy: 0.0854\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.1197e-04 - accuracy: 1.0000 - val_loss: -9.0715 - val_accuracy: 0.0915\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9816e-04 - accuracy: 1.0000 - val_loss: -9.4620 - val_accuracy: 0.0854\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8900e-04 - accuracy: 1.0000 - val_loss: -9.5116 - val_accuracy: 0.0854\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8646e-04 - accuracy: 1.0000 - val_loss: -9.5173 - val_accuracy: 0.0854\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8945e-04 - accuracy: 1.0000 - val_loss: -9.5225 - val_accuracy: 0.0854\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7782e-04 - accuracy: 1.0000 - val_loss: -9.4227 - val_accuracy: 0.0854\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7094e-04 - accuracy: 1.0000 - val_loss: -9.8019 - val_accuracy: 0.0854\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.8966e-04 - accuracy: 1.0000 - val_loss: -9.4533 - val_accuracy: 0.0854\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5117e-04 - accuracy: 1.0000 - val_loss: -9.3650 - val_accuracy: 0.0915\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3903e-04 - accuracy: 1.0000 - val_loss: -9.7132 - val_accuracy: 0.0854\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4720e-04 - accuracy: 1.0000 - val_loss: -9.4664 - val_accuracy: 0.0915\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.3154e-04 - accuracy: 1.0000 - val_loss: -9.5166 - val_accuracy: 0.0854\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.3647e-04 - accuracy: 1.0000 - val_loss: -9.7587 - val_accuracy: 0.0854\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.1416e-04 - accuracy: 1.0000 - val_loss: -9.5587 - val_accuracy: 0.0854\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.1262e-04 - accuracy: 1.0000 - val_loss: -9.7568 - val_accuracy: 0.0854\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0014e-04 - accuracy: 1.0000 - val_loss: -9.6102 - val_accuracy: 0.0854\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9647e-04 - accuracy: 1.0000 - val_loss: -9.6602 - val_accuracy: 0.0854\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9445e-04 - accuracy: 1.0000 - val_loss: -9.7334 - val_accuracy: 0.0854\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8490e-04 - accuracy: 1.0000 - val_loss: -9.7091 - val_accuracy: 0.0854\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8898e-04 - accuracy: 1.0000 - val_loss: -9.7959 - val_accuracy: 0.0854\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7911e-04 - accuracy: 1.0000 - val_loss: -9.7524 - val_accuracy: 0.0854\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Epoch 1/300\n",
      "32/32 [==============================] - 2s 24ms/step - loss: 0.6855 - accuracy: 0.5293 - val_loss: 0.3148 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6172 - val_loss: 0.7372 - val_accuracy: 0.1585\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6025 - accuracy: 0.7012 - val_loss: 0.4367 - val_accuracy: 0.1463\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7051 - val_loss: -0.2693 - val_accuracy: 0.0915\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7520 - val_loss: -0.1637 - val_accuracy: 0.1585\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7734 - val_loss: -0.4282 - val_accuracy: 0.1524\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7637 - val_loss: -0.0138 - val_accuracy: 0.1768\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8047 - val_loss: -1.1248 - val_accuracy: 0.1037\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7715 - val_loss: -0.2713 - val_accuracy: 0.1829\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7852 - val_loss: -0.9330 - val_accuracy: 0.1341\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8086 - val_loss: -1.1458 - val_accuracy: 0.1280\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8086 - val_loss: -1.5027 - val_accuracy: 0.1037\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8359 - val_loss: -0.9958 - val_accuracy: 0.1524\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8359 - val_loss: -1.3791 - val_accuracy: 0.1402\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8672 - val_loss: -1.4133 - val_accuracy: 0.1524\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8516 - val_loss: -2.7421 - val_accuracy: 0.0854\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7871 - val_loss: -0.9196 - val_accuracy: 0.1646\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8223 - val_loss: -1.0757 - val_accuracy: 0.1585\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3547 - accuracy: 0.8496 - val_loss: -1.2420 - val_accuracy: 0.1707\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3242 - accuracy: 0.8613 - val_loss: -2.1852 - val_accuracy: 0.0915\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8750 - val_loss: -2.9874 - val_accuracy: 0.0793\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2814 - accuracy: 0.8867 - val_loss: -2.5392 - val_accuracy: 0.1159\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8828 - val_loss: -2.1841 - val_accuracy: 0.1159\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8711 - val_loss: -2.5412 - val_accuracy: 0.0915\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2921 - accuracy: 0.8906 - val_loss: -2.5546 - val_accuracy: 0.1220\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.8945 - val_loss: -2.9554 - val_accuracy: 0.1037\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.9004 - val_loss: -3.1880 - val_accuracy: 0.0915\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.9102 - val_loss: -2.9699 - val_accuracy: 0.1159\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8730 - val_loss: -2.3170 - val_accuracy: 0.1341\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2332 - accuracy: 0.9023 - val_loss: -0.6091 - val_accuracy: 0.1707\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.8926 - val_loss: -2.6711 - val_accuracy: 0.1037\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9219 - val_loss: -2.4951 - val_accuracy: 0.1159\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9023 - val_loss: -3.0819 - val_accuracy: 0.1098\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9160 - val_loss: -4.1501 - val_accuracy: 0.0793\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.9434 - val_loss: -3.8135 - val_accuracy: 0.0915\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1660 - accuracy: 0.9395 - val_loss: -4.9341 - val_accuracy: 0.0732\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2278 - accuracy: 0.8984 - val_loss: -1.6100 - val_accuracy: 0.1646\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.8945 - val_loss: -2.8016 - val_accuracy: 0.1098\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: -3.0910 - val_accuracy: 0.0976\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1747 - accuracy: 0.9316 - val_loss: -3.9554 - val_accuracy: 0.0793\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9492 - val_loss: -3.9526 - val_accuracy: 0.1159\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9609 - val_loss: -3.3594 - val_accuracy: 0.1463\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9277 - val_loss: -4.4123 - val_accuracy: 0.1220\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9570 - val_loss: -4.4443 - val_accuracy: 0.1341\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9434 - val_loss: -5.5141 - val_accuracy: 0.0549\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.9688 - val_loss: -5.7389 - val_accuracy: 0.0732\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9629 - val_loss: -3.6242 - val_accuracy: 0.1280\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9473 - val_loss: -4.5752 - val_accuracy: 0.1037\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9590 - val_loss: -4.8763 - val_accuracy: 0.1098\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9570 - val_loss: -3.4915 - val_accuracy: 0.1341\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9766 - val_loss: -4.6482 - val_accuracy: 0.1037\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9590 - val_loss: -5.9478 - val_accuracy: 0.0854\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9473 - val_loss: -4.2528 - val_accuracy: 0.1098\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9727 - val_loss: -6.5261 - val_accuracy: 0.0610\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9648 - val_loss: -7.2119 - val_accuracy: 0.0549\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9648 - val_loss: -7.6167 - val_accuracy: 0.0549\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9805 - val_loss: -6.5646 - val_accuracy: 0.0610\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9824 - val_loss: -6.6538 - val_accuracy: 0.0671\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: -5.5542 - val_accuracy: 0.1159\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9824 - val_loss: -6.9589 - val_accuracy: 0.0671\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9902 - val_loss: -6.4635 - val_accuracy: 0.0671\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9785 - val_loss: -6.1323 - val_accuracy: 0.1159\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9766 - val_loss: -5.0844 - val_accuracy: 0.1098\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9707 - val_loss: -6.7410 - val_accuracy: 0.0854\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9688 - val_loss: -5.9448 - val_accuracy: 0.0976\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9531 - val_loss: -7.9770 - val_accuracy: 0.0854\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9570 - val_loss: -4.7098 - val_accuracy: 0.1220\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9648 - val_loss: -6.3992 - val_accuracy: 0.0854\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9883 - val_loss: -7.8591 - val_accuracy: 0.0610\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: -6.0729 - val_accuracy: 0.0976\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: -7.1648 - val_accuracy: 0.0976\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9844 - val_loss: -8.3977 - val_accuracy: 0.0732\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9688 - val_loss: -8.5884 - val_accuracy: 0.0732\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1193 - accuracy: 0.9531 - val_loss: -6.6702 - val_accuracy: 0.1037\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9727 - val_loss: -7.1177 - val_accuracy: 0.0854\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9844 - val_loss: -6.9941 - val_accuracy: 0.0854\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9961 - val_loss: -8.8131 - val_accuracy: 0.0488\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9941 - val_loss: -7.9562 - val_accuracy: 0.1098\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: -7.9376 - val_accuracy: 0.0976\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: -8.9810 - val_accuracy: 0.0671\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: -8.2348 - val_accuracy: 0.0915\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: -9.4040 - val_accuracy: 0.0732\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: -9.1735 - val_accuracy: 0.0793\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: -8.2720 - val_accuracy: 0.1037\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: -8.5940 - val_accuracy: 0.0915\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: -8.3665 - val_accuracy: 0.1037\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: -8.9283 - val_accuracy: 0.0915\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: -9.5015 - val_accuracy: 0.0915\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: -9.3085 - val_accuracy: 0.0915\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: -9.3083 - val_accuracy: 0.0915\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: -9.5814 - val_accuracy: 0.0854\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: -9.8022 - val_accuracy: 0.0854\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: -9.0835 - val_accuracy: 0.0915\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: -10.6617 - val_accuracy: 0.0793\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -10.5564 - val_accuracy: 0.0854\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: -10.5431 - val_accuracy: 0.0915\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: -9.3658 - val_accuracy: 0.1098\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: -9.7191 - val_accuracy: 0.0976\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -9.1975 - val_accuracy: 0.0976\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -10.2801 - val_accuracy: 0.0915\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -10.5174 - val_accuracy: 0.0793\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -10.4151 - val_accuracy: 0.0915\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -9.6579 - val_accuracy: 0.0915\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -10.4200 - val_accuracy: 0.0854\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -11.0403 - val_accuracy: 0.0854\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -10.5853 - val_accuracy: 0.0915\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.9627 - val_accuracy: 0.0854\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.6484 - val_accuracy: 0.0915\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.9354 - val_accuracy: 0.0854\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -11.0106 - val_accuracy: 0.0854\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.9975 - val_accuracy: 0.0854\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -11.0230 - val_accuracy: 0.0915\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.7008e-04 - accuracy: 1.0000 - val_loss: -11.0802 - val_accuracy: 0.0854\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.1341e-04 - accuracy: 1.0000 - val_loss: -11.2314 - val_accuracy: 0.0854\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2132e-04 - accuracy: 1.0000 - val_loss: -10.8913 - val_accuracy: 0.0915\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1852e-04 - accuracy: 1.0000 - val_loss: -11.4552 - val_accuracy: 0.0854\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.6968e-04 - accuracy: 1.0000 - val_loss: -10.9994 - val_accuracy: 0.0854\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4272e-04 - accuracy: 1.0000 - val_loss: -11.2141 - val_accuracy: 0.0915\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.4894e-04 - accuracy: 1.0000 - val_loss: -11.2480 - val_accuracy: 0.0854\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.8655e-04 - accuracy: 1.0000 - val_loss: -11.4082 - val_accuracy: 0.0915\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3123e-04 - accuracy: 1.0000 - val_loss: -11.6860 - val_accuracy: 0.0854\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3185e-04 - accuracy: 1.0000 - val_loss: -11.2637 - val_accuracy: 0.0915\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.3594e-04 - accuracy: 1.0000 - val_loss: -11.8620 - val_accuracy: 0.0854\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.0378e-04 - accuracy: 1.0000 - val_loss: -11.3225 - val_accuracy: 0.0915\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4937e-04 - accuracy: 1.0000 - val_loss: -11.5403 - val_accuracy: 0.0915\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7732e-04 - accuracy: 1.0000 - val_loss: -11.4732 - val_accuracy: 0.0915\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2639e-04 - accuracy: 1.0000 - val_loss: -11.7522 - val_accuracy: 0.0854\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.1121e-04 - accuracy: 1.0000 - val_loss: -11.6001 - val_accuracy: 0.0915\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3926e-04 - accuracy: 1.0000 - val_loss: -11.6919 - val_accuracy: 0.0854\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.9598e-04 - accuracy: 1.0000 - val_loss: -11.7568 - val_accuracy: 0.0915\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4693e-04 - accuracy: 1.0000 - val_loss: -11.7425 - val_accuracy: 0.0854\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7413e-04 - accuracy: 1.0000 - val_loss: -12.0232 - val_accuracy: 0.0915\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5350e-04 - accuracy: 1.0000 - val_loss: -11.7389 - val_accuracy: 0.0854\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2380e-04 - accuracy: 1.0000 - val_loss: -12.0172 - val_accuracy: 0.0915\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9332e-04 - accuracy: 1.0000 - val_loss: -12.0037 - val_accuracy: 0.0915\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9942e-04 - accuracy: 1.0000 - val_loss: -12.0709 - val_accuracy: 0.0854\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9669e-04 - accuracy: 1.0000 - val_loss: -12.0012 - val_accuracy: 0.0915\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5380e-04 - accuracy: 1.0000 - val_loss: -12.0670 - val_accuracy: 0.0915\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6605e-04 - accuracy: 1.0000 - val_loss: -12.2006 - val_accuracy: 0.0915\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4616e-04 - accuracy: 1.0000 - val_loss: -12.0527 - val_accuracy: 0.0915\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4516e-04 - accuracy: 1.0000 - val_loss: -12.3110 - val_accuracy: 0.0915\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4606e-04 - accuracy: 1.0000 - val_loss: -12.2063 - val_accuracy: 0.0915\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.1924e-04 - accuracy: 1.0000 - val_loss: -12.3403 - val_accuracy: 0.0915\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9526e-04 - accuracy: 1.0000 - val_loss: -12.1202 - val_accuracy: 0.0915\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0525e-04 - accuracy: 1.0000 - val_loss: -12.0131 - val_accuracy: 0.0976\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9245e-04 - accuracy: 1.0000 - val_loss: -12.4211 - val_accuracy: 0.0915\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7503e-04 - accuracy: 1.0000 - val_loss: -12.3437 - val_accuracy: 0.0915\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5396e-04 - accuracy: 1.0000 - val_loss: -12.4629 - val_accuracy: 0.0915\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.5001e-04 - accuracy: 1.0000 - val_loss: -12.3485 - val_accuracy: 0.0915\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.3555e-04 - accuracy: 1.0000 - val_loss: -12.3814 - val_accuracy: 0.0915\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.3844e-04 - accuracy: 1.0000 - val_loss: -12.6272 - val_accuracy: 0.0854\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2268e-04 - accuracy: 1.0000 - val_loss: -12.3199 - val_accuracy: 0.0915\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2987e-04 - accuracy: 1.0000 - val_loss: -12.4511 - val_accuracy: 0.0915\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1443e-04 - accuracy: 1.0000 - val_loss: -12.6820 - val_accuracy: 0.0915\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1163e-04 - accuracy: 1.0000 - val_loss: -12.6368 - val_accuracy: 0.0915\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.0117e-04 - accuracy: 1.0000 - val_loss: -12.5142 - val_accuracy: 0.0915\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9537e-04 - accuracy: 1.0000 - val_loss: -12.7806 - val_accuracy: 0.0915\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.9404e-04 - accuracy: 1.0000 - val_loss: -12.5978 - val_accuracy: 0.0915\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8931e-04 - accuracy: 1.0000 - val_loss: -12.6885 - val_accuracy: 0.0915\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7672e-04 - accuracy: 1.0000 - val_loss: -12.6083 - val_accuracy: 0.0915\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8042e-04 - accuracy: 1.0000 - val_loss: -12.5358 - val_accuracy: 0.0915\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6736e-04 - accuracy: 1.0000 - val_loss: -12.9076 - val_accuracy: 0.0915\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6402e-04 - accuracy: 1.0000 - val_loss: -12.8857 - val_accuracy: 0.0915\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5338e-04 - accuracy: 1.0000 - val_loss: -12.7555 - val_accuracy: 0.0915\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4887e-04 - accuracy: 1.0000 - val_loss: -12.8156 - val_accuracy: 0.0915\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4741e-04 - accuracy: 1.0000 - val_loss: -12.9670 - val_accuracy: 0.0915\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4212e-04 - accuracy: 1.0000 - val_loss: -12.8931 - val_accuracy: 0.0915\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3893e-04 - accuracy: 1.0000 - val_loss: -13.0278 - val_accuracy: 0.0915\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4007e-04 - accuracy: 1.0000 - val_loss: -13.0401 - val_accuracy: 0.0915\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3069e-04 - accuracy: 1.0000 - val_loss: -12.9972 - val_accuracy: 0.0915\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2398e-04 - accuracy: 1.0000 - val_loss: -12.9973 - val_accuracy: 0.0915\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2163e-04 - accuracy: 1.0000 - val_loss: -12.9623 - val_accuracy: 0.0915\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1854e-04 - accuracy: 1.0000 - val_loss: -13.0580 - val_accuracy: 0.0915\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2163e-04 - accuracy: 1.0000 - val_loss: -12.9612 - val_accuracy: 0.0915\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1505e-04 - accuracy: 1.0000 - val_loss: -13.0964 - val_accuracy: 0.0915\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1089e-04 - accuracy: 1.0000 - val_loss: -13.1151 - val_accuracy: 0.0915\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0921e-04 - accuracy: 1.0000 - val_loss: -12.8822 - val_accuracy: 0.0976\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0509e-04 - accuracy: 1.0000 - val_loss: -13.3132 - val_accuracy: 0.0915\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0480e-04 - accuracy: 1.0000 - val_loss: -13.2335 - val_accuracy: 0.0915\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.3463e-05 - accuracy: 1.0000 - val_loss: -13.2596 - val_accuracy: 0.0915\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4554e-05 - accuracy: 1.0000 - val_loss: -13.2703 - val_accuracy: 0.0915\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.9669e-05 - accuracy: 1.0000 - val_loss: -13.2940 - val_accuracy: 0.0915\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.6965e-05 - accuracy: 1.0000 - val_loss: -13.3983 - val_accuracy: 0.0915\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4248e-05 - accuracy: 1.0000 - val_loss: -13.3432 - val_accuracy: 0.0915\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.5505e-05 - accuracy: 1.0000 - val_loss: -13.5198 - val_accuracy: 0.0915\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.4708e-05 - accuracy: 1.0000 - val_loss: -13.2585 - val_accuracy: 0.0915\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.6011e-05 - accuracy: 1.0000 - val_loss: -13.3570 - val_accuracy: 0.0976\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.5108e-05 - accuracy: 1.0000 - val_loss: -13.5800 - val_accuracy: 0.0915\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.2513e-05 - accuracy: 1.0000 - val_loss: -13.4490 - val_accuracy: 0.0915\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 7.0375e-05 - accuracy: 1.0000 - val_loss: -13.4723 - val_accuracy: 0.0915\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8218e-05 - accuracy: 1.0000 - val_loss: -13.5296 - val_accuracy: 0.0915\n",
      "Epoch 192/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.5702e-05 - accuracy: 1.0000 - val_loss: -13.4376 - val_accuracy: 0.0976\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5051e-05 - accuracy: 1.0000 - val_loss: -13.5997 - val_accuracy: 0.0915\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2119e-05 - accuracy: 1.0000 - val_loss: -13.4515 - val_accuracy: 0.0915\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2645e-05 - accuracy: 1.0000 - val_loss: -13.6356 - val_accuracy: 0.0915\n",
      "Epoch 196/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1994e-05 - accuracy: 1.0000 - val_loss: -13.5297 - val_accuracy: 0.0976\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.7249e-05 - accuracy: 1.0000 - val_loss: -13.5598 - val_accuracy: 0.0976\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7274e-05 - accuracy: 1.0000 - val_loss: -13.7300 - val_accuracy: 0.0915\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4451e-05 - accuracy: 1.0000 - val_loss: -13.5018 - val_accuracy: 0.0976\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4194e-05 - accuracy: 1.0000 - val_loss: -13.6486 - val_accuracy: 0.0915\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.0459e-05 - accuracy: 1.0000 - val_loss: -13.7315 - val_accuracy: 0.0915\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9913e-05 - accuracy: 1.0000 - val_loss: -13.6929 - val_accuracy: 0.0976\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8926e-05 - accuracy: 1.0000 - val_loss: -13.8014 - val_accuracy: 0.0915\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7126e-05 - accuracy: 1.0000 - val_loss: -13.7143 - val_accuracy: 0.0976\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5032e-05 - accuracy: 1.0000 - val_loss: -13.8795 - val_accuracy: 0.0915\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4700e-05 - accuracy: 1.0000 - val_loss: -13.7631 - val_accuracy: 0.0976\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3834e-05 - accuracy: 1.0000 - val_loss: -13.8250 - val_accuracy: 0.0915\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1105e-05 - accuracy: 1.0000 - val_loss: -13.8342 - val_accuracy: 0.0976\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0653e-05 - accuracy: 1.0000 - val_loss: -13.9176 - val_accuracy: 0.0915\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9261e-05 - accuracy: 1.0000 - val_loss: -13.7937 - val_accuracy: 0.0976\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7620e-05 - accuracy: 1.0000 - val_loss: -13.9099 - val_accuracy: 0.0915\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7188e-05 - accuracy: 1.0000 - val_loss: -13.9012 - val_accuracy: 0.0976\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6122e-05 - accuracy: 1.0000 - val_loss: -13.9069 - val_accuracy: 0.0915\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.5263e-05 - accuracy: 1.0000 - val_loss: -13.7834 - val_accuracy: 0.0976\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5043e-05 - accuracy: 1.0000 - val_loss: -13.9626 - val_accuracy: 0.0976\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3990e-05 - accuracy: 1.0000 - val_loss: -13.9035 - val_accuracy: 0.0976\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2114e-05 - accuracy: 1.0000 - val_loss: -14.0236 - val_accuracy: 0.0976\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.1300e-05 - accuracy: 1.0000 - val_loss: -14.1453 - val_accuracy: 0.0915\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0238e-05 - accuracy: 1.0000 - val_loss: -14.0291 - val_accuracy: 0.0976\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9650e-05 - accuracy: 1.0000 - val_loss: -14.1043 - val_accuracy: 0.0915\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.8258e-05 - accuracy: 1.0000 - val_loss: -14.0557 - val_accuracy: 0.0976\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7620e-05 - accuracy: 1.0000 - val_loss: -14.1717 - val_accuracy: 0.0976\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7766e-05 - accuracy: 1.0000 - val_loss: -14.2449 - val_accuracy: 0.0915\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.8581e-05 - accuracy: 1.0000 - val_loss: -13.9812 - val_accuracy: 0.0976\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7747e-05 - accuracy: 1.0000 - val_loss: -14.2973 - val_accuracy: 0.0915\n",
      "Epoch 226/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5217e-05 - accuracy: 1.0000 - val_loss: -14.1127 - val_accuracy: 0.0976\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4230e-05 - accuracy: 1.0000 - val_loss: -14.1783 - val_accuracy: 0.0976\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3507e-05 - accuracy: 1.0000 - val_loss: -14.2122 - val_accuracy: 0.0976\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2512e-05 - accuracy: 1.0000 - val_loss: -14.2552 - val_accuracy: 0.0976\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1665e-05 - accuracy: 1.0000 - val_loss: -14.2316 - val_accuracy: 0.0976\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1174e-05 - accuracy: 1.0000 - val_loss: -14.3040 - val_accuracy: 0.0976\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0815e-05 - accuracy: 1.0000 - val_loss: -14.3525 - val_accuracy: 0.0976\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0330e-05 - accuracy: 1.0000 - val_loss: -14.3577 - val_accuracy: 0.0915\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9538e-05 - accuracy: 1.0000 - val_loss: -14.3834 - val_accuracy: 0.0976\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8865e-05 - accuracy: 1.0000 - val_loss: -14.2851 - val_accuracy: 0.0976\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8195e-05 - accuracy: 1.0000 - val_loss: -14.4057 - val_accuracy: 0.0976\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7800e-05 - accuracy: 1.0000 - val_loss: -14.3840 - val_accuracy: 0.0976\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7233e-05 - accuracy: 1.0000 - val_loss: -14.3847 - val_accuracy: 0.0976\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7219e-05 - accuracy: 1.0000 - val_loss: -14.4151 - val_accuracy: 0.0976\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6488e-05 - accuracy: 1.0000 - val_loss: -14.4868 - val_accuracy: 0.0976\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5959e-05 - accuracy: 1.0000 - val_loss: -14.4331 - val_accuracy: 0.0976\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5465e-05 - accuracy: 1.0000 - val_loss: -14.4423 - val_accuracy: 0.0976\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5029e-05 - accuracy: 1.0000 - val_loss: -14.5678 - val_accuracy: 0.0976\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4886e-05 - accuracy: 1.0000 - val_loss: -14.4781 - val_accuracy: 0.0976\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4293e-05 - accuracy: 1.0000 - val_loss: -14.5447 - val_accuracy: 0.0976\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4029e-05 - accuracy: 1.0000 - val_loss: -14.5096 - val_accuracy: 0.0976\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3603e-05 - accuracy: 1.0000 - val_loss: -14.6032 - val_accuracy: 0.0976\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3153e-05 - accuracy: 1.0000 - val_loss: -14.5674 - val_accuracy: 0.0976\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3023e-05 - accuracy: 1.0000 - val_loss: -14.6848 - val_accuracy: 0.0976\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.2790e-05 - accuracy: 1.0000 - val_loss: -14.5873 - val_accuracy: 0.0976\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2241e-05 - accuracy: 1.0000 - val_loss: -14.6809 - val_accuracy: 0.0976\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.2211e-05 - accuracy: 1.0000 - val_loss: -14.5488 - val_accuracy: 0.0976\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1547e-05 - accuracy: 1.0000 - val_loss: -14.6649 - val_accuracy: 0.0976\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1153e-05 - accuracy: 1.0000 - val_loss: -14.6841 - val_accuracy: 0.0976\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0792e-05 - accuracy: 1.0000 - val_loss: -14.6768 - val_accuracy: 0.0976\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0928e-05 - accuracy: 1.0000 - val_loss: -14.7150 - val_accuracy: 0.0976\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0407e-05 - accuracy: 1.0000 - val_loss: -14.6570 - val_accuracy: 0.0976\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.9662e-06 - accuracy: 1.0000 - val_loss: -14.7493 - val_accuracy: 0.0976\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.6701e-06 - accuracy: 1.0000 - val_loss: -14.6844 - val_accuracy: 0.0976\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.5420e-06 - accuracy: 1.0000 - val_loss: -14.7366 - val_accuracy: 0.0976\n",
      "Epoch 261/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2036e-06 - accuracy: 1.0000 - val_loss: -14.6961 - val_accuracy: 0.0976\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.0539e-06 - accuracy: 1.0000 - val_loss: -14.8036 - val_accuracy: 0.0976\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.7728e-06 - accuracy: 1.0000 - val_loss: -14.7709 - val_accuracy: 0.0976\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.5005e-06 - accuracy: 1.0000 - val_loss: -14.7861 - val_accuracy: 0.0976\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2393e-06 - accuracy: 1.0000 - val_loss: -14.8266 - val_accuracy: 0.0976\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9930e-06 - accuracy: 1.0000 - val_loss: -14.8181 - val_accuracy: 0.0976\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.7616e-06 - accuracy: 1.0000 - val_loss: -14.8229 - val_accuracy: 0.0976\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7093e-06 - accuracy: 1.0000 - val_loss: -14.8604 - val_accuracy: 0.0976\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.5192e-06 - accuracy: 1.0000 - val_loss: -14.8400 - val_accuracy: 0.0976\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3027e-06 - accuracy: 1.0000 - val_loss: -14.9225 - val_accuracy: 0.0976\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0156e-06 - accuracy: 1.0000 - val_loss: -14.8331 - val_accuracy: 0.0976\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0144e-06 - accuracy: 1.0000 - val_loss: -14.9386 - val_accuracy: 0.0976\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7522e-06 - accuracy: 1.0000 - val_loss: -14.9033 - val_accuracy: 0.0976\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.5832e-06 - accuracy: 1.0000 - val_loss: -14.9844 - val_accuracy: 0.0976\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.4011e-06 - accuracy: 1.0000 - val_loss: -14.8976 - val_accuracy: 0.0976\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1740e-06 - accuracy: 1.0000 - val_loss: -14.9568 - val_accuracy: 0.0976\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0844e-06 - accuracy: 1.0000 - val_loss: -14.9525 - val_accuracy: 0.0976\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.0606e-06 - accuracy: 1.0000 - val_loss: -15.0373 - val_accuracy: 0.0976\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8438e-06 - accuracy: 1.0000 - val_loss: -14.9867 - val_accuracy: 0.0976\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7125e-06 - accuracy: 1.0000 - val_loss: -15.0410 - val_accuracy: 0.0976\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5108e-06 - accuracy: 1.0000 - val_loss: -14.9894 - val_accuracy: 0.0976\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4138e-06 - accuracy: 1.0000 - val_loss: -15.0238 - val_accuracy: 0.0976\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4827e-06 - accuracy: 1.0000 - val_loss: -15.0935 - val_accuracy: 0.0976\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2231e-06 - accuracy: 1.0000 - val_loss: -15.0484 - val_accuracy: 0.0976\n",
      "Epoch 285/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0080e-06 - accuracy: 1.0000 - val_loss: -15.0545 - val_accuracy: 0.0976\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8194e-06 - accuracy: 1.0000 - val_loss: -15.0511 - val_accuracy: 0.0976\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7680e-06 - accuracy: 1.0000 - val_loss: -15.0170 - val_accuracy: 0.0976\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.6385e-06 - accuracy: 1.0000 - val_loss: -15.1080 - val_accuracy: 0.0976\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4820e-06 - accuracy: 1.0000 - val_loss: -15.1495 - val_accuracy: 0.0976\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3406e-06 - accuracy: 1.0000 - val_loss: -15.0985 - val_accuracy: 0.0976\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3015e-06 - accuracy: 1.0000 - val_loss: -15.1791 - val_accuracy: 0.0976\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1852e-06 - accuracy: 1.0000 - val_loss: -15.1295 - val_accuracy: 0.0976\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0813e-06 - accuracy: 1.0000 - val_loss: -15.1752 - val_accuracy: 0.0976\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.9936e-06 - accuracy: 1.0000 - val_loss: -15.1629 - val_accuracy: 0.0976\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8963e-06 - accuracy: 1.0000 - val_loss: -15.2214 - val_accuracy: 0.0976\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8703e-06 - accuracy: 1.0000 - val_loss: -15.1358 - val_accuracy: 0.0976\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7954e-06 - accuracy: 1.0000 - val_loss: -15.1837 - val_accuracy: 0.0976\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6548e-06 - accuracy: 1.0000 - val_loss: -15.1968 - val_accuracy: 0.0976\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.5900e-06 - accuracy: 1.0000 - val_loss: -15.1768 - val_accuracy: 0.0976\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4625e-06 - accuracy: 1.0000 - val_loss: -15.2096 - val_accuracy: 0.0976\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Epoch 1/300\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.7060 - accuracy: 0.4570 - val_loss: 0.7737 - val_accuracy: 0.1951\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.6211 - val_loss: 0.5892 - val_accuracy: 0.1524\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6358 - accuracy: 0.6309 - val_loss: 0.2688 - val_accuracy: 0.1402\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.6699 - val_loss: 0.2635 - val_accuracy: 0.1524\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7246 - val_loss: -0.5620 - val_accuracy: 0.0854\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7031 - val_loss: -0.0529 - val_accuracy: 0.1768\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.7539 - val_loss: -0.6445 - val_accuracy: 0.1341\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7598 - val_loss: -0.2060 - val_accuracy: 0.1829\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7539 - val_loss: -0.5611 - val_accuracy: 0.1768\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7676 - val_loss: 0.5334 - val_accuracy: 0.1951\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7773 - val_loss: -1.0817 - val_accuracy: 0.1585\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7754 - val_loss: -0.8544 - val_accuracy: 0.1646\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.7949 - val_loss: -1.1873 - val_accuracy: 0.1463\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.7949 - val_loss: -1.3110 - val_accuracy: 0.1037\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8223 - val_loss: -0.2690 - val_accuracy: 0.1524\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: -0.5277 - val_accuracy: 0.1646\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8418 - val_loss: -1.8662 - val_accuracy: 0.1098\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8105 - val_loss: -1.2651 - val_accuracy: 0.1646\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8477 - val_loss: -0.9472 - val_accuracy: 0.1646\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8418 - val_loss: -1.8477 - val_accuracy: 0.1220\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8438 - val_loss: -1.6533 - val_accuracy: 0.1280\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8477 - val_loss: -1.1355 - val_accuracy: 0.1524\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8809 - val_loss: -1.3180 - val_accuracy: 0.1402\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.8867 - val_loss: -2.0304 - val_accuracy: 0.1341\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8633 - val_loss: -1.3737 - val_accuracy: 0.1524\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.8945 - val_loss: -2.4173 - val_accuracy: 0.1220\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.8867 - val_loss: -2.1042 - val_accuracy: 0.1280\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.8809 - val_loss: -1.3487 - val_accuracy: 0.1463\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2721 - accuracy: 0.8926 - val_loss: -1.4434 - val_accuracy: 0.1341\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8926 - val_loss: -2.0821 - val_accuracy: 0.1220\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2393 - accuracy: 0.9141 - val_loss: -2.8335 - val_accuracy: 0.1037\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8770 - val_loss: -2.3719 - val_accuracy: 0.1098\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2115 - accuracy: 0.9316 - val_loss: -2.8768 - val_accuracy: 0.0793\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2285 - accuracy: 0.9023 - val_loss: -2.6990 - val_accuracy: 0.0976\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1910 - accuracy: 0.9297 - val_loss: -1.9641 - val_accuracy: 0.1220\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9219 - val_loss: -2.8058 - val_accuracy: 0.0976\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2000 - accuracy: 0.9199 - val_loss: -2.2634 - val_accuracy: 0.1098\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9141 - val_loss: -3.1187 - val_accuracy: 0.0915\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2387 - accuracy: 0.9121 - val_loss: -1.3190 - val_accuracy: 0.1585\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2244 - accuracy: 0.9043 - val_loss: -2.7653 - val_accuracy: 0.1159\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9316 - val_loss: -1.0371 - val_accuracy: 0.1646\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2185 - accuracy: 0.9141 - val_loss: -2.4258 - val_accuracy: 0.1463\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9355 - val_loss: -3.5507 - val_accuracy: 0.0976\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9512 - val_loss: -3.7015 - val_accuracy: 0.1098\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 0.9453 - val_loss: -3.4118 - val_accuracy: 0.1037\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1391 - accuracy: 0.9492 - val_loss: -1.7166 - val_accuracy: 0.1463\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9512 - val_loss: -4.6726 - val_accuracy: 0.0793\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9688 - val_loss: -4.5444 - val_accuracy: 0.0854\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9629 - val_loss: -4.3451 - val_accuracy: 0.1098\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9766 - val_loss: -5.0953 - val_accuracy: 0.0915\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9258 - val_loss: -3.6138 - val_accuracy: 0.1159\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1359 - accuracy: 0.9492 - val_loss: -3.1493 - val_accuracy: 0.1220\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1070 - accuracy: 0.9570 - val_loss: -4.1704 - val_accuracy: 0.0976\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9648 - val_loss: -5.2138 - val_accuracy: 0.0854\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9824 - val_loss: -4.3601 - val_accuracy: 0.0976\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9844 - val_loss: -4.0283 - val_accuracy: 0.1037\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: -2.1454 - val_accuracy: 0.1402\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9707 - val_loss: -4.3139 - val_accuracy: 0.1098\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9727 - val_loss: -4.6221 - val_accuracy: 0.0976\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9902 - val_loss: -6.2351 - val_accuracy: 0.0854\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9707 - val_loss: -4.7708 - val_accuracy: 0.0915\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9883 - val_loss: -4.3168 - val_accuracy: 0.1098\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9863 - val_loss: -4.8111 - val_accuracy: 0.1098\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: -3.8977 - val_accuracy: 0.1159\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9746 - val_loss: -3.5792 - val_accuracy: 0.1098\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9805 - val_loss: -5.0931 - val_accuracy: 0.1098\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9785 - val_loss: -6.5722 - val_accuracy: 0.0854\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9492 - val_loss: -3.8999 - val_accuracy: 0.0915\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.9570 - val_loss: -4.3087 - val_accuracy: 0.0976\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9629 - val_loss: -5.4495 - val_accuracy: 0.1037\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9922 - val_loss: -5.5100 - val_accuracy: 0.0915\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9922 - val_loss: -4.9513 - val_accuracy: 0.0854\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: -4.4143 - val_accuracy: 0.1159\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9922 - val_loss: -6.3454 - val_accuracy: 0.0854\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: -6.6103 - val_accuracy: 0.0854\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: -4.6991 - val_accuracy: 0.1220\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: -6.4008 - val_accuracy: 0.0915\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: -5.5770 - val_accuracy: 0.0976\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9980 - val_loss: -5.6962 - val_accuracy: 0.0976\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: -5.7176 - val_accuracy: 0.0976\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: -6.5527 - val_accuracy: 0.0854\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: -6.3611 - val_accuracy: 0.0976\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: -6.6009 - val_accuracy: 0.0915\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -6.9071 - val_accuracy: 0.0915\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -6.7437 - val_accuracy: 0.0854\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -6.9529 - val_accuracy: 0.0915\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -6.6510 - val_accuracy: 0.0915\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -6.7534 - val_accuracy: 0.0915\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -7.2381 - val_accuracy: 0.0915\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -6.7942 - val_accuracy: 0.0915\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.3178 - val_accuracy: 0.0854\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.0980 - val_accuracy: 0.0854\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -7.1412 - val_accuracy: 0.0915\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -6.9674 - val_accuracy: 0.0915\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.1961 - val_accuracy: 0.0915\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.0380 - val_accuracy: 0.0915\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.1020 - val_accuracy: 0.0915\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -6.7842 - val_accuracy: 0.0915\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.1936 - val_accuracy: 0.0915\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -6.9935 - val_accuracy: 0.0915\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.2677 - val_accuracy: 0.0915\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.3088 - val_accuracy: 0.0915\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.5165 - val_accuracy: 0.0915\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.2228 - val_accuracy: 0.0915\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.5270 - val_accuracy: 0.0915\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -7.4654 - val_accuracy: 0.0915\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.8660e-04 - accuracy: 1.0000 - val_loss: -7.5158 - val_accuracy: 0.0915\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.6611 - val_accuracy: 0.0915\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.5691 - val_accuracy: 0.0854\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2203e-04 - accuracy: 1.0000 - val_loss: -7.2865 - val_accuracy: 0.0915\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.4683e-04 - accuracy: 1.0000 - val_loss: -7.7675 - val_accuracy: 0.0915\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7107e-04 - accuracy: 1.0000 - val_loss: -7.6207 - val_accuracy: 0.0915\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9281e-04 - accuracy: 1.0000 - val_loss: -7.5351 - val_accuracy: 0.0915\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.6026e-04 - accuracy: 1.0000 - val_loss: -7.5230 - val_accuracy: 0.0915\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4111e-04 - accuracy: 1.0000 - val_loss: -7.6756 - val_accuracy: 0.0915\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 6.9769e-04 - accuracy: 1.0000 - val_loss: -7.4824 - val_accuracy: 0.0915\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 6.8847e-04 - accuracy: 1.0000 - val_loss: -7.6839 - val_accuracy: 0.0915\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.6055e-04 - accuracy: 1.0000 - val_loss: -7.6810 - val_accuracy: 0.0915\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 6.3507e-04 - accuracy: 1.0000 - val_loss: -7.9558 - val_accuracy: 0.0915\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 6.1381e-04 - accuracy: 1.0000 - val_loss: -7.6930 - val_accuracy: 0.0915\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.9275e-04 - accuracy: 1.0000 - val_loss: -7.7567 - val_accuracy: 0.0915\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.7298e-04 - accuracy: 1.0000 - val_loss: -8.0804 - val_accuracy: 0.0854\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4963e-04 - accuracy: 1.0000 - val_loss: -7.8019 - val_accuracy: 0.0915\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 5.3628e-04 - accuracy: 1.0000 - val_loss: -8.0311 - val_accuracy: 0.0915\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.2537e-04 - accuracy: 1.0000 - val_loss: -7.9030 - val_accuracy: 0.0915\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9527e-04 - accuracy: 1.0000 - val_loss: -7.9242 - val_accuracy: 0.0915\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0063e-04 - accuracy: 1.0000 - val_loss: -8.1534 - val_accuracy: 0.0915\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.9003e-04 - accuracy: 1.0000 - val_loss: -8.0600 - val_accuracy: 0.0915\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6054e-04 - accuracy: 1.0000 - val_loss: -8.0947 - val_accuracy: 0.0915\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4918e-04 - accuracy: 1.0000 - val_loss: -8.1491 - val_accuracy: 0.0915\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1865e-04 - accuracy: 1.0000 - val_loss: -7.9746 - val_accuracy: 0.0915\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.2254e-04 - accuracy: 1.0000 - val_loss: -8.2201 - val_accuracy: 0.0915\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9349e-04 - accuracy: 1.0000 - val_loss: -8.1940 - val_accuracy: 0.0915\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8277e-04 - accuracy: 1.0000 - val_loss: -8.1043 - val_accuracy: 0.0915\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7685e-04 - accuracy: 1.0000 - val_loss: -8.3373 - val_accuracy: 0.0854\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.6990e-04 - accuracy: 1.0000 - val_loss: -8.1776 - val_accuracy: 0.0915\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6671e-04 - accuracy: 1.0000 - val_loss: -8.2580 - val_accuracy: 0.0915\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3103e-04 - accuracy: 1.0000 - val_loss: -8.1348 - val_accuracy: 0.0915\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.2777e-04 - accuracy: 1.0000 - val_loss: -8.3221 - val_accuracy: 0.0915\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.1733e-04 - accuracy: 1.0000 - val_loss: -8.1720 - val_accuracy: 0.0915\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0854e-04 - accuracy: 1.0000 - val_loss: -8.1973 - val_accuracy: 0.0915\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1066e-04 - accuracy: 1.0000 - val_loss: -8.2705 - val_accuracy: 0.0915\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8922e-04 - accuracy: 1.0000 - val_loss: -8.2635 - val_accuracy: 0.0915\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.8317e-04 - accuracy: 1.0000 - val_loss: -8.3917 - val_accuracy: 0.0915\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7506e-04 - accuracy: 1.0000 - val_loss: -8.4922 - val_accuracy: 0.0915\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.6465e-04 - accuracy: 1.0000 - val_loss: -8.5985 - val_accuracy: 0.0915\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.6463e-04 - accuracy: 1.0000 - val_loss: -8.3138 - val_accuracy: 0.0915\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.4466e-04 - accuracy: 1.0000 - val_loss: -8.5106 - val_accuracy: 0.0915\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3793e-04 - accuracy: 1.0000 - val_loss: -8.4688 - val_accuracy: 0.0915\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3006e-04 - accuracy: 1.0000 - val_loss: -8.5238 - val_accuracy: 0.0915\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2456e-04 - accuracy: 1.0000 - val_loss: -8.5903 - val_accuracy: 0.0915\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1525e-04 - accuracy: 1.0000 - val_loss: -8.6147 - val_accuracy: 0.0915\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1185e-04 - accuracy: 1.0000 - val_loss: -8.5095 - val_accuracy: 0.0915\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.0402e-04 - accuracy: 1.0000 - val_loss: -8.6659 - val_accuracy: 0.0915\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0136e-04 - accuracy: 1.0000 - val_loss: -8.6463 - val_accuracy: 0.0915\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.9501e-04 - accuracy: 1.0000 - val_loss: -8.6021 - val_accuracy: 0.0915\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9780e-04 - accuracy: 1.0000 - val_loss: -8.5011 - val_accuracy: 0.0915\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8498e-04 - accuracy: 1.0000 - val_loss: -8.8007 - val_accuracy: 0.0915\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.7518e-04 - accuracy: 1.0000 - val_loss: -8.7635 - val_accuracy: 0.0915\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6953e-04 - accuracy: 1.0000 - val_loss: -8.7567 - val_accuracy: 0.0915\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.7442e-04 - accuracy: 1.0000 - val_loss: -8.4543 - val_accuracy: 0.0915\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.6335e-04 - accuracy: 1.0000 - val_loss: -8.8305 - val_accuracy: 0.0915\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.5701e-04 - accuracy: 1.0000 - val_loss: -8.7189 - val_accuracy: 0.0915\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5412e-04 - accuracy: 1.0000 - val_loss: -8.7506 - val_accuracy: 0.0915\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.5083e-04 - accuracy: 1.0000 - val_loss: -8.6002 - val_accuracy: 0.0915\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.4618e-04 - accuracy: 1.0000 - val_loss: -8.8480 - val_accuracy: 0.0915\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3752e-04 - accuracy: 1.0000 - val_loss: -8.8065 - val_accuracy: 0.0915\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3445e-04 - accuracy: 1.0000 - val_loss: -8.7898 - val_accuracy: 0.0915\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3334e-04 - accuracy: 1.0000 - val_loss: -8.7579 - val_accuracy: 0.0915\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.2985e-04 - accuracy: 1.0000 - val_loss: -8.8376 - val_accuracy: 0.0915\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2628e-04 - accuracy: 1.0000 - val_loss: -8.9221 - val_accuracy: 0.0915\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2017e-04 - accuracy: 1.0000 - val_loss: -8.8878 - val_accuracy: 0.0915\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1745e-04 - accuracy: 1.0000 - val_loss: -8.8665 - val_accuracy: 0.0915\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1542e-04 - accuracy: 1.0000 - val_loss: -8.9490 - val_accuracy: 0.0915\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 1.1235e-04 - accuracy: 1.0000 - val_loss: -8.9533 - val_accuracy: 0.0915\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 1.0839e-04 - accuracy: 1.0000 - val_loss: -8.8369 - val_accuracy: 0.0915\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0808e-04 - accuracy: 1.0000 - val_loss: -8.9107 - val_accuracy: 0.0915\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 1.0085e-04 - accuracy: 1.0000 - val_loss: -9.0178 - val_accuracy: 0.0915\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.9222e-05 - accuracy: 1.0000 - val_loss: -9.0995 - val_accuracy: 0.0915\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 9.8604e-05 - accuracy: 1.0000 - val_loss: -8.9211 - val_accuracy: 0.0915\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 9.6966e-05 - accuracy: 1.0000 - val_loss: -9.0541 - val_accuracy: 0.0915\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 9.1537e-05 - accuracy: 1.0000 - val_loss: -9.1612 - val_accuracy: 0.0915\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.7269e-05 - accuracy: 1.0000 - val_loss: -9.1328 - val_accuracy: 0.0915\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.9731e-05 - accuracy: 1.0000 - val_loss: -9.3438 - val_accuracy: 0.0915\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.4541e-05 - accuracy: 1.0000 - val_loss: -8.9388 - val_accuracy: 0.0915\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.2438e-05 - accuracy: 1.0000 - val_loss: -9.4168 - val_accuracy: 0.0854\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 8.4773e-05 - accuracy: 1.0000 - val_loss: -9.1416 - val_accuracy: 0.0915\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 7.6268e-05 - accuracy: 1.0000 - val_loss: -9.1552 - val_accuracy: 0.0915\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.4302e-05 - accuracy: 1.0000 - val_loss: -9.2335 - val_accuracy: 0.0915\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.3422e-05 - accuracy: 1.0000 - val_loss: -9.4029 - val_accuracy: 0.0854\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 7.2213e-05 - accuracy: 1.0000 - val_loss: -9.1214 - val_accuracy: 0.0915\n",
      "Epoch 192/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.9942e-05 - accuracy: 1.0000 - val_loss: -9.1563 - val_accuracy: 0.0915\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.8468e-05 - accuracy: 1.0000 - val_loss: -9.1751 - val_accuracy: 0.0915\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.6985e-05 - accuracy: 1.0000 - val_loss: -9.3941 - val_accuracy: 0.0915\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 6.3401e-05 - accuracy: 1.0000 - val_loss: -9.1803 - val_accuracy: 0.0915\n",
      "Epoch 196/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.2005e-05 - accuracy: 1.0000 - val_loss: -9.2306 - val_accuracy: 0.0915\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.0298e-05 - accuracy: 1.0000 - val_loss: -9.3358 - val_accuracy: 0.0915\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.8477e-05 - accuracy: 1.0000 - val_loss: -9.4585 - val_accuracy: 0.0915\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 5.8560e-05 - accuracy: 1.0000 - val_loss: -9.4241 - val_accuracy: 0.0915\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5791e-05 - accuracy: 1.0000 - val_loss: -9.4587 - val_accuracy: 0.0915\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4277e-05 - accuracy: 1.0000 - val_loss: -9.4274 - val_accuracy: 0.0915\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3588e-05 - accuracy: 1.0000 - val_loss: -9.1884 - val_accuracy: 0.0915\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.6044e-05 - accuracy: 1.0000 - val_loss: -9.3099 - val_accuracy: 0.0915\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0557e-05 - accuracy: 1.0000 - val_loss: -9.5881 - val_accuracy: 0.0915\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9615e-05 - accuracy: 1.0000 - val_loss: -9.5042 - val_accuracy: 0.0915\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.7256e-05 - accuracy: 1.0000 - val_loss: -9.4459 - val_accuracy: 0.0915\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6022e-05 - accuracy: 1.0000 - val_loss: -9.3858 - val_accuracy: 0.0915\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.5918e-05 - accuracy: 1.0000 - val_loss: -9.5385 - val_accuracy: 0.0915\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4880e-05 - accuracy: 1.0000 - val_loss: -9.6120 - val_accuracy: 0.0915\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.3469e-05 - accuracy: 1.0000 - val_loss: -9.5224 - val_accuracy: 0.0915\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1872e-05 - accuracy: 1.0000 - val_loss: -9.5751 - val_accuracy: 0.0915\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0352e-05 - accuracy: 1.0000 - val_loss: -9.4852 - val_accuracy: 0.0915\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0722e-05 - accuracy: 1.0000 - val_loss: -9.6275 - val_accuracy: 0.0915\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0387e-05 - accuracy: 1.0000 - val_loss: -9.8458 - val_accuracy: 0.0854\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0449e-05 - accuracy: 1.0000 - val_loss: -9.5153 - val_accuracy: 0.0915\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6541e-05 - accuracy: 1.0000 - val_loss: -9.6126 - val_accuracy: 0.0915\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6385e-05 - accuracy: 1.0000 - val_loss: -9.7517 - val_accuracy: 0.0915\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4924e-05 - accuracy: 1.0000 - val_loss: -9.4952 - val_accuracy: 0.0915\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4947e-05 - accuracy: 1.0000 - val_loss: -9.7180 - val_accuracy: 0.0915\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2758e-05 - accuracy: 1.0000 - val_loss: -9.7063 - val_accuracy: 0.0915\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.2371e-05 - accuracy: 1.0000 - val_loss: -9.6034 - val_accuracy: 0.0915\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1352e-05 - accuracy: 1.0000 - val_loss: -9.7238 - val_accuracy: 0.0915\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0895e-05 - accuracy: 1.0000 - val_loss: -9.7180 - val_accuracy: 0.0915\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0457e-05 - accuracy: 1.0000 - val_loss: -9.7550 - val_accuracy: 0.0915\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9086e-05 - accuracy: 1.0000 - val_loss: -9.6792 - val_accuracy: 0.0915\n",
      "Epoch 226/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8350e-05 - accuracy: 1.0000 - val_loss: -9.7276 - val_accuracy: 0.0915\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7815e-05 - accuracy: 1.0000 - val_loss: -9.8035 - val_accuracy: 0.0915\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7254e-05 - accuracy: 1.0000 - val_loss: -9.7874 - val_accuracy: 0.0915\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.6533e-05 - accuracy: 1.0000 - val_loss: -9.7112 - val_accuracy: 0.0915\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.6567e-05 - accuracy: 1.0000 - val_loss: -9.7438 - val_accuracy: 0.0915\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.5459e-05 - accuracy: 1.0000 - val_loss: -9.7747 - val_accuracy: 0.0915\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4596e-05 - accuracy: 1.0000 - val_loss: -9.8688 - val_accuracy: 0.0915\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4236e-05 - accuracy: 1.0000 - val_loss: -9.8361 - val_accuracy: 0.0915\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.3885e-05 - accuracy: 1.0000 - val_loss: -9.9156 - val_accuracy: 0.0915\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3952e-05 - accuracy: 1.0000 - val_loss: -9.8872 - val_accuracy: 0.0915\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2777e-05 - accuracy: 1.0000 - val_loss: -9.8890 - val_accuracy: 0.0915\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1998e-05 - accuracy: 1.0000 - val_loss: -9.9817 - val_accuracy: 0.0915\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1193e-05 - accuracy: 1.0000 - val_loss: -9.8537 - val_accuracy: 0.0915\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1405e-05 - accuracy: 1.0000 - val_loss: -10.0627 - val_accuracy: 0.0915\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.0300e-05 - accuracy: 1.0000 - val_loss: -9.8904 - val_accuracy: 0.0915\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9982e-05 - accuracy: 1.0000 - val_loss: -9.9298 - val_accuracy: 0.0915\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9400e-05 - accuracy: 1.0000 - val_loss: -9.9329 - val_accuracy: 0.0915\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8917e-05 - accuracy: 1.0000 - val_loss: -9.9427 - val_accuracy: 0.0915\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8802e-05 - accuracy: 1.0000 - val_loss: -10.0919 - val_accuracy: 0.0915\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8317e-05 - accuracy: 1.0000 - val_loss: -9.8914 - val_accuracy: 0.0915\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8961e-05 - accuracy: 1.0000 - val_loss: -10.0048 - val_accuracy: 0.0915\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7545e-05 - accuracy: 1.0000 - val_loss: -10.0965 - val_accuracy: 0.0915\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7027e-05 - accuracy: 1.0000 - val_loss: -10.0698 - val_accuracy: 0.0915\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7047e-05 - accuracy: 1.0000 - val_loss: -9.9816 - val_accuracy: 0.0915\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6183e-05 - accuracy: 1.0000 - val_loss: -10.1070 - val_accuracy: 0.0915\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5949e-05 - accuracy: 1.0000 - val_loss: -10.0482 - val_accuracy: 0.0915\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5889e-05 - accuracy: 1.0000 - val_loss: -10.2203 - val_accuracy: 0.0915\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5213e-05 - accuracy: 1.0000 - val_loss: -10.0588 - val_accuracy: 0.0915\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4802e-05 - accuracy: 1.0000 - val_loss: -10.1620 - val_accuracy: 0.0915\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4346e-05 - accuracy: 1.0000 - val_loss: -10.1234 - val_accuracy: 0.0915\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4674e-05 - accuracy: 1.0000 - val_loss: -10.2842 - val_accuracy: 0.0915\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3910e-05 - accuracy: 1.0000 - val_loss: -10.0046 - val_accuracy: 0.0915\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3458e-05 - accuracy: 1.0000 - val_loss: -10.3020 - val_accuracy: 0.0915\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3274e-05 - accuracy: 1.0000 - val_loss: -10.1044 - val_accuracy: 0.0915\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3066e-05 - accuracy: 1.0000 - val_loss: -10.2192 - val_accuracy: 0.0915\n",
      "Epoch 261/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.2574e-05 - accuracy: 1.0000 - val_loss: -10.1920 - val_accuracy: 0.0915\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2360e-05 - accuracy: 1.0000 - val_loss: -10.2969 - val_accuracy: 0.0915\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2023e-05 - accuracy: 1.0000 - val_loss: -10.1500 - val_accuracy: 0.0915\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1701e-05 - accuracy: 1.0000 - val_loss: -10.1854 - val_accuracy: 0.0915\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1526e-05 - accuracy: 1.0000 - val_loss: -10.2235 - val_accuracy: 0.0915\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1212e-05 - accuracy: 1.0000 - val_loss: -10.2242 - val_accuracy: 0.0915\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0983e-05 - accuracy: 1.0000 - val_loss: -10.2578 - val_accuracy: 0.0915\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0695e-05 - accuracy: 1.0000 - val_loss: -10.1910 - val_accuracy: 0.0915\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0591e-05 - accuracy: 1.0000 - val_loss: -10.3428 - val_accuracy: 0.0915\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0243e-05 - accuracy: 1.0000 - val_loss: -10.1971 - val_accuracy: 0.0915\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0230e-05 - accuracy: 1.0000 - val_loss: -10.2705 - val_accuracy: 0.0915\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.8261e-06 - accuracy: 1.0000 - val_loss: -10.3508 - val_accuracy: 0.0915\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.7980e-06 - accuracy: 1.0000 - val_loss: -10.3342 - val_accuracy: 0.0915\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.3226e-06 - accuracy: 1.0000 - val_loss: -10.2860 - val_accuracy: 0.0915\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.2014e-06 - accuracy: 1.0000 - val_loss: -10.3775 - val_accuracy: 0.0915\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 9.0826e-06 - accuracy: 1.0000 - val_loss: -10.2919 - val_accuracy: 0.0915\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.8238e-06 - accuracy: 1.0000 - val_loss: -10.3835 - val_accuracy: 0.0915\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6924e-06 - accuracy: 1.0000 - val_loss: -10.3665 - val_accuracy: 0.0915\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.4528e-06 - accuracy: 1.0000 - val_loss: -10.3354 - val_accuracy: 0.0915\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.6978e-06 - accuracy: 1.0000 - val_loss: -10.4385 - val_accuracy: 0.0915\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.0007e-06 - accuracy: 1.0000 - val_loss: -10.3519 - val_accuracy: 0.0915\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9213e-06 - accuracy: 1.0000 - val_loss: -10.5001 - val_accuracy: 0.0915\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.6999e-06 - accuracy: 1.0000 - val_loss: -10.3701 - val_accuracy: 0.0915\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.6393e-06 - accuracy: 1.0000 - val_loss: -10.4637 - val_accuracy: 0.0915\n",
      "Epoch 285/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.4813e-06 - accuracy: 1.0000 - val_loss: -10.4731 - val_accuracy: 0.0915\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1997e-06 - accuracy: 1.0000 - val_loss: -10.4658 - val_accuracy: 0.0915\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0805e-06 - accuracy: 1.0000 - val_loss: -10.5129 - val_accuracy: 0.0915\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.9741e-06 - accuracy: 1.0000 - val_loss: -10.5124 - val_accuracy: 0.0915\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8033e-06 - accuracy: 1.0000 - val_loss: -10.5544 - val_accuracy: 0.0915\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.7194e-06 - accuracy: 1.0000 - val_loss: -10.5551 - val_accuracy: 0.0915\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.4941e-06 - accuracy: 1.0000 - val_loss: -10.4886 - val_accuracy: 0.0915\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4342e-06 - accuracy: 1.0000 - val_loss: -10.4784 - val_accuracy: 0.0915\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3215e-06 - accuracy: 1.0000 - val_loss: -10.5522 - val_accuracy: 0.0915\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1373e-06 - accuracy: 1.0000 - val_loss: -10.5503 - val_accuracy: 0.0915\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.0353e-06 - accuracy: 1.0000 - val_loss: -10.5537 - val_accuracy: 0.0915\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9067e-06 - accuracy: 1.0000 - val_loss: -10.4947 - val_accuracy: 0.0915\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7656e-06 - accuracy: 1.0000 - val_loss: -10.6201 - val_accuracy: 0.0915\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.6171e-06 - accuracy: 1.0000 - val_loss: -10.6149 - val_accuracy: 0.0915\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.4691e-06 - accuracy: 1.0000 - val_loss: -10.5849 - val_accuracy: 0.0915\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.3677e-06 - accuracy: 1.0000 - val_loss: -10.6267 - val_accuracy: 0.0915\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Epoch 1/300\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 0.6785 - accuracy: 0.5898 - val_loss: 0.4644 - val_accuracy: 0.0793\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.5938 - val_loss: 0.8425 - val_accuracy: 0.1829\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6797 - val_loss: 0.4714 - val_accuracy: 0.1768\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7070 - val_loss: -0.1327 - val_accuracy: 0.0854\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7246 - val_loss: 0.0307 - val_accuracy: 0.1707\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7695 - val_loss: -0.4338 - val_accuracy: 0.1341\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7266 - val_loss: -0.0520 - val_accuracy: 0.1768\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7637 - val_loss: -0.6930 - val_accuracy: 0.1159\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4500 - accuracy: 0.8164 - val_loss: -0.1803 - val_accuracy: 0.1768\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8086 - val_loss: 0.1432 - val_accuracy: 0.1768\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7871 - val_loss: -0.2666 - val_accuracy: 0.1768\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7910 - val_loss: 0.3528 - val_accuracy: 0.1951\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: -1.2280 - val_accuracy: 0.1159\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8047 - val_loss: -0.9595 - val_accuracy: 0.1524\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8320 - val_loss: -1.1399 - val_accuracy: 0.1402\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8125 - val_loss: -1.3867 - val_accuracy: 0.1220\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8496 - val_loss: -1.3694 - val_accuracy: 0.1220\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8633 - val_loss: -0.2257 - val_accuracy: 0.1768\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8262 - val_loss: -1.2215 - val_accuracy: 0.1402\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3389 - accuracy: 0.8613 - val_loss: -1.0636 - val_accuracy: 0.1524\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8574 - val_loss: -1.5062 - val_accuracy: 0.1402\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8652 - val_loss: -1.3905 - val_accuracy: 0.1463\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8320 - val_loss: -1.0676 - val_accuracy: 0.1768\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8555 - val_loss: -1.0546 - val_accuracy: 0.1646\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3508 - accuracy: 0.8418 - val_loss: -1.4271 - val_accuracy: 0.1341\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8691 - val_loss: -1.6278 - val_accuracy: 0.1524\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2847 - accuracy: 0.8770 - val_loss: -2.1488 - val_accuracy: 0.1280\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.8848 - val_loss: -1.9508 - val_accuracy: 0.1463\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.8945 - val_loss: -3.1596 - val_accuracy: 0.0976\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3223 - accuracy: 0.8516 - val_loss: -2.2223 - val_accuracy: 0.1037\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.9062 - val_loss: -2.6738 - val_accuracy: 0.1037\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.9043 - val_loss: -1.9326 - val_accuracy: 0.1585\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.9023 - val_loss: -1.7262 - val_accuracy: 0.1585\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2862 - accuracy: 0.8672 - val_loss: -2.5893 - val_accuracy: 0.1280\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.9219 - val_loss: -2.5630 - val_accuracy: 0.1341\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2216 - accuracy: 0.9219 - val_loss: -2.0096 - val_accuracy: 0.1402\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9180 - val_loss: -2.5791 - val_accuracy: 0.1463\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9336 - val_loss: -4.3743 - val_accuracy: 0.0915\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2037 - accuracy: 0.9121 - val_loss: -4.1473 - val_accuracy: 0.0976\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1848 - accuracy: 0.9473 - val_loss: -4.0965 - val_accuracy: 0.1098\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9375 - val_loss: -3.8312 - val_accuracy: 0.0976\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9395 - val_loss: -4.2813 - val_accuracy: 0.0915\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1829 - accuracy: 0.9316 - val_loss: -3.9382 - val_accuracy: 0.1037\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9570 - val_loss: -4.1158 - val_accuracy: 0.0976\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1577 - accuracy: 0.9492 - val_loss: -3.5468 - val_accuracy: 0.1280\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9453 - val_loss: -2.9311 - val_accuracy: 0.1341\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9180 - val_loss: -3.4992 - val_accuracy: 0.1280\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9551 - val_loss: -4.2987 - val_accuracy: 0.1098\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1133 - accuracy: 0.9648 - val_loss: -5.8609 - val_accuracy: 0.0549\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9395 - val_loss: -4.3820 - val_accuracy: 0.1220\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1857 - accuracy: 0.9336 - val_loss: -3.1815 - val_accuracy: 0.1402\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1663 - accuracy: 0.9395 - val_loss: -4.2206 - val_accuracy: 0.1220\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9707 - val_loss: -4.8544 - val_accuracy: 0.1159\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9707 - val_loss: -4.6928 - val_accuracy: 0.1220\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9668 - val_loss: -6.4757 - val_accuracy: 0.0793\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9707 - val_loss: -6.2005 - val_accuracy: 0.0976\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.9746 - val_loss: -4.7468 - val_accuracy: 0.1159\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9688 - val_loss: -5.5249 - val_accuracy: 0.0976\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9766 - val_loss: -3.7794 - val_accuracy: 0.1524\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9570 - val_loss: -6.2351 - val_accuracy: 0.0610\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9727 - val_loss: -5.2982 - val_accuracy: 0.0732\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9727 - val_loss: -5.2625 - val_accuracy: 0.0793\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9785 - val_loss: -6.4858 - val_accuracy: 0.0854\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9883 - val_loss: -5.2257 - val_accuracy: 0.1037\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9863 - val_loss: -4.9512 - val_accuracy: 0.1220\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9844 - val_loss: -5.5160 - val_accuracy: 0.1098\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9883 - val_loss: -5.2361 - val_accuracy: 0.1037\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: -5.6778 - val_accuracy: 0.1098\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9902 - val_loss: -4.3785 - val_accuracy: 0.1341\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: -7.4181 - val_accuracy: 0.0854\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2436 - accuracy: 0.9160 - val_loss: -4.1971 - val_accuracy: 0.1220\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2114 - accuracy: 0.9219 - val_loss: -3.8544 - val_accuracy: 0.1220\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9453 - val_loss: -4.2269 - val_accuracy: 0.1402\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9570 - val_loss: -5.4554 - val_accuracy: 0.1098\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9707 - val_loss: -6.0189 - val_accuracy: 0.0732\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9883 - val_loss: -5.4207 - val_accuracy: 0.0976\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: -5.1918 - val_accuracy: 0.1220\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9941 - val_loss: -6.0743 - val_accuracy: 0.0976\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9961 - val_loss: -6.4826 - val_accuracy: 0.0854\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9980 - val_loss: -6.0207 - val_accuracy: 0.1098\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: -6.1906 - val_accuracy: 0.1037\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: -6.5355 - val_accuracy: 0.0915\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: -6.0182 - val_accuracy: 0.1037\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9980 - val_loss: -6.6650 - val_accuracy: 0.0854\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: -6.3566 - val_accuracy: 0.0976\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: -7.2672 - val_accuracy: 0.0793\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: -6.1822 - val_accuracy: 0.1037\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: -6.0575 - val_accuracy: 0.1280\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: -6.5629 - val_accuracy: 0.0976\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: -5.7899 - val_accuracy: 0.1280\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: -6.4073 - val_accuracy: 0.1098\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: -8.6957 - val_accuracy: 0.0488\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9668 - val_loss: -7.5763 - val_accuracy: 0.0915\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9551 - val_loss: -9.1863 - val_accuracy: 0.0305\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.9004 - val_loss: -3.8246 - val_accuracy: 0.1280\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2111 - accuracy: 0.9355 - val_loss: -6.9345 - val_accuracy: 0.0732\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9414 - val_loss: -7.3338 - val_accuracy: 0.0793\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9844 - val_loss: -6.4696 - val_accuracy: 0.1037\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9941 - val_loss: -5.6641 - val_accuracy: 0.1098\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: -6.7864 - val_accuracy: 0.0732\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: -6.7346 - val_accuracy: 0.0915\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: -6.5659 - val_accuracy: 0.0854\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: -6.3689 - val_accuracy: 0.1159\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -6.5018 - val_accuracy: 0.1037\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: -6.8524 - val_accuracy: 0.0854\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -6.4340 - val_accuracy: 0.1159\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -6.9043 - val_accuracy: 0.0793\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -7.0697 - val_accuracy: 0.0915\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -6.7550 - val_accuracy: 0.1037\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -6.8834 - val_accuracy: 0.0976\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -7.4345 - val_accuracy: 0.0854\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -6.9255 - val_accuracy: 0.1037\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.0055 - val_accuracy: 0.1037\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.3206 - val_accuracy: 0.0976\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.4443 - val_accuracy: 0.0854\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.6701 - val_accuracy: 0.0915\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.2658 - val_accuracy: 0.0976\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.4877 - val_accuracy: 0.0915\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.3972 - val_accuracy: 0.0976\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.2995 - val_accuracy: 0.1037\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.6179 - val_accuracy: 0.0915\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.6480 - val_accuracy: 0.0915\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.6930 - val_accuracy: 0.0915\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.6604 - val_accuracy: 0.0915\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.9039 - val_accuracy: 0.0854\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.8180 - val_accuracy: 0.0854\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.9059 - val_accuracy: 0.0915\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.0999 - val_accuracy: 0.0915\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.1390 - val_accuracy: 0.0793\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.7744 - val_accuracy: 0.1098\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.6119e-04 - accuracy: 1.0000 - val_loss: -8.1249 - val_accuracy: 0.0854\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.6758e-04 - accuracy: 1.0000 - val_loss: -8.1565 - val_accuracy: 0.0915\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.5634e-04 - accuracy: 1.0000 - val_loss: -7.8908 - val_accuracy: 0.1098\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.9967e-04 - accuracy: 1.0000 - val_loss: -7.8632 - val_accuracy: 0.1098\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.1937e-04 - accuracy: 1.0000 - val_loss: -8.1380 - val_accuracy: 0.0915\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8405e-04 - accuracy: 1.0000 - val_loss: -8.0510 - val_accuracy: 0.1098\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1377e-04 - accuracy: 1.0000 - val_loss: -8.2916 - val_accuracy: 0.0976\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2973e-04 - accuracy: 1.0000 - val_loss: -8.4830 - val_accuracy: 0.0793\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.7517e-04 - accuracy: 1.0000 - val_loss: -8.2896 - val_accuracy: 0.1037\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.4391e-04 - accuracy: 1.0000 - val_loss: -8.1180 - val_accuracy: 0.1037\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.3280e-04 - accuracy: 1.0000 - val_loss: -8.3021 - val_accuracy: 0.1037\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9142e-04 - accuracy: 1.0000 - val_loss: -8.1407 - val_accuracy: 0.1098\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.7318e-04 - accuracy: 1.0000 - val_loss: -8.5425 - val_accuracy: 0.0915\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4414e-04 - accuracy: 1.0000 - val_loss: -8.2968 - val_accuracy: 0.1037\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.5945e-04 - accuracy: 1.0000 - val_loss: -8.3856 - val_accuracy: 0.0976\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2027e-04 - accuracy: 1.0000 - val_loss: -8.5796 - val_accuracy: 0.0976\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.0294e-04 - accuracy: 1.0000 - val_loss: -8.3624 - val_accuracy: 0.1037\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8921e-04 - accuracy: 1.0000 - val_loss: -8.7367 - val_accuracy: 0.0854\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.5972e-04 - accuracy: 1.0000 - val_loss: -8.5148 - val_accuracy: 0.0976\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6620e-04 - accuracy: 1.0000 - val_loss: -8.5606 - val_accuracy: 0.0976\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3336e-04 - accuracy: 1.0000 - val_loss: -8.7088 - val_accuracy: 0.0976\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.1155e-04 - accuracy: 1.0000 - val_loss: -8.5432 - val_accuracy: 0.1037\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1767e-04 - accuracy: 1.0000 - val_loss: -8.5914 - val_accuracy: 0.0976\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9268e-04 - accuracy: 1.0000 - val_loss: -8.8327 - val_accuracy: 0.0976\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7895e-04 - accuracy: 1.0000 - val_loss: -8.9196 - val_accuracy: 0.0976\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0109e-04 - accuracy: 1.0000 - val_loss: -9.0188 - val_accuracy: 0.0976\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.7764e-04 - accuracy: 1.0000 - val_loss: -8.7835 - val_accuracy: 0.1037\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4636e-04 - accuracy: 1.0000 - val_loss: -8.7673 - val_accuracy: 0.0976\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3369e-04 - accuracy: 1.0000 - val_loss: -9.0123 - val_accuracy: 0.0976\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3757e-04 - accuracy: 1.0000 - val_loss: -8.8537 - val_accuracy: 0.0976\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0142e-04 - accuracy: 1.0000 - val_loss: -8.9230 - val_accuracy: 0.0976\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.0163e-04 - accuracy: 1.0000 - val_loss: -9.0020 - val_accuracy: 0.0976\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8431e-04 - accuracy: 1.0000 - val_loss: -9.1053 - val_accuracy: 0.0976\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8883e-04 - accuracy: 1.0000 - val_loss: -8.9409 - val_accuracy: 0.0976\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.7122e-04 - accuracy: 1.0000 - val_loss: -9.2677 - val_accuracy: 0.0854\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.6570e-04 - accuracy: 1.0000 - val_loss: -9.1472 - val_accuracy: 0.0976\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6134e-04 - accuracy: 1.0000 - val_loss: -9.2059 - val_accuracy: 0.0976\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4674e-04 - accuracy: 1.0000 - val_loss: -9.2430 - val_accuracy: 0.0915\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4324e-04 - accuracy: 1.0000 - val_loss: -9.2784 - val_accuracy: 0.0915\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.3379e-04 - accuracy: 1.0000 - val_loss: -9.3249 - val_accuracy: 0.0915\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3294e-04 - accuracy: 1.0000 - val_loss: -9.4384 - val_accuracy: 0.0915\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.3223e-04 - accuracy: 1.0000 - val_loss: -9.1024 - val_accuracy: 0.1037\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1154e-04 - accuracy: 1.0000 - val_loss: -9.3611 - val_accuracy: 0.0915\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1215e-04 - accuracy: 1.0000 - val_loss: -9.2952 - val_accuracy: 0.0976\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.0040e-04 - accuracy: 1.0000 - val_loss: -9.3783 - val_accuracy: 0.0976\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0166e-04 - accuracy: 1.0000 - val_loss: -9.5115 - val_accuracy: 0.0915\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.0268e-04 - accuracy: 1.0000 - val_loss: -9.3581 - val_accuracy: 0.0976\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8728e-04 - accuracy: 1.0000 - val_loss: -9.5198 - val_accuracy: 0.0915\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8396e-04 - accuracy: 1.0000 - val_loss: -9.5383 - val_accuracy: 0.0915\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7734e-04 - accuracy: 1.0000 - val_loss: -9.5738 - val_accuracy: 0.0915\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7172e-04 - accuracy: 1.0000 - val_loss: -9.4920 - val_accuracy: 0.0976\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6724e-04 - accuracy: 1.0000 - val_loss: -9.3959 - val_accuracy: 0.0976\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6204e-04 - accuracy: 1.0000 - val_loss: -9.5626 - val_accuracy: 0.0976\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6493e-04 - accuracy: 1.0000 - val_loss: -9.5846 - val_accuracy: 0.0976\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6059e-04 - accuracy: 1.0000 - val_loss: -9.6423 - val_accuracy: 0.0915\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5183e-04 - accuracy: 1.0000 - val_loss: -9.5885 - val_accuracy: 0.0976\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4519e-04 - accuracy: 1.0000 - val_loss: -9.5230 - val_accuracy: 0.0976\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4607e-04 - accuracy: 1.0000 - val_loss: -9.7677 - val_accuracy: 0.0915\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4948e-04 - accuracy: 1.0000 - val_loss: -9.7239 - val_accuracy: 0.0976\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3095e-04 - accuracy: 1.0000 - val_loss: -9.8845 - val_accuracy: 0.0915\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3289e-04 - accuracy: 1.0000 - val_loss: -9.5826 - val_accuracy: 0.0976\n",
      "Epoch 192/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3035e-04 - accuracy: 1.0000 - val_loss: -9.8543 - val_accuracy: 0.0915\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2603e-04 - accuracy: 1.0000 - val_loss: -9.7297 - val_accuracy: 0.0976\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2261e-04 - accuracy: 1.0000 - val_loss: -9.8826 - val_accuracy: 0.0915\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1804e-04 - accuracy: 1.0000 - val_loss: -9.9266 - val_accuracy: 0.0915\n",
      "Epoch 196/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1647e-04 - accuracy: 1.0000 - val_loss: -9.8529 - val_accuracy: 0.0976\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1353e-04 - accuracy: 1.0000 - val_loss: -9.8939 - val_accuracy: 0.0915\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: -9.9378 - val_accuracy: 0.0915\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0552e-04 - accuracy: 1.0000 - val_loss: -9.9160 - val_accuracy: 0.0915\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0468e-04 - accuracy: 1.0000 - val_loss: -9.9223 - val_accuracy: 0.0915\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0037e-04 - accuracy: 1.0000 - val_loss: -10.0687 - val_accuracy: 0.0915\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.9104e-05 - accuracy: 1.0000 - val_loss: -10.1370 - val_accuracy: 0.0915\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0432e-04 - accuracy: 1.0000 - val_loss: -10.2020 - val_accuracy: 0.0915\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.8350e-05 - accuracy: 1.0000 - val_loss: -10.0081 - val_accuracy: 0.0915\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.9084e-05 - accuracy: 1.0000 - val_loss: -10.0751 - val_accuracy: 0.0915\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 8.8971e-05 - accuracy: 1.0000 - val_loss: -10.0281 - val_accuracy: 0.0915\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.6698e-05 - accuracy: 1.0000 - val_loss: -10.0322 - val_accuracy: 0.0915\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4658e-05 - accuracy: 1.0000 - val_loss: -10.2807 - val_accuracy: 0.0915\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4474e-05 - accuracy: 1.0000 - val_loss: -10.4040 - val_accuracy: 0.0915\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.3852e-05 - accuracy: 1.0000 - val_loss: -10.0981 - val_accuracy: 0.0915\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.0578e-05 - accuracy: 1.0000 - val_loss: -10.1274 - val_accuracy: 0.0915\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.7922e-05 - accuracy: 1.0000 - val_loss: -10.3162 - val_accuracy: 0.0915\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5452e-05 - accuracy: 1.0000 - val_loss: -10.2639 - val_accuracy: 0.0915\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1069e-05 - accuracy: 1.0000 - val_loss: -10.4190 - val_accuracy: 0.0915\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1840e-05 - accuracy: 1.0000 - val_loss: -10.0445 - val_accuracy: 0.0976\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.0697e-05 - accuracy: 1.0000 - val_loss: -10.3523 - val_accuracy: 0.0915\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 6.8634e-05 - accuracy: 1.0000 - val_loss: -10.2757 - val_accuracy: 0.0915\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6797e-05 - accuracy: 1.0000 - val_loss: -10.3806 - val_accuracy: 0.0915\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5549e-05 - accuracy: 1.0000 - val_loss: -10.3546 - val_accuracy: 0.0915\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2311e-05 - accuracy: 1.0000 - val_loss: -10.5548 - val_accuracy: 0.0915\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.3517e-05 - accuracy: 1.0000 - val_loss: -10.2700 - val_accuracy: 0.0915\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2042e-05 - accuracy: 1.0000 - val_loss: -10.4855 - val_accuracy: 0.0915\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.9337e-05 - accuracy: 1.0000 - val_loss: -10.4843 - val_accuracy: 0.0915\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7361e-05 - accuracy: 1.0000 - val_loss: -10.4907 - val_accuracy: 0.0915\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.6113e-05 - accuracy: 1.0000 - val_loss: -10.5919 - val_accuracy: 0.0915\n",
      "Epoch 226/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5275e-05 - accuracy: 1.0000 - val_loss: -10.4061 - val_accuracy: 0.0915\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.6251e-05 - accuracy: 1.0000 - val_loss: -10.5287 - val_accuracy: 0.0915\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2767e-05 - accuracy: 1.0000 - val_loss: -10.5755 - val_accuracy: 0.0915\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1449e-05 - accuracy: 1.0000 - val_loss: -10.5906 - val_accuracy: 0.0915\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3230e-05 - accuracy: 1.0000 - val_loss: -10.6657 - val_accuracy: 0.0915\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8470e-05 - accuracy: 1.0000 - val_loss: -10.7581 - val_accuracy: 0.0915\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8880e-05 - accuracy: 1.0000 - val_loss: -10.9513 - val_accuracy: 0.0915\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7515e-05 - accuracy: 1.0000 - val_loss: -10.7130 - val_accuracy: 0.0915\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.6751e-05 - accuracy: 1.0000 - val_loss: -10.5899 - val_accuracy: 0.0915\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5458e-05 - accuracy: 1.0000 - val_loss: -10.7754 - val_accuracy: 0.0915\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3393e-05 - accuracy: 1.0000 - val_loss: -10.7098 - val_accuracy: 0.0915\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3037e-05 - accuracy: 1.0000 - val_loss: -10.6327 - val_accuracy: 0.0915\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2455e-05 - accuracy: 1.0000 - val_loss: -10.6936 - val_accuracy: 0.0915\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0334e-05 - accuracy: 1.0000 - val_loss: -10.8892 - val_accuracy: 0.0915\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9229e-05 - accuracy: 1.0000 - val_loss: -10.9616 - val_accuracy: 0.0915\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9470e-05 - accuracy: 1.0000 - val_loss: -10.8904 - val_accuracy: 0.0915\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9493e-05 - accuracy: 1.0000 - val_loss: -10.9945 - val_accuracy: 0.0915\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7872e-05 - accuracy: 1.0000 - val_loss: -11.1479 - val_accuracy: 0.0915\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8469e-05 - accuracy: 1.0000 - val_loss: -10.9604 - val_accuracy: 0.0915\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6137e-05 - accuracy: 1.0000 - val_loss: -11.0563 - val_accuracy: 0.0915\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3922e-05 - accuracy: 1.0000 - val_loss: -10.9092 - val_accuracy: 0.0915\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3660e-05 - accuracy: 1.0000 - val_loss: -11.0933 - val_accuracy: 0.0915\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.2903e-05 - accuracy: 1.0000 - val_loss: -10.9936 - val_accuracy: 0.0915\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1612e-05 - accuracy: 1.0000 - val_loss: -11.0965 - val_accuracy: 0.0915\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2066e-05 - accuracy: 1.0000 - val_loss: -10.8178 - val_accuracy: 0.0915\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1271e-05 - accuracy: 1.0000 - val_loss: -11.1970 - val_accuracy: 0.0915\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.0391e-05 - accuracy: 1.0000 - val_loss: -11.1075 - val_accuracy: 0.0915\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9988e-05 - accuracy: 1.0000 - val_loss: -11.3500 - val_accuracy: 0.0915\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9476e-05 - accuracy: 1.0000 - val_loss: -11.0539 - val_accuracy: 0.0915\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7878e-05 - accuracy: 1.0000 - val_loss: -11.2754 - val_accuracy: 0.0915\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7919e-05 - accuracy: 1.0000 - val_loss: -11.2499 - val_accuracy: 0.0915\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7166e-05 - accuracy: 1.0000 - val_loss: -11.2964 - val_accuracy: 0.0915\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.6673e-05 - accuracy: 1.0000 - val_loss: -11.1687 - val_accuracy: 0.0915\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.5352e-05 - accuracy: 1.0000 - val_loss: -11.3378 - val_accuracy: 0.0915\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4776e-05 - accuracy: 1.0000 - val_loss: -11.1580 - val_accuracy: 0.0915\n",
      "Epoch 261/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4070e-05 - accuracy: 1.0000 - val_loss: -11.3930 - val_accuracy: 0.0915\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.3754e-05 - accuracy: 1.0000 - val_loss: -11.2455 - val_accuracy: 0.0915\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.3534e-05 - accuracy: 1.0000 - val_loss: -11.3185 - val_accuracy: 0.0915\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2580e-05 - accuracy: 1.0000 - val_loss: -11.2415 - val_accuracy: 0.0915\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2439e-05 - accuracy: 1.0000 - val_loss: -11.2617 - val_accuracy: 0.0915\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2550e-05 - accuracy: 1.0000 - val_loss: -11.4682 - val_accuracy: 0.0915\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1252e-05 - accuracy: 1.0000 - val_loss: -11.4779 - val_accuracy: 0.0915\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1138e-05 - accuracy: 1.0000 - val_loss: -11.4790 - val_accuracy: 0.0915\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0172e-05 - accuracy: 1.0000 - val_loss: -11.4179 - val_accuracy: 0.0915\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.0625e-05 - accuracy: 1.0000 - val_loss: -11.5109 - val_accuracy: 0.0915\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0047e-05 - accuracy: 1.0000 - val_loss: -11.4594 - val_accuracy: 0.0915\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9273e-05 - accuracy: 1.0000 - val_loss: -11.6710 - val_accuracy: 0.0915\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9026e-05 - accuracy: 1.0000 - val_loss: -11.5250 - val_accuracy: 0.0915\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8825e-05 - accuracy: 1.0000 - val_loss: -11.4589 - val_accuracy: 0.0915\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7947e-05 - accuracy: 1.0000 - val_loss: -11.5975 - val_accuracy: 0.0915\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7745e-05 - accuracy: 1.0000 - val_loss: -11.6109 - val_accuracy: 0.0854\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7209e-05 - accuracy: 1.0000 - val_loss: -11.5385 - val_accuracy: 0.0915\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7004e-05 - accuracy: 1.0000 - val_loss: -11.6766 - val_accuracy: 0.0915\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6634e-05 - accuracy: 1.0000 - val_loss: -11.8032 - val_accuracy: 0.0854\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6740e-05 - accuracy: 1.0000 - val_loss: -11.6057 - val_accuracy: 0.0915\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.5914e-05 - accuracy: 1.0000 - val_loss: -11.7384 - val_accuracy: 0.0915\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5560e-05 - accuracy: 1.0000 - val_loss: -11.6379 - val_accuracy: 0.0915\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.5084e-05 - accuracy: 1.0000 - val_loss: -11.7883 - val_accuracy: 0.0915\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4778e-05 - accuracy: 1.0000 - val_loss: -11.6405 - val_accuracy: 0.0915\n",
      "Epoch 285/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4591e-05 - accuracy: 1.0000 - val_loss: -11.8255 - val_accuracy: 0.0915\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4512e-05 - accuracy: 1.0000 - val_loss: -11.8262 - val_accuracy: 0.0854\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4300e-05 - accuracy: 1.0000 - val_loss: -11.7591 - val_accuracy: 0.0854\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3570e-05 - accuracy: 1.0000 - val_loss: -11.7970 - val_accuracy: 0.0854\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3849e-05 - accuracy: 1.0000 - val_loss: -11.8063 - val_accuracy: 0.0915\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3049e-05 - accuracy: 1.0000 - val_loss: -11.8456 - val_accuracy: 0.0915\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3018e-05 - accuracy: 1.0000 - val_loss: -11.8021 - val_accuracy: 0.0915\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2559e-05 - accuracy: 1.0000 - val_loss: -11.8554 - val_accuracy: 0.0854\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2339e-05 - accuracy: 1.0000 - val_loss: -11.8026 - val_accuracy: 0.0915\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1966e-05 - accuracy: 1.0000 - val_loss: -11.9193 - val_accuracy: 0.0915\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2139e-05 - accuracy: 1.0000 - val_loss: -12.0008 - val_accuracy: 0.0854\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1595e-05 - accuracy: 1.0000 - val_loss: -12.0285 - val_accuracy: 0.0854\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1577e-05 - accuracy: 1.0000 - val_loss: -11.9202 - val_accuracy: 0.0854\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1291e-05 - accuracy: 1.0000 - val_loss: -11.8397 - val_accuracy: 0.0915\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0897e-05 - accuracy: 1.0000 - val_loss: -12.0855 - val_accuracy: 0.0854\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0756e-05 - accuracy: 1.0000 - val_loss: -12.0003 - val_accuracy: 0.0854\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 22ms/step - loss: 0.6759 - accuracy: 0.5781 - val_loss: 0.3566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6484 - val_loss: 0.6451 - val_accuracy: 0.1585\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5910 - accuracy: 0.7070 - val_loss: 0.1932 - val_accuracy: 0.1341\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5473 - accuracy: 0.7383 - val_loss: 0.1767 - val_accuracy: 0.1524\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7461 - val_loss: 0.2108 - val_accuracy: 0.1646\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.7676 - val_loss: -0.7017 - val_accuracy: 0.0854\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.7949 - val_loss: -0.2277 - val_accuracy: 0.1402\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7988 - val_loss: -0.9347 - val_accuracy: 0.0915\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4419 - accuracy: 0.8105 - val_loss: 0.0519 - val_accuracy: 0.1829\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7988 - val_loss: -0.0190 - val_accuracy: 0.1707\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.8008 - val_loss: -0.8500 - val_accuracy: 0.1098\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: -0.6229 - val_accuracy: 0.1341\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8301 - val_loss: -1.0555 - val_accuracy: 0.1098\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8281 - val_loss: -0.6905 - val_accuracy: 0.1585\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3722 - accuracy: 0.8340 - val_loss: -1.7488 - val_accuracy: 0.0793\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3633 - accuracy: 0.8320 - val_loss: -1.3185 - val_accuracy: 0.1098\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8496 - val_loss: -1.1012 - val_accuracy: 0.1463\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8457 - val_loss: -1.7445 - val_accuracy: 0.0976\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3350 - accuracy: 0.8555 - val_loss: -1.0272 - val_accuracy: 0.1463\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8555 - val_loss: -1.8226 - val_accuracy: 0.0976\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3028 - accuracy: 0.8770 - val_loss: -2.0908 - val_accuracy: 0.0976\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8574 - val_loss: -1.3615 - val_accuracy: 0.1220\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.8828 - val_loss: -1.5289 - val_accuracy: 0.1220\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.8926 - val_loss: -1.8426 - val_accuracy: 0.1037\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2762 - accuracy: 0.8906 - val_loss: -2.0511 - val_accuracy: 0.1037\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.8691 - val_loss: -2.3261 - val_accuracy: 0.0854\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2928 - accuracy: 0.8750 - val_loss: -1.1892 - val_accuracy: 0.1463\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.8926 - val_loss: -2.6669 - val_accuracy: 0.0976\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9180 - val_loss: -2.1067 - val_accuracy: 0.1098\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2146 - accuracy: 0.9082 - val_loss: -1.9231 - val_accuracy: 0.1220\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2654 - accuracy: 0.8848 - val_loss: -1.5290 - val_accuracy: 0.1463\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9199 - val_loss: -2.6199 - val_accuracy: 0.0915\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1942 - accuracy: 0.9316 - val_loss: -2.5026 - val_accuracy: 0.1159\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1786 - accuracy: 0.9395 - val_loss: -1.6243 - val_accuracy: 0.1402\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2597 - accuracy: 0.8906 - val_loss: -2.9299 - val_accuracy: 0.0854\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2559 - accuracy: 0.8867 - val_loss: -1.6919 - val_accuracy: 0.1341\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2132 - accuracy: 0.9141 - val_loss: -2.9504 - val_accuracy: 0.0915\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.9414 - val_loss: -2.0304 - val_accuracy: 0.1280\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1693 - accuracy: 0.9238 - val_loss: -3.2649 - val_accuracy: 0.0793\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9473 - val_loss: -2.7335 - val_accuracy: 0.1220\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9590 - val_loss: -3.0224 - val_accuracy: 0.0976\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9648 - val_loss: -2.2122 - val_accuracy: 0.1341\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1202 - accuracy: 0.9648 - val_loss: -3.2455 - val_accuracy: 0.0976\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1158 - accuracy: 0.9648 - val_loss: -4.0445 - val_accuracy: 0.0732\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1283 - accuracy: 0.9590 - val_loss: -3.9312 - val_accuracy: 0.0732\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.9199 - val_loss: -0.8895 - val_accuracy: 0.1585\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2727 - accuracy: 0.8984 - val_loss: -3.1046 - val_accuracy: 0.0793\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1934 - accuracy: 0.9219 - val_loss: -3.4804 - val_accuracy: 0.0915\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9473 - val_loss: -3.2004 - val_accuracy: 0.0854\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1307 - accuracy: 0.9551 - val_loss: -2.3372 - val_accuracy: 0.1037\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9648 - val_loss: -3.3823 - val_accuracy: 0.0793\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9727 - val_loss: -3.8680 - val_accuracy: 0.0732\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9766 - val_loss: -3.0088 - val_accuracy: 0.1220\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0950 - accuracy: 0.9629 - val_loss: -4.5883 - val_accuracy: 0.0671\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9824 - val_loss: -4.1401 - val_accuracy: 0.0854\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9805 - val_loss: -4.6894 - val_accuracy: 0.0793\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9785 - val_loss: -3.9105 - val_accuracy: 0.0854\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9824 - val_loss: -3.1790 - val_accuracy: 0.1098\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0802 - accuracy: 0.9746 - val_loss: -4.8207 - val_accuracy: 0.0793\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9727 - val_loss: -4.9595 - val_accuracy: 0.0854\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0634 - accuracy: 0.9805 - val_loss: -4.9019 - val_accuracy: 0.0732\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9883 - val_loss: -4.5654 - val_accuracy: 0.0793\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9902 - val_loss: -4.4689 - val_accuracy: 0.0854\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0639 - accuracy: 0.9805 - val_loss: -5.3466 - val_accuracy: 0.0671\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0497 - accuracy: 0.9883 - val_loss: -3.8328 - val_accuracy: 0.1098\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9902 - val_loss: -5.2136 - val_accuracy: 0.0732\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9961 - val_loss: -5.0838 - val_accuracy: 0.0793\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9863 - val_loss: -4.3549 - val_accuracy: 0.1098\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9883 - val_loss: -7.0904 - val_accuracy: 0.0549\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9883 - val_loss: -5.0089 - val_accuracy: 0.0793\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9863 - val_loss: -4.9345 - val_accuracy: 0.0732\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9961 - val_loss: -5.2677 - val_accuracy: 0.0915\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: -5.8390 - val_accuracy: 0.0732\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: -5.4065 - val_accuracy: 0.0793\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: -6.0568 - val_accuracy: 0.0732\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: -5.5273 - val_accuracy: 0.0732\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: -5.7718 - val_accuracy: 0.0732\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9980 - val_loss: -5.1008 - val_accuracy: 0.0915\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9922 - val_loss: -5.1007 - val_accuracy: 0.0915\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: -5.9132 - val_accuracy: 0.0732\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9668 - val_loss: -4.0805 - val_accuracy: 0.1037\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1053 - accuracy: 0.9609 - val_loss: -5.4765 - val_accuracy: 0.0793\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.9336 - val_loss: -5.1248 - val_accuracy: 0.0610\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9570 - val_loss: -6.4597 - val_accuracy: 0.0671\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9727 - val_loss: -2.7423 - val_accuracy: 0.1524\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1225 - accuracy: 0.9434 - val_loss: -4.9964 - val_accuracy: 0.0854\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9766 - val_loss: -4.7343 - val_accuracy: 0.0793\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9883 - val_loss: -5.7080 - val_accuracy: 0.0854\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9961 - val_loss: -5.7977 - val_accuracy: 0.0793\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9980 - val_loss: -6.6550 - val_accuracy: 0.0671\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9980 - val_loss: -6.4658 - val_accuracy: 0.0732\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9980 - val_loss: -6.8439 - val_accuracy: 0.0732\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9961 - val_loss: -5.5393 - val_accuracy: 0.0976\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9961 - val_loss: -5.4453 - val_accuracy: 0.0793\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 0.9922 - val_loss: -5.7023 - val_accuracy: 0.0793\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: -5.2983 - val_accuracy: 0.0976\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: -5.6500 - val_accuracy: 0.0854\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: -6.6317 - val_accuracy: 0.0732\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: -6.3464 - val_accuracy: 0.0732\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -6.3927 - val_accuracy: 0.0793\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6892 - accuracy: 0.5195 - val_loss: 0.5998 - val_accuracy: 0.0915\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6055 - val_loss: 0.2659 - val_accuracy: 0.0183\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6328 - val_loss: 0.4915 - val_accuracy: 0.1463\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.6289 - val_loss: 0.0866 - val_accuracy: 0.1037\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5820 - accuracy: 0.6953 - val_loss: 0.3371 - val_accuracy: 0.1585\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5850 - accuracy: 0.7148 - val_loss: -0.3503 - val_accuracy: 0.0793\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7129 - val_loss: 0.0060 - val_accuracy: 0.1646\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7207 - val_loss: -0.6779 - val_accuracy: 0.0915\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7148 - val_loss: -0.1961 - val_accuracy: 0.1585\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7617 - val_loss: 0.0178 - val_accuracy: 0.1890\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.7676 - val_loss: -0.8185 - val_accuracy: 0.1280\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7676 - val_loss: -0.0513 - val_accuracy: 0.1829\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4481 - accuracy: 0.7891 - val_loss: -0.8681 - val_accuracy: 0.1463\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: -0.9841 - val_accuracy: 0.1402\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.7910 - val_loss: -0.6865 - val_accuracy: 0.1646\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8105 - val_loss: -1.0087 - val_accuracy: 0.1463\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8203 - val_loss: -0.8542 - val_accuracy: 0.1707\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8184 - val_loss: -0.8713 - val_accuracy: 0.1524\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.8340 - val_loss: -1.6197 - val_accuracy: 0.0854\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8262 - val_loss: -1.4356 - val_accuracy: 0.1159\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8379 - val_loss: -0.9527 - val_accuracy: 0.1768\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.8398 - val_loss: -2.3698 - val_accuracy: 0.0671\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8457 - val_loss: -1.6925 - val_accuracy: 0.1220\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3310 - accuracy: 0.8496 - val_loss: -1.2263 - val_accuracy: 0.1463\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8438 - val_loss: -1.7499 - val_accuracy: 0.0976\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8574 - val_loss: -2.4302 - val_accuracy: 0.0976\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3103 - accuracy: 0.8711 - val_loss: -1.5334 - val_accuracy: 0.1402\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2924 - accuracy: 0.8926 - val_loss: -1.7648 - val_accuracy: 0.1159\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2690 - accuracy: 0.9141 - val_loss: -1.7005 - val_accuracy: 0.1220\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.9043 - val_loss: -2.7597 - val_accuracy: 0.0854\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2596 - accuracy: 0.9043 - val_loss: -2.2283 - val_accuracy: 0.1159\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2672 - accuracy: 0.8926 - val_loss: -2.4009 - val_accuracy: 0.1098\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.9238 - val_loss: -2.6297 - val_accuracy: 0.0976\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2469 - accuracy: 0.9023 - val_loss: -2.7855 - val_accuracy: 0.1098\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2773 - accuracy: 0.8887 - val_loss: -1.9663 - val_accuracy: 0.1220\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.9102 - val_loss: -2.6337 - val_accuracy: 0.1098\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2046 - accuracy: 0.9258 - val_loss: -2.2207 - val_accuracy: 0.1220\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1807 - accuracy: 0.9395 - val_loss: -2.8282 - val_accuracy: 0.0915\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1871 - accuracy: 0.9277 - val_loss: -1.8621 - val_accuracy: 0.1341\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.9395 - val_loss: -3.1790 - val_accuracy: 0.0793\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1592 - accuracy: 0.9492 - val_loss: -2.9209 - val_accuracy: 0.0915\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1701 - accuracy: 0.9434 - val_loss: -3.0348 - val_accuracy: 0.0976\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1391 - accuracy: 0.9551 - val_loss: -2.8873 - val_accuracy: 0.1098\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1460 - accuracy: 0.9453 - val_loss: -3.3493 - val_accuracy: 0.0854\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 0.9570 - val_loss: -3.7882 - val_accuracy: 0.0976\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9629 - val_loss: -3.6945 - val_accuracy: 0.0793\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0989 - accuracy: 0.9707 - val_loss: -2.9485 - val_accuracy: 0.1098\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: -3.3503 - val_accuracy: 0.0976\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9805 - val_loss: -3.7406 - val_accuracy: 0.0793\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1275 - accuracy: 0.9590 - val_loss: -3.8766 - val_accuracy: 0.0854\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9668 - val_loss: -4.9875 - val_accuracy: 0.0671\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9629 - val_loss: -4.3421 - val_accuracy: 0.0915\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9707 - val_loss: -2.7699 - val_accuracy: 0.1402\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0925 - accuracy: 0.9629 - val_loss: -4.5983 - val_accuracy: 0.0610\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0690 - accuracy: 0.9883 - val_loss: -3.7481 - val_accuracy: 0.1037\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9785 - val_loss: -3.7752 - val_accuracy: 0.1220\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9785 - val_loss: -3.8255 - val_accuracy: 0.0915\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 0.9883 - val_loss: -4.0823 - val_accuracy: 0.0915\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9883 - val_loss: -5.7055 - val_accuracy: 0.0610\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0597 - accuracy: 0.9863 - val_loss: -3.8576 - val_accuracy: 0.1098\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9980 - val_loss: -4.7440 - val_accuracy: 0.0732\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9961 - val_loss: -4.8421 - val_accuracy: 0.0732\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9941 - val_loss: -4.4093 - val_accuracy: 0.0976\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: -4.8871 - val_accuracy: 0.1098\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9961 - val_loss: -5.3138 - val_accuracy: 0.0610\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9980 - val_loss: -5.6115 - val_accuracy: 0.0854\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9883 - val_loss: -5.2236 - val_accuracy: 0.0854\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9980 - val_loss: -5.5343 - val_accuracy: 0.0854\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: -5.2159 - val_accuracy: 0.0915\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: -4.9882 - val_accuracy: 0.0976\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: -5.1807 - val_accuracy: 0.0915\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: -5.6944 - val_accuracy: 0.0854\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: -5.6930 - val_accuracy: 0.0793\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: -6.1466 - val_accuracy: 0.0732\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: -5.6932 - val_accuracy: 0.0976\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: -5.8866 - val_accuracy: 0.0854\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -6.6502 - val_accuracy: 0.0671\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: -6.9631 - val_accuracy: 0.0671\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: -5.5511 - val_accuracy: 0.0915\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: -5.3756 - val_accuracy: 0.1159\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: -6.6023 - val_accuracy: 0.0793\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: -6.1224 - val_accuracy: 0.0854\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -6.2335 - val_accuracy: 0.0854\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -5.8999 - val_accuracy: 0.0915\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -6.0747 - val_accuracy: 0.0976\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -6.4841 - val_accuracy: 0.0854\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -6.5057 - val_accuracy: 0.0854\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -6.7565 - val_accuracy: 0.0793\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -6.1800 - val_accuracy: 0.1037\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -6.2774 - val_accuracy: 0.0976\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -6.0934 - val_accuracy: 0.1098\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -6.4494 - val_accuracy: 0.0976\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -6.1870 - val_accuracy: 0.1037\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -6.7139 - val_accuracy: 0.0915\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -6.5975 - val_accuracy: 0.0976\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -7.1043 - val_accuracy: 0.0732\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.0041 - val_accuracy: 0.0915\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -6.7890 - val_accuracy: 0.0915\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -6.6688 - val_accuracy: 0.0915\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -6.8064 - val_accuracy: 0.0915\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6881 - accuracy: 0.5430 - val_loss: 0.4564 - val_accuracy: 0.0183\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.6211 - val_loss: 0.5693 - val_accuracy: 0.1220\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6449 - accuracy: 0.6289 - val_loss: 0.4916 - val_accuracy: 0.1463\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.6660 - val_loss: 0.1779 - val_accuracy: 0.1098\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5756 - accuracy: 0.7188 - val_loss: 0.4580 - val_accuracy: 0.1646\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7363 - val_loss: -0.5879 - val_accuracy: 0.0366\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7461 - val_loss: 0.0582 - val_accuracy: 0.1646\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7773 - val_loss: 6.9605e-04 - val_accuracy: 0.1829\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4628 - accuracy: 0.7910 - val_loss: -0.8563 - val_accuracy: 0.1159\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7910 - val_loss: -0.1287 - val_accuracy: 0.1890\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8125 - val_loss: -0.9842 - val_accuracy: 0.1341\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7754 - val_loss: -0.0538 - val_accuracy: 0.1829\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.7715 - val_loss: 0.2419 - val_accuracy: 0.1951\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.8184 - val_loss: -0.5950 - val_accuracy: 0.1646\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8145 - val_loss: -0.9952 - val_accuracy: 0.1768\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8184 - val_loss: -1.4343 - val_accuracy: 0.1402\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8555 - val_loss: -0.5528 - val_accuracy: 0.1890\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8164 - val_loss: -1.7026 - val_accuracy: 0.0915\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3745 - accuracy: 0.8457 - val_loss: -0.3653 - val_accuracy: 0.1890\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8477 - val_loss: -1.0280 - val_accuracy: 0.1768\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8457 - val_loss: -1.2913 - val_accuracy: 0.1585\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8613 - val_loss: -1.3031 - val_accuracy: 0.1524\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3331 - accuracy: 0.8789 - val_loss: -0.6937 - val_accuracy: 0.1890\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8711 - val_loss: -1.6900 - val_accuracy: 0.1463\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3176 - accuracy: 0.8672 - val_loss: -2.1414 - val_accuracy: 0.1402\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3051 - accuracy: 0.8672 - val_loss: -2.5745 - val_accuracy: 0.0854\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8477 - val_loss: -0.3906 - val_accuracy: 0.1890\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8633 - val_loss: -1.7103 - val_accuracy: 0.1524\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2863 - accuracy: 0.8867 - val_loss: -2.0382 - val_accuracy: 0.1463\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8867 - val_loss: -1.3213 - val_accuracy: 0.1646\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2809 - accuracy: 0.8887 - val_loss: -2.4262 - val_accuracy: 0.1098\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2630 - accuracy: 0.9043 - val_loss: -1.9210 - val_accuracy: 0.1524\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.8906 - val_loss: -2.7421 - val_accuracy: 0.1159\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2537 - accuracy: 0.9043 - val_loss: -3.3789 - val_accuracy: 0.0915\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.9141 - val_loss: -3.4369 - val_accuracy: 0.0915\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8672 - val_loss: -1.9543 - val_accuracy: 0.1707\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2604 - accuracy: 0.8965 - val_loss: -2.9622 - val_accuracy: 0.0976\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2359 - accuracy: 0.9062 - val_loss: -2.9010 - val_accuracy: 0.1098\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9219 - val_loss: -2.9789 - val_accuracy: 0.1463\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2238 - accuracy: 0.9160 - val_loss: -1.8555 - val_accuracy: 0.1280\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2100 - accuracy: 0.9199 - val_loss: -3.5533 - val_accuracy: 0.0854\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2179 - accuracy: 0.9238 - val_loss: -2.1052 - val_accuracy: 0.1585\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2311 - accuracy: 0.8965 - val_loss: -4.4180 - val_accuracy: 0.0732\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.9219 - val_loss: -2.7354 - val_accuracy: 0.1524\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1671 - accuracy: 0.9414 - val_loss: -3.7876 - val_accuracy: 0.1037\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1849 - accuracy: 0.9375 - val_loss: -3.1995 - val_accuracy: 0.1341\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2093 - accuracy: 0.9160 - val_loss: -4.4195 - val_accuracy: 0.0732\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1685 - accuracy: 0.9414 - val_loss: -2.7429 - val_accuracy: 0.1341\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1595 - accuracy: 0.9434 - val_loss: -3.0559 - val_accuracy: 0.1159\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1483 - accuracy: 0.9434 - val_loss: -3.5906 - val_accuracy: 0.1280\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1486 - accuracy: 0.9492 - val_loss: -4.1795 - val_accuracy: 0.0793\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1311 - accuracy: 0.9590 - val_loss: -3.9792 - val_accuracy: 0.1159\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9629 - val_loss: -4.7871 - val_accuracy: 0.0732\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9570 - val_loss: -3.9503 - val_accuracy: 0.0976\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9688 - val_loss: -4.4748 - val_accuracy: 0.1098\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.9688 - val_loss: -4.2589 - val_accuracy: 0.0854\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0954 - accuracy: 0.9707 - val_loss: -4.5424 - val_accuracy: 0.0854\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.9688 - val_loss: -4.8551 - val_accuracy: 0.0793\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9668 - val_loss: -3.2563 - val_accuracy: 0.1280\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9746 - val_loss: -4.3365 - val_accuracy: 0.0915\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9688 - val_loss: -5.6159 - val_accuracy: 0.0671\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9863 - val_loss: -4.7213 - val_accuracy: 0.0976\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0782 - accuracy: 0.9785 - val_loss: -5.7408 - val_accuracy: 0.0610\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9707 - val_loss: -4.6392 - val_accuracy: 0.1098\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9707 - val_loss: -5.8789 - val_accuracy: 0.0793\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9785 - val_loss: -4.9874 - val_accuracy: 0.0976\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9863 - val_loss: -6.0150 - val_accuracy: 0.0976\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0632 - accuracy: 0.9844 - val_loss: -5.6469 - val_accuracy: 0.0854\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9902 - val_loss: -5.3216 - val_accuracy: 0.1098\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9824 - val_loss: -4.7377 - val_accuracy: 0.1159\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9902 - val_loss: -5.3327 - val_accuracy: 0.1037\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9902 - val_loss: -7.2937 - val_accuracy: 0.0732\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9863 - val_loss: -6.5880 - val_accuracy: 0.0915\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9844 - val_loss: -4.1876 - val_accuracy: 0.1463\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9785 - val_loss: -6.3196 - val_accuracy: 0.0854\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: -5.9033 - val_accuracy: 0.1159\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: -7.2262 - val_accuracy: 0.0732\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9922 - val_loss: -7.0744 - val_accuracy: 0.0793\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: -4.8295 - val_accuracy: 0.1220\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9941 - val_loss: -6.1717 - val_accuracy: 0.1037\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: -5.6776 - val_accuracy: 0.1098\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9941 - val_loss: -7.3926 - val_accuracy: 0.0732\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9961 - val_loss: -5.3855 - val_accuracy: 0.1220\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0387 - accuracy: 0.9961 - val_loss: -5.5313 - val_accuracy: 0.1098\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: -6.2955 - val_accuracy: 0.1037\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9805 - val_loss: -7.3470 - val_accuracy: 0.0976\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9824 - val_loss: -5.1795 - val_accuracy: 0.1402\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9746 - val_loss: -6.6387 - val_accuracy: 0.1159\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9902 - val_loss: -7.0529 - val_accuracy: 0.0549\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9824 - val_loss: -7.3843 - val_accuracy: 0.1037\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9805 - val_loss: -4.8194 - val_accuracy: 0.1280\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9902 - val_loss: -7.7804 - val_accuracy: 0.0915\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9980 - val_loss: -7.7355 - val_accuracy: 0.0793\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: -7.4430 - val_accuracy: 0.0915\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: -7.1859 - val_accuracy: 0.0915\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: -7.5381 - val_accuracy: 0.0793\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: -7.4880 - val_accuracy: 0.0915\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -8.1202 - val_accuracy: 0.0793\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -7.5060 - val_accuracy: 0.0854\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -8.0078 - val_accuracy: 0.0793\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 0.6953 - accuracy: 0.4902 - val_loss: 0.8563 - val_accuracy: 0.2134\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6074 - val_loss: 0.7534 - val_accuracy: 0.1524\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.7129 - val_loss: 0.4257 - val_accuracy: 0.1463\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7227 - val_loss: 0.2963 - val_accuracy: 0.1341\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5452 - accuracy: 0.7402 - val_loss: 0.0730 - val_accuracy: 0.1280\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5096 - accuracy: 0.7715 - val_loss: 0.0192 - val_accuracy: 0.1585\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: -0.2140 - val_accuracy: 0.1585\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.8027 - val_loss: -0.4400 - val_accuracy: 0.1341\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7852 - val_loss: -0.0204 - val_accuracy: 0.1829\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4334 - accuracy: 0.8047 - val_loss: -0.4324 - val_accuracy: 0.1768\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.8008 - val_loss: -1.4245 - val_accuracy: 0.0793\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8184 - val_loss: -0.2076 - val_accuracy: 0.1829\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3843 - accuracy: 0.8340 - val_loss: -0.5883 - val_accuracy: 0.1646\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8418 - val_loss: -1.1183 - val_accuracy: 0.1402\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3713 - accuracy: 0.8496 - val_loss: -1.0188 - val_accuracy: 0.1402\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8672 - val_loss: -1.3756 - val_accuracy: 0.1220\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8594 - val_loss: -1.7182 - val_accuracy: 0.0976\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8613 - val_loss: -2.1609 - val_accuracy: 0.0732\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3423 - accuracy: 0.8555 - val_loss: -1.5271 - val_accuracy: 0.1159\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3463 - accuracy: 0.8535 - val_loss: -1.0780 - val_accuracy: 0.1524\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8750 - val_loss: -1.9606 - val_accuracy: 0.1159\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3071 - accuracy: 0.8828 - val_loss: -0.4805 - val_accuracy: 0.1768\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3318 - accuracy: 0.8672 - val_loss: -1.8853 - val_accuracy: 0.1280\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2969 - accuracy: 0.8867 - val_loss: -1.6990 - val_accuracy: 0.1280\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2805 - accuracy: 0.8926 - val_loss: -1.8458 - val_accuracy: 0.1280\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.8887 - val_loss: -2.8245 - val_accuracy: 0.0732\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.8926 - val_loss: -2.5637 - val_accuracy: 0.1037\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.9062 - val_loss: -1.9831 - val_accuracy: 0.1098\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2485 - accuracy: 0.9141 - val_loss: -1.9372 - val_accuracy: 0.1220\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2542 - accuracy: 0.9062 - val_loss: -2.4881 - val_accuracy: 0.1159\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2493 - accuracy: 0.9043 - val_loss: -3.1821 - val_accuracy: 0.0671\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2659 - accuracy: 0.8984 - val_loss: -2.0186 - val_accuracy: 0.1402\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.8926 - val_loss: -2.5384 - val_accuracy: 0.0854\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.9121 - val_loss: -2.6682 - val_accuracy: 0.1098\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2123 - accuracy: 0.9297 - val_loss: -2.4460 - val_accuracy: 0.1159\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2178 - accuracy: 0.9238 - val_loss: -3.1421 - val_accuracy: 0.0915\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1973 - accuracy: 0.9199 - val_loss: -3.9194 - val_accuracy: 0.0854\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.9336 - val_loss: -3.3074 - val_accuracy: 0.0854\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1844 - accuracy: 0.9355 - val_loss: -3.0219 - val_accuracy: 0.1098\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1847 - accuracy: 0.9414 - val_loss: -2.8694 - val_accuracy: 0.1220\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1821 - accuracy: 0.9395 - val_loss: -3.4362 - val_accuracy: 0.0732\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1716 - accuracy: 0.9355 - val_loss: -2.9094 - val_accuracy: 0.1220\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.9336 - val_loss: -2.0040 - val_accuracy: 0.1463\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2283 - accuracy: 0.9004 - val_loss: -3.5854 - val_accuracy: 0.0793\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9336 - val_loss: -2.6899 - val_accuracy: 0.1220\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1822 - accuracy: 0.9277 - val_loss: -3.4076 - val_accuracy: 0.1098\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9531 - val_loss: -4.4172 - val_accuracy: 0.0732\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.9473 - val_loss: -2.9622 - val_accuracy: 0.1341\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1578 - accuracy: 0.9355 - val_loss: -4.7007 - val_accuracy: 0.0549\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1264 - accuracy: 0.9570 - val_loss: -3.9123 - val_accuracy: 0.0976\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9707 - val_loss: -4.3315 - val_accuracy: 0.0915\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9688 - val_loss: -4.6799 - val_accuracy: 0.0732\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1136 - accuracy: 0.9590 - val_loss: -4.7281 - val_accuracy: 0.0793\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1093 - accuracy: 0.9629 - val_loss: -3.1102 - val_accuracy: 0.1280\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9688 - val_loss: -4.1984 - val_accuracy: 0.1098\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9766 - val_loss: -4.4274 - val_accuracy: 0.0854\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0906 - accuracy: 0.9707 - val_loss: -5.7453 - val_accuracy: 0.0488\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1135 - accuracy: 0.9551 - val_loss: -4.4565 - val_accuracy: 0.1037\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1298 - accuracy: 0.9570 - val_loss: -4.1342 - val_accuracy: 0.1280\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9375 - val_loss: -5.1157 - val_accuracy: 0.0671\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1168 - accuracy: 0.9629 - val_loss: -3.7133 - val_accuracy: 0.1159\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0922 - accuracy: 0.9785 - val_loss: -5.8778 - val_accuracy: 0.0671\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0903 - accuracy: 0.9727 - val_loss: -4.8673 - val_accuracy: 0.1037\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9648 - val_loss: -5.3061 - val_accuracy: 0.0854\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9688 - val_loss: -6.3516 - val_accuracy: 0.0549\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1025 - accuracy: 0.9648 - val_loss: -5.0519 - val_accuracy: 0.1037\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9746 - val_loss: -5.5485 - val_accuracy: 0.0793\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9727 - val_loss: -6.1989 - val_accuracy: 0.0793\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9746 - val_loss: -5.8401 - val_accuracy: 0.0793\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: -5.4758 - val_accuracy: 0.0976\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: -7.0437 - val_accuracy: 0.0610\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9805 - val_loss: -5.4802 - val_accuracy: 0.1159\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: -4.7915 - val_accuracy: 0.1159\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9824 - val_loss: -6.8967 - val_accuracy: 0.0610\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9844 - val_loss: -6.0463 - val_accuracy: 0.1037\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 0.9766 - val_loss: -6.1701 - val_accuracy: 0.0915\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9883 - val_loss: -5.2600 - val_accuracy: 0.1098\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9922 - val_loss: -7.0446 - val_accuracy: 0.0732\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9805 - val_loss: -6.8081 - val_accuracy: 0.0915\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: -6.7649 - val_accuracy: 0.0793\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9824 - val_loss: -6.0382 - val_accuracy: 0.1037\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9902 - val_loss: -6.6877 - val_accuracy: 0.0793\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 0.9902 - val_loss: -6.9566 - val_accuracy: 0.0915\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: -7.4904 - val_accuracy: 0.0732\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9941 - val_loss: -6.8425 - val_accuracy: 0.0854\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9961 - val_loss: -7.4750 - val_accuracy: 0.0793\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9961 - val_loss: -6.1698 - val_accuracy: 0.1220\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9922 - val_loss: -7.6596 - val_accuracy: 0.0854\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 0.9961 - val_loss: -8.3040 - val_accuracy: 0.0915\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9941 - val_loss: -7.3277 - val_accuracy: 0.0915\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: -7.3315 - val_accuracy: 0.0976\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9980 - val_loss: -8.1008 - val_accuracy: 0.0671\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9980 - val_loss: -7.4122 - val_accuracy: 0.0915\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: -7.5502 - val_accuracy: 0.0976\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 0.9980 - val_loss: -5.8399 - val_accuracy: 0.1402\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: -8.7119 - val_accuracy: 0.0610\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2143 - accuracy: 0.9277 - val_loss: -4.6834 - val_accuracy: 0.1280\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1815 - accuracy: 0.9355 - val_loss: -4.8016 - val_accuracy: 0.1098\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9570 - val_loss: -6.6076 - val_accuracy: 0.0915\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9824 - val_loss: -5.7675 - val_accuracy: 0.0976\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9922 - val_loss: -6.1792 - val_accuracy: 0.1159\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9922 - val_loss: -6.9530 - val_accuracy: 0.0854\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: -6.9189 - val_accuracy: 0.0915\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: -7.7318 - val_accuracy: 0.0732\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: -6.7311 - val_accuracy: 0.0976\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: -5.8108 - val_accuracy: 0.1037\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: -7.6072 - val_accuracy: 0.0976\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: -6.7549 - val_accuracy: 0.1037\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: -7.4696 - val_accuracy: 0.0915\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: -7.5177 - val_accuracy: 0.0976\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: -8.0047 - val_accuracy: 0.0793\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: -7.6790 - val_accuracy: 0.0854\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: -7.7529 - val_accuracy: 0.0915\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -7.3364 - val_accuracy: 0.1037\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -7.8730 - val_accuracy: 0.1037\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: -8.6202 - val_accuracy: 0.0854\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -7.6048 - val_accuracy: 0.1098\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -7.9549 - val_accuracy: 0.1037\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -8.4878 - val_accuracy: 0.0854\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -8.7230 - val_accuracy: 0.0854\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -8.7112 - val_accuracy: 0.0854\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -8.3381 - val_accuracy: 0.0854\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -8.4076 - val_accuracy: 0.0854\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -8.3119 - val_accuracy: 0.0976\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -8.1833 - val_accuracy: 0.1037\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -8.9536 - val_accuracy: 0.0854\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.5210 - val_accuracy: 0.0854\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.6405 - val_accuracy: 0.0854\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.5032 - val_accuracy: 0.1037\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -8.8922 - val_accuracy: 0.0915\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.9028 - val_accuracy: 0.0854\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.7145 - val_accuracy: 0.0915\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -9.2962 - val_accuracy: 0.0854\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -8.7541 - val_accuracy: 0.0915\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.8153 - val_accuracy: 0.0915\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.9949 - val_accuracy: 0.0854\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.7225 - val_accuracy: 0.0976\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -9.0820 - val_accuracy: 0.0854\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.6930 - val_accuracy: 0.1037\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.1835 - val_accuracy: 0.0854\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.4174 - val_accuracy: 0.0854\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.0208 - val_accuracy: 0.0976\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.5589 - val_accuracy: 0.0854\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.3058 - val_accuracy: 0.0854\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.2399 - val_accuracy: 0.0854\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.2462 - val_accuracy: 0.0915\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.3838 - val_accuracy: 0.0854\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.2523 - val_accuracy: 0.0915\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.5326 - val_accuracy: 0.0854\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.3155 - val_accuracy: 0.0976\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.6063 - val_accuracy: 0.0915\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.3895 - val_accuracy: 0.0915\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.4953 - val_accuracy: 0.0915\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.6530 - val_accuracy: 0.0854\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.4515 - val_accuracy: 0.0915\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.6290 - val_accuracy: 0.0915\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.9936 - val_accuracy: 0.0854\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.7320 - val_accuracy: 0.0854\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.4630 - val_accuracy: 0.0976\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.9420e-04 - accuracy: 1.0000 - val_loss: -9.8103 - val_accuracy: 0.0854\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.7225e-04 - accuracy: 1.0000 - val_loss: -9.4575 - val_accuracy: 0.0976\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 9.8974e-04 - accuracy: 1.0000 - val_loss: -10.0447 - val_accuracy: 0.0854\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 9.4412e-04 - accuracy: 1.0000 - val_loss: -9.4273 - val_accuracy: 0.0976\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.0938 - val_accuracy: 0.0854\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.3308e-04 - accuracy: 1.0000 - val_loss: -9.8737 - val_accuracy: 0.0854\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.0210e-04 - accuracy: 1.0000 - val_loss: -9.7557 - val_accuracy: 0.0915\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.9254e-04 - accuracy: 1.0000 - val_loss: -9.9749 - val_accuracy: 0.0854\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.8340e-04 - accuracy: 1.0000 - val_loss: -9.9213 - val_accuracy: 0.0915\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.4163e-04 - accuracy: 1.0000 - val_loss: -9.6850 - val_accuracy: 0.0976\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.6129e-04 - accuracy: 1.0000 - val_loss: -9.9668 - val_accuracy: 0.0915\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.6847e-04 - accuracy: 1.0000 - val_loss: -9.8996 - val_accuracy: 0.0915\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6671e-04 - accuracy: 1.0000 - val_loss: -10.0775 - val_accuracy: 0.0915\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8.1082e-04 - accuracy: 1.0000 - val_loss: -9.7676 - val_accuracy: 0.0976\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.4502e-04 - accuracy: 1.0000 - val_loss: -10.0038 - val_accuracy: 0.0915\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.5341e-04 - accuracy: 1.0000 - val_loss: -10.2504 - val_accuracy: 0.0854\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.0553e-04 - accuracy: 1.0000 - val_loss: -9.9181 - val_accuracy: 0.0915\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.2950e-04 - accuracy: 1.0000 - val_loss: -10.2479 - val_accuracy: 0.0854\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.8596e-04 - accuracy: 1.0000 - val_loss: -9.9342 - val_accuracy: 0.0915\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6.8075e-04 - accuracy: 1.0000 - val_loss: -10.2508 - val_accuracy: 0.0915\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5404e-04 - accuracy: 1.0000 - val_loss: -10.2936 - val_accuracy: 0.0854\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4731e-04 - accuracy: 1.0000 - val_loss: -10.0683 - val_accuracy: 0.0915\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.5710e-04 - accuracy: 1.0000 - val_loss: -10.4681 - val_accuracy: 0.0915\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4181e-04 - accuracy: 1.0000 - val_loss: -10.0327 - val_accuracy: 0.0915\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.3923e-04 - accuracy: 1.0000 - val_loss: -10.3094 - val_accuracy: 0.0854\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1280e-04 - accuracy: 1.0000 - val_loss: -10.3714 - val_accuracy: 0.0915\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.9959e-04 - accuracy: 1.0000 - val_loss: -10.3152 - val_accuracy: 0.0915\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.7615e-04 - accuracy: 1.0000 - val_loss: -10.4220 - val_accuracy: 0.0915\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.7182e-04 - accuracy: 1.0000 - val_loss: -10.3920 - val_accuracy: 0.0915\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.6965e-04 - accuracy: 1.0000 - val_loss: -10.5505 - val_accuracy: 0.0854\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.5013e-04 - accuracy: 1.0000 - val_loss: -10.4141 - val_accuracy: 0.0915\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.3294e-04 - accuracy: 1.0000 - val_loss: -10.5683 - val_accuracy: 0.0915\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.3019e-04 - accuracy: 1.0000 - val_loss: -10.4395 - val_accuracy: 0.0915\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.2791e-04 - accuracy: 1.0000 - val_loss: -10.6380 - val_accuracy: 0.0854\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 5.0806e-04 - accuracy: 1.0000 - val_loss: -10.3725 - val_accuracy: 0.0915\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4510e-04 - accuracy: 1.0000 - val_loss: -10.6183 - val_accuracy: 0.0915\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9240e-04 - accuracy: 1.0000 - val_loss: -10.5622 - val_accuracy: 0.0915\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7941e-04 - accuracy: 1.0000 - val_loss: -10.4512 - val_accuracy: 0.0915\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.0574e-04 - accuracy: 1.0000 - val_loss: -10.9075 - val_accuracy: 0.0854\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4.8954e-04 - accuracy: 1.0000 - val_loss: -10.5201 - val_accuracy: 0.0915\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7861e-04 - accuracy: 1.0000 - val_loss: -10.7004 - val_accuracy: 0.0915\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 0.6860 - accuracy: 0.5293 - val_loss: 0.8737 - val_accuracy: 0.2134\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.5801 - val_loss: 0.5815 - val_accuracy: 0.1524\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6331 - accuracy: 0.6777 - val_loss: 0.1488 - val_accuracy: 0.0610\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.6582 - val_loss: -0.0153 - val_accuracy: 0.0915\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.6680 - val_loss: -0.0395 - val_accuracy: 0.1037\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.7129 - val_loss: 0.1140 - val_accuracy: 0.1585\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7578 - val_loss: 0.2570 - val_accuracy: 0.1829\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5080 - accuracy: 0.7441 - val_loss: -0.4663 - val_accuracy: 0.1524\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7520 - val_loss: -0.2825 - val_accuracy: 0.1768\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5011 - accuracy: 0.7383 - val_loss: -0.3812 - val_accuracy: 0.1768\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4900 - accuracy: 0.7598 - val_loss: -0.8365 - val_accuracy: 0.1463\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4559 - accuracy: 0.7910 - val_loss: -0.4516 - val_accuracy: 0.1646\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7598 - val_loss: -0.2831 - val_accuracy: 0.1768\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.7852 - val_loss: -0.4988 - val_accuracy: 0.1707\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7812 - val_loss: -1.2277 - val_accuracy: 0.1341\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.7949 - val_loss: -0.9988 - val_accuracy: 0.1402\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4252 - accuracy: 0.7910 - val_loss: -0.9011 - val_accuracy: 0.1524\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7832 - val_loss: -0.8286 - val_accuracy: 0.1402\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8066 - val_loss: -1.1867 - val_accuracy: 0.1463\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8301 - val_loss: -0.1538 - val_accuracy: 0.1890\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8281 - val_loss: -1.3942 - val_accuracy: 0.1463\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.8340 - val_loss: -1.0826 - val_accuracy: 0.1585\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8418 - val_loss: -2.2006 - val_accuracy: 0.1098\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8223 - val_loss: -0.3611 - val_accuracy: 0.1829\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8418 - val_loss: -1.6802 - val_accuracy: 0.1220\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3420 - accuracy: 0.8477 - val_loss: -1.2484 - val_accuracy: 0.1524\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3244 - accuracy: 0.8770 - val_loss: -2.0134 - val_accuracy: 0.1220\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3203 - accuracy: 0.8672 - val_loss: -2.0025 - val_accuracy: 0.1341\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3163 - accuracy: 0.8691 - val_loss: -1.6859 - val_accuracy: 0.1402\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2865 - accuracy: 0.8848 - val_loss: -2.3493 - val_accuracy: 0.1159\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2779 - accuracy: 0.8887 - val_loss: -2.1584 - val_accuracy: 0.1280\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2785 - accuracy: 0.8848 - val_loss: -2.8902 - val_accuracy: 0.0915\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3089 - accuracy: 0.8594 - val_loss: -1.8970 - val_accuracy: 0.1402\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2759 - accuracy: 0.8770 - val_loss: -3.5724 - val_accuracy: 0.0793\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8828 - val_loss: -2.1366 - val_accuracy: 0.1341\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2655 - accuracy: 0.9102 - val_loss: -3.1653 - val_accuracy: 0.0976\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.9062 - val_loss: -2.2700 - val_accuracy: 0.1220\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2515 - accuracy: 0.8984 - val_loss: -1.8145 - val_accuracy: 0.1463\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3116 - accuracy: 0.8809 - val_loss: -2.9921 - val_accuracy: 0.1159\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2627 - accuracy: 0.8926 - val_loss: -2.6970 - val_accuracy: 0.0915\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8496 - val_loss: -0.4610 - val_accuracy: 0.1402\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8359 - val_loss: -2.9982 - val_accuracy: 0.0854\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.8555 - val_loss: -2.0062 - val_accuracy: 0.1280\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2543 - accuracy: 0.9043 - val_loss: -2.2443 - val_accuracy: 0.1341\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2182 - accuracy: 0.9277 - val_loss: -2.9506 - val_accuracy: 0.1098\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1951 - accuracy: 0.9355 - val_loss: -3.0002 - val_accuracy: 0.1098\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9492 - val_loss: -1.5753 - val_accuracy: 0.1463\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.9004 - val_loss: -2.6651 - val_accuracy: 0.1220\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2294 - accuracy: 0.9160 - val_loss: -2.6977 - val_accuracy: 0.1341\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1967 - accuracy: 0.9316 - val_loss: -3.1579 - val_accuracy: 0.1159\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.9395 - val_loss: -3.6085 - val_accuracy: 0.0915\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1604 - accuracy: 0.9492 - val_loss: -2.7163 - val_accuracy: 0.1402\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1627 - accuracy: 0.9434 - val_loss: -3.0129 - val_accuracy: 0.1098\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.9590 - val_loss: -4.0548 - val_accuracy: 0.0976\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9121 - val_loss: -3.2203 - val_accuracy: 0.1220\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2151 - accuracy: 0.9219 - val_loss: -2.0713 - val_accuracy: 0.1463\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1809 - accuracy: 0.9316 - val_loss: -3.6342 - val_accuracy: 0.1037\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1669 - accuracy: 0.9316 - val_loss: -3.2393 - val_accuracy: 0.0915\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1382 - accuracy: 0.9531 - val_loss: -2.9475 - val_accuracy: 0.1159\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9688 - val_loss: -4.0489 - val_accuracy: 0.1037\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1206 - accuracy: 0.9668 - val_loss: -4.4309 - val_accuracy: 0.0854\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1235 - accuracy: 0.9570 - val_loss: -3.6453 - val_accuracy: 0.1098\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1058 - accuracy: 0.9648 - val_loss: -3.4128 - val_accuracy: 0.1098\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9707 - val_loss: -4.6174 - val_accuracy: 0.0915\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9746 - val_loss: -4.4830 - val_accuracy: 0.1037\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9766 - val_loss: -3.6808 - val_accuracy: 0.1220\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0888 - accuracy: 0.9707 - val_loss: -5.4321 - val_accuracy: 0.0915\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9668 - val_loss: -4.0716 - val_accuracy: 0.1220\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9766 - val_loss: -4.0773 - val_accuracy: 0.1098\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9707 - val_loss: -5.5096 - val_accuracy: 0.0976\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9629 - val_loss: -4.8970 - val_accuracy: 0.1098\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0973 - accuracy: 0.9648 - val_loss: -4.3727 - val_accuracy: 0.1098\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9785 - val_loss: -5.6012 - val_accuracy: 0.0915\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9746 - val_loss: -4.3036 - val_accuracy: 0.1037\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9746 - val_loss: -5.1436 - val_accuracy: 0.1037\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1095 - accuracy: 0.9570 - val_loss: -5.3871 - val_accuracy: 0.0976\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 0.9727 - val_loss: -3.9818 - val_accuracy: 0.0976\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9824 - val_loss: -5.5539 - val_accuracy: 0.0915\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 0.9844 - val_loss: -4.1941 - val_accuracy: 0.1098\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9883 - val_loss: -6.1191 - val_accuracy: 0.0793\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9863 - val_loss: -4.0574 - val_accuracy: 0.1098\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9863 - val_loss: -4.8930 - val_accuracy: 0.1037\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: -4.4656 - val_accuracy: 0.1037\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9805 - val_loss: -5.7171 - val_accuracy: 0.0915\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.9844 - val_loss: -4.0450 - val_accuracy: 0.1159\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9824 - val_loss: -6.8342 - val_accuracy: 0.0854\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0582 - accuracy: 0.9766 - val_loss: -4.9773 - val_accuracy: 0.1159\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: -4.5869 - val_accuracy: 0.0976\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9766 - val_loss: -4.8148 - val_accuracy: 0.1037\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9824 - val_loss: -5.7418 - val_accuracy: 0.0976\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9922 - val_loss: -6.2213 - val_accuracy: 0.0976\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9980 - val_loss: -6.0039 - val_accuracy: 0.0976\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: -5.6620 - val_accuracy: 0.1037\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: -7.0609 - val_accuracy: 0.0732\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9961 - val_loss: -6.6421 - val_accuracy: 0.0976\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: -5.0092 - val_accuracy: 0.1037\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9980 - val_loss: -5.7925 - val_accuracy: 0.1037\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: -6.3595 - val_accuracy: 0.1037\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9980 - val_loss: -6.4016 - val_accuracy: 0.0976\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: -6.4690 - val_accuracy: 0.0915\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: -6.5568 - val_accuracy: 0.0976\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: -6.6100 - val_accuracy: 0.1037\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: -6.2019 - val_accuracy: 0.0976\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -6.5856 - val_accuracy: 0.0976\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: -6.9380 - val_accuracy: 0.0976\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: -6.5399 - val_accuracy: 0.0976\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: -6.2524 - val_accuracy: 0.1037\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: -6.6324 - val_accuracy: 0.1037\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: -6.5105 - val_accuracy: 0.1037\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: -6.4097 - val_accuracy: 0.1037\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -6.9168 - val_accuracy: 0.0976\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -7.1174 - val_accuracy: 0.0976\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: -6.8371 - val_accuracy: 0.0976\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -7.1368 - val_accuracy: 0.0976\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -7.0057 - val_accuracy: 0.0976\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -7.0552 - val_accuracy: 0.0976\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -6.6451 - val_accuracy: 0.1037\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: -6.6389 - val_accuracy: 0.1037\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -7.1521 - val_accuracy: 0.0976\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -7.1388 - val_accuracy: 0.1037\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -7.4341 - val_accuracy: 0.0976\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.5015 - val_accuracy: 0.0976\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.3755 - val_accuracy: 0.0976\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -7.2506 - val_accuracy: 0.1037\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -6.7494 - val_accuracy: 0.1037\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.0221 - val_accuracy: 0.1037\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.5562 - val_accuracy: 0.0976\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.0874 - val_accuracy: 0.0976\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -7.6744 - val_accuracy: 0.0976\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.3609 - val_accuracy: 0.0976\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.9914 - val_accuracy: 0.0976\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.1062 - val_accuracy: 0.1037\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.6707 - val_accuracy: 0.0976\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.5935 - val_accuracy: 0.0976\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -7.9726 - val_accuracy: 0.0976\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -6.8002 - val_accuracy: 0.1037\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.4178 - val_accuracy: 0.1037\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.9873 - val_accuracy: 0.0976\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.7625 - val_accuracy: 0.0976\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.5927 - val_accuracy: 0.0976\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.1488 - val_accuracy: 0.0976\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.5414 - val_accuracy: 0.1037\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.1067 - val_accuracy: 0.0976\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.1751 - val_accuracy: 0.0976\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.7041 - val_accuracy: 0.0976\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.9448 - val_accuracy: 0.0976\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.9871 - val_accuracy: 0.0976\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.8972 - val_accuracy: 0.0976\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.0904 - val_accuracy: 0.0976\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.0640 - val_accuracy: 0.0976\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.9802 - val_accuracy: 0.0976\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.9810 - val_accuracy: 0.0976\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.1472 - val_accuracy: 0.0976\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.0478 - val_accuracy: 0.0976\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.9009 - val_accuracy: 0.0976\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.2898 - val_accuracy: 0.0976\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.0947 - val_accuracy: 0.0976\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.2024 - val_accuracy: 0.1037\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.3905 - val_accuracy: 0.0976\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.2927 - val_accuracy: 0.0976\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.9252 - val_accuracy: 0.1037\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.2448 - val_accuracy: 0.0976\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.8353 - val_accuracy: 0.1037\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.2115 - val_accuracy: 0.0976\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.6023 - val_accuracy: 0.0976\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.1935 - val_accuracy: 0.0976\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.7195e-04 - accuracy: 1.0000 - val_loss: -8.3640 - val_accuracy: 0.0976\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.1811e-04 - accuracy: 1.0000 - val_loss: -8.3820 - val_accuracy: 0.0976\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.9975e-04 - accuracy: 1.0000 - val_loss: -8.3793 - val_accuracy: 0.1037\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.1780e-04 - accuracy: 1.0000 - val_loss: -8.1922 - val_accuracy: 0.0976\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8.6379e-04 - accuracy: 1.0000 - val_loss: -8.4961 - val_accuracy: 0.1037\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3004e-04 - accuracy: 1.0000 - val_loss: -8.5518 - val_accuracy: 0.0976\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.3935e-04 - accuracy: 1.0000 - val_loss: -8.2629 - val_accuracy: 0.1037\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.9019e-04 - accuracy: 1.0000 - val_loss: -8.7500 - val_accuracy: 0.0976\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.8852e-04 - accuracy: 1.0000 - val_loss: -8.2490 - val_accuracy: 0.1037\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.2162e-04 - accuracy: 1.0000 - val_loss: -8.5735 - val_accuracy: 0.0976\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7184e-04 - accuracy: 1.0000 - val_loss: -8.5012 - val_accuracy: 0.1037\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.6821e-04 - accuracy: 1.0000 - val_loss: -8.5283 - val_accuracy: 0.0976\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.2748e-04 - accuracy: 1.0000 - val_loss: -8.7152 - val_accuracy: 0.0976\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.2350e-04 - accuracy: 1.0000 - val_loss: -8.5800 - val_accuracy: 0.0976\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6.8688e-04 - accuracy: 1.0000 - val_loss: -8.7064 - val_accuracy: 0.0976\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.9258e-04 - accuracy: 1.0000 - val_loss: -8.7557 - val_accuracy: 0.0976\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.9861e-04 - accuracy: 1.0000 - val_loss: -8.6192 - val_accuracy: 0.0976\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.5401e-04 - accuracy: 1.0000 - val_loss: -8.5959 - val_accuracy: 0.0976\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.5894e-04 - accuracy: 1.0000 - val_loss: -8.5781 - val_accuracy: 0.1037\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.3773e-04 - accuracy: 1.0000 - val_loss: -9.0198 - val_accuracy: 0.0976\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6.2278e-04 - accuracy: 1.0000 - val_loss: -8.5989 - val_accuracy: 0.0976\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.0700e-04 - accuracy: 1.0000 - val_loss: -8.8630 - val_accuracy: 0.0976\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.3547e-04 - accuracy: 1.0000 - val_loss: -8.6724 - val_accuracy: 0.1037\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.0049e-04 - accuracy: 1.0000 - val_loss: -8.6764 - val_accuracy: 0.0976\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.7962e-04 - accuracy: 1.0000 - val_loss: -9.0195 - val_accuracy: 0.0976\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.5473e-04 - accuracy: 1.0000 - val_loss: -8.7592 - val_accuracy: 0.1037\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.6199e-04 - accuracy: 1.0000 - val_loss: -8.8911 - val_accuracy: 0.0976\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5.5030e-04 - accuracy: 1.0000 - val_loss: -8.8306 - val_accuracy: 0.0976\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.3042e-04 - accuracy: 1.0000 - val_loss: -8.8303 - val_accuracy: 0.0976\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.2097e-04 - accuracy: 1.0000 - val_loss: -8.8681 - val_accuracy: 0.1037\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.3526e-04 - accuracy: 1.0000 - val_loss: -9.0569 - val_accuracy: 0.0976\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.0037e-04 - accuracy: 1.0000 - val_loss: -8.7912 - val_accuracy: 0.1037\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.0015e-04 - accuracy: 1.0000 - val_loss: -9.2089 - val_accuracy: 0.0976\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.9027e-04 - accuracy: 1.0000 - val_loss: -8.6470 - val_accuracy: 0.1037\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6938 - accuracy: 0.5254 - val_loss: 0.8012 - val_accuracy: 0.1829\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.6113 - val_loss: 0.6169 - val_accuracy: 0.1341\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6875 - val_loss: 0.5678 - val_accuracy: 0.1524\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.6914 - val_loss: 0.3716 - val_accuracy: 0.1341\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5946 - accuracy: 0.7168 - val_loss: 0.1669 - val_accuracy: 0.1341\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5665 - accuracy: 0.7422 - val_loss: 0.0648 - val_accuracy: 0.1159\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7520 - val_loss: -0.2988 - val_accuracy: 0.1037\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5223 - accuracy: 0.7734 - val_loss: -0.6436 - val_accuracy: 0.0976\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7734 - val_loss: -0.1322 - val_accuracy: 0.1646\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4903 - accuracy: 0.7695 - val_loss: 0.1157 - val_accuracy: 0.1829\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4594 - accuracy: 0.7832 - val_loss: -0.4439 - val_accuracy: 0.1585\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7891 - val_loss: -1.1720 - val_accuracy: 0.0854\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7949 - val_loss: -1.0710 - val_accuracy: 0.1098\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.8066 - val_loss: -0.0470 - val_accuracy: 0.1951\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.7812 - val_loss: -0.2660 - val_accuracy: 0.1829\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7988 - val_loss: -0.8659 - val_accuracy: 0.1220\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8281 - val_loss: -0.7162 - val_accuracy: 0.1585\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3936 - accuracy: 0.8320 - val_loss: -0.9698 - val_accuracy: 0.1220\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8281 - val_loss: -1.1324 - val_accuracy: 0.1402\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8281 - val_loss: -1.7799 - val_accuracy: 0.0671\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8281 - val_loss: -0.6175 - val_accuracy: 0.1585\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8203 - val_loss: 0.7088 - val_accuracy: 0.2012\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.8281 - val_loss: -0.8029 - val_accuracy: 0.1768\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8379 - val_loss: -0.9239 - val_accuracy: 0.1463\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.8496 - val_loss: -0.2715 - val_accuracy: 0.1951\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3684 - accuracy: 0.8398 - val_loss: -1.6677 - val_accuracy: 0.1159\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3515 - accuracy: 0.8516 - val_loss: -0.7408 - val_accuracy: 0.1524\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8438 - val_loss: -2.2056 - val_accuracy: 0.0793\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8438 - val_loss: -0.9661 - val_accuracy: 0.1585\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3253 - accuracy: 0.8848 - val_loss: -2.0753 - val_accuracy: 0.0793\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.8594 - val_loss: -1.2431 - val_accuracy: 0.1402\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3216 - accuracy: 0.8691 - val_loss: -1.9159 - val_accuracy: 0.0976\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3051 - accuracy: 0.8906 - val_loss: -1.3855 - val_accuracy: 0.1585\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3220 - accuracy: 0.8516 - val_loss: -1.8896 - val_accuracy: 0.1159\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3062 - accuracy: 0.8691 - val_loss: -1.4755 - val_accuracy: 0.1524\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2828 - accuracy: 0.8926 - val_loss: -1.4354 - val_accuracy: 0.1463\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8887 - val_loss: -2.1218 - val_accuracy: 0.0854\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2719 - accuracy: 0.8887 - val_loss: -1.8659 - val_accuracy: 0.1159\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2670 - accuracy: 0.8848 - val_loss: -2.1092 - val_accuracy: 0.1098\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2514 - accuracy: 0.9004 - val_loss: -2.5961 - val_accuracy: 0.0915\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2518 - accuracy: 0.8984 - val_loss: -1.3725 - val_accuracy: 0.1585\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2477 - accuracy: 0.8926 - val_loss: -2.2272 - val_accuracy: 0.1220\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2188 - accuracy: 0.9180 - val_loss: -2.2160 - val_accuracy: 0.1341\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2216 - accuracy: 0.9199 - val_loss: -1.0410 - val_accuracy: 0.1646\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2482 - accuracy: 0.9121 - val_loss: -2.6619 - val_accuracy: 0.0915\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.8906 - val_loss: -1.9335 - val_accuracy: 0.1402\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2652 - accuracy: 0.8926 - val_loss: -1.1508 - val_accuracy: 0.1585\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2348 - accuracy: 0.9141 - val_loss: -2.7416 - val_accuracy: 0.1037\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2100 - accuracy: 0.9180 - val_loss: -2.7633 - val_accuracy: 0.1098\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2213 - accuracy: 0.9102 - val_loss: -2.0725 - val_accuracy: 0.1402\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.9062 - val_loss: -1.1833 - val_accuracy: 0.1829\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2235 - accuracy: 0.9160 - val_loss: -3.4050 - val_accuracy: 0.0915\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1925 - accuracy: 0.9199 - val_loss: -2.6423 - val_accuracy: 0.1220\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2340 - accuracy: 0.9023 - val_loss: -3.0052 - val_accuracy: 0.1341\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1863 - accuracy: 0.9277 - val_loss: -3.5288 - val_accuracy: 0.1098\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1611 - accuracy: 0.9453 - val_loss: -2.9570 - val_accuracy: 0.1220\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9395 - val_loss: -3.3037 - val_accuracy: 0.1098\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1399 - accuracy: 0.9570 - val_loss: -3.7163 - val_accuracy: 0.0976\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1300 - accuracy: 0.9590 - val_loss: -4.3304 - val_accuracy: 0.0793\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.9434 - val_loss: -2.2307 - val_accuracy: 0.1646\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1610 - accuracy: 0.9531 - val_loss: -2.8890 - val_accuracy: 0.1220\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1491 - accuracy: 0.9414 - val_loss: -4.0835 - val_accuracy: 0.0915\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9434 - val_loss: -1.8544 - val_accuracy: 0.1768\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2424 - accuracy: 0.8828 - val_loss: -4.5030 - val_accuracy: 0.0671\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1594 - accuracy: 0.9375 - val_loss: -3.5301 - val_accuracy: 0.0976\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1300 - accuracy: 0.9551 - val_loss: -4.0588 - val_accuracy: 0.0915\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1451 - accuracy: 0.9512 - val_loss: -4.1184 - val_accuracy: 0.1098\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9297 - val_loss: -3.9950 - val_accuracy: 0.0610\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1902 - accuracy: 0.9219 - val_loss: -1.8777 - val_accuracy: 0.1524\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9453 - val_loss: -1.9791 - val_accuracy: 0.1585\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9512 - val_loss: -4.3719 - val_accuracy: 0.0793\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9512 - val_loss: -3.6746 - val_accuracy: 0.1220\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9590 - val_loss: -4.7215 - val_accuracy: 0.0915\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1000 - accuracy: 0.9727 - val_loss: -4.3617 - val_accuracy: 0.1037\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.9727 - val_loss: -4.7640 - val_accuracy: 0.0793\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1010 - accuracy: 0.9688 - val_loss: -3.8867 - val_accuracy: 0.1341\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9746 - val_loss: -3.7365 - val_accuracy: 0.1280\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9805 - val_loss: -4.9738 - val_accuracy: 0.0976\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0700 - accuracy: 0.9805 - val_loss: -4.3264 - val_accuracy: 0.1220\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9805 - val_loss: -5.0677 - val_accuracy: 0.1037\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 0.9785 - val_loss: -5.1488 - val_accuracy: 0.1037\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9844 - val_loss: -4.3993 - val_accuracy: 0.1280\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9824 - val_loss: -4.7207 - val_accuracy: 0.1159\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9707 - val_loss: -3.1413 - val_accuracy: 0.1402\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9824 - val_loss: -5.8963 - val_accuracy: 0.0915\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9785 - val_loss: -5.0403 - val_accuracy: 0.1098\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9883 - val_loss: -4.6446 - val_accuracy: 0.1220\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0678 - accuracy: 0.9727 - val_loss: -5.4348 - val_accuracy: 0.1098\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0698 - accuracy: 0.9785 - val_loss: -3.9061 - val_accuracy: 0.1341\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9727 - val_loss: -5.1772 - val_accuracy: 0.1098\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9844 - val_loss: -5.5787 - val_accuracy: 0.0976\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9746 - val_loss: -5.0607 - val_accuracy: 0.1220\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0812 - accuracy: 0.9668 - val_loss: -5.0043 - val_accuracy: 0.1159\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.9863 - val_loss: -4.8602 - val_accuracy: 0.1280\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: -7.2690 - val_accuracy: 0.0854\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9883 - val_loss: -5.9161 - val_accuracy: 0.0976\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 0.9883 - val_loss: -5.6646 - val_accuracy: 0.1159\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9883 - val_loss: -6.0243 - val_accuracy: 0.0915\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0333 - accuracy: 0.9922 - val_loss: -6.5034 - val_accuracy: 0.0976\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9941 - val_loss: -5.6918 - val_accuracy: 0.1280\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: -7.3343 - val_accuracy: 0.0732\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9922 - val_loss: -6.0397 - val_accuracy: 0.1159\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9961 - val_loss: -6.3133 - val_accuracy: 0.1159\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9883 - val_loss: -6.0802 - val_accuracy: 0.1220\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0371 - accuracy: 0.9902 - val_loss: -7.0701 - val_accuracy: 0.0915\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: -6.1369 - val_accuracy: 0.1220\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9844 - val_loss: -5.2700 - val_accuracy: 0.1402\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9883 - val_loss: -6.4566 - val_accuracy: 0.1037\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9980 - val_loss: -6.9222 - val_accuracy: 0.1098\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9941 - val_loss: -7.5115 - val_accuracy: 0.0732\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.9824 - val_loss: -4.4691 - val_accuracy: 0.1402\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: -7.9696 - val_accuracy: 0.0854\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: -5.2225 - val_accuracy: 0.1220\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: -6.4683 - val_accuracy: 0.1220\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: -7.8650 - val_accuracy: 0.0732\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 0.9980 - val_loss: -6.7938 - val_accuracy: 0.1098\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: -5.8092 - val_accuracy: 0.1220\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9961 - val_loss: -6.9945 - val_accuracy: 0.1037\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9941 - val_loss: -7.4600 - val_accuracy: 0.0976\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9883 - val_loss: -6.9903 - val_accuracy: 0.1220\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: -5.9313 - val_accuracy: 0.1159\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 0.9961 - val_loss: -6.0327 - val_accuracy: 0.1159\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: -7.8588 - val_accuracy: 0.0915\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9980 - val_loss: -7.9634 - val_accuracy: 0.0976\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: -8.1658 - val_accuracy: 0.0854\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: -7.6533 - val_accuracy: 0.0976\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: -7.4553 - val_accuracy: 0.1037\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: -6.8617 - val_accuracy: 0.1159\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: -8.2277 - val_accuracy: 0.0976\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: -7.3648 - val_accuracy: 0.1098\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: -7.3706 - val_accuracy: 0.1098\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: -8.4433 - val_accuracy: 0.0915\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: -7.7663 - val_accuracy: 0.1037\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: -7.9920 - val_accuracy: 0.0976\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: -9.1097 - val_accuracy: 0.0732\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: -7.9073 - val_accuracy: 0.0976\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: -8.5008 - val_accuracy: 0.0854\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: -8.2518 - val_accuracy: 0.0976\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -8.0575 - val_accuracy: 0.1037\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -7.8302 - val_accuracy: 0.1098\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: -9.3063 - val_accuracy: 0.0854\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: -8.0459 - val_accuracy: 0.1098\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: -8.8945 - val_accuracy: 0.0915\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: -8.3303 - val_accuracy: 0.1037\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: -8.7210 - val_accuracy: 0.0976\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -7.5232 - val_accuracy: 0.1159\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: -7.5581 - val_accuracy: 0.1159\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: -8.9892 - val_accuracy: 0.0915\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: -8.1594 - val_accuracy: 0.1098\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -8.0419 - val_accuracy: 0.1098\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -8.9019 - val_accuracy: 0.0976\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -8.1892 - val_accuracy: 0.1098\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -8.2577 - val_accuracy: 0.1098\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -7.9934 - val_accuracy: 0.1098\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.8701 - val_accuracy: 0.1037\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -8.4716 - val_accuracy: 0.1098\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.7094 - val_accuracy: 0.1037\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: -6.9903 - val_accuracy: 0.1280\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 0.9961 - val_loss: -6.2252 - val_accuracy: 0.1280\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: -8.3558 - val_accuracy: 0.1098\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: -9.1000 - val_accuracy: 0.0732\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9961 - val_loss: -6.1682 - val_accuracy: 0.1280\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9785 - val_loss: -8.5321 - val_accuracy: 0.0854\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2208 - accuracy: 0.9375 - val_loss: -6.2282 - val_accuracy: 0.1463\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2950 - accuracy: 0.8984 - val_loss: -0.7669 - val_accuracy: 0.1585\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1376 - accuracy: 0.9570 - val_loss: -5.3479 - val_accuracy: 0.1220\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9746 - val_loss: -5.4589 - val_accuracy: 0.0976\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9902 - val_loss: -5.1549 - val_accuracy: 0.1098\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: -5.1796 - val_accuracy: 0.1098\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: -6.4848 - val_accuracy: 0.0854\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: -5.7533 - val_accuracy: 0.1037\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: -6.3674 - val_accuracy: 0.1159\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: -5.7018 - val_accuracy: 0.1159\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: -6.3711 - val_accuracy: 0.1037\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: -7.0559 - val_accuracy: 0.0854\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: -5.6978 - val_accuracy: 0.1220\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -5.7706 - val_accuracy: 0.1098\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: -6.3497 - val_accuracy: 0.1098\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: -6.2996 - val_accuracy: 0.1098\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -6.8929 - val_accuracy: 0.1037\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -6.1597 - val_accuracy: 0.1098\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -6.3829 - val_accuracy: 0.1098\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -6.5263 - val_accuracy: 0.1098\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -6.5653 - val_accuracy: 0.1098\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: -6.7692 - val_accuracy: 0.1098\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -6.7924 - val_accuracy: 0.1098\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -6.9838 - val_accuracy: 0.1098\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -6.6138 - val_accuracy: 0.1098\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -7.0758 - val_accuracy: 0.1098\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -6.6555 - val_accuracy: 0.1159\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.2316 - val_accuracy: 0.1037\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -6.9527 - val_accuracy: 0.1098\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.1171 - val_accuracy: 0.1098\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -6.6203 - val_accuracy: 0.1098\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.4698 - val_accuracy: 0.1037\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -6.8004 - val_accuracy: 0.1098\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.4506 - val_accuracy: 0.1098\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.2938 - val_accuracy: 0.1098\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -7.1645 - val_accuracy: 0.1098\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.3233 - val_accuracy: 0.1098\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 22ms/step - loss: 0.6851 - accuracy: 0.5625 - val_loss: 0.5637 - val_accuracy: 0.0976\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.6895 - val_loss: 0.6644 - val_accuracy: 0.1463\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6050 - accuracy: 0.7148 - val_loss: 0.4958 - val_accuracy: 0.1463\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5596 - accuracy: 0.7344 - val_loss: 0.7663 - val_accuracy: 0.1890\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5200 - accuracy: 0.7266 - val_loss: 0.2015 - val_accuracy: 0.1707\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4804 - accuracy: 0.7832 - val_loss: -0.4516 - val_accuracy: 0.1341\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7852 - val_loss: -0.3869 - val_accuracy: 0.1524\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8203 - val_loss: -0.6230 - val_accuracy: 0.1463\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4273 - accuracy: 0.8125 - val_loss: -0.8644 - val_accuracy: 0.1402\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.8047 - val_loss: -0.4235 - val_accuracy: 0.1646\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8418 - val_loss: -0.6862 - val_accuracy: 0.1585\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3924 - accuracy: 0.8438 - val_loss: -1.1895 - val_accuracy: 0.1220\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3834 - accuracy: 0.8379 - val_loss: -0.3849 - val_accuracy: 0.1829\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3691 - accuracy: 0.8398 - val_loss: -1.6939 - val_accuracy: 0.0854\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.7988 - val_loss: 0.1854 - val_accuracy: 0.1951\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8184 - val_loss: -0.9707 - val_accuracy: 0.1585\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3794 - accuracy: 0.8418 - val_loss: -2.0197 - val_accuracy: 0.0732\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3638 - accuracy: 0.8438 - val_loss: -1.6574 - val_accuracy: 0.1037\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.8516 - val_loss: -1.0516 - val_accuracy: 0.1707\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3406 - accuracy: 0.8633 - val_loss: -1.6554 - val_accuracy: 0.1341\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3275 - accuracy: 0.8691 - val_loss: -1.6565 - val_accuracy: 0.1220\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3100 - accuracy: 0.8848 - val_loss: -2.2282 - val_accuracy: 0.0915\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3127 - accuracy: 0.8535 - val_loss: -1.9042 - val_accuracy: 0.1463\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3130 - accuracy: 0.8691 - val_loss: -1.4640 - val_accuracy: 0.1585\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3094 - accuracy: 0.8574 - val_loss: -1.8301 - val_accuracy: 0.1402\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2774 - accuracy: 0.8887 - val_loss: -1.4623 - val_accuracy: 0.1585\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2586 - accuracy: 0.8984 - val_loss: -2.6144 - val_accuracy: 0.0854\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2518 - accuracy: 0.9043 - val_loss: -2.0227 - val_accuracy: 0.1402\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2607 - accuracy: 0.9004 - val_loss: -1.8363 - val_accuracy: 0.1463\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.2565 - accuracy: 0.8945 - val_loss: -2.1113 - val_accuracy: 0.1463\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2494 - accuracy: 0.9004 - val_loss: -2.2390 - val_accuracy: 0.1463\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.2482 - accuracy: 0.9062 - val_loss: -2.2534 - val_accuracy: 0.1280\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: -2.5436 - val_accuracy: 0.1280\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2196 - accuracy: 0.9141 - val_loss: -3.2911 - val_accuracy: 0.0854\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2398 - accuracy: 0.9004 - val_loss: -3.0764 - val_accuracy: 0.0915\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1925 - accuracy: 0.9277 - val_loss: -2.7977 - val_accuracy: 0.1280\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1994 - accuracy: 0.9219 - val_loss: -2.6451 - val_accuracy: 0.1280\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2076 - accuracy: 0.9180 - val_loss: -2.0565 - val_accuracy: 0.1707\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1876 - accuracy: 0.9336 - val_loss: -3.0049 - val_accuracy: 0.1098\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2117 - accuracy: 0.9160 - val_loss: -3.6919 - val_accuracy: 0.0549\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2002 - accuracy: 0.9258 - val_loss: -2.8130 - val_accuracy: 0.1280\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1934 - accuracy: 0.9277 - val_loss: -3.6716 - val_accuracy: 0.0976\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1696 - accuracy: 0.9414 - val_loss: -2.1795 - val_accuracy: 0.1463\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2123 - accuracy: 0.9102 - val_loss: -4.0455 - val_accuracy: 0.0915\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2017 - accuracy: 0.9160 - val_loss: -2.3989 - val_accuracy: 0.1585\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2883 - accuracy: 0.8691 - val_loss: -2.6279 - val_accuracy: 0.1220\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2527 - accuracy: 0.8906 - val_loss: -4.0560 - val_accuracy: 0.0610\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2170 - accuracy: 0.9199 - val_loss: -2.6954 - val_accuracy: 0.1646\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1996 - accuracy: 0.9180 - val_loss: -2.9165 - val_accuracy: 0.1402\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1613 - accuracy: 0.9453 - val_loss: -3.3372 - val_accuracy: 0.1159\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1327 - accuracy: 0.9570 - val_loss: -3.7815 - val_accuracy: 0.1037\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1226 - accuracy: 0.9629 - val_loss: -3.9351 - val_accuracy: 0.1098\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1326 - accuracy: 0.9492 - val_loss: -4.3214 - val_accuracy: 0.0671\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1191 - accuracy: 0.9570 - val_loss: -3.9129 - val_accuracy: 0.1220\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.9590 - val_loss: -4.2887 - val_accuracy: 0.1098\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1004 - accuracy: 0.9746 - val_loss: -3.3491 - val_accuracy: 0.1341\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1001 - accuracy: 0.9629 - val_loss: -4.6610 - val_accuracy: 0.0976\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1010 - accuracy: 0.9707 - val_loss: -4.6130 - val_accuracy: 0.1098\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1077 - accuracy: 0.9629 - val_loss: -4.0625 - val_accuracy: 0.1341\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1149 - accuracy: 0.9551 - val_loss: -4.7345 - val_accuracy: 0.0793\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0969 - accuracy: 0.9707 - val_loss: -4.8442 - val_accuracy: 0.0732\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1035 - accuracy: 0.9688 - val_loss: -4.5503 - val_accuracy: 0.0793\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1191 - accuracy: 0.9512 - val_loss: -5.2222 - val_accuracy: 0.0549\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0942 - accuracy: 0.9688 - val_loss: -5.2923 - val_accuracy: 0.0915\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.9473 - val_loss: -4.4043 - val_accuracy: 0.1220\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0937 - accuracy: 0.9727 - val_loss: -5.3537 - val_accuracy: 0.0793\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0969 - accuracy: 0.9688 - val_loss: -4.8338 - val_accuracy: 0.1159\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9668 - val_loss: -5.7278 - val_accuracy: 0.0549\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.9824 - val_loss: -5.0427 - val_accuracy: 0.0976\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9824 - val_loss: -5.0628 - val_accuracy: 0.1098\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0539 - accuracy: 0.9883 - val_loss: -5.6114 - val_accuracy: 0.0610\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0637 - accuracy: 0.9805 - val_loss: -5.4944 - val_accuracy: 0.0976\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9863 - val_loss: -5.4230 - val_accuracy: 0.0976\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: -4.8399 - val_accuracy: 0.1159\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0810 - accuracy: 0.9766 - val_loss: -5.5246 - val_accuracy: 0.0915\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1088 - accuracy: 0.9531 - val_loss: -5.5615 - val_accuracy: 0.1098\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1271 - accuracy: 0.9512 - val_loss: -5.5732 - val_accuracy: 0.1037\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0860 - accuracy: 0.9766 - val_loss: -6.6456 - val_accuracy: 0.0671\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0564 - accuracy: 0.9844 - val_loss: -5.1960 - val_accuracy: 0.1159\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0502 - accuracy: 0.9863 - val_loss: -6.9276 - val_accuracy: 0.0671\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 0.9922 - val_loss: -6.1828 - val_accuracy: 0.1098\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9922 - val_loss: -5.4229 - val_accuracy: 0.1280\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 0.9961 - val_loss: -6.3657 - val_accuracy: 0.1037\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9941 - val_loss: -7.4874 - val_accuracy: 0.0549\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0385 - accuracy: 0.9902 - val_loss: -6.3878 - val_accuracy: 0.1220\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0490 - accuracy: 0.9805 - val_loss: -7.5278 - val_accuracy: 0.0793\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0588 - accuracy: 0.9785 - val_loss: -6.2708 - val_accuracy: 0.1098\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9922 - val_loss: -6.0511 - val_accuracy: 0.0732\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0335 - accuracy: 0.9922 - val_loss: -6.2026 - val_accuracy: 0.0976\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0363 - accuracy: 0.9922 - val_loss: -6.7922 - val_accuracy: 0.0793\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0322 - accuracy: 0.9941 - val_loss: -8.0805 - val_accuracy: 0.0488\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9941 - val_loss: -5.8168 - val_accuracy: 0.1159\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: -8.1020 - val_accuracy: 0.0915\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0334 - accuracy: 0.9941 - val_loss: -6.4470 - val_accuracy: 0.1280\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9961 - val_loss: -8.0180 - val_accuracy: 0.0427\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: -8.4216 - val_accuracy: 0.0488\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0663 - accuracy: 0.9727 - val_loss: -8.5526 - val_accuracy: 0.0854\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9766 - val_loss: -5.9171 - val_accuracy: 0.0915\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0499 - accuracy: 0.9883 - val_loss: -7.3060 - val_accuracy: 0.0610\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: -5.9833 - val_accuracy: 0.1220\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9922 - val_loss: -7.4940 - val_accuracy: 0.0976\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 0.9941 - val_loss: -7.6652 - val_accuracy: 0.0793\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: -7.7698 - val_accuracy: 0.0915\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: -7.6320 - val_accuracy: 0.0854\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: -7.9794 - val_accuracy: 0.0915\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: -7.1894 - val_accuracy: 0.1159\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9980 - val_loss: -7.6915 - val_accuracy: 0.0793\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: -7.8494 - val_accuracy: 0.1159\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: -8.0129 - val_accuracy: 0.0793\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: -8.7272 - val_accuracy: 0.0610\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: -8.7875 - val_accuracy: 0.0610\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: -8.4049 - val_accuracy: 0.0854\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -8.7606 - val_accuracy: 0.0610\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -9.0469 - val_accuracy: 0.0610\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -8.7801 - val_accuracy: 0.0732\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -8.8328 - val_accuracy: 0.0610\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -9.3857 - val_accuracy: 0.0610\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -9.1821 - val_accuracy: 0.0671\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: -9.0113 - val_accuracy: 0.0793\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: -9.7912 - val_accuracy: 0.0610\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: -9.4690 - val_accuracy: 0.0671\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -9.2731 - val_accuracy: 0.0610\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -9.4420 - val_accuracy: 0.0549\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -8.2809 - val_accuracy: 0.1220\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -9.6869 - val_accuracy: 0.0610\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -9.8586 - val_accuracy: 0.0610\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -9.2985 - val_accuracy: 0.0671\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -9.0125 - val_accuracy: 0.0976\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -9.3528 - val_accuracy: 0.0671\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -9.3452 - val_accuracy: 0.0671\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.1074 - val_accuracy: 0.1037\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -9.7265 - val_accuracy: 0.0610\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.5028 - val_accuracy: 0.0610\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.4625 - val_accuracy: 0.0732\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.5884 - val_accuracy: 0.0610\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.5985 - val_accuracy: 0.0671\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.7099 - val_accuracy: 0.0610\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.6698 - val_accuracy: 0.0610\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.8795 - val_accuracy: 0.0610\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.5102 - val_accuracy: 0.0976\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.0808 - val_accuracy: 0.0610\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.7831 - val_accuracy: 0.0671\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.6477 - val_accuracy: 0.0976\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -9.9337 - val_accuracy: 0.0610\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -9.9081 - val_accuracy: 0.0671\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.7628 - val_accuracy: 0.0854\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.8928 - val_accuracy: 0.0732\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.2693 - val_accuracy: 0.0610\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.8409 - val_accuracy: 0.0915\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.1035 - val_accuracy: 0.0671\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.9950 - val_accuracy: 0.0671\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.4049 - val_accuracy: 0.0610\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.0063 - val_accuracy: 0.0854\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.8320 - val_accuracy: 0.1037\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.3045 - val_accuracy: 0.0671\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.3257e-04 - accuracy: 1.0000 - val_loss: -10.0727 - val_accuracy: 0.0793\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 9.2083e-04 - accuracy: 1.0000 - val_loss: -10.2833 - val_accuracy: 0.0671\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.0617e-04 - accuracy: 1.0000 - val_loss: -10.1749 - val_accuracy: 0.0732\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.8979e-04 - accuracy: 1.0000 - val_loss: -10.3689 - val_accuracy: 0.0610\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8.9486e-04 - accuracy: 1.0000 - val_loss: -10.4558 - val_accuracy: 0.0671\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.0310e-04 - accuracy: 1.0000 - val_loss: -10.2956 - val_accuracy: 0.0732\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 8.5873e-04 - accuracy: 1.0000 - val_loss: -10.1335 - val_accuracy: 0.0915\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8.4181e-04 - accuracy: 1.0000 - val_loss: -10.3307 - val_accuracy: 0.0732\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.8338e-04 - accuracy: 1.0000 - val_loss: -10.2723 - val_accuracy: 0.0915\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.0036e-04 - accuracy: 1.0000 - val_loss: -10.4538 - val_accuracy: 0.0671\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7.7469e-04 - accuracy: 1.0000 - val_loss: -10.6756 - val_accuracy: 0.0610\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.9494e-04 - accuracy: 1.0000 - val_loss: -10.2788 - val_accuracy: 0.0976\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.6213e-04 - accuracy: 1.0000 - val_loss: -10.4642 - val_accuracy: 0.0732\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7.3636e-04 - accuracy: 1.0000 - val_loss: -10.6330 - val_accuracy: 0.0610\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.0555e-04 - accuracy: 1.0000 - val_loss: -10.5797 - val_accuracy: 0.0671\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.8938e-04 - accuracy: 1.0000 - val_loss: -10.5499 - val_accuracy: 0.0732\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 6.8874e-04 - accuracy: 1.0000 - val_loss: -10.5344 - val_accuracy: 0.0671\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6.5260e-04 - accuracy: 1.0000 - val_loss: -10.5261 - val_accuracy: 0.0732\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.4032e-04 - accuracy: 1.0000 - val_loss: -10.7801 - val_accuracy: 0.0671\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6.3352e-04 - accuracy: 1.0000 - val_loss: -10.5094 - val_accuracy: 0.0854\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.7692e-04 - accuracy: 1.0000 - val_loss: -10.7803 - val_accuracy: 0.0671\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.5078e-04 - accuracy: 1.0000 - val_loss: -10.7375 - val_accuracy: 0.0732\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.4487e-04 - accuracy: 1.0000 - val_loss: -10.4812 - val_accuracy: 0.1037\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.1702e-04 - accuracy: 1.0000 - val_loss: -10.8445 - val_accuracy: 0.0671\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.7807e-04 - accuracy: 1.0000 - val_loss: -10.6416 - val_accuracy: 0.0915\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.7286e-04 - accuracy: 1.0000 - val_loss: -10.7548 - val_accuracy: 0.0793\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.5007e-04 - accuracy: 1.0000 - val_loss: -10.8408 - val_accuracy: 0.0671\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.5426e-04 - accuracy: 1.0000 - val_loss: -10.8677 - val_accuracy: 0.0671\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.2314e-04 - accuracy: 1.0000 - val_loss: -10.8259 - val_accuracy: 0.0732\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.4039e-04 - accuracy: 1.0000 - val_loss: -10.9770 - val_accuracy: 0.0671\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.1758e-04 - accuracy: 1.0000 - val_loss: -10.7354 - val_accuracy: 0.0976\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.6356e-04 - accuracy: 1.0000 - val_loss: -10.8149 - val_accuracy: 0.0793\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.2996e-04 - accuracy: 1.0000 - val_loss: -11.0000 - val_accuracy: 0.0671\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.8811e-04 - accuracy: 1.0000 - val_loss: -10.9176 - val_accuracy: 0.0732\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.9121e-04 - accuracy: 1.0000 - val_loss: -10.8747 - val_accuracy: 0.0732\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9110e-04 - accuracy: 1.0000 - val_loss: -11.0969 - val_accuracy: 0.0671\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7061e-04 - accuracy: 1.0000 - val_loss: -10.9080 - val_accuracy: 0.0793\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6691e-04 - accuracy: 1.0000 - val_loss: -11.0768 - val_accuracy: 0.0671\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.6775e-04 - accuracy: 1.0000 - val_loss: -11.0225 - val_accuracy: 0.0732\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.4275e-04 - accuracy: 1.0000 - val_loss: -11.1133 - val_accuracy: 0.0732\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.4453e-04 - accuracy: 1.0000 - val_loss: -10.9824 - val_accuracy: 0.0915\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 4.3263e-04 - accuracy: 1.0000 - val_loss: -11.1476 - val_accuracy: 0.0671\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.2138e-04 - accuracy: 1.0000 - val_loss: -11.0676 - val_accuracy: 0.0793\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.1360e-04 - accuracy: 1.0000 - val_loss: -11.1418 - val_accuracy: 0.0732\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4.1477e-04 - accuracy: 1.0000 - val_loss: -11.0973 - val_accuracy: 0.0732\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.1575e-04 - accuracy: 1.0000 - val_loss: -11.2275 - val_accuracy: 0.0671\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3.9768e-04 - accuracy: 1.0000 - val_loss: -11.2595 - val_accuracy: 0.0671\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.9034e-04 - accuracy: 1.0000 - val_loss: -11.1781 - val_accuracy: 0.0793\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.7964e-04 - accuracy: 1.0000 - val_loss: -11.3347 - val_accuracy: 0.0671\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.8766e-04 - accuracy: 1.0000 - val_loss: -10.9958 - val_accuracy: 0.1037\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.9337e-04 - accuracy: 1.0000 - val_loss: -11.4790 - val_accuracy: 0.0671\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 3.8734e-04 - accuracy: 1.0000 - val_loss: -11.2678 - val_accuracy: 0.0793\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.7267e-04 - accuracy: 1.0000 - val_loss: -11.2473 - val_accuracy: 0.0793\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.5674e-04 - accuracy: 1.0000 - val_loss: -11.3766 - val_accuracy: 0.0732\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.4764e-04 - accuracy: 1.0000 - val_loss: -11.2048 - val_accuracy: 0.0854\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.5471e-04 - accuracy: 1.0000 - val_loss: -11.5629 - val_accuracy: 0.0671\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.3879e-04 - accuracy: 1.0000 - val_loss: -11.1697 - val_accuracy: 0.0976\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.6618e-04 - accuracy: 1.0000 - val_loss: -11.6420 - val_accuracy: 0.0671\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.2594e-04 - accuracy: 1.0000 - val_loss: -11.1813 - val_accuracy: 0.0976\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.2333e-04 - accuracy: 1.0000 - val_loss: -11.5553 - val_accuracy: 0.0671\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.2055e-04 - accuracy: 1.0000 - val_loss: -11.4394 - val_accuracy: 0.0793\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.1443e-04 - accuracy: 1.0000 - val_loss: -11.4780 - val_accuracy: 0.0732\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.1062e-04 - accuracy: 1.0000 - val_loss: -11.3982 - val_accuracy: 0.0793\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3.0901e-04 - accuracy: 1.0000 - val_loss: -11.3913 - val_accuracy: 0.0793\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.0133e-04 - accuracy: 1.0000 - val_loss: -11.6478 - val_accuracy: 0.0671\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.1659e-04 - accuracy: 1.0000 - val_loss: -11.3280 - val_accuracy: 0.1037\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.9645e-04 - accuracy: 1.0000 - val_loss: -11.6017 - val_accuracy: 0.0732\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.9462e-04 - accuracy: 1.0000 - val_loss: -11.5637 - val_accuracy: 0.0793\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2.8148e-04 - accuracy: 1.0000 - val_loss: -11.5742 - val_accuracy: 0.0793\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.7784e-04 - accuracy: 1.0000 - val_loss: -11.5260 - val_accuracy: 0.0793\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.7393e-04 - accuracy: 1.0000 - val_loss: -11.6012 - val_accuracy: 0.0793\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.7312e-04 - accuracy: 1.0000 - val_loss: -11.5333 - val_accuracy: 0.0793\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.6915e-04 - accuracy: 1.0000 - val_loss: -11.6558 - val_accuracy: 0.0793\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.7267e-04 - accuracy: 1.0000 - val_loss: -11.5493 - val_accuracy: 0.0793\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.6502e-04 - accuracy: 1.0000 - val_loss: -11.6576 - val_accuracy: 0.0793\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5108e-04 - accuracy: 1.0000 - val_loss: -11.7957 - val_accuracy: 0.0732\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.5224e-04 - accuracy: 1.0000 - val_loss: -11.7054 - val_accuracy: 0.0793\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5278e-04 - accuracy: 1.0000 - val_loss: -11.8236 - val_accuracy: 0.0732\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.4357e-04 - accuracy: 1.0000 - val_loss: -11.6788 - val_accuracy: 0.0854\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.3867e-04 - accuracy: 1.0000 - val_loss: -11.6677 - val_accuracy: 0.0793\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.3809e-04 - accuracy: 1.0000 - val_loss: -11.7910 - val_accuracy: 0.0793\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2943e-04 - accuracy: 1.0000 - val_loss: -11.7822 - val_accuracy: 0.0793\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2761e-04 - accuracy: 1.0000 - val_loss: -11.8437 - val_accuracy: 0.0732\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2638e-04 - accuracy: 1.0000 - val_loss: -11.6791 - val_accuracy: 0.0915\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2375e-04 - accuracy: 1.0000 - val_loss: -11.9050 - val_accuracy: 0.0732\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.1857e-04 - accuracy: 1.0000 - val_loss: -11.8270 - val_accuracy: 0.0793\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2007e-04 - accuracy: 1.0000 - val_loss: -11.8813 - val_accuracy: 0.0793\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.3072e-04 - accuracy: 1.0000 - val_loss: -11.6858 - val_accuracy: 0.0915\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.1311e-04 - accuracy: 1.0000 - val_loss: -11.9395 - val_accuracy: 0.0732\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.0767e-04 - accuracy: 1.0000 - val_loss: -11.8753 - val_accuracy: 0.0793\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2.0525e-04 - accuracy: 1.0000 - val_loss: -11.9377 - val_accuracy: 0.0793\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2.1073e-04 - accuracy: 1.0000 - val_loss: -11.8031 - val_accuracy: 0.0915\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.0234e-04 - accuracy: 1.0000 - val_loss: -11.9484 - val_accuracy: 0.0854\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9905e-04 - accuracy: 1.0000 - val_loss: -11.9333 - val_accuracy: 0.0793\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.9359e-04 - accuracy: 1.0000 - val_loss: -12.0294 - val_accuracy: 0.0793\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9494e-04 - accuracy: 1.0000 - val_loss: -12.0967 - val_accuracy: 0.0732\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9242e-04 - accuracy: 1.0000 - val_loss: -12.0007 - val_accuracy: 0.0793\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8324e-04 - accuracy: 1.0000 - val_loss: -12.0001 - val_accuracy: 0.0793\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.8500e-04 - accuracy: 1.0000 - val_loss: -12.0034 - val_accuracy: 0.0793\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8404e-04 - accuracy: 1.0000 - val_loss: -12.0971 - val_accuracy: 0.0793\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.7950e-04 - accuracy: 1.0000 - val_loss: -12.0210 - val_accuracy: 0.0854\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8087e-04 - accuracy: 1.0000 - val_loss: -12.0430 - val_accuracy: 0.0854\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7536e-04 - accuracy: 1.0000 - val_loss: -12.0086 - val_accuracy: 0.0854\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7350e-04 - accuracy: 1.0000 - val_loss: -12.0965 - val_accuracy: 0.0854\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.6823e-04 - accuracy: 1.0000 - val_loss: -12.1215 - val_accuracy: 0.0793\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6919e-04 - accuracy: 1.0000 - val_loss: -12.2141 - val_accuracy: 0.0793\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6973e-04 - accuracy: 1.0000 - val_loss: -12.1212 - val_accuracy: 0.0793\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.6999e-04 - accuracy: 1.0000 - val_loss: -12.2491 - val_accuracy: 0.0793\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6502e-04 - accuracy: 1.0000 - val_loss: -12.0794 - val_accuracy: 0.0854\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.5871e-04 - accuracy: 1.0000 - val_loss: -12.1708 - val_accuracy: 0.0854\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.5797e-04 - accuracy: 1.0000 - val_loss: -12.2900 - val_accuracy: 0.0793\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5296e-04 - accuracy: 1.0000 - val_loss: -12.1925 - val_accuracy: 0.0793\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5493e-04 - accuracy: 1.0000 - val_loss: -12.3336 - val_accuracy: 0.0732\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4910e-04 - accuracy: 1.0000 - val_loss: -12.1336 - val_accuracy: 0.0854\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.4852e-04 - accuracy: 1.0000 - val_loss: -12.3170 - val_accuracy: 0.0793\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4946e-04 - accuracy: 1.0000 - val_loss: -12.3804 - val_accuracy: 0.0793\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.4904e-04 - accuracy: 1.0000 - val_loss: -12.1797 - val_accuracy: 0.0854\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5025e-04 - accuracy: 1.0000 - val_loss: -12.4092 - val_accuracy: 0.0793\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.4699e-04 - accuracy: 1.0000 - val_loss: -12.2516 - val_accuracy: 0.0854\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4068e-04 - accuracy: 1.0000 - val_loss: -12.4318 - val_accuracy: 0.0793\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.3694e-04 - accuracy: 1.0000 - val_loss: -12.2917 - val_accuracy: 0.0854\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3628e-04 - accuracy: 1.0000 - val_loss: -12.3059 - val_accuracy: 0.0793\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.3573e-04 - accuracy: 1.0000 - val_loss: -12.3807 - val_accuracy: 0.0793\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.3229e-04 - accuracy: 1.0000 - val_loss: -12.2838 - val_accuracy: 0.0854\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.2906e-04 - accuracy: 1.0000 - val_loss: -12.4558 - val_accuracy: 0.0793\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2986e-04 - accuracy: 1.0000 - val_loss: -12.3832 - val_accuracy: 0.0854\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2865e-04 - accuracy: 1.0000 - val_loss: -12.6042 - val_accuracy: 0.0793\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.2613e-04 - accuracy: 1.0000 - val_loss: -12.3346 - val_accuracy: 0.0854\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2379e-04 - accuracy: 1.0000 - val_loss: -12.5510 - val_accuracy: 0.0793\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2357e-04 - accuracy: 1.0000 - val_loss: -12.4959 - val_accuracy: 0.0793\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2280e-04 - accuracy: 1.0000 - val_loss: -12.4559 - val_accuracy: 0.0793\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2078e-04 - accuracy: 1.0000 - val_loss: -12.4474 - val_accuracy: 0.0854\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1757e-04 - accuracy: 1.0000 - val_loss: -12.5688 - val_accuracy: 0.0793\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1787e-04 - accuracy: 1.0000 - val_loss: -12.5268 - val_accuracy: 0.0793\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.1771e-04 - accuracy: 1.0000 - val_loss: -12.4610 - val_accuracy: 0.0854\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1844e-04 - accuracy: 1.0000 - val_loss: -12.5878 - val_accuracy: 0.0793\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2025e-04 - accuracy: 1.0000 - val_loss: -12.4231 - val_accuracy: 0.0854\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.1644e-04 - accuracy: 1.0000 - val_loss: -12.6814 - val_accuracy: 0.0793\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0986e-04 - accuracy: 1.0000 - val_loss: -12.6656 - val_accuracy: 0.0793\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0773e-04 - accuracy: 1.0000 - val_loss: -12.5733 - val_accuracy: 0.0854\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0615e-04 - accuracy: 1.0000 - val_loss: -12.6290 - val_accuracy: 0.0793\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0466e-04 - accuracy: 1.0000 - val_loss: -12.6817 - val_accuracy: 0.0793\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0523e-04 - accuracy: 1.0000 - val_loss: -12.5174 - val_accuracy: 0.0854\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0731e-04 - accuracy: 1.0000 - val_loss: -12.8410 - val_accuracy: 0.0793\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0586e-04 - accuracy: 1.0000 - val_loss: -12.7125 - val_accuracy: 0.0793\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 18ms/step - loss: 0.6917 - accuracy: 0.5488 - val_loss: 0.5675 - val_accuracy: 0.0915\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.6230 - val_loss: 0.4851 - val_accuracy: 0.1463\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6408 - accuracy: 0.6797 - val_loss: 0.2189 - val_accuracy: 0.0854\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.6855 - val_loss: 0.4721 - val_accuracy: 0.1524\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5946 - accuracy: 0.6836 - val_loss: 0.6688 - val_accuracy: 0.1890\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.7012 - val_loss: 0.3823 - val_accuracy: 0.1707\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5412 - accuracy: 0.7246 - val_loss: -0.1587 - val_accuracy: 0.1402\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7305 - val_loss: 0.2676 - val_accuracy: 0.1890\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5332 - accuracy: 0.7188 - val_loss: 0.3347 - val_accuracy: 0.1768\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4992 - accuracy: 0.7324 - val_loss: -0.0332 - val_accuracy: 0.1707\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4759 - accuracy: 0.7578 - val_loss: -0.4337 - val_accuracy: 0.1402\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4676 - accuracy: 0.7715 - val_loss: -0.1487 - val_accuracy: 0.1829\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4466 - accuracy: 0.7734 - val_loss: -0.7399 - val_accuracy: 0.1524\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7930 - val_loss: -1.1345 - val_accuracy: 0.0915\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4328 - accuracy: 0.7832 - val_loss: -0.2016 - val_accuracy: 0.1890\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.7930 - val_loss: -1.1384 - val_accuracy: 0.0915\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: -0.3019 - val_accuracy: 0.1829\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.7988 - val_loss: -1.7924 - val_accuracy: 0.0366\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7598 - val_loss: -1.1832 - val_accuracy: 0.1037\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4066 - accuracy: 0.7891 - val_loss: -0.8907 - val_accuracy: 0.1646\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8145 - val_loss: -1.1710 - val_accuracy: 0.1463\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3747 - accuracy: 0.8262 - val_loss: -0.9134 - val_accuracy: 0.1707\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3697 - accuracy: 0.8281 - val_loss: -1.3728 - val_accuracy: 0.1280\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8516 - val_loss: -1.4626 - val_accuracy: 0.1159\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3421 - accuracy: 0.8555 - val_loss: -1.4106 - val_accuracy: 0.1220\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3207 - accuracy: 0.8691 - val_loss: -1.7241 - val_accuracy: 0.1037\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.8652 - val_loss: -1.0962 - val_accuracy: 0.1585\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8633 - val_loss: -1.8535 - val_accuracy: 0.1037\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8535 - val_loss: -0.9947 - val_accuracy: 0.1341\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2988 - accuracy: 0.8633 - val_loss: -2.0344 - val_accuracy: 0.0732\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2953 - accuracy: 0.8594 - val_loss: -2.0603 - val_accuracy: 0.1098\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2965 - accuracy: 0.8672 - val_loss: -1.7410 - val_accuracy: 0.1159\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2795 - accuracy: 0.9062 - val_loss: -1.3691 - val_accuracy: 0.1402\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2689 - accuracy: 0.8770 - val_loss: -1.1513 - val_accuracy: 0.1341\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2440 - accuracy: 0.8965 - val_loss: -2.0675 - val_accuracy: 0.1220\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2303 - accuracy: 0.9062 - val_loss: -2.4552 - val_accuracy: 0.0854\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2208 - accuracy: 0.9082 - val_loss: -2.3165 - val_accuracy: 0.0976\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2253 - accuracy: 0.9121 - val_loss: -1.9238 - val_accuracy: 0.1341\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2154 - accuracy: 0.9082 - val_loss: -2.0366 - val_accuracy: 0.1220\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2136 - accuracy: 0.9141 - val_loss: -2.2046 - val_accuracy: 0.1098\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1933 - accuracy: 0.9258 - val_loss: -2.4293 - val_accuracy: 0.1098\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1779 - accuracy: 0.9316 - val_loss: -2.4809 - val_accuracy: 0.1098\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1784 - accuracy: 0.9336 - val_loss: -1.7258 - val_accuracy: 0.1341\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2237 - accuracy: 0.9102 - val_loss: -3.5521 - val_accuracy: 0.0549\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2211 - accuracy: 0.8965 - val_loss: -1.6563 - val_accuracy: 0.1341\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1782 - accuracy: 0.9355 - val_loss: -2.9388 - val_accuracy: 0.0854\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1766 - accuracy: 0.9355 - val_loss: -2.8179 - val_accuracy: 0.1037\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1531 - accuracy: 0.9473 - val_loss: -3.4244 - val_accuracy: 0.0793\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1530 - accuracy: 0.9512 - val_loss: -3.0455 - val_accuracy: 0.1159\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1668 - accuracy: 0.9453 - val_loss: -3.3958 - val_accuracy: 0.0854\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1768 - accuracy: 0.9297 - val_loss: -3.3612 - val_accuracy: 0.0854\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1439 - accuracy: 0.9551 - val_loss: -2.2841 - val_accuracy: 0.1402\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1336 - accuracy: 0.9395 - val_loss: -3.1465 - val_accuracy: 0.0915\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1005 - accuracy: 0.9746 - val_loss: -3.2954 - val_accuracy: 0.1159\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1195 - accuracy: 0.9551 - val_loss: -3.7098 - val_accuracy: 0.0854\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9785 - val_loss: -3.6106 - val_accuracy: 0.0976\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1016 - accuracy: 0.9551 - val_loss: -2.0942 - val_accuracy: 0.1463\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1231 - accuracy: 0.9551 - val_loss: -4.1126 - val_accuracy: 0.0793\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1011 - accuracy: 0.9688 - val_loss: -3.3429 - val_accuracy: 0.1098\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9688 - val_loss: -3.0775 - val_accuracy: 0.1280\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0917 - accuracy: 0.9688 - val_loss: -4.4437 - val_accuracy: 0.0732\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0776 - accuracy: 0.9785 - val_loss: -4.6763 - val_accuracy: 0.0671\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.9824 - val_loss: -3.2808 - val_accuracy: 0.1280\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0599 - accuracy: 0.9863 - val_loss: -3.7197 - val_accuracy: 0.1037\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9746 - val_loss: -4.3296 - val_accuracy: 0.0793\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9629 - val_loss: -3.6143 - val_accuracy: 0.1098\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0691 - accuracy: 0.9766 - val_loss: -4.6434 - val_accuracy: 0.0915\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0524 - accuracy: 0.9922 - val_loss: -4.2895 - val_accuracy: 0.0976\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9902 - val_loss: -4.4069 - val_accuracy: 0.0915\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0450 - accuracy: 0.9922 - val_loss: -5.0409 - val_accuracy: 0.0854\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9922 - val_loss: -4.1377 - val_accuracy: 0.1098\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9961 - val_loss: -3.3543 - val_accuracy: 0.1037\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1130 - accuracy: 0.9570 - val_loss: -4.3230 - val_accuracy: 0.1098\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1072 - accuracy: 0.9668 - val_loss: -3.6288 - val_accuracy: 0.1280\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9727 - val_loss: -4.1904 - val_accuracy: 0.0976\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9805 - val_loss: -5.1524 - val_accuracy: 0.0671\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9941 - val_loss: -4.8114 - val_accuracy: 0.0915\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0356 - accuracy: 0.9941 - val_loss: -3.8129 - val_accuracy: 0.1220\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9902 - val_loss: -4.2645 - val_accuracy: 0.1159\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9961 - val_loss: -5.2928 - val_accuracy: 0.0854\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9980 - val_loss: -4.9508 - val_accuracy: 0.1037\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0219 - accuracy: 0.9961 - val_loss: -5.2711 - val_accuracy: 0.0915\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9980 - val_loss: -5.9420 - val_accuracy: 0.0732\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9980 - val_loss: -4.6267 - val_accuracy: 0.1220\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: -5.5018 - val_accuracy: 0.0854\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: -5.8173 - val_accuracy: 0.0915\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: -5.5781 - val_accuracy: 0.0915\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: -5.7974 - val_accuracy: 0.0854\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: -6.4127 - val_accuracy: 0.0793\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: -5.7882 - val_accuracy: 0.0854\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: -5.7981 - val_accuracy: 0.0915\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: -6.1865 - val_accuracy: 0.0793\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: -5.7747 - val_accuracy: 0.0915\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -6.2963 - val_accuracy: 0.0854\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: -5.7856 - val_accuracy: 0.0854\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: -6.8327 - val_accuracy: 0.0793\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: -6.7398 - val_accuracy: 0.0854\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: -7.2135 - val_accuracy: 0.0671\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: -6.5341 - val_accuracy: 0.0915\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: -6.2853 - val_accuracy: 0.0793\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: -6.7224 - val_accuracy: 0.0732\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -6.1029 - val_accuracy: 0.1037\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -6.7917 - val_accuracy: 0.0793\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -6.6067 - val_accuracy: 0.0854\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -6.4501 - val_accuracy: 0.0854\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -6.4820 - val_accuracy: 0.1037\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -6.4812 - val_accuracy: 0.0915\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -6.5702 - val_accuracy: 0.0854\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -7.3999 - val_accuracy: 0.0732\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -6.9696 - val_accuracy: 0.0854\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -6.8663 - val_accuracy: 0.0854\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -7.0746 - val_accuracy: 0.0854\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -6.7088 - val_accuracy: 0.0915\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.2533 - val_accuracy: 0.0854\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -7.0562 - val_accuracy: 0.0854\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -6.7199 - val_accuracy: 0.1037\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -7.5077 - val_accuracy: 0.0793\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.1602 - val_accuracy: 0.0854\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.1665 - val_accuracy: 0.0854\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.1519 - val_accuracy: 0.0915\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.2251 - val_accuracy: 0.0854\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -6.9739 - val_accuracy: 0.0976\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -7.1640 - val_accuracy: 0.0854\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.2820 - val_accuracy: 0.0915\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.5709 - val_accuracy: 0.0854\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.2617 - val_accuracy: 0.0915\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.2275 - val_accuracy: 0.0976\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.1866 - val_accuracy: 0.0915\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.6414 - val_accuracy: 0.0854\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.5047 - val_accuracy: 0.0854\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.2906 - val_accuracy: 0.0976\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.5913 - val_accuracy: 0.0915\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.2072 - val_accuracy: 0.0976\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.5717 - val_accuracy: 0.0854\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.7356 - val_accuracy: 0.0854\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.5025 - val_accuracy: 0.0915\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.4235 - val_accuracy: 0.0976\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.7400 - val_accuracy: 0.0915\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.3941 - val_accuracy: 0.0976\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.7822 - val_accuracy: 0.0915\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.8753 - val_accuracy: 0.0854\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.8550 - val_accuracy: 0.0915\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7495 - val_accuracy: 0.0915\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.9714 - val_accuracy: 0.0854\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.7929 - val_accuracy: 0.0915\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.1322 - val_accuracy: 0.0854\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.6853 - val_accuracy: 0.0915\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -7.9434 - val_accuracy: 0.0915\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.7020e-04 - accuracy: 1.0000 - val_loss: -7.6084 - val_accuracy: 0.0915\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -7.9402 - val_accuracy: 0.0915\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.6500e-04 - accuracy: 1.0000 - val_loss: -8.0539 - val_accuracy: 0.0915\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.4678e-04 - accuracy: 1.0000 - val_loss: -7.7637 - val_accuracy: 0.0915\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.2324e-04 - accuracy: 1.0000 - val_loss: -8.0591 - val_accuracy: 0.0854\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9.3896e-04 - accuracy: 1.0000 - val_loss: -8.1586 - val_accuracy: 0.0854\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.9712e-04 - accuracy: 1.0000 - val_loss: -8.1232 - val_accuracy: 0.0915\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.4372e-04 - accuracy: 1.0000 - val_loss: -7.7903 - val_accuracy: 0.0976\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.5148e-04 - accuracy: 1.0000 - val_loss: -8.1026 - val_accuracy: 0.0915\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7.9482e-04 - accuracy: 1.0000 - val_loss: -8.1765 - val_accuracy: 0.0915\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.1608e-04 - accuracy: 1.0000 - val_loss: -7.8845 - val_accuracy: 0.0976\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.4357e-04 - accuracy: 1.0000 - val_loss: -8.2744 - val_accuracy: 0.0854\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.9412e-04 - accuracy: 1.0000 - val_loss: -7.8324 - val_accuracy: 0.0976\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.9765e-04 - accuracy: 1.0000 - val_loss: -8.4150 - val_accuracy: 0.0854\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.9738e-04 - accuracy: 1.0000 - val_loss: -8.0030 - val_accuracy: 0.0915\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.8460e-04 - accuracy: 1.0000 - val_loss: -8.3843 - val_accuracy: 0.0854\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.7600e-04 - accuracy: 1.0000 - val_loss: -8.1054 - val_accuracy: 0.0915\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.8699e-04 - accuracy: 1.0000 - val_loss: -8.4374 - val_accuracy: 0.0915\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.6286e-04 - accuracy: 1.0000 - val_loss: -8.2787 - val_accuracy: 0.0915\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.3529e-04 - accuracy: 1.0000 - val_loss: -8.2683 - val_accuracy: 0.0915\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.5986e-04 - accuracy: 1.0000 - val_loss: -8.4663 - val_accuracy: 0.0915\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.0398e-04 - accuracy: 1.0000 - val_loss: -8.3185 - val_accuracy: 0.0915\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5.9789e-04 - accuracy: 1.0000 - val_loss: -8.3440 - val_accuracy: 0.0915\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.7729e-04 - accuracy: 1.0000 - val_loss: -8.3379 - val_accuracy: 0.0915\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.8460e-04 - accuracy: 1.0000 - val_loss: -8.5590 - val_accuracy: 0.0915\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.8816e-04 - accuracy: 1.0000 - val_loss: -8.2851 - val_accuracy: 0.0915\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.8166e-04 - accuracy: 1.0000 - val_loss: -8.3242 - val_accuracy: 0.0915\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.5746e-04 - accuracy: 1.0000 - val_loss: -8.6544 - val_accuracy: 0.0915\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.5937e-04 - accuracy: 1.0000 - val_loss: -8.3327 - val_accuracy: 0.0915\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.5967e-04 - accuracy: 1.0000 - val_loss: -8.4051 - val_accuracy: 0.0915\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.1804e-04 - accuracy: 1.0000 - val_loss: -8.6371 - val_accuracy: 0.0915\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.1921e-04 - accuracy: 1.0000 - val_loss: -8.6177 - val_accuracy: 0.0915\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4.9307e-04 - accuracy: 1.0000 - val_loss: -8.3771 - val_accuracy: 0.0915\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 4.9575e-04 - accuracy: 1.0000 - val_loss: -8.5793 - val_accuracy: 0.0915\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.6171e-04 - accuracy: 1.0000 - val_loss: -8.6907 - val_accuracy: 0.0915\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.6974e-04 - accuracy: 1.0000 - val_loss: -8.5875 - val_accuracy: 0.0915\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.5393e-04 - accuracy: 1.0000 - val_loss: -8.4854 - val_accuracy: 0.0915\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.0829e-04 - accuracy: 1.0000 - val_loss: -8.8695 - val_accuracy: 0.0915\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.5830e-04 - accuracy: 1.0000 - val_loss: -8.7064 - val_accuracy: 0.0915\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.4546e-04 - accuracy: 1.0000 - val_loss: -8.6373 - val_accuracy: 0.0915\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.2970e-04 - accuracy: 1.0000 - val_loss: -8.7414 - val_accuracy: 0.0915\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.0537e-04 - accuracy: 1.0000 - val_loss: -8.6716 - val_accuracy: 0.0915\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.0683e-04 - accuracy: 1.0000 - val_loss: -8.7468 - val_accuracy: 0.0915\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.0616e-04 - accuracy: 1.0000 - val_loss: -8.7153 - val_accuracy: 0.0915\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 3.9248e-04 - accuracy: 1.0000 - val_loss: -8.8632 - val_accuracy: 0.0915\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7525e-04 - accuracy: 1.0000 - val_loss: -8.7829 - val_accuracy: 0.0915\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7072e-04 - accuracy: 1.0000 - val_loss: -8.8791 - val_accuracy: 0.0915\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3.7023e-04 - accuracy: 1.0000 - val_loss: -8.6600 - val_accuracy: 0.0915\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.9818e-04 - accuracy: 1.0000 - val_loss: -8.9810 - val_accuracy: 0.0915\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7135e-04 - accuracy: 1.0000 - val_loss: -8.9287 - val_accuracy: 0.0915\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.4572e-04 - accuracy: 1.0000 - val_loss: -8.7761 - val_accuracy: 0.0915\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.4865e-04 - accuracy: 1.0000 - val_loss: -9.0161 - val_accuracy: 0.0915\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.4495e-04 - accuracy: 1.0000 - val_loss: -8.7719 - val_accuracy: 0.0915\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.3940e-04 - accuracy: 1.0000 - val_loss: -9.0453 - val_accuracy: 0.0915\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.1963e-04 - accuracy: 1.0000 - val_loss: -8.8882 - val_accuracy: 0.0915\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.1332e-04 - accuracy: 1.0000 - val_loss: -8.9793 - val_accuracy: 0.0915\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.1299e-04 - accuracy: 1.0000 - val_loss: -9.0051 - val_accuracy: 0.0915\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.9961e-04 - accuracy: 1.0000 - val_loss: -8.9700 - val_accuracy: 0.0915\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.9924e-04 - accuracy: 1.0000 - val_loss: -9.1066 - val_accuracy: 0.0915\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2.9116e-04 - accuracy: 1.0000 - val_loss: -9.0083 - val_accuracy: 0.0915\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.8938e-04 - accuracy: 1.0000 - val_loss: -9.0783 - val_accuracy: 0.0915\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.9794e-04 - accuracy: 1.0000 - val_loss: -8.9437 - val_accuracy: 0.0915\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.9795e-04 - accuracy: 1.0000 - val_loss: -9.2977 - val_accuracy: 0.0915\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.8974e-04 - accuracy: 1.0000 - val_loss: -8.9379 - val_accuracy: 0.0915\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.7357e-04 - accuracy: 1.0000 - val_loss: -9.1815 - val_accuracy: 0.0915\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.7249e-04 - accuracy: 1.0000 - val_loss: -9.1529 - val_accuracy: 0.0915\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.6874e-04 - accuracy: 1.0000 - val_loss: -9.1470 - val_accuracy: 0.0915\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.7000e-04 - accuracy: 1.0000 - val_loss: -9.0900 - val_accuracy: 0.0915\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.5889e-04 - accuracy: 1.0000 - val_loss: -9.1983 - val_accuracy: 0.0915\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.5181e-04 - accuracy: 1.0000 - val_loss: -9.2985 - val_accuracy: 0.0915\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.4345e-04 - accuracy: 1.0000 - val_loss: -9.2019 - val_accuracy: 0.0915\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.4395e-04 - accuracy: 1.0000 - val_loss: -9.1652 - val_accuracy: 0.0915\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.3320e-04 - accuracy: 1.0000 - val_loss: -9.2389 - val_accuracy: 0.0915\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.3640e-04 - accuracy: 1.0000 - val_loss: -9.2127 - val_accuracy: 0.0915\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.3469e-04 - accuracy: 1.0000 - val_loss: -9.2118 - val_accuracy: 0.0915\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2578e-04 - accuracy: 1.0000 - val_loss: -9.2848 - val_accuracy: 0.0915\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2240e-04 - accuracy: 1.0000 - val_loss: -9.2375 - val_accuracy: 0.0915\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1432e-04 - accuracy: 1.0000 - val_loss: -9.3214 - val_accuracy: 0.0915\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2.0967e-04 - accuracy: 1.0000 - val_loss: -9.2208 - val_accuracy: 0.0915\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1685e-04 - accuracy: 1.0000 - val_loss: -9.4910 - val_accuracy: 0.0915\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1769e-04 - accuracy: 1.0000 - val_loss: -9.1970 - val_accuracy: 0.0915\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.0611e-04 - accuracy: 1.0000 - val_loss: -9.5225 - val_accuracy: 0.0915\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9971e-04 - accuracy: 1.0000 - val_loss: -9.3188 - val_accuracy: 0.0915\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2.0188e-04 - accuracy: 1.0000 - val_loss: -9.4744 - val_accuracy: 0.0915\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9493e-04 - accuracy: 1.0000 - val_loss: -9.3324 - val_accuracy: 0.0915\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.0471e-04 - accuracy: 1.0000 - val_loss: -9.5398 - val_accuracy: 0.0915\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9192e-04 - accuracy: 1.0000 - val_loss: -9.4925 - val_accuracy: 0.0915\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8753e-04 - accuracy: 1.0000 - val_loss: -9.5496 - val_accuracy: 0.0915\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7716e-04 - accuracy: 1.0000 - val_loss: -9.4345 - val_accuracy: 0.0915\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7657e-04 - accuracy: 1.0000 - val_loss: -9.4444 - val_accuracy: 0.0915\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7251e-04 - accuracy: 1.0000 - val_loss: -9.4845 - val_accuracy: 0.0915\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.7117e-04 - accuracy: 1.0000 - val_loss: -9.4587 - val_accuracy: 0.0915\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6897e-04 - accuracy: 1.0000 - val_loss: -9.5385 - val_accuracy: 0.0915\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7090e-04 - accuracy: 1.0000 - val_loss: -9.6848 - val_accuracy: 0.0915\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6473e-04 - accuracy: 1.0000 - val_loss: -9.4391 - val_accuracy: 0.0915\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6475e-04 - accuracy: 1.0000 - val_loss: -9.6320 - val_accuracy: 0.0915\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.6068e-04 - accuracy: 1.0000 - val_loss: -9.6390 - val_accuracy: 0.0915\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6005e-04 - accuracy: 1.0000 - val_loss: -9.5431 - val_accuracy: 0.0915\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.5364e-04 - accuracy: 1.0000 - val_loss: -9.6505 - val_accuracy: 0.0915\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5507e-04 - accuracy: 1.0000 - val_loss: -9.6482 - val_accuracy: 0.0915\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5071e-04 - accuracy: 1.0000 - val_loss: -9.6041 - val_accuracy: 0.0915\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.4862e-04 - accuracy: 1.0000 - val_loss: -9.7687 - val_accuracy: 0.0915\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.4710e-04 - accuracy: 1.0000 - val_loss: -9.6867 - val_accuracy: 0.0915\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4907e-04 - accuracy: 1.0000 - val_loss: -9.6722 - val_accuracy: 0.0915\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4012e-04 - accuracy: 1.0000 - val_loss: -9.7280 - val_accuracy: 0.0915\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3753e-04 - accuracy: 1.0000 - val_loss: -9.7352 - val_accuracy: 0.0915\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3862e-04 - accuracy: 1.0000 - val_loss: -9.7976 - val_accuracy: 0.0915\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3684e-04 - accuracy: 1.0000 - val_loss: -9.7230 - val_accuracy: 0.0915\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3229e-04 - accuracy: 1.0000 - val_loss: -9.7920 - val_accuracy: 0.0915\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.3084e-04 - accuracy: 1.0000 - val_loss: -9.8459 - val_accuracy: 0.0915\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2806e-04 - accuracy: 1.0000 - val_loss: -9.7815 - val_accuracy: 0.0915\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2843e-04 - accuracy: 1.0000 - val_loss: -9.8469 - val_accuracy: 0.0915\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2846e-04 - accuracy: 1.0000 - val_loss: -9.7986 - val_accuracy: 0.0915\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2481e-04 - accuracy: 1.0000 - val_loss: -9.8052 - val_accuracy: 0.0915\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2514e-04 - accuracy: 1.0000 - val_loss: -9.8513 - val_accuracy: 0.0915\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1969e-04 - accuracy: 1.0000 - val_loss: -9.8660 - val_accuracy: 0.0915\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.1759e-04 - accuracy: 1.0000 - val_loss: -9.8819 - val_accuracy: 0.0915\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1820e-04 - accuracy: 1.0000 - val_loss: -9.8383 - val_accuracy: 0.0915\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1431e-04 - accuracy: 1.0000 - val_loss: -9.9150 - val_accuracy: 0.0915\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1334e-04 - accuracy: 1.0000 - val_loss: -10.0030 - val_accuracy: 0.0915\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1147e-04 - accuracy: 1.0000 - val_loss: -9.9174 - val_accuracy: 0.0915\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1090e-04 - accuracy: 1.0000 - val_loss: -9.9107 - val_accuracy: 0.0915\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1316e-04 - accuracy: 1.0000 - val_loss: -9.9060 - val_accuracy: 0.0915\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0621e-04 - accuracy: 1.0000 - val_loss: -10.0042 - val_accuracy: 0.0915\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0609e-04 - accuracy: 1.0000 - val_loss: -9.9604 - val_accuracy: 0.0915\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0296e-04 - accuracy: 1.0000 - val_loss: -10.0270 - val_accuracy: 0.0915\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.0192e-04 - accuracy: 1.0000 - val_loss: -9.9618 - val_accuracy: 0.0915\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0088e-04 - accuracy: 1.0000 - val_loss: -10.0699 - val_accuracy: 0.0915\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0056e-04 - accuracy: 1.0000 - val_loss: -10.0116 - val_accuracy: 0.0915\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.7337e-05 - accuracy: 1.0000 - val_loss: -9.9944 - val_accuracy: 0.0915\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 9.6211e-05 - accuracy: 1.0000 - val_loss: -10.1056 - val_accuracy: 0.0915\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9.4934e-05 - accuracy: 1.0000 - val_loss: -10.1066 - val_accuracy: 0.0915\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.5964e-05 - accuracy: 1.0000 - val_loss: -10.0957 - val_accuracy: 0.0915\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 9.1311e-05 - accuracy: 1.0000 - val_loss: -10.0438 - val_accuracy: 0.0915\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.0762e-05 - accuracy: 1.0000 - val_loss: -10.1638 - val_accuracy: 0.0915\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.0282e-05 - accuracy: 1.0000 - val_loss: -10.1767 - val_accuracy: 0.0915\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 9.0188e-05 - accuracy: 1.0000 - val_loss: -10.1232 - val_accuracy: 0.0915\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.6298e-05 - accuracy: 1.0000 - val_loss: -10.2289 - val_accuracy: 0.0915\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8.5516e-05 - accuracy: 1.0000 - val_loss: -10.1281 - val_accuracy: 0.0915\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.4814e-05 - accuracy: 1.0000 - val_loss: -10.1935 - val_accuracy: 0.0915\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 8.5767e-05 - accuracy: 1.0000 - val_loss: -10.2511 - val_accuracy: 0.0915\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 8.4814e-05 - accuracy: 1.0000 - val_loss: -10.1215 - val_accuracy: 0.0915\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 8.1213e-05 - accuracy: 1.0000 - val_loss: -10.2745 - val_accuracy: 0.0915\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8.1011e-05 - accuracy: 1.0000 - val_loss: -10.2395 - val_accuracy: 0.0915\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.8768e-05 - accuracy: 1.0000 - val_loss: -10.2539 - val_accuracy: 0.0915\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.8158e-05 - accuracy: 1.0000 - val_loss: -10.2341 - val_accuracy: 0.0915\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.7826e-05 - accuracy: 1.0000 - val_loss: -10.2460 - val_accuracy: 0.0915\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.5940e-05 - accuracy: 1.0000 - val_loss: -10.3557 - val_accuracy: 0.0915\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.5847e-05 - accuracy: 1.0000 - val_loss: -10.3420 - val_accuracy: 0.0915\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.3694e-05 - accuracy: 1.0000 - val_loss: -10.2872 - val_accuracy: 0.0915\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.3136e-05 - accuracy: 1.0000 - val_loss: -10.3416 - val_accuracy: 0.0915\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.2017e-05 - accuracy: 1.0000 - val_loss: -10.3425 - val_accuracy: 0.0915\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 2s 18ms/step - loss: 0.6884 - accuracy: 0.5488 - val_loss: 0.4058 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6660 - accuracy: 0.6289 - val_loss: 0.3752 - val_accuracy: 0.0793\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.6504 - val_loss: 0.5828 - val_accuracy: 0.1707\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6044 - accuracy: 0.6973 - val_loss: 0.3742 - val_accuracy: 0.1585\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5673 - accuracy: 0.7207 - val_loss: -0.0794 - val_accuracy: 0.1341\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5463 - accuracy: 0.7129 - val_loss: 0.0322 - val_accuracy: 0.1768\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.7363 - val_loss: 0.1280 - val_accuracy: 0.1829\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4991 - accuracy: 0.7539 - val_loss: -0.7748 - val_accuracy: 0.1037\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4787 - accuracy: 0.7793 - val_loss: -0.5265 - val_accuracy: 0.1768\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4730 - accuracy: 0.7734 - val_loss: 0.0071 - val_accuracy: 0.1951\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4622 - accuracy: 0.7734 - val_loss: -1.1542 - val_accuracy: 0.1463\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: -0.8605 - val_accuracy: 0.1768\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4260 - accuracy: 0.8145 - val_loss: -0.7010 - val_accuracy: 0.1890\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.8164 - val_loss: -1.1146 - val_accuracy: 0.1646\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8301 - val_loss: -0.7631 - val_accuracy: 0.1890\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4077 - accuracy: 0.8145 - val_loss: -0.5928 - val_accuracy: 0.1951\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3998 - accuracy: 0.8320 - val_loss: -0.9345 - val_accuracy: 0.1890\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3943 - accuracy: 0.8379 - val_loss: -1.4261 - val_accuracy: 0.1524\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8340 - val_loss: -1.8059 - val_accuracy: 0.1402\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3547 - accuracy: 0.8730 - val_loss: -1.4644 - val_accuracy: 0.1646\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.8535 - val_loss: -2.3891 - val_accuracy: 0.1037\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3843 - accuracy: 0.8340 - val_loss: -0.6339 - val_accuracy: 0.1951\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.8203 - val_loss: -2.4318 - val_accuracy: 0.1098\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.8516 - val_loss: -2.0963 - val_accuracy: 0.1524\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3247 - accuracy: 0.8613 - val_loss: -2.4051 - val_accuracy: 0.1280\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3155 - accuracy: 0.8789 - val_loss: -1.8500 - val_accuracy: 0.1768\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3231 - accuracy: 0.8711 - val_loss: -3.2143 - val_accuracy: 0.1037\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8516 - val_loss: -2.6822 - val_accuracy: 0.1402\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3368 - accuracy: 0.8535 - val_loss: -2.2011 - val_accuracy: 0.1707\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3069 - accuracy: 0.8809 - val_loss: -1.3386 - val_accuracy: 0.1951\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3140 - accuracy: 0.8574 - val_loss: -1.9347 - val_accuracy: 0.1524\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2758 - accuracy: 0.8945 - val_loss: -2.3281 - val_accuracy: 0.1524\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2739 - accuracy: 0.8965 - val_loss: -3.1951 - val_accuracy: 0.1037\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2988 - accuracy: 0.8633 - val_loss: -2.4094 - val_accuracy: 0.1463\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2704 - accuracy: 0.8984 - val_loss: -3.4290 - val_accuracy: 0.1463\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3531 - accuracy: 0.8320 - val_loss: -1.5578 - val_accuracy: 0.1829\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2660 - accuracy: 0.8906 - val_loss: -3.9700 - val_accuracy: 0.0915\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2517 - accuracy: 0.9043 - val_loss: -2.9022 - val_accuracy: 0.1341\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2318 - accuracy: 0.9180 - val_loss: -3.2450 - val_accuracy: 0.1280\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2400 - accuracy: 0.9082 - val_loss: -3.0734 - val_accuracy: 0.1585\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2702 - accuracy: 0.8789 - val_loss: -3.9878 - val_accuracy: 0.1159\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2207 - accuracy: 0.9258 - val_loss: -3.0924 - val_accuracy: 0.1280\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2223 - accuracy: 0.9102 - val_loss: -4.0099 - val_accuracy: 0.1220\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1972 - accuracy: 0.9258 - val_loss: -3.9098 - val_accuracy: 0.1463\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2038 - accuracy: 0.9199 - val_loss: -4.5889 - val_accuracy: 0.1220\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1855 - accuracy: 0.9375 - val_loss: -4.1075 - val_accuracy: 0.1280\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1855 - accuracy: 0.9277 - val_loss: -4.4088 - val_accuracy: 0.1159\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1866 - accuracy: 0.9238 - val_loss: -3.7084 - val_accuracy: 0.1585\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1807 - accuracy: 0.9375 - val_loss: -4.3846 - val_accuracy: 0.1159\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1756 - accuracy: 0.9355 - val_loss: -4.0468 - val_accuracy: 0.1280\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9434 - val_loss: -4.6411 - val_accuracy: 0.1402\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1608 - accuracy: 0.9453 - val_loss: -4.2495 - val_accuracy: 0.1402\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1903 - accuracy: 0.9219 - val_loss: -4.5701 - val_accuracy: 0.1220\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.9434 - val_loss: -3.5427 - val_accuracy: 0.1585\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1684 - accuracy: 0.9492 - val_loss: -4.4255 - val_accuracy: 0.1524\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1532 - accuracy: 0.9434 - val_loss: -6.0861 - val_accuracy: 0.1098\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1371 - accuracy: 0.9609 - val_loss: -4.8481 - val_accuracy: 0.1402\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1331 - accuracy: 0.9551 - val_loss: -5.2771 - val_accuracy: 0.1280\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1224 - accuracy: 0.9629 - val_loss: -4.8138 - val_accuracy: 0.1341\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9512 - val_loss: -5.9324 - val_accuracy: 0.1280\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1369 - accuracy: 0.9492 - val_loss: -5.2154 - val_accuracy: 0.1402\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.9531 - val_loss: -3.7516 - val_accuracy: 0.1707\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1484 - accuracy: 0.9473 - val_loss: -6.0316 - val_accuracy: 0.0915\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1350 - accuracy: 0.9492 - val_loss: -5.0897 - val_accuracy: 0.1402\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1361 - accuracy: 0.9492 - val_loss: -4.3380 - val_accuracy: 0.1402\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2164 - accuracy: 0.9199 - val_loss: -8.5783 - val_accuracy: 0.0854\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2290 - accuracy: 0.8965 - val_loss: -3.3730 - val_accuracy: 0.1646\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1758 - accuracy: 0.9375 - val_loss: -5.0268 - val_accuracy: 0.1280\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1282 - accuracy: 0.9570 - val_loss: -6.7360 - val_accuracy: 0.0793\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 0.9668 - val_loss: -4.7847 - val_accuracy: 0.1463\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0909 - accuracy: 0.9785 - val_loss: -5.1648 - val_accuracy: 0.1341\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0920 - accuracy: 0.9707 - val_loss: -5.9230 - val_accuracy: 0.1341\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1069 - accuracy: 0.9648 - val_loss: -6.3051 - val_accuracy: 0.0976\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9688 - val_loss: -5.7754 - val_accuracy: 0.1341\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0992 - accuracy: 0.9688 - val_loss: -6.2397 - val_accuracy: 0.1280\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0910 - accuracy: 0.9707 - val_loss: -6.2150 - val_accuracy: 0.1037\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0901 - accuracy: 0.9746 - val_loss: -6.3454 - val_accuracy: 0.1037\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9746 - val_loss: -5.8792 - val_accuracy: 0.1280\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0726 - accuracy: 0.9805 - val_loss: -7.4647 - val_accuracy: 0.0976\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0700 - accuracy: 0.9746 - val_loss: -6.5194 - val_accuracy: 0.1402\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0801 - accuracy: 0.9688 - val_loss: -6.5710 - val_accuracy: 0.1280\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9824 - val_loss: -7.9773 - val_accuracy: 0.0793\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0919 - accuracy: 0.9707 - val_loss: -6.4704 - val_accuracy: 0.1341\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0637 - accuracy: 0.9785 - val_loss: -7.3318 - val_accuracy: 0.1159\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: -7.7876 - val_accuracy: 0.1098\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: -5.7865 - val_accuracy: 0.1341\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9707 - val_loss: -6.6476 - val_accuracy: 0.1280\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9824 - val_loss: -9.3554 - val_accuracy: 0.0793\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1089 - accuracy: 0.9570 - val_loss: -8.6879 - val_accuracy: 0.0854\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9766 - val_loss: -7.3845 - val_accuracy: 0.1037\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1013 - accuracy: 0.9707 - val_loss: -6.2250 - val_accuracy: 0.1524\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9707 - val_loss: -9.8190 - val_accuracy: 0.0732\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9707 - val_loss: -6.6544 - val_accuracy: 0.1402\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9668 - val_loss: -8.3152 - val_accuracy: 0.1159\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9727 - val_loss: -7.6996 - val_accuracy: 0.1098\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: -9.1417 - val_accuracy: 0.0854\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9746 - val_loss: -7.2668 - val_accuracy: 0.1220\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9902 - val_loss: -7.0709 - val_accuracy: 0.1280\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9922 - val_loss: -8.7591 - val_accuracy: 0.0915\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9941 - val_loss: -7.2153 - val_accuracy: 0.1463\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9863 - val_loss: -8.8494 - val_accuracy: 0.1098\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9941 - val_loss: -8.4472 - val_accuracy: 0.1037\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9941 - val_loss: -8.6534 - val_accuracy: 0.1159\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9922 - val_loss: -8.8899 - val_accuracy: 0.1159\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9883 - val_loss: -9.8214 - val_accuracy: 0.0793\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9902 - val_loss: -9.9539 - val_accuracy: 0.0854\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9922 - val_loss: -10.0157 - val_accuracy: 0.1037\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.9922 - val_loss: -7.6888 - val_accuracy: 0.1220\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9961 - val_loss: -8.8560 - val_accuracy: 0.1463\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: -7.5253 - val_accuracy: 0.1402\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9961 - val_loss: -8.4491 - val_accuracy: 0.1159\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: -8.9682 - val_accuracy: 0.1280\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: -8.6953 - val_accuracy: 0.1280\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: -9.2559 - val_accuracy: 0.1159\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.9980 - val_loss: -9.0149 - val_accuracy: 0.1220\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: -8.8987 - val_accuracy: 0.1220\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: -10.6283 - val_accuracy: 0.0976\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: -9.7963 - val_accuracy: 0.1159\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: -8.9420 - val_accuracy: 0.1280\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9863 - val_loss: -8.0317 - val_accuracy: 0.1463\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9922 - val_loss: -11.0438 - val_accuracy: 0.0610\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0646 - accuracy: 0.9727 - val_loss: -8.3287 - val_accuracy: 0.1341\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1426 - accuracy: 0.9512 - val_loss: -5.6575 - val_accuracy: 0.1524\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1371 - accuracy: 0.9395 - val_loss: -9.7337 - val_accuracy: 0.0793\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9707 - val_loss: -9.6311 - val_accuracy: 0.1280\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0681 - accuracy: 0.9668 - val_loss: -8.0439 - val_accuracy: 0.1159\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9805 - val_loss: -11.4609 - val_accuracy: 0.0976\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9902 - val_loss: -8.5974 - val_accuracy: 0.1220\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9980 - val_loss: -10.7368 - val_accuracy: 0.1220\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: -8.3042 - val_accuracy: 0.1341\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: -10.2285 - val_accuracy: 0.1037\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9980 - val_loss: -10.5871 - val_accuracy: 0.1098\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: -10.3865 - val_accuracy: 0.1098\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: -9.7827 - val_accuracy: 0.1341\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: -10.6051 - val_accuracy: 0.1220\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: -11.1625 - val_accuracy: 0.1098\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -10.7800 - val_accuracy: 0.1220\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: -10.8452 - val_accuracy: 0.1098\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -10.8584 - val_accuracy: 0.1159\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -11.0735 - val_accuracy: 0.1098\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -10.9893 - val_accuracy: 0.1159\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -11.4412 - val_accuracy: 0.1037\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -11.0202 - val_accuracy: 0.1098\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -11.5401 - val_accuracy: 0.1037\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -11.0622 - val_accuracy: 0.1280\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -11.2652 - val_accuracy: 0.1098\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -11.7598 - val_accuracy: 0.1159\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -11.0009 - val_accuracy: 0.1341\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -11.4800 - val_accuracy: 0.1037\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -11.1206 - val_accuracy: 0.1341\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -11.5648 - val_accuracy: 0.1098\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -11.3536 - val_accuracy: 0.1220\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -11.4143 - val_accuracy: 0.1098\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -11.5710 - val_accuracy: 0.1159\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -11.3951 - val_accuracy: 0.1280\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -11.8451 - val_accuracy: 0.1037\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -11.5007 - val_accuracy: 0.1280\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -11.7342 - val_accuracy: 0.1098\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -11.8617 - val_accuracy: 0.1037\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -11.6281 - val_accuracy: 0.1220\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -11.5136 - val_accuracy: 0.1280\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -12.0441 - val_accuracy: 0.1098\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -11.6371 - val_accuracy: 0.1280\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -11.7892 - val_accuracy: 0.1098\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -12.0355 - val_accuracy: 0.1098\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -11.7667 - val_accuracy: 0.1220\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -12.0075 - val_accuracy: 0.1098\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -11.6728 - val_accuracy: 0.1159\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -12.1654 - val_accuracy: 0.0976\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -11.6553 - val_accuracy: 0.1280\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -11.9785 - val_accuracy: 0.1098\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -12.0219 - val_accuracy: 0.1098\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -11.8476 - val_accuracy: 0.1280\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -11.8410 - val_accuracy: 0.1220\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -12.4125 - val_accuracy: 0.0976\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -11.8387 - val_accuracy: 0.1280\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -12.3127 - val_accuracy: 0.0976\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -11.7444 - val_accuracy: 0.1280\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -12.2614 - val_accuracy: 0.0976\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -11.9741 - val_accuracy: 0.1280\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -12.2901 - val_accuracy: 0.0976\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -11.8811 - val_accuracy: 0.1280\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -12.2557 - val_accuracy: 0.1037\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -12.2311 - val_accuracy: 0.1220\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -12.3033 - val_accuracy: 0.1159\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -12.0172 - val_accuracy: 0.1280\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.6694e-04 - accuracy: 1.0000 - val_loss: -12.3039 - val_accuracy: 0.1159\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.5071e-04 - accuracy: 1.0000 - val_loss: -12.1131 - val_accuracy: 0.1280\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 9.4689e-04 - accuracy: 1.0000 - val_loss: -12.5131 - val_accuracy: 0.1037\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.2221e-04 - accuracy: 1.0000 - val_loss: -12.1262 - val_accuracy: 0.1280\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.1013e-04 - accuracy: 1.0000 - val_loss: -12.3212 - val_accuracy: 0.1280\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.7916e-04 - accuracy: 1.0000 - val_loss: -12.4268 - val_accuracy: 0.1220\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 8.3124e-04 - accuracy: 1.0000 - val_loss: -12.2517 - val_accuracy: 0.1159\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8.6727e-04 - accuracy: 1.0000 - val_loss: -12.3949 - val_accuracy: 0.1220\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.5888e-04 - accuracy: 1.0000 - val_loss: -12.3952 - val_accuracy: 0.1220\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 8.5437e-04 - accuracy: 1.0000 - val_loss: -12.3980 - val_accuracy: 0.1220\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.7047e-04 - accuracy: 1.0000 - val_loss: -12.3577 - val_accuracy: 0.1220\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.8562e-04 - accuracy: 1.0000 - val_loss: -12.6073 - val_accuracy: 0.1037\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.0387e-04 - accuracy: 1.0000 - val_loss: -12.4737 - val_accuracy: 0.1220\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.6979e-04 - accuracy: 1.0000 - val_loss: -12.4963 - val_accuracy: 0.1159\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7.6343e-04 - accuracy: 1.0000 - val_loss: -12.4808 - val_accuracy: 0.1220\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 7.3160e-04 - accuracy: 1.0000 - val_loss: -12.5698 - val_accuracy: 0.1159\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.2063e-04 - accuracy: 1.0000 - val_loss: -12.6666 - val_accuracy: 0.1098\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.1558e-04 - accuracy: 1.0000 - val_loss: -12.5829 - val_accuracy: 0.1220\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.1944e-04 - accuracy: 1.0000 - val_loss: -12.4303 - val_accuracy: 0.1220\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.8543e-04 - accuracy: 1.0000 - val_loss: -12.6670 - val_accuracy: 0.1098\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.5670e-04 - accuracy: 1.0000 - val_loss: -12.6534 - val_accuracy: 0.1159\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.5596e-04 - accuracy: 1.0000 - val_loss: -12.5574 - val_accuracy: 0.1159\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.5740e-04 - accuracy: 1.0000 - val_loss: -12.8097 - val_accuracy: 0.1098\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.1566e-04 - accuracy: 1.0000 - val_loss: -12.4942 - val_accuracy: 0.1280\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2889e-04 - accuracy: 1.0000 - val_loss: -12.7909 - val_accuracy: 0.1098\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.0593e-04 - accuracy: 1.0000 - val_loss: -12.6875 - val_accuracy: 0.1220\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.0790e-04 - accuracy: 1.0000 - val_loss: -12.7841 - val_accuracy: 0.1159\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.0130e-04 - accuracy: 1.0000 - val_loss: -12.8222 - val_accuracy: 0.1159\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 5.8115e-04 - accuracy: 1.0000 - val_loss: -12.7047 - val_accuracy: 0.1220\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.6733e-04 - accuracy: 1.0000 - val_loss: -13.0329 - val_accuracy: 0.1098\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.5942e-04 - accuracy: 1.0000 - val_loss: -12.6658 - val_accuracy: 0.1220\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.5690e-04 - accuracy: 1.0000 - val_loss: -12.8459 - val_accuracy: 0.1159\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.5009e-04 - accuracy: 1.0000 - val_loss: -12.6777 - val_accuracy: 0.1220\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.6003e-04 - accuracy: 1.0000 - val_loss: -12.9564 - val_accuracy: 0.1159\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5.2574e-04 - accuracy: 1.0000 - val_loss: -12.7417 - val_accuracy: 0.1159\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.4351e-04 - accuracy: 1.0000 - val_loss: -13.0455 - val_accuracy: 0.1098\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.2745e-04 - accuracy: 1.0000 - val_loss: -12.9445 - val_accuracy: 0.1159\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.3048e-04 - accuracy: 1.0000 - val_loss: -13.0646 - val_accuracy: 0.1098\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9639e-04 - accuracy: 1.0000 - val_loss: -12.8071 - val_accuracy: 0.1159\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4.7637e-04 - accuracy: 1.0000 - val_loss: -13.1356 - val_accuracy: 0.1098\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.9466e-04 - accuracy: 1.0000 - val_loss: -12.6880 - val_accuracy: 0.1220\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.8491e-04 - accuracy: 1.0000 - val_loss: -12.9881 - val_accuracy: 0.1159\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 5.0458e-04 - accuracy: 1.0000 - val_loss: -12.8529 - val_accuracy: 0.1220\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.5842e-04 - accuracy: 1.0000 - val_loss: -13.0384 - val_accuracy: 0.1159\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4.5354e-04 - accuracy: 1.0000 - val_loss: -13.0306 - val_accuracy: 0.1159\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 4.5709e-04 - accuracy: 1.0000 - val_loss: -13.1230 - val_accuracy: 0.1159\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.2707e-04 - accuracy: 1.0000 - val_loss: -13.0762 - val_accuracy: 0.1159\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.1936e-04 - accuracy: 1.0000 - val_loss: -13.0635 - val_accuracy: 0.1159\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.2050e-04 - accuracy: 1.0000 - val_loss: -13.0797 - val_accuracy: 0.1159\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.0596e-04 - accuracy: 1.0000 - val_loss: -13.1024 - val_accuracy: 0.1159\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.0152e-04 - accuracy: 1.0000 - val_loss: -13.1969 - val_accuracy: 0.1159\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.9554e-04 - accuracy: 1.0000 - val_loss: -13.1978 - val_accuracy: 0.1159\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.9128e-04 - accuracy: 1.0000 - val_loss: -13.0057 - val_accuracy: 0.1280\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.9391e-04 - accuracy: 1.0000 - val_loss: -13.2134 - val_accuracy: 0.1159\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 3.7331e-04 - accuracy: 1.0000 - val_loss: -13.1672 - val_accuracy: 0.1220\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.8184e-04 - accuracy: 1.0000 - val_loss: -13.2700 - val_accuracy: 0.1220\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.6954e-04 - accuracy: 1.0000 - val_loss: -13.2666 - val_accuracy: 0.1159\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.6529e-04 - accuracy: 1.0000 - val_loss: -13.1318 - val_accuracy: 0.1159\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.6525e-04 - accuracy: 1.0000 - val_loss: -13.3266 - val_accuracy: 0.1159\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.5399e-04 - accuracy: 1.0000 - val_loss: -13.2278 - val_accuracy: 0.1159\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 3.4703e-04 - accuracy: 1.0000 - val_loss: -13.3284 - val_accuracy: 0.1159\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.4189e-04 - accuracy: 1.0000 - val_loss: -13.2602 - val_accuracy: 0.1159\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 3.3547e-04 - accuracy: 1.0000 - val_loss: -13.2834 - val_accuracy: 0.1159\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.4571e-04 - accuracy: 1.0000 - val_loss: -13.3210 - val_accuracy: 0.1159\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.2705e-04 - accuracy: 1.0000 - val_loss: -13.3480 - val_accuracy: 0.1159\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.3887e-04 - accuracy: 1.0000 - val_loss: -13.3755 - val_accuracy: 0.1159\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.5790e-04 - accuracy: 1.0000 - val_loss: -13.3221 - val_accuracy: 0.1220\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.1521e-04 - accuracy: 1.0000 - val_loss: -13.3845 - val_accuracy: 0.1159\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.1813e-04 - accuracy: 1.0000 - val_loss: -13.5779 - val_accuracy: 0.1098\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3.0011e-04 - accuracy: 1.0000 - val_loss: -13.3961 - val_accuracy: 0.1159\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2.9810e-04 - accuracy: 1.0000 - val_loss: -13.4444 - val_accuracy: 0.1159\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.0000e-04 - accuracy: 1.0000 - val_loss: -13.4283 - val_accuracy: 0.1220\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.0215e-04 - accuracy: 1.0000 - val_loss: -13.5485 - val_accuracy: 0.1159\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.9349e-04 - accuracy: 1.0000 - val_loss: -13.5462 - val_accuracy: 0.1159\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.0137e-04 - accuracy: 1.0000 - val_loss: -13.5626 - val_accuracy: 0.1159\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.8370e-04 - accuracy: 1.0000 - val_loss: -13.6023 - val_accuracy: 0.1159\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.7693e-04 - accuracy: 1.0000 - val_loss: -13.5685 - val_accuracy: 0.1159\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.6866e-04 - accuracy: 1.0000 - val_loss: -13.5520 - val_accuracy: 0.1220\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2.7319e-04 - accuracy: 1.0000 - val_loss: -13.5906 - val_accuracy: 0.1159\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.7245e-04 - accuracy: 1.0000 - val_loss: -13.7091 - val_accuracy: 0.1159\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.6245e-04 - accuracy: 1.0000 - val_loss: -13.6559 - val_accuracy: 0.1159\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.5908e-04 - accuracy: 1.0000 - val_loss: -13.6454 - val_accuracy: 0.1159\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5798e-04 - accuracy: 1.0000 - val_loss: -13.6418 - val_accuracy: 0.1159\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.5381e-04 - accuracy: 1.0000 - val_loss: -13.7773 - val_accuracy: 0.1159\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.4547e-04 - accuracy: 1.0000 - val_loss: -13.6011 - val_accuracy: 0.1220\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.4572e-04 - accuracy: 1.0000 - val_loss: -13.7570 - val_accuracy: 0.1159\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5062e-04 - accuracy: 1.0000 - val_loss: -13.6355 - val_accuracy: 0.1159\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.4660e-04 - accuracy: 1.0000 - val_loss: -13.7800 - val_accuracy: 0.1159\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.3735e-04 - accuracy: 1.0000 - val_loss: -13.8078 - val_accuracy: 0.1159\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.3189e-04 - accuracy: 1.0000 - val_loss: -13.8035 - val_accuracy: 0.1159\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2696e-04 - accuracy: 1.0000 - val_loss: -13.7407 - val_accuracy: 0.1159\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2535e-04 - accuracy: 1.0000 - val_loss: -13.7332 - val_accuracy: 0.1159\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.2227e-04 - accuracy: 1.0000 - val_loss: -13.8251 - val_accuracy: 0.1159\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.1416e-04 - accuracy: 1.0000 - val_loss: -13.9580 - val_accuracy: 0.1159\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1589e-04 - accuracy: 1.0000 - val_loss: -13.7047 - val_accuracy: 0.1220\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 2.3286e-04 - accuracy: 1.0000 - val_loss: -13.9284 - val_accuracy: 0.1159\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2018e-04 - accuracy: 1.0000 - val_loss: -13.8625 - val_accuracy: 0.1220\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.0928e-04 - accuracy: 1.0000 - val_loss: -13.8809 - val_accuracy: 0.1220\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.0750e-04 - accuracy: 1.0000 - val_loss: -13.9631 - val_accuracy: 0.1159\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0285e-04 - accuracy: 1.0000 - val_loss: -13.9554 - val_accuracy: 0.1159\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9816e-04 - accuracy: 1.0000 - val_loss: -13.9236 - val_accuracy: 0.1159\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9783e-04 - accuracy: 1.0000 - val_loss: -13.9288 - val_accuracy: 0.1159\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9490e-04 - accuracy: 1.0000 - val_loss: -14.0404 - val_accuracy: 0.1159\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9136e-04 - accuracy: 1.0000 - val_loss: -14.0070 - val_accuracy: 0.1159\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.9257e-04 - accuracy: 1.0000 - val_loss: -14.0585 - val_accuracy: 0.1159\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8592e-04 - accuracy: 1.0000 - val_loss: -14.0870 - val_accuracy: 0.1159\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.8485e-04 - accuracy: 1.0000 - val_loss: -13.9353 - val_accuracy: 0.1220\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8102e-04 - accuracy: 1.0000 - val_loss: -14.0439 - val_accuracy: 0.1159\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8247e-04 - accuracy: 1.0000 - val_loss: -14.0991 - val_accuracy: 0.1159\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.7522e-04 - accuracy: 1.0000 - val_loss: -13.9567 - val_accuracy: 0.1159\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.7967e-04 - accuracy: 1.0000 - val_loss: -14.1354 - val_accuracy: 0.1159\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8033e-04 - accuracy: 1.0000 - val_loss: -14.1291 - val_accuracy: 0.1220\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.8223e-04 - accuracy: 1.0000 - val_loss: -14.0428 - val_accuracy: 0.1220\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.6879e-04 - accuracy: 1.0000 - val_loss: -14.0524 - val_accuracy: 0.1220\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 0.6921 - accuracy: 0.5352 - val_loss: 0.7930 - val_accuracy: 0.2012\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6673 - accuracy: 0.5977 - val_loss: 0.4846 - val_accuracy: 0.0976\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6453 - accuracy: 0.6895 - val_loss: 0.6883 - val_accuracy: 0.1585\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6237 - accuracy: 0.6895 - val_loss: 0.2978 - val_accuracy: 0.1280\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5999 - accuracy: 0.6934 - val_loss: 0.6167 - val_accuracy: 0.1585\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5741 - accuracy: 0.7109 - val_loss: 0.6033 - val_accuracy: 0.1646\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5690 - accuracy: 0.6973 - val_loss: -0.0911 - val_accuracy: 0.1280\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5496 - accuracy: 0.7207 - val_loss: -0.0238 - val_accuracy: 0.1341\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5252 - accuracy: 0.7539 - val_loss: -0.0283 - val_accuracy: 0.1402\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4941 - accuracy: 0.7812 - val_loss: 0.2309 - val_accuracy: 0.1646\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4800 - accuracy: 0.7871 - val_loss: -0.5043 - val_accuracy: 0.1098\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4905 - accuracy: 0.7617 - val_loss: -0.3424 - val_accuracy: 0.1463\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4608 - accuracy: 0.7969 - val_loss: -0.1402 - val_accuracy: 0.1524\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4466 - accuracy: 0.8047 - val_loss: -0.0111 - val_accuracy: 0.1768\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4426 - accuracy: 0.8223 - val_loss: -0.7219 - val_accuracy: 0.1220\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4213 - accuracy: 0.8203 - val_loss: -0.4478 - val_accuracy: 0.1646\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4137 - accuracy: 0.8340 - val_loss: -0.1883 - val_accuracy: 0.1890\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.8027 - val_loss: -0.8590 - val_accuracy: 0.1280\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4107 - accuracy: 0.8359 - val_loss: -1.0485 - val_accuracy: 0.1037\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3966 - accuracy: 0.8301 - val_loss: -0.7706 - val_accuracy: 0.1463\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3953 - accuracy: 0.8262 - val_loss: -0.6295 - val_accuracy: 0.1646\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3790 - accuracy: 0.8535 - val_loss: -0.5020 - val_accuracy: 0.1829\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3725 - accuracy: 0.8379 - val_loss: -1.0261 - val_accuracy: 0.1341\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8398 - val_loss: -1.2811 - val_accuracy: 0.1037\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3622 - accuracy: 0.8574 - val_loss: -1.0135 - val_accuracy: 0.1524\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3558 - accuracy: 0.8613 - val_loss: -1.1265 - val_accuracy: 0.1341\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3425 - accuracy: 0.8672 - val_loss: -1.0257 - val_accuracy: 0.1585\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3502 - accuracy: 0.8574 - val_loss: -1.1087 - val_accuracy: 0.1585\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3545 - accuracy: 0.8496 - val_loss: -1.2675 - val_accuracy: 0.1402\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3626 - accuracy: 0.8398 - val_loss: -1.7369 - val_accuracy: 0.0915\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3390 - accuracy: 0.8672 - val_loss: -1.6346 - val_accuracy: 0.0915\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3206 - accuracy: 0.8691 - val_loss: -1.8738 - val_accuracy: 0.0915\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3132 - accuracy: 0.8770 - val_loss: -1.5539 - val_accuracy: 0.1098\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3015 - accuracy: 0.8789 - val_loss: -1.7128 - val_accuracy: 0.1037\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2986 - accuracy: 0.8770 - val_loss: -1.7599 - val_accuracy: 0.1098\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.2841 - accuracy: 0.8887 - val_loss: -1.5247 - val_accuracy: 0.1402\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2879 - accuracy: 0.8984 - val_loss: -1.4935 - val_accuracy: 0.1646\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 0.8887 - val_loss: -2.0855 - val_accuracy: 0.0976\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2591 - accuracy: 0.8945 - val_loss: -2.1350 - val_accuracy: 0.1037\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2604 - accuracy: 0.9023 - val_loss: -1.6738 - val_accuracy: 0.1280\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2497 - accuracy: 0.8945 - val_loss: -2.3256 - val_accuracy: 0.0915\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2536 - accuracy: 0.9004 - val_loss: -2.1256 - val_accuracy: 0.1098\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2554 - accuracy: 0.8984 - val_loss: -1.7163 - val_accuracy: 0.1524\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2457 - accuracy: 0.9082 - val_loss: -1.8947 - val_accuracy: 0.1402\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2368 - accuracy: 0.8906 - val_loss: -1.7618 - val_accuracy: 0.1463\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2356 - accuracy: 0.9102 - val_loss: -1.3886 - val_accuracy: 0.1646\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2210 - accuracy: 0.9082 - val_loss: -2.6420 - val_accuracy: 0.1037\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2172 - accuracy: 0.9062 - val_loss: -1.7555 - val_accuracy: 0.1463\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2127 - accuracy: 0.9121 - val_loss: -2.2992 - val_accuracy: 0.1463\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2248 - accuracy: 0.9102 - val_loss: -1.1556 - val_accuracy: 0.1768\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1964 - accuracy: 0.9277 - val_loss: -1.6197 - val_accuracy: 0.1768\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2095 - accuracy: 0.9160 - val_loss: -2.1542 - val_accuracy: 0.1463\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1952 - accuracy: 0.9258 - val_loss: -2.8308 - val_accuracy: 0.1037\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1813 - accuracy: 0.9297 - val_loss: -2.6331 - val_accuracy: 0.1341\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1836 - accuracy: 0.9238 - val_loss: -3.3403 - val_accuracy: 0.0915\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1879 - accuracy: 0.9316 - val_loss: -3.6141 - val_accuracy: 0.0549\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1927 - accuracy: 0.9297 - val_loss: -3.5222 - val_accuracy: 0.0793\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1897 - accuracy: 0.9258 - val_loss: -3.2885 - val_accuracy: 0.0976\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1693 - accuracy: 0.9355 - val_loss: -3.6074 - val_accuracy: 0.0732\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1515 - accuracy: 0.9512 - val_loss: -4.1075 - val_accuracy: 0.0488\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1653 - accuracy: 0.9492 - val_loss: -3.6619 - val_accuracy: 0.0793\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1435 - accuracy: 0.9473 - val_loss: -3.9858 - val_accuracy: 0.0549\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1512 - accuracy: 0.9414 - val_loss: -3.3260 - val_accuracy: 0.0915\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1301 - accuracy: 0.9512 - val_loss: -2.9566 - val_accuracy: 0.1220\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1274 - accuracy: 0.9570 - val_loss: -3.4236 - val_accuracy: 0.1159\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1343 - accuracy: 0.9434 - val_loss: -3.5559 - val_accuracy: 0.0976\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1153 - accuracy: 0.9609 - val_loss: -4.1265 - val_accuracy: 0.0610\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1311 - accuracy: 0.9434 - val_loss: -4.3551 - val_accuracy: 0.0488\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1253 - accuracy: 0.9512 - val_loss: -3.6003 - val_accuracy: 0.1037\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1151 - accuracy: 0.9668 - val_loss: -4.1386 - val_accuracy: 0.0732\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1309 - accuracy: 0.9609 - val_loss: -4.7192 - val_accuracy: 0.0549\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1391 - accuracy: 0.9375 - val_loss: -4.1062 - val_accuracy: 0.0732\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1183 - accuracy: 0.9512 - val_loss: -4.1586 - val_accuracy: 0.0915\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1126 - accuracy: 0.9629 - val_loss: -3.8356 - val_accuracy: 0.1037\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1035 - accuracy: 0.9629 - val_loss: -4.2577 - val_accuracy: 0.0793\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1105 - accuracy: 0.9570 - val_loss: -4.7446 - val_accuracy: 0.0671\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1019 - accuracy: 0.9688 - val_loss: -4.6131 - val_accuracy: 0.0793\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0938 - accuracy: 0.9707 - val_loss: -4.4511 - val_accuracy: 0.0854\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0874 - accuracy: 0.9688 - val_loss: -4.3285 - val_accuracy: 0.0854\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: -4.3023 - val_accuracy: 0.1098\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.9805 - val_loss: -4.5767 - val_accuracy: 0.0793\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0871 - accuracy: 0.9688 - val_loss: -4.0133 - val_accuracy: 0.1220\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0913 - accuracy: 0.9746 - val_loss: -4.0290 - val_accuracy: 0.1280\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0750 - accuracy: 0.9785 - val_loss: -4.2609 - val_accuracy: 0.1037\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0779 - accuracy: 0.9707 - val_loss: -4.4687 - val_accuracy: 0.1098\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0650 - accuracy: 0.9824 - val_loss: -4.2206 - val_accuracy: 0.1159\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0717 - accuracy: 0.9824 - val_loss: -4.1319 - val_accuracy: 0.1159\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0659 - accuracy: 0.9844 - val_loss: -5.0283 - val_accuracy: 0.0854\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0559 - accuracy: 0.9902 - val_loss: -4.6305 - val_accuracy: 0.1037\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: -4.8011 - val_accuracy: 0.0915\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0740 - accuracy: 0.9805 - val_loss: -5.0814 - val_accuracy: 0.1098\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0808 - accuracy: 0.9727 - val_loss: -5.8263 - val_accuracy: 0.0671\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0678 - accuracy: 0.9805 - val_loss: -5.3899 - val_accuracy: 0.0793\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0701 - accuracy: 0.9766 - val_loss: -6.2729 - val_accuracy: 0.0427\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9785 - val_loss: -6.3511 - val_accuracy: 0.0549\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0883 - accuracy: 0.9668 - val_loss: -5.9685 - val_accuracy: 0.0671\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1088 - accuracy: 0.9629 - val_loss: -6.3154 - val_accuracy: 0.0427\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1028 - accuracy: 0.9590 - val_loss: -5.5350 - val_accuracy: 0.0793\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9766 - val_loss: -5.6114 - val_accuracy: 0.0732\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0601 - accuracy: 0.9922 - val_loss: -5.6888 - val_accuracy: 0.0854\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 0.6874 - accuracy: 0.5430 - val_loss: 0.3214 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6807 - accuracy: 0.5371 - val_loss: 0.8507 - val_accuracy: 0.1768\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6653 - accuracy: 0.5996 - val_loss: 0.4190 - val_accuracy: 0.1098\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6428 - accuracy: 0.6719 - val_loss: 0.5305 - val_accuracy: 0.1585\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6129 - accuracy: 0.6934 - val_loss: 0.3079 - val_accuracy: 0.1280\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5846 - accuracy: 0.7148 - val_loss: 0.1178 - val_accuracy: 0.1341\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5575 - accuracy: 0.7383 - val_loss: 0.0303 - val_accuracy: 0.1402\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5322 - accuracy: 0.7383 - val_loss: 0.3770 - val_accuracy: 0.1890\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5362 - accuracy: 0.7188 - val_loss: -0.2681 - val_accuracy: 0.1402\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5360 - accuracy: 0.7188 - val_loss: -0.5838 - val_accuracy: 0.1220\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4990 - accuracy: 0.7461 - val_loss: 0.1398 - val_accuracy: 0.1890\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.4913 - accuracy: 0.7637 - val_loss: -0.2422 - val_accuracy: 0.1585\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4878 - accuracy: 0.7461 - val_loss: -0.7971 - val_accuracy: 0.1159\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4688 - accuracy: 0.7500 - val_loss: -0.3122 - val_accuracy: 0.1829\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4599 - accuracy: 0.7676 - val_loss: -0.4829 - val_accuracy: 0.1585\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4475 - accuracy: 0.7715 - val_loss: -0.2328 - val_accuracy: 0.1890\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4413 - accuracy: 0.7793 - val_loss: -0.7981 - val_accuracy: 0.1402\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4475 - accuracy: 0.7617 - val_loss: -1.2579 - val_accuracy: 0.0915\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4343 - accuracy: 0.7930 - val_loss: -0.5988 - val_accuracy: 0.1524\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4148 - accuracy: 0.8145 - val_loss: -1.1186 - val_accuracy: 0.1402\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4115 - accuracy: 0.8008 - val_loss: -1.3212 - val_accuracy: 0.1159\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4276 - accuracy: 0.7832 - val_loss: -1.4080 - val_accuracy: 0.1098\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.8203 - val_loss: -0.7984 - val_accuracy: 0.1402\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3895 - accuracy: 0.8164 - val_loss: -1.0188 - val_accuracy: 0.1463\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3828 - accuracy: 0.8418 - val_loss: -1.1207 - val_accuracy: 0.1341\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3663 - accuracy: 0.8418 - val_loss: -1.1060 - val_accuracy: 0.1524\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3787 - accuracy: 0.8223 - val_loss: -0.6314 - val_accuracy: 0.1707\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3670 - accuracy: 0.8262 - val_loss: -0.9204 - val_accuracy: 0.1585\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3527 - accuracy: 0.8438 - val_loss: -0.9393 - val_accuracy: 0.1463\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3419 - accuracy: 0.8418 - val_loss: -1.6634 - val_accuracy: 0.1341\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3364 - accuracy: 0.8516 - val_loss: -1.3754 - val_accuracy: 0.1463\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3233 - accuracy: 0.8652 - val_loss: -1.8824 - val_accuracy: 0.1159\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3174 - accuracy: 0.8672 - val_loss: -1.9483 - val_accuracy: 0.1037\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3049 - accuracy: 0.8711 - val_loss: -1.8271 - val_accuracy: 0.1341\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.2937 - accuracy: 0.8730 - val_loss: -1.6770 - val_accuracy: 0.1341\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2961 - accuracy: 0.8789 - val_loss: -2.1768 - val_accuracy: 0.1098\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2990 - accuracy: 0.8750 - val_loss: -2.3448 - val_accuracy: 0.1037\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2777 - accuracy: 0.8867 - val_loss: -1.6235 - val_accuracy: 0.1463\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2651 - accuracy: 0.8848 - val_loss: -2.1022 - val_accuracy: 0.1098\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3032 - accuracy: 0.8789 - val_loss: -1.5152 - val_accuracy: 0.1463\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2972 - accuracy: 0.8574 - val_loss: -1.6988 - val_accuracy: 0.1585\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3124 - accuracy: 0.8633 - val_loss: -1.8873 - val_accuracy: 0.1280\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2891 - accuracy: 0.8711 - val_loss: -2.6202 - val_accuracy: 0.0915\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2692 - accuracy: 0.9062 - val_loss: -2.6579 - val_accuracy: 0.0976\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2646 - accuracy: 0.9121 - val_loss: -2.7388 - val_accuracy: 0.0976\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2454 - accuracy: 0.9062 - val_loss: -2.4161 - val_accuracy: 0.1098\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2238 - accuracy: 0.9180 - val_loss: -2.4318 - val_accuracy: 0.1220\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2124 - accuracy: 0.9277 - val_loss: -2.5968 - val_accuracy: 0.1098\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2032 - accuracy: 0.9297 - val_loss: -2.8990 - val_accuracy: 0.1098\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1938 - accuracy: 0.9336 - val_loss: -2.6377 - val_accuracy: 0.1220\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1965 - accuracy: 0.9180 - val_loss: -2.2714 - val_accuracy: 0.1341\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2177 - accuracy: 0.9004 - val_loss: -2.3008 - val_accuracy: 0.1280\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2004 - accuracy: 0.9238 - val_loss: -2.9174 - val_accuracy: 0.1159\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1744 - accuracy: 0.9355 - val_loss: -2.2588 - val_accuracy: 0.1280\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1715 - accuracy: 0.9355 - val_loss: -2.9979 - val_accuracy: 0.1220\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1541 - accuracy: 0.9492 - val_loss: -3.1503 - val_accuracy: 0.1159\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1535 - accuracy: 0.9434 - val_loss: -3.3402 - val_accuracy: 0.1037\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1433 - accuracy: 0.9629 - val_loss: -3.6559 - val_accuracy: 0.1098\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1387 - accuracy: 0.9531 - val_loss: -2.9591 - val_accuracy: 0.1159\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1309 - accuracy: 0.9609 - val_loss: -3.3866 - val_accuracy: 0.1098\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1240 - accuracy: 0.9707 - val_loss: -3.5065 - val_accuracy: 0.1098\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1326 - accuracy: 0.9473 - val_loss: -3.1121 - val_accuracy: 0.1280\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1311 - accuracy: 0.9648 - val_loss: -3.1458 - val_accuracy: 0.1341\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1423 - accuracy: 0.9414 - val_loss: -3.8004 - val_accuracy: 0.1037\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1194 - accuracy: 0.9570 - val_loss: -4.0055 - val_accuracy: 0.1037\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1203 - accuracy: 0.9609 - val_loss: -4.1610 - val_accuracy: 0.0915\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1143 - accuracy: 0.9609 - val_loss: -4.0827 - val_accuracy: 0.0976\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1083 - accuracy: 0.9648 - val_loss: -3.3716 - val_accuracy: 0.1220\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0997 - accuracy: 0.9766 - val_loss: -4.1447 - val_accuracy: 0.1037\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0916 - accuracy: 0.9746 - val_loss: -4.3708 - val_accuracy: 0.0976\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.0878 - accuracy: 0.9785 - val_loss: -4.2752 - val_accuracy: 0.0915\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0943 - accuracy: 0.9766 - val_loss: -4.1961 - val_accuracy: 0.1098\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0784 - accuracy: 0.9766 - val_loss: -3.6499 - val_accuracy: 0.1280\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0686 - accuracy: 0.9805 - val_loss: -4.1909 - val_accuracy: 0.1220\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0659 - accuracy: 0.9805 - val_loss: -3.5074 - val_accuracy: 0.1220\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0684 - accuracy: 0.9824 - val_loss: -4.7622 - val_accuracy: 0.1098\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.9785 - val_loss: -4.4887 - val_accuracy: 0.1098\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0593 - accuracy: 0.9863 - val_loss: -4.8501 - val_accuracy: 0.1037\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0673 - accuracy: 0.9805 - val_loss: -4.2641 - val_accuracy: 0.1220\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0514 - accuracy: 0.9922 - val_loss: -4.1953 - val_accuracy: 0.1159\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0627 - accuracy: 0.9844 - val_loss: -4.0589 - val_accuracy: 0.1280\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0589 - accuracy: 0.9863 - val_loss: -4.6705 - val_accuracy: 0.1098\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0479 - accuracy: 0.9922 - val_loss: -4.9315 - val_accuracy: 0.1098\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0395 - accuracy: 0.9980 - val_loss: -5.3037 - val_accuracy: 0.1037\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0416 - accuracy: 0.9922 - val_loss: -5.1780 - val_accuracy: 0.1098\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 0.9902 - val_loss: -4.5698 - val_accuracy: 0.1159\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0397 - accuracy: 0.9883 - val_loss: -5.2385 - val_accuracy: 0.1098\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.9941 - val_loss: -5.8245 - val_accuracy: 0.0854\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9883 - val_loss: -5.0865 - val_accuracy: 0.1098\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: -5.2018 - val_accuracy: 0.1037\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0502 - accuracy: 0.9805 - val_loss: -4.8025 - val_accuracy: 0.1037\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0331 - accuracy: 0.9922 - val_loss: -5.2460 - val_accuracy: 0.1098\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9922 - val_loss: -5.9285 - val_accuracy: 0.0976\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9961 - val_loss: -5.8752 - val_accuracy: 0.0915\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9980 - val_loss: -5.4301 - val_accuracy: 0.1037\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9980 - val_loss: -5.5858 - val_accuracy: 0.1037\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: -5.3729 - val_accuracy: 0.1098\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: -5.7014 - val_accuracy: 0.1098\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9980 - val_loss: -5.5883 - val_accuracy: 0.1098\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0194 - accuracy: 0.9980 - val_loss: -5.5184 - val_accuracy: 0.1098\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 50ms/step - loss: 0.6914 - accuracy: 0.5039 - val_loss: 0.7991 - val_accuracy: 0.2012\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6675 - accuracy: 0.6270 - val_loss: 0.4668 - val_accuracy: 0.0854\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6504 - accuracy: 0.6602 - val_loss: 0.6202 - val_accuracy: 0.1646\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6270 - accuracy: 0.6719 - val_loss: 0.6312 - val_accuracy: 0.1707\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5967 - accuracy: 0.7246 - val_loss: 0.3208 - val_accuracy: 0.1280\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5726 - accuracy: 0.7109 - val_loss: 0.5539 - val_accuracy: 0.1768\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.5571 - accuracy: 0.7422 - val_loss: 0.2215 - val_accuracy: 0.1463\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5363 - accuracy: 0.7539 - val_loss: 0.1429 - val_accuracy: 0.1646\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5104 - accuracy: 0.7793 - val_loss: -0.0194 - val_accuracy: 0.1524\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4955 - accuracy: 0.7754 - val_loss: -0.5322 - val_accuracy: 0.1280\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4798 - accuracy: 0.8047 - val_loss: 0.0595 - val_accuracy: 0.1707\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.4731 - accuracy: 0.7832 - val_loss: 0.0352 - val_accuracy: 0.1829\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4617 - accuracy: 0.8047 - val_loss: -0.0889 - val_accuracy: 0.1768\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4682 - accuracy: 0.7754 - val_loss: 0.1996 - val_accuracy: 0.1951\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4589 - accuracy: 0.7734 - val_loss: 0.0068 - val_accuracy: 0.1829\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4428 - accuracy: 0.8008 - val_loss: -1.0091 - val_accuracy: 0.1098\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4494 - accuracy: 0.7910 - val_loss: -0.2274 - val_accuracy: 0.1890\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4180 - accuracy: 0.8379 - val_loss: -0.7497 - val_accuracy: 0.1402\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4112 - accuracy: 0.8320 - val_loss: -0.6466 - val_accuracy: 0.1463\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.8320 - val_loss: -0.6935 - val_accuracy: 0.1585\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3959 - accuracy: 0.8516 - val_loss: -0.5899 - val_accuracy: 0.1524\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3907 - accuracy: 0.8359 - val_loss: -1.0502 - val_accuracy: 0.1402\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3772 - accuracy: 0.8535 - val_loss: -1.0283 - val_accuracy: 0.1402\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3697 - accuracy: 0.8555 - val_loss: -0.6812 - val_accuracy: 0.1768\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3696 - accuracy: 0.8535 - val_loss: -0.3508 - val_accuracy: 0.1951\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3848 - accuracy: 0.8418 - val_loss: -1.1297 - val_accuracy: 0.1402\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3694 - accuracy: 0.8516 - val_loss: -1.4659 - val_accuracy: 0.1159\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3474 - accuracy: 0.8652 - val_loss: -1.8306 - val_accuracy: 0.1159\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3564 - accuracy: 0.8535 - val_loss: -0.5519 - val_accuracy: 0.1768\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3490 - accuracy: 0.8594 - val_loss: -0.8584 - val_accuracy: 0.1707\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3363 - accuracy: 0.8496 - val_loss: -0.1397 - val_accuracy: 0.2012\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3561 - accuracy: 0.8320 - val_loss: -1.1539 - val_accuracy: 0.1646\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3278 - accuracy: 0.8730 - val_loss: -0.6717 - val_accuracy: 0.1890\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3144 - accuracy: 0.8789 - val_loss: -1.5281 - val_accuracy: 0.1402\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3107 - accuracy: 0.8926 - val_loss: -1.3250 - val_accuracy: 0.1585\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3028 - accuracy: 0.8828 - val_loss: -0.7195 - val_accuracy: 0.1768\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3106 - accuracy: 0.8691 - val_loss: -1.4939 - val_accuracy: 0.1524\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2958 - accuracy: 0.8887 - val_loss: -1.7006 - val_accuracy: 0.1402\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2886 - accuracy: 0.9004 - val_loss: -1.4769 - val_accuracy: 0.1646\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3025 - accuracy: 0.8809 - val_loss: -0.9030 - val_accuracy: 0.1524\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.2985 - accuracy: 0.8809 - val_loss: -1.3353 - val_accuracy: 0.1646\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2638 - accuracy: 0.9082 - val_loss: -1.8569 - val_accuracy: 0.1159\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 0.9160 - val_loss: -2.1459 - val_accuracy: 0.1220\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2521 - accuracy: 0.9180 - val_loss: -1.8233 - val_accuracy: 0.1037\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2631 - accuracy: 0.8984 - val_loss: -1.9027 - val_accuracy: 0.1463\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2515 - accuracy: 0.9141 - val_loss: -1.6630 - val_accuracy: 0.1159\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2360 - accuracy: 0.9199 - val_loss: -2.2602 - val_accuracy: 0.1220\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2227 - accuracy: 0.9277 - val_loss: -2.3716 - val_accuracy: 0.0976\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2264 - accuracy: 0.9180 - val_loss: -2.2973 - val_accuracy: 0.1220\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2355 - accuracy: 0.9141 - val_loss: -3.2649 - val_accuracy: 0.0671\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2454 - accuracy: 0.8984 - val_loss: -2.8497 - val_accuracy: 0.0793\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2445 - accuracy: 0.9004 - val_loss: -2.2367 - val_accuracy: 0.1098\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2075 - accuracy: 0.9258 - val_loss: -2.3568 - val_accuracy: 0.1463\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2046 - accuracy: 0.9355 - val_loss: -2.5730 - val_accuracy: 0.0976\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2248 - accuracy: 0.9180 - val_loss: -2.0624 - val_accuracy: 0.1280\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2144 - accuracy: 0.9238 - val_loss: -2.5732 - val_accuracy: 0.1037\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1931 - accuracy: 0.9375 - val_loss: -2.4723 - val_accuracy: 0.1220\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1804 - accuracy: 0.9414 - val_loss: -3.5216 - val_accuracy: 0.0549\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1970 - accuracy: 0.9258 - val_loss: -3.8120 - val_accuracy: 0.0549\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2295 - accuracy: 0.9102 - val_loss: -3.0703 - val_accuracy: 0.0976\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.2104 - accuracy: 0.9219 - val_loss: -2.3738 - val_accuracy: 0.1280\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2151 - accuracy: 0.9180 - val_loss: -1.2061 - val_accuracy: 0.1829\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2236 - accuracy: 0.9062 - val_loss: -1.6858 - val_accuracy: 0.1280\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2112 - accuracy: 0.9180 - val_loss: -3.1096 - val_accuracy: 0.0915\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1735 - accuracy: 0.9375 - val_loss: -2.4295 - val_accuracy: 0.1159\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1701 - accuracy: 0.9434 - val_loss: -2.7203 - val_accuracy: 0.1098\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1590 - accuracy: 0.9434 - val_loss: -2.7232 - val_accuracy: 0.0915\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9512 - val_loss: -2.9548 - val_accuracy: 0.0976\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1431 - accuracy: 0.9551 - val_loss: -3.5074 - val_accuracy: 0.0793\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.1426 - accuracy: 0.9531 - val_loss: -3.3083 - val_accuracy: 0.0915\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1298 - accuracy: 0.9590 - val_loss: -3.2936 - val_accuracy: 0.0854\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1269 - accuracy: 0.9609 - val_loss: -3.3273 - val_accuracy: 0.0915\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1247 - accuracy: 0.9648 - val_loss: -4.3064 - val_accuracy: 0.0610\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1329 - accuracy: 0.9590 - val_loss: -3.2555 - val_accuracy: 0.0976\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1192 - accuracy: 0.9688 - val_loss: -2.7617 - val_accuracy: 0.1098\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.9629 - val_loss: -2.8989 - val_accuracy: 0.1098\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1329 - accuracy: 0.9590 - val_loss: -2.1976 - val_accuracy: 0.1220\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1280 - accuracy: 0.9473 - val_loss: -3.6018 - val_accuracy: 0.0854\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1202 - accuracy: 0.9570 - val_loss: -3.9816 - val_accuracy: 0.0793\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1206 - accuracy: 0.9590 - val_loss: -3.5401 - val_accuracy: 0.1037\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1028 - accuracy: 0.9668 - val_loss: -3.3131 - val_accuracy: 0.1098\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0985 - accuracy: 0.9727 - val_loss: -3.6010 - val_accuracy: 0.0976\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: -2.7764 - val_accuracy: 0.1280\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1248 - accuracy: 0.9629 - val_loss: -2.2923 - val_accuracy: 0.1524\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1117 - accuracy: 0.9668 - val_loss: -2.2997 - val_accuracy: 0.1341\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1125 - accuracy: 0.9609 - val_loss: -3.3039 - val_accuracy: 0.1098\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0923 - accuracy: 0.9688 - val_loss: -3.6491 - val_accuracy: 0.0976\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0875 - accuracy: 0.9766 - val_loss: -4.2710 - val_accuracy: 0.0915\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.1020 - accuracy: 0.9668 - val_loss: -4.7042 - val_accuracy: 0.0793\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1188 - accuracy: 0.9609 - val_loss: -4.1514 - val_accuracy: 0.0854\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1014 - accuracy: 0.9609 - val_loss: -3.9363 - val_accuracy: 0.0976\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9766 - val_loss: -4.0455 - val_accuracy: 0.0976\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0816 - accuracy: 0.9785 - val_loss: -3.8584 - val_accuracy: 0.1159\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0685 - accuracy: 0.9824 - val_loss: -3.5089 - val_accuracy: 0.1098\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0774 - accuracy: 0.9785 - val_loss: -3.3077 - val_accuracy: 0.1280\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0727 - accuracy: 0.9785 - val_loss: -3.7626 - val_accuracy: 0.1159\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0602 - accuracy: 0.9863 - val_loss: -4.1962 - val_accuracy: 0.0976\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: -4.0431 - val_accuracy: 0.1037\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0610 - accuracy: 0.9785 - val_loss: -4.1569 - val_accuracy: 0.1098\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0550 - accuracy: 0.9785 - val_loss: -4.6881 - val_accuracy: 0.0915\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 2s 44ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.7229 - val_accuracy: 0.1951\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6739 - accuracy: 0.5918 - val_loss: 0.5839 - val_accuracy: 0.1220\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6530 - accuracy: 0.6719 - val_loss: 0.5452 - val_accuracy: 0.1402\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.7012 - val_loss: 0.4975 - val_accuracy: 0.1463\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5959 - accuracy: 0.7109 - val_loss: 0.2651 - val_accuracy: 0.1341\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5686 - accuracy: 0.7188 - val_loss: 0.2117 - val_accuracy: 0.1402\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5410 - accuracy: 0.7168 - val_loss: 0.3128 - val_accuracy: 0.1585\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5104 - accuracy: 0.7500 - val_loss: -0.3051 - val_accuracy: 0.1220\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4977 - accuracy: 0.7676 - val_loss: -0.1074 - val_accuracy: 0.1585\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4796 - accuracy: 0.7754 - val_loss: -0.0440 - val_accuracy: 0.1707\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4600 - accuracy: 0.7910 - val_loss: 0.0209 - val_accuracy: 0.1829\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4489 - accuracy: 0.7910 - val_loss: -0.1132 - val_accuracy: 0.1829\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4340 - accuracy: 0.8223 - val_loss: -0.6133 - val_accuracy: 0.1524\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4213 - accuracy: 0.8281 - val_loss: -0.1972 - val_accuracy: 0.1829\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4213 - accuracy: 0.8262 - val_loss: -0.5467 - val_accuracy: 0.1585\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.8320 - val_loss: -0.7355 - val_accuracy: 0.1646\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.4034 - accuracy: 0.8145 - val_loss: -0.7473 - val_accuracy: 0.1463\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4051 - accuracy: 0.8379 - val_loss: -1.2956 - val_accuracy: 0.1037\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3907 - accuracy: 0.8340 - val_loss: -0.8052 - val_accuracy: 0.1463\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4053 - accuracy: 0.8242 - val_loss: -1.1554 - val_accuracy: 0.1402\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3915 - accuracy: 0.8418 - val_loss: -0.2665 - val_accuracy: 0.1768\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3780 - accuracy: 0.8496 - val_loss: -0.8085 - val_accuracy: 0.1707\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3703 - accuracy: 0.8438 - val_loss: -1.3460 - val_accuracy: 0.1220\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3493 - accuracy: 0.8535 - val_loss: -1.3077 - val_accuracy: 0.1341\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3520 - accuracy: 0.8574 - val_loss: -1.3787 - val_accuracy: 0.1463\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3443 - accuracy: 0.8516 - val_loss: -2.0196 - val_accuracy: 0.0915\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3320 - accuracy: 0.8594 - val_loss: -1.5424 - val_accuracy: 0.1341\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3252 - accuracy: 0.8691 - val_loss: -1.1344 - val_accuracy: 0.1524\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3124 - accuracy: 0.8789 - val_loss: -1.2026 - val_accuracy: 0.1524\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3039 - accuracy: 0.8789 - val_loss: -1.6298 - val_accuracy: 0.1341\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.2952 - accuracy: 0.8789 - val_loss: -1.9449 - val_accuracy: 0.1159\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2941 - accuracy: 0.8828 - val_loss: -1.4774 - val_accuracy: 0.1280\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2981 - accuracy: 0.8770 - val_loss: -2.3975 - val_accuracy: 0.1037\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2837 - accuracy: 0.8926 - val_loss: -1.8248 - val_accuracy: 0.1220\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2724 - accuracy: 0.8906 - val_loss: -1.8842 - val_accuracy: 0.1280\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2674 - accuracy: 0.9023 - val_loss: -1.8787 - val_accuracy: 0.1341\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2587 - accuracy: 0.9062 - val_loss: -2.2425 - val_accuracy: 0.1159\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2667 - accuracy: 0.8828 - val_loss: -2.3681 - val_accuracy: 0.1159\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2466 - accuracy: 0.9102 - val_loss: -2.5312 - val_accuracy: 0.1037\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2369 - accuracy: 0.9082 - val_loss: -2.1560 - val_accuracy: 0.1280\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2293 - accuracy: 0.9180 - val_loss: -2.4788 - val_accuracy: 0.1037\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2251 - accuracy: 0.9023 - val_loss: -2.6074 - val_accuracy: 0.1037\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2071 - accuracy: 0.9238 - val_loss: -3.2302 - val_accuracy: 0.0793\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2080 - accuracy: 0.9141 - val_loss: -2.6364 - val_accuracy: 0.1159\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2080 - accuracy: 0.9238 - val_loss: -2.6798 - val_accuracy: 0.1220\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2126 - accuracy: 0.9238 - val_loss: -2.8957 - val_accuracy: 0.1037\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1993 - accuracy: 0.9180 - val_loss: -3.3821 - val_accuracy: 0.0854\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2058 - accuracy: 0.9258 - val_loss: -3.5899 - val_accuracy: 0.0488\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2044 - accuracy: 0.9141 - val_loss: -2.7160 - val_accuracy: 0.1220\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1692 - accuracy: 0.9375 - val_loss: -3.0941 - val_accuracy: 0.1220\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1621 - accuracy: 0.9453 - val_loss: -3.4771 - val_accuracy: 0.0732\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1724 - accuracy: 0.9336 - val_loss: -3.6361 - val_accuracy: 0.0793\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1918 - accuracy: 0.9277 - val_loss: -3.7550 - val_accuracy: 0.0793\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1945 - accuracy: 0.9277 - val_loss: -3.2769 - val_accuracy: 0.1037\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1575 - accuracy: 0.9395 - val_loss: -3.5323 - val_accuracy: 0.0854\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1414 - accuracy: 0.9492 - val_loss: -4.0057 - val_accuracy: 0.0915\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1586 - accuracy: 0.9277 - val_loss: -2.7615 - val_accuracy: 0.1280\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1523 - accuracy: 0.9414 - val_loss: -2.6393 - val_accuracy: 0.1280\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1411 - accuracy: 0.9492 - val_loss: -3.2105 - val_accuracy: 0.1280\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1230 - accuracy: 0.9570 - val_loss: -3.7135 - val_accuracy: 0.1037\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1208 - accuracy: 0.9551 - val_loss: -3.8950 - val_accuracy: 0.1098\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1135 - accuracy: 0.9648 - val_loss: -4.4486 - val_accuracy: 0.0732\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1413 - accuracy: 0.9531 - val_loss: -4.5848 - val_accuracy: 0.0671\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1302 - accuracy: 0.9473 - val_loss: -4.2700 - val_accuracy: 0.0854\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1098 - accuracy: 0.9688 - val_loss: -4.3847 - val_accuracy: 0.0854\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0997 - accuracy: 0.9668 - val_loss: -4.3452 - val_accuracy: 0.0976\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0947 - accuracy: 0.9727 - val_loss: -4.2330 - val_accuracy: 0.0915\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1150 - accuracy: 0.9668 - val_loss: -4.6494 - val_accuracy: 0.0976\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1353 - accuracy: 0.9551 - val_loss: -4.0076 - val_accuracy: 0.0793\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1052 - accuracy: 0.9688 - val_loss: -3.9914 - val_accuracy: 0.1037\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1003 - accuracy: 0.9648 - val_loss: -4.4167 - val_accuracy: 0.0854\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1007 - accuracy: 0.9688 - val_loss: -4.6838 - val_accuracy: 0.0915\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0814 - accuracy: 0.9785 - val_loss: -4.4390 - val_accuracy: 0.0915\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0764 - accuracy: 0.9824 - val_loss: -4.7884 - val_accuracy: 0.0976\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0749 - accuracy: 0.9785 - val_loss: -5.0212 - val_accuracy: 0.0854\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0688 - accuracy: 0.9863 - val_loss: -5.0593 - val_accuracy: 0.0793\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0686 - accuracy: 0.9824 - val_loss: -4.9659 - val_accuracy: 0.0976\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0608 - accuracy: 0.9902 - val_loss: -4.8554 - val_accuracy: 0.0915\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0691 - accuracy: 0.9863 - val_loss: -4.8567 - val_accuracy: 0.0976\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0567 - accuracy: 0.9902 - val_loss: -4.8465 - val_accuracy: 0.0915\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0585 - accuracy: 0.9922 - val_loss: -5.2494 - val_accuracy: 0.0976\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0608 - accuracy: 0.9863 - val_loss: -4.9367 - val_accuracy: 0.0915\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0591 - accuracy: 0.9863 - val_loss: -5.6459 - val_accuracy: 0.0915\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0554 - accuracy: 0.9863 - val_loss: -4.9322 - val_accuracy: 0.0915\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0555 - accuracy: 0.9863 - val_loss: -5.0135 - val_accuracy: 0.0976\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0601 - accuracy: 0.9863 - val_loss: -5.2458 - val_accuracy: 0.0915\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0579 - accuracy: 0.9844 - val_loss: -5.4629 - val_accuracy: 0.0854\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: -5.3908 - val_accuracy: 0.0976\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0436 - accuracy: 0.9941 - val_loss: -5.6993 - val_accuracy: 0.0854\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9941 - val_loss: -5.9191 - val_accuracy: 0.0854\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0457 - accuracy: 0.9902 - val_loss: -6.4418 - val_accuracy: 0.0732\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0402 - accuracy: 0.9902 - val_loss: -5.4463 - val_accuracy: 0.0854\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0464 - accuracy: 0.9902 - val_loss: -5.8855 - val_accuracy: 0.0854\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0483 - accuracy: 0.9902 - val_loss: -6.4064 - val_accuracy: 0.0854\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0474 - accuracy: 0.9922 - val_loss: -6.1586 - val_accuracy: 0.0793\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0385 - accuracy: 0.9883 - val_loss: -6.4512 - val_accuracy: 0.0732\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0338 - accuracy: 0.9941 - val_loss: -6.7619 - val_accuracy: 0.0549\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0310 - accuracy: 0.9941 - val_loss: -6.9894 - val_accuracy: 0.0610\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9961 - val_loss: -6.4168 - val_accuracy: 0.0915\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0292 - accuracy: 0.9941 - val_loss: -6.1536 - val_accuracy: 0.0915\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0292 - accuracy: 0.9941 - val_loss: -7.1647 - val_accuracy: 0.0793\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9980 - val_loss: -6.5607 - val_accuracy: 0.0854\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: -7.0945 - val_accuracy: 0.0854\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: -6.8713 - val_accuracy: 0.0854\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0559 - accuracy: 0.9785 - val_loss: -8.4340 - val_accuracy: 0.0549\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0642 - accuracy: 0.9824 - val_loss: -6.5876 - val_accuracy: 0.0854\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0526 - accuracy: 0.9863 - val_loss: -5.4683 - val_accuracy: 0.1098\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0418 - accuracy: 0.9922 - val_loss: -5.6215 - val_accuracy: 0.0976\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0571 - accuracy: 0.9746 - val_loss: -4.4823 - val_accuracy: 0.1159\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0702 - accuracy: 0.9746 - val_loss: -5.2823 - val_accuracy: 0.1159\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0964 - accuracy: 0.9570 - val_loss: -6.6946 - val_accuracy: 0.0793\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0487 - accuracy: 0.9922 - val_loss: -6.1278 - val_accuracy: 0.0671\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0399 - accuracy: 0.9902 - val_loss: -7.2728 - val_accuracy: 0.0732\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: -6.4227 - val_accuracy: 0.0976\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9941 - val_loss: -6.2481 - val_accuracy: 0.0976\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0249 - accuracy: 0.9961 - val_loss: -5.5095 - val_accuracy: 0.1159\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.9902 - val_loss: -5.7145 - val_accuracy: 0.1037\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0376 - accuracy: 0.9844 - val_loss: -5.6598 - val_accuracy: 0.1037\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0316 - accuracy: 0.9941 - val_loss: -6.6787 - val_accuracy: 0.0976\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.9922 - val_loss: -7.0846 - val_accuracy: 0.0793\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0395 - accuracy: 0.9902 - val_loss: -7.6446 - val_accuracy: 0.0732\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: -6.9465 - val_accuracy: 0.0854\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0422 - accuracy: 0.9844 - val_loss: -8.8133 - val_accuracy: 0.0671\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9941 - val_loss: -8.0610 - val_accuracy: 0.0549\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9941 - val_loss: -7.8293 - val_accuracy: 0.0854\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: -6.7649 - val_accuracy: 0.0976\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: -6.6869 - val_accuracy: 0.0915\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: -7.8875 - val_accuracy: 0.0732\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: -7.8469 - val_accuracy: 0.0915\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -7.9547 - val_accuracy: 0.0854\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: -7.8389 - val_accuracy: 0.0854\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -7.8894 - val_accuracy: 0.0915\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: -8.1040 - val_accuracy: 0.0915\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: -7.9260 - val_accuracy: 0.0854\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -8.0098 - val_accuracy: 0.0854\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -7.9814 - val_accuracy: 0.0915\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -8.2400 - val_accuracy: 0.0854\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: -7.7354 - val_accuracy: 0.0915\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: -8.4517 - val_accuracy: 0.0854\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: -8.2048 - val_accuracy: 0.0854\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: -7.9421 - val_accuracy: 0.0915\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -8.6615 - val_accuracy: 0.0793\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -8.1822 - val_accuracy: 0.0915\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -8.2169 - val_accuracy: 0.0915\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -8.4264 - val_accuracy: 0.0854\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -8.3223 - val_accuracy: 0.0915\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -8.6066 - val_accuracy: 0.0854\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -8.1730 - val_accuracy: 0.0915\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -8.6537 - val_accuracy: 0.0854\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -8.3705 - val_accuracy: 0.0915\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -8.6529 - val_accuracy: 0.0854\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -8.3045 - val_accuracy: 0.0915\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -9.0400 - val_accuracy: 0.0854\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -8.3394 - val_accuracy: 0.0915\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -9.0163 - val_accuracy: 0.0854\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -8.6193 - val_accuracy: 0.0915\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -8.8477 - val_accuracy: 0.0854\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -8.4381 - val_accuracy: 0.0915\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -8.9723 - val_accuracy: 0.0854\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -8.5153 - val_accuracy: 0.0915\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -8.9991 - val_accuracy: 0.0854\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -8.7627 - val_accuracy: 0.0915\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -8.8268 - val_accuracy: 0.0915\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.9347 - val_accuracy: 0.0915\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.9083 - val_accuracy: 0.0915\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -9.0305 - val_accuracy: 0.0854\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -8.9035 - val_accuracy: 0.0915\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -9.0104 - val_accuracy: 0.0915\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -9.1138 - val_accuracy: 0.0915\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -9.0042 - val_accuracy: 0.0915\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -9.1835 - val_accuracy: 0.0915\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -9.0357 - val_accuracy: 0.0915\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -9.1403 - val_accuracy: 0.0915\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -9.1801 - val_accuracy: 0.0915\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -9.1082 - val_accuracy: 0.0915\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -9.0929 - val_accuracy: 0.0915\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -9.2554 - val_accuracy: 0.0915\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -9.2669 - val_accuracy: 0.0915\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -9.2682 - val_accuracy: 0.0915\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -9.2762 - val_accuracy: 0.0915\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -9.2342 - val_accuracy: 0.0915\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.3693 - val_accuracy: 0.0915\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.3613 - val_accuracy: 0.0915\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.3070 - val_accuracy: 0.0915\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.5063 - val_accuracy: 0.0915\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.3253 - val_accuracy: 0.0915\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.4265 - val_accuracy: 0.0915\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.3807 - val_accuracy: 0.0915\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.5653 - val_accuracy: 0.0915\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.4009 - val_accuracy: 0.0915\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.5720 - val_accuracy: 0.0915\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.4921 - val_accuracy: 0.0915\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -9.5976 - val_accuracy: 0.0915\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -9.5537 - val_accuracy: 0.0915\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.4743 - val_accuracy: 0.0915\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.7430 - val_accuracy: 0.0915\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -9.4452 - val_accuracy: 0.0915\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.7670 - val_accuracy: 0.0915\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.6371 - val_accuracy: 0.0915\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.7203 - val_accuracy: 0.0915\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 38ms/step - loss: 0.6953 - accuracy: 0.5020 - val_loss: 0.6107 - val_accuracy: 0.0732\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.6230 - val_loss: 0.7126 - val_accuracy: 0.1768\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6629 - accuracy: 0.6543 - val_loss: 0.4613 - val_accuracy: 0.0976\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6451 - accuracy: 0.6680 - val_loss: 0.6337 - val_accuracy: 0.1707\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6175 - accuracy: 0.6973 - val_loss: 0.3212 - val_accuracy: 0.1220\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5882 - accuracy: 0.7051 - val_loss: 0.2167 - val_accuracy: 0.1341\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5692 - accuracy: 0.7207 - val_loss: 0.8116 - val_accuracy: 0.1890\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5530 - accuracy: 0.7227 - val_loss: 0.0838 - val_accuracy: 0.1402\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5200 - accuracy: 0.7402 - val_loss: -0.0409 - val_accuracy: 0.1402\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5286 - accuracy: 0.7363 - val_loss: 1.0662 - val_accuracy: 0.2012\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5185 - accuracy: 0.7461 - val_loss: -0.6772 - val_accuracy: 0.0671\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5278 - accuracy: 0.7188 - val_loss: -0.3405 - val_accuracy: 0.1220\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5123 - accuracy: 0.7344 - val_loss: 0.3818 - val_accuracy: 0.1951\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4987 - accuracy: 0.7480 - val_loss: -0.6331 - val_accuracy: 0.1037\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4828 - accuracy: 0.7520 - val_loss: 0.0165 - val_accuracy: 0.1829\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4550 - accuracy: 0.7773 - val_loss: -0.6426 - val_accuracy: 0.1280\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4394 - accuracy: 0.7949 - val_loss: -0.6229 - val_accuracy: 0.1280\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4255 - accuracy: 0.8008 - val_loss: -0.6657 - val_accuracy: 0.1402\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4183 - accuracy: 0.8047 - val_loss: -0.7734 - val_accuracy: 0.1220\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4059 - accuracy: 0.8027 - val_loss: -0.9256 - val_accuracy: 0.1159\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3953 - accuracy: 0.8203 - val_loss: -1.1847 - val_accuracy: 0.0976\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3837 - accuracy: 0.8164 - val_loss: -1.5861 - val_accuracy: 0.0732\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.8125 - val_loss: -1.6477 - val_accuracy: 0.0671\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3957 - accuracy: 0.8145 - val_loss: -1.3861 - val_accuracy: 0.1037\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3623 - accuracy: 0.8223 - val_loss: -0.7846 - val_accuracy: 0.1463\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3448 - accuracy: 0.8301 - val_loss: -1.2216 - val_accuracy: 0.1159\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3471 - accuracy: 0.8398 - val_loss: -1.2323 - val_accuracy: 0.1220\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3332 - accuracy: 0.8477 - val_loss: -0.9524 - val_accuracy: 0.1402\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3245 - accuracy: 0.8652 - val_loss: -1.9643 - val_accuracy: 0.0793\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3175 - accuracy: 0.8594 - val_loss: -2.1929 - val_accuracy: 0.0671\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3178 - accuracy: 0.8457 - val_loss: -1.8806 - val_accuracy: 0.0976\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2841 - accuracy: 0.8789 - val_loss: -1.9444 - val_accuracy: 0.0732\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2994 - accuracy: 0.8672 - val_loss: -2.2120 - val_accuracy: 0.0732\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2751 - accuracy: 0.8828 - val_loss: -2.0674 - val_accuracy: 0.0915\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2666 - accuracy: 0.8848 - val_loss: -1.9371 - val_accuracy: 0.1098\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2680 - accuracy: 0.8809 - val_loss: -1.5490 - val_accuracy: 0.1280\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2551 - accuracy: 0.8906 - val_loss: -2.2134 - val_accuracy: 0.0915\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2683 - accuracy: 0.8789 - val_loss: -2.3489 - val_accuracy: 0.0610\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2485 - accuracy: 0.8848 - val_loss: -3.0948 - val_accuracy: 0.0610\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2690 - accuracy: 0.8945 - val_loss: -2.7661 - val_accuracy: 0.0671\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2443 - accuracy: 0.8887 - val_loss: -2.8824 - val_accuracy: 0.0732\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2335 - accuracy: 0.8945 - val_loss: -2.2745 - val_accuracy: 0.0854\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.2055 - accuracy: 0.9238 - val_loss: -2.9893 - val_accuracy: 0.0671\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2251 - accuracy: 0.9062 - val_loss: -3.2765 - val_accuracy: 0.0671\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2245 - accuracy: 0.8965 - val_loss: -2.7444 - val_accuracy: 0.0732\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1914 - accuracy: 0.9395 - val_loss: -2.2502 - val_accuracy: 0.1098\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1777 - accuracy: 0.9277 - val_loss: -2.3429 - val_accuracy: 0.1098\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1663 - accuracy: 0.9316 - val_loss: -2.8294 - val_accuracy: 0.0915\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1752 - accuracy: 0.9414 - val_loss: -2.9461 - val_accuracy: 0.0732\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1821 - accuracy: 0.9219 - val_loss: -2.2485 - val_accuracy: 0.1098\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1647 - accuracy: 0.9453 - val_loss: -2.8620 - val_accuracy: 0.1037\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1497 - accuracy: 0.9473 - val_loss: -2.8202 - val_accuracy: 0.1037\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1317 - accuracy: 0.9551 - val_loss: -2.6181 - val_accuracy: 0.1159\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1488 - accuracy: 0.9492 - val_loss: -3.7088 - val_accuracy: 0.0732\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1449 - accuracy: 0.9473 - val_loss: -3.9260 - val_accuracy: 0.0549\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.1363 - accuracy: 0.9434 - val_loss: -3.8094 - val_accuracy: 0.0610\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1154 - accuracy: 0.9609 - val_loss: -3.6453 - val_accuracy: 0.0732\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1116 - accuracy: 0.9668 - val_loss: -3.3616 - val_accuracy: 0.0976\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1080 - accuracy: 0.9707 - val_loss: -3.1873 - val_accuracy: 0.0976\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1121 - accuracy: 0.9727 - val_loss: -3.2747 - val_accuracy: 0.1098\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1044 - accuracy: 0.9668 - val_loss: -2.9068 - val_accuracy: 0.1159\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0986 - accuracy: 0.9707 - val_loss: -3.8959 - val_accuracy: 0.0854\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1010 - accuracy: 0.9688 - val_loss: -4.1946 - val_accuracy: 0.0671\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: -3.6389 - val_accuracy: 0.0976\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0892 - accuracy: 0.9766 - val_loss: -3.6882 - val_accuracy: 0.0915\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9746 - val_loss: -3.9480 - val_accuracy: 0.0793\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0711 - accuracy: 0.9844 - val_loss: -4.2474 - val_accuracy: 0.0854\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.9902 - val_loss: -4.1339 - val_accuracy: 0.0854\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0601 - accuracy: 0.9844 - val_loss: -4.0586 - val_accuracy: 0.0915\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: -4.1677 - val_accuracy: 0.0915\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0690 - accuracy: 0.9824 - val_loss: -3.9380 - val_accuracy: 0.0976\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0838 - accuracy: 0.9746 - val_loss: -2.5350 - val_accuracy: 0.1280\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1004 - accuracy: 0.9629 - val_loss: -2.5813 - val_accuracy: 0.1341\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0976 - accuracy: 0.9648 - val_loss: -2.1878 - val_accuracy: 0.1524\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1007 - accuracy: 0.9629 - val_loss: -4.0983 - val_accuracy: 0.1098\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.9688 - val_loss: -3.4556 - val_accuracy: 0.1280\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1006 - accuracy: 0.9590 - val_loss: -4.5631 - val_accuracy: 0.0976\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9707 - val_loss: -4.3695 - val_accuracy: 0.0915\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9883 - val_loss: -5.2006 - val_accuracy: 0.0732\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 0.9961 - val_loss: -4.8999 - val_accuracy: 0.0793\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 0.9980 - val_loss: -4.8699 - val_accuracy: 0.0854\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0338 - accuracy: 0.9980 - val_loss: -5.0247 - val_accuracy: 0.0793\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9980 - val_loss: -4.6085 - val_accuracy: 0.0915\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 0.9941 - val_loss: -5.0317 - val_accuracy: 0.0854\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: -4.3752 - val_accuracy: 0.1037\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0327 - accuracy: 0.9941 - val_loss: -4.6440 - val_accuracy: 0.0976\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9941 - val_loss: -4.6466 - val_accuracy: 0.0976\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0281 - accuracy: 0.9980 - val_loss: -5.1376 - val_accuracy: 0.0854\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9980 - val_loss: -5.6984 - val_accuracy: 0.0854\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: -4.8875 - val_accuracy: 0.0976\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: -5.4160 - val_accuracy: 0.0854\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: -5.4422 - val_accuracy: 0.0854\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: -4.8599 - val_accuracy: 0.0976\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: -4.4853 - val_accuracy: 0.1098\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: -5.4477 - val_accuracy: 0.0915\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: -6.0311 - val_accuracy: 0.0793\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0206 - accuracy: 0.9961 - val_loss: -6.1549 - val_accuracy: 0.0854\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: -6.1036 - val_accuracy: 0.0793\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9961 - val_loss: -5.6905 - val_accuracy: 0.0854\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: -4.9115 - val_accuracy: 0.1098\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: -4.6234 - val_accuracy: 0.1098\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: -5.6861 - val_accuracy: 0.0854\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: -6.0552 - val_accuracy: 0.0854\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: -6.0604 - val_accuracy: 0.0854\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: -5.2744 - val_accuracy: 0.0915\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: -5.0885 - val_accuracy: 0.1098\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: -6.0759 - val_accuracy: 0.0854\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: -6.3982 - val_accuracy: 0.0854\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: -5.7106 - val_accuracy: 0.0915\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: -5.9368 - val_accuracy: 0.0915\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: -6.2464 - val_accuracy: 0.0854\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -5.9002 - val_accuracy: 0.0854\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -5.9539 - val_accuracy: 0.0854\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: -6.3124 - val_accuracy: 0.0854\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: -6.4437 - val_accuracy: 0.0854\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: -5.7212 - val_accuracy: 0.0915\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: -6.4079 - val_accuracy: 0.0854\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -6.8097 - val_accuracy: 0.0854\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: -5.8909 - val_accuracy: 0.0915\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: -6.4676 - val_accuracy: 0.0854\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: -6.5864 - val_accuracy: 0.0854\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -6.3459 - val_accuracy: 0.0854\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: -6.2321 - val_accuracy: 0.0915\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -6.9309 - val_accuracy: 0.0854\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -6.4792 - val_accuracy: 0.0854\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -6.3251 - val_accuracy: 0.0854\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: -6.7789 - val_accuracy: 0.0854\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -6.5305 - val_accuracy: 0.0854\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -6.4246 - val_accuracy: 0.0915\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: -7.1867 - val_accuracy: 0.0854\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -6.7785 - val_accuracy: 0.0854\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -6.3872 - val_accuracy: 0.0915\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -6.9643 - val_accuracy: 0.0854\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -6.5632 - val_accuracy: 0.0854\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -6.9553 - val_accuracy: 0.0854\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -6.8302 - val_accuracy: 0.0854\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -6.9212 - val_accuracy: 0.0854\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -6.8619 - val_accuracy: 0.0854\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -6.8138 - val_accuracy: 0.0854\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -6.8603 - val_accuracy: 0.0854\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.1745 - val_accuracy: 0.0854\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -6.7745 - val_accuracy: 0.0915\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.2711 - val_accuracy: 0.0854\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -6.7977 - val_accuracy: 0.0915\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -7.2884 - val_accuracy: 0.0854\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -6.6542 - val_accuracy: 0.0915\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -7.2146 - val_accuracy: 0.0854\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -6.7730 - val_accuracy: 0.0915\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -7.3057 - val_accuracy: 0.0854\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -7.2098 - val_accuracy: 0.0854\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.1109 - val_accuracy: 0.0854\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.3129 - val_accuracy: 0.0854\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -6.9026 - val_accuracy: 0.0915\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -7.6181 - val_accuracy: 0.0854\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -6.6967 - val_accuracy: 0.0915\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -7.6047 - val_accuracy: 0.0854\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.1039 - val_accuracy: 0.0915\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.5618 - val_accuracy: 0.0854\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -6.9265 - val_accuracy: 0.0915\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.5613 - val_accuracy: 0.0854\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.0826 - val_accuracy: 0.0915\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.3924 - val_accuracy: 0.0854\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.4040 - val_accuracy: 0.0854\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.4768 - val_accuracy: 0.0854\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.4120 - val_accuracy: 0.0854\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.5651 - val_accuracy: 0.0854\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.2750 - val_accuracy: 0.0915\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -7.6292 - val_accuracy: 0.0854\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.4246 - val_accuracy: 0.0854\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.4960 - val_accuracy: 0.0854\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.5079 - val_accuracy: 0.0854\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.6152 - val_accuracy: 0.0854\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.4843 - val_accuracy: 0.0854\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.5626 - val_accuracy: 0.0854\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.7028 - val_accuracy: 0.0854\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.6168 - val_accuracy: 0.0854\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.6141 - val_accuracy: 0.0854\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.7354 - val_accuracy: 0.0854\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -7.5627 - val_accuracy: 0.0854\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.7220 - val_accuracy: 0.0854\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.6820 - val_accuracy: 0.0854\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.7827 - val_accuracy: 0.0854\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7055 - val_accuracy: 0.0854\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.6848 - val_accuracy: 0.0854\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7436 - val_accuracy: 0.0854\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.8504 - val_accuracy: 0.0854\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7594 - val_accuracy: 0.0854\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7845 - val_accuracy: 0.0854\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -7.9603 - val_accuracy: 0.0854\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -7.7606 - val_accuracy: 0.0854\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.8771 - val_accuracy: 0.0854\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.8275 - val_accuracy: 0.0854\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -7.8190 - val_accuracy: 0.0854\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -7.9338 - val_accuracy: 0.0854\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -7.8935 - val_accuracy: 0.0854\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.6971e-04 - accuracy: 1.0000 - val_loss: -7.9094 - val_accuracy: 0.0854\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.6814e-04 - accuracy: 1.0000 - val_loss: -7.9260 - val_accuracy: 0.0854\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.4837e-04 - accuracy: 1.0000 - val_loss: -7.9638 - val_accuracy: 0.0854\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.4623e-04 - accuracy: 1.0000 - val_loss: -7.9419 - val_accuracy: 0.0854\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.4218e-04 - accuracy: 1.0000 - val_loss: -7.9887 - val_accuracy: 0.0854\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 40ms/step - loss: 0.6915 - accuracy: 0.4922 - val_loss: 0.6088 - val_accuracy: 0.1159\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6792 - accuracy: 0.5664 - val_loss: 0.5550 - val_accuracy: 0.1220\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6570 - accuracy: 0.6660 - val_loss: 0.5492 - val_accuracy: 0.1402\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6392 - accuracy: 0.6543 - val_loss: 0.3653 - val_accuracy: 0.1159\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6148 - accuracy: 0.6738 - val_loss: 0.3787 - val_accuracy: 0.1463\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5819 - accuracy: 0.7168 - val_loss: 0.6177 - val_accuracy: 0.1890\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5619 - accuracy: 0.7266 - val_loss: 0.1742 - val_accuracy: 0.1585\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5220 - accuracy: 0.7871 - val_loss: -0.1026 - val_accuracy: 0.1341\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5082 - accuracy: 0.7637 - val_loss: -0.1992 - val_accuracy: 0.1585\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4837 - accuracy: 0.7793 - val_loss: -0.0166 - val_accuracy: 0.1768\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.4621 - accuracy: 0.7891 - val_loss: -0.0323 - val_accuracy: 0.1951\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4495 - accuracy: 0.8125 - val_loss: -0.3305 - val_accuracy: 0.1707\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.7949 - val_loss: -1.0419 - val_accuracy: 0.1220\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4328 - accuracy: 0.8008 - val_loss: -0.5624 - val_accuracy: 0.1707\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4136 - accuracy: 0.8262 - val_loss: -0.8623 - val_accuracy: 0.1402\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4144 - accuracy: 0.8125 - val_loss: -1.0611 - val_accuracy: 0.1341\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4122 - accuracy: 0.8066 - val_loss: 0.0493 - val_accuracy: 0.1951\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8164 - val_loss: -1.0035 - val_accuracy: 0.1341\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3789 - accuracy: 0.8457 - val_loss: -0.3603 - val_accuracy: 0.1890\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3779 - accuracy: 0.8496 - val_loss: -0.7195 - val_accuracy: 0.1951\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.3675 - accuracy: 0.8457 - val_loss: -0.8596 - val_accuracy: 0.1646\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3565 - accuracy: 0.8574 - val_loss: -1.2047 - val_accuracy: 0.1463\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3504 - accuracy: 0.8535 - val_loss: -0.9963 - val_accuracy: 0.1707\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3357 - accuracy: 0.8652 - val_loss: -1.3382 - val_accuracy: 0.1341\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3341 - accuracy: 0.8691 - val_loss: -1.3076 - val_accuracy: 0.1463\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3258 - accuracy: 0.8809 - val_loss: -1.2913 - val_accuracy: 0.1524\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3194 - accuracy: 0.8730 - val_loss: -1.7866 - val_accuracy: 0.1280\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3342 - accuracy: 0.8516 - val_loss: -1.6576 - val_accuracy: 0.1220\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3292 - accuracy: 0.8477 - val_loss: -1.1078 - val_accuracy: 0.1768\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2978 - accuracy: 0.8828 - val_loss: -2.1387 - val_accuracy: 0.0793\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3131 - accuracy: 0.8711 - val_loss: -1.2078 - val_accuracy: 0.1707\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2932 - accuracy: 0.8887 - val_loss: -1.8650 - val_accuracy: 0.1341\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2819 - accuracy: 0.8848 - val_loss: -2.5588 - val_accuracy: 0.0732\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.3672 - accuracy: 0.8340 - val_loss: -2.6619 - val_accuracy: 0.0549\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3097 - accuracy: 0.8555 - val_loss: -1.8531 - val_accuracy: 0.1098\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2781 - accuracy: 0.8984 - val_loss: -1.4748 - val_accuracy: 0.1463\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2666 - accuracy: 0.8945 - val_loss: -0.9376 - val_accuracy: 0.1768\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2794 - accuracy: 0.8887 - val_loss: -1.3478 - val_accuracy: 0.1585\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2865 - accuracy: 0.8809 - val_loss: -2.2085 - val_accuracy: 0.1220\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2677 - accuracy: 0.8887 - val_loss: -2.7499 - val_accuracy: 0.0549\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2678 - accuracy: 0.8926 - val_loss: -2.3323 - val_accuracy: 0.0793\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2426 - accuracy: 0.9023 - val_loss: -2.1837 - val_accuracy: 0.1220\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2408 - accuracy: 0.9180 - val_loss: -1.8197 - val_accuracy: 0.1341\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2236 - accuracy: 0.9238 - val_loss: -2.5160 - val_accuracy: 0.0854\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2393 - accuracy: 0.9062 - val_loss: -2.3533 - val_accuracy: 0.1098\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2496 - accuracy: 0.9023 - val_loss: -3.0326 - val_accuracy: 0.0549\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2452 - accuracy: 0.9004 - val_loss: -2.8751 - val_accuracy: 0.0732\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2483 - accuracy: 0.9004 - val_loss: -2.5263 - val_accuracy: 0.0915\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2160 - accuracy: 0.9336 - val_loss: -2.1124 - val_accuracy: 0.1341\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2349 - accuracy: 0.9199 - val_loss: -2.1630 - val_accuracy: 0.1220\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2309 - accuracy: 0.9141 - val_loss: -2.0397 - val_accuracy: 0.1341\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2099 - accuracy: 0.9297 - val_loss: -2.1279 - val_accuracy: 0.1402\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2094 - accuracy: 0.9238 - val_loss: -2.0833 - val_accuracy: 0.1402\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1864 - accuracy: 0.9355 - val_loss: -2.1415 - val_accuracy: 0.1463\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1944 - accuracy: 0.9199 - val_loss: -2.7069 - val_accuracy: 0.1037\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2118 - accuracy: 0.9238 - val_loss: -3.2448 - val_accuracy: 0.0793\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2001 - accuracy: 0.9297 - val_loss: -2.6320 - val_accuracy: 0.0976\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1797 - accuracy: 0.9492 - val_loss: -3.3943 - val_accuracy: 0.0793\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1640 - accuracy: 0.9473 - val_loss: -2.2946 - val_accuracy: 0.1280\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1492 - accuracy: 0.9609 - val_loss: -2.7781 - val_accuracy: 0.1159\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1544 - accuracy: 0.9492 - val_loss: -2.9870 - val_accuracy: 0.0976\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1455 - accuracy: 0.9551 - val_loss: -3.0377 - val_accuracy: 0.0976\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1453 - accuracy: 0.9492 - val_loss: -3.1812 - val_accuracy: 0.0976\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1440 - accuracy: 0.9531 - val_loss: -2.4869 - val_accuracy: 0.1341\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1473 - accuracy: 0.9492 - val_loss: -2.8288 - val_accuracy: 0.1280\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1416 - accuracy: 0.9531 - val_loss: -2.7602 - val_accuracy: 0.1402\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1325 - accuracy: 0.9570 - val_loss: -3.2274 - val_accuracy: 0.1037\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1230 - accuracy: 0.9570 - val_loss: -2.8176 - val_accuracy: 0.1220\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1188 - accuracy: 0.9688 - val_loss: -3.1797 - val_accuracy: 0.1159\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1188 - accuracy: 0.9688 - val_loss: -2.4843 - val_accuracy: 0.1402\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1268 - accuracy: 0.9609 - val_loss: -2.7383 - val_accuracy: 0.1402\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1255 - accuracy: 0.9570 - val_loss: -4.2462 - val_accuracy: 0.0671\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.1150 - accuracy: 0.9629 - val_loss: -3.7925 - val_accuracy: 0.0915\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1062 - accuracy: 0.9727 - val_loss: -3.5018 - val_accuracy: 0.0915\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1094 - accuracy: 0.9746 - val_loss: -3.7255 - val_accuracy: 0.0976\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1049 - accuracy: 0.9648 - val_loss: -3.0320 - val_accuracy: 0.1341\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1004 - accuracy: 0.9688 - val_loss: -4.3575 - val_accuracy: 0.0671\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1042 - accuracy: 0.9590 - val_loss: -3.7042 - val_accuracy: 0.1098\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0958 - accuracy: 0.9746 - val_loss: -3.2985 - val_accuracy: 0.1280\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9727 - val_loss: -3.2454 - val_accuracy: 0.1402\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0850 - accuracy: 0.9707 - val_loss: -2.2901 - val_accuracy: 0.1463\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0972 - accuracy: 0.9648 - val_loss: -3.7661 - val_accuracy: 0.1159\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1074 - accuracy: 0.9629 - val_loss: -4.5219 - val_accuracy: 0.0732\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0858 - accuracy: 0.9727 - val_loss: -3.6545 - val_accuracy: 0.1159\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0815 - accuracy: 0.9824 - val_loss: -3.9302 - val_accuracy: 0.1220\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0847 - accuracy: 0.9746 - val_loss: -3.7546 - val_accuracy: 0.1159\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0738 - accuracy: 0.9844 - val_loss: -4.4703 - val_accuracy: 0.0915\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0638 - accuracy: 0.9863 - val_loss: -3.7711 - val_accuracy: 0.1280\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0651 - accuracy: 0.9863 - val_loss: -3.3216 - val_accuracy: 0.1220\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0572 - accuracy: 0.9844 - val_loss: -4.4445 - val_accuracy: 0.0915\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0521 - accuracy: 0.9902 - val_loss: -4.0878 - val_accuracy: 0.1098\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0548 - accuracy: 0.9844 - val_loss: -4.8035 - val_accuracy: 0.0854\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0694 - accuracy: 0.9707 - val_loss: -2.7882 - val_accuracy: 0.1463\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0778 - accuracy: 0.9746 - val_loss: -4.0480 - val_accuracy: 0.1037\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.9863 - val_loss: -4.6058 - val_accuracy: 0.1037\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0555 - accuracy: 0.9883 - val_loss: -3.4790 - val_accuracy: 0.1220\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0544 - accuracy: 0.9902 - val_loss: -4.6139 - val_accuracy: 0.0976\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 0.9883 - val_loss: -3.9503 - val_accuracy: 0.1220\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0654 - accuracy: 0.9824 - val_loss: -4.7085 - val_accuracy: 0.0976\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.9922 - val_loss: -4.7144 - val_accuracy: 0.0976\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: -5.2765 - val_accuracy: 0.0793\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0585 - accuracy: 0.9766 - val_loss: -5.1270 - val_accuracy: 0.0854\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.9922 - val_loss: -5.4062 - val_accuracy: 0.0915\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 0.9922 - val_loss: -5.1294 - val_accuracy: 0.0915\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9902 - val_loss: -5.2478 - val_accuracy: 0.0915\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 0.9805 - val_loss: -5.0142 - val_accuracy: 0.0976\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.9824 - val_loss: -5.1258 - val_accuracy: 0.0976\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 0.9863 - val_loss: -4.0397 - val_accuracy: 0.1220\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0412 - accuracy: 0.9902 - val_loss: -5.0598 - val_accuracy: 0.1098\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0366 - accuracy: 0.9941 - val_loss: -4.9922 - val_accuracy: 0.1037\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0358 - accuracy: 0.9922 - val_loss: -5.3336 - val_accuracy: 0.0976\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0345 - accuracy: 0.9961 - val_loss: -4.4625 - val_accuracy: 0.1220\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0290 - accuracy: 0.9961 - val_loss: -4.7075 - val_accuracy: 0.1037\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: -4.5831 - val_accuracy: 0.1159\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0300 - accuracy: 0.9941 - val_loss: -5.3757 - val_accuracy: 0.1037\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0305 - accuracy: 0.9922 - val_loss: -5.6464 - val_accuracy: 0.0915\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: -6.3837 - val_accuracy: 0.0610\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: -5.2581 - val_accuracy: 0.1037\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0412 - accuracy: 0.9844 - val_loss: -6.3564 - val_accuracy: 0.0732\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0653 - accuracy: 0.9766 - val_loss: -4.3873 - val_accuracy: 0.1159\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0773 - accuracy: 0.9766 - val_loss: -3.3959 - val_accuracy: 0.1402\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9883 - val_loss: -4.0595 - val_accuracy: 0.1341\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0459 - accuracy: 0.9883 - val_loss: -4.7281 - val_accuracy: 0.1220\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0339 - accuracy: 0.9922 - val_loss: -4.2961 - val_accuracy: 0.1341\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0321 - accuracy: 0.9922 - val_loss: -3.6554 - val_accuracy: 0.1341\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0452 - accuracy: 0.9805 - val_loss: -5.3836 - val_accuracy: 0.1159\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: -4.4865 - val_accuracy: 0.1220\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9922 - val_loss: -5.7413 - val_accuracy: 0.0976\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9961 - val_loss: -4.3459 - val_accuracy: 0.1220\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0262 - accuracy: 0.9941 - val_loss: -3.8283 - val_accuracy: 0.1402\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0316 - accuracy: 0.9922 - val_loss: -3.5327 - val_accuracy: 0.1524\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0560 - accuracy: 0.9785 - val_loss: -3.6631 - val_accuracy: 0.1159\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9883 - val_loss: -4.0018 - val_accuracy: 0.1402\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: -3.9002 - val_accuracy: 0.1280\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9941 - val_loss: -5.8092 - val_accuracy: 0.0915\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9980 - val_loss: -5.9032 - val_accuracy: 0.0793\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: -6.5233 - val_accuracy: 0.0915\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0137 - accuracy: 0.9980 - val_loss: -4.7471 - val_accuracy: 0.1280\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0150 - accuracy: 0.9980 - val_loss: -5.6152 - val_accuracy: 0.1098\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: -6.6373 - val_accuracy: 0.0915\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: -6.0975 - val_accuracy: 0.0976\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: -5.7246 - val_accuracy: 0.1159\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: -5.8235 - val_accuracy: 0.1037\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: -6.1138 - val_accuracy: 0.1098\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -6.1419 - val_accuracy: 0.1220\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -6.1463 - val_accuracy: 0.1037\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: -6.5625 - val_accuracy: 0.1037\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: -5.9886 - val_accuracy: 0.1220\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: -6.4271 - val_accuracy: 0.1037\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -6.2787 - val_accuracy: 0.1037\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: -5.8686 - val_accuracy: 0.1220\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -6.6348 - val_accuracy: 0.1098\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: -6.4080 - val_accuracy: 0.1037\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -5.9614 - val_accuracy: 0.1098\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -6.4049 - val_accuracy: 0.1098\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: -6.6086 - val_accuracy: 0.1037\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -6.3910 - val_accuracy: 0.1098\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: -6.1982 - val_accuracy: 0.1159\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -6.4180 - val_accuracy: 0.1098\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -6.6547 - val_accuracy: 0.1098\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -6.3371 - val_accuracy: 0.1159\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -6.7548 - val_accuracy: 0.1037\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -6.7141 - val_accuracy: 0.1098\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -6.2175 - val_accuracy: 0.1220\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -6.8499 - val_accuracy: 0.1037\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -6.1407 - val_accuracy: 0.1220\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -7.0455 - val_accuracy: 0.0976\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -6.6457 - val_accuracy: 0.1098\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -6.4517 - val_accuracy: 0.1159\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -6.7889 - val_accuracy: 0.1098\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -6.9616 - val_accuracy: 0.1037\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -6.6286 - val_accuracy: 0.1037\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -6.7054 - val_accuracy: 0.1098\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -6.6320 - val_accuracy: 0.1037\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -7.0756 - val_accuracy: 0.1037\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -6.7678 - val_accuracy: 0.1220\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -6.6665 - val_accuracy: 0.1037\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -6.7656 - val_accuracy: 0.1098\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -6.8919 - val_accuracy: 0.1220\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -7.1140 - val_accuracy: 0.0915\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -6.8086 - val_accuracy: 0.1098\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -6.7923 - val_accuracy: 0.1037\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -6.8147 - val_accuracy: 0.1037\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -6.9969 - val_accuracy: 0.1037\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -6.9287 - val_accuracy: 0.1159\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -6.8984 - val_accuracy: 0.1037\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -7.0197 - val_accuracy: 0.1037\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -6.9490 - val_accuracy: 0.1098\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.0663 - val_accuracy: 0.1037\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -6.9124 - val_accuracy: 0.1098\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.2499 - val_accuracy: 0.1037\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -6.9896 - val_accuracy: 0.1098\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.1425 - val_accuracy: 0.1037\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -6.9261 - val_accuracy: 0.1098\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.5048 - val_accuracy: 0.0976\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -6.9849 - val_accuracy: 0.1159\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.3266 - val_accuracy: 0.1037\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -7.0578 - val_accuracy: 0.1037\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.2912 - val_accuracy: 0.1037\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.2081 - val_accuracy: 0.1098\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/300\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 0.6884 - accuracy: 0.5703 - val_loss: 0.7363 - val_accuracy: 0.1646\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.6656 - accuracy: 0.6367 - val_loss: 0.7118 - val_accuracy: 0.1585\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6455 - accuracy: 0.6680 - val_loss: 0.4550 - val_accuracy: 0.1402\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6227 - accuracy: 0.6934 - val_loss: 0.6586 - val_accuracy: 0.1585\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6101 - accuracy: 0.6680 - val_loss: 0.7851 - val_accuracy: 0.1768\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5824 - accuracy: 0.6992 - val_loss: 0.4080 - val_accuracy: 0.1524\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.7402 - val_loss: -0.0065 - val_accuracy: 0.1220\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5342 - accuracy: 0.7480 - val_loss: -0.0234 - val_accuracy: 0.1402\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5127 - accuracy: 0.7500 - val_loss: -0.3302 - val_accuracy: 0.1159\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4943 - accuracy: 0.7695 - val_loss: -0.2502 - val_accuracy: 0.1341\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: -0.5732 - val_accuracy: 0.1159\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4613 - accuracy: 0.7969 - val_loss: -0.3411 - val_accuracy: 0.1463\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4299 - accuracy: 0.8105 - val_loss: -0.4298 - val_accuracy: 0.1402\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4278 - accuracy: 0.8105 - val_loss: -0.6637 - val_accuracy: 0.1280\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4136 - accuracy: 0.8066 - val_loss: -0.0538 - val_accuracy: 0.1829\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3979 - accuracy: 0.8242 - val_loss: -0.7159 - val_accuracy: 0.1280\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3867 - accuracy: 0.8145 - val_loss: -0.9771 - val_accuracy: 0.1098\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3722 - accuracy: 0.8281 - val_loss: -1.1993 - val_accuracy: 0.0976\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3547 - accuracy: 0.8477 - val_loss: -0.8538 - val_accuracy: 0.1402\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3633 - accuracy: 0.8379 - val_loss: -0.4538 - val_accuracy: 0.1707\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3482 - accuracy: 0.8457 - val_loss: -1.3599 - val_accuracy: 0.1098\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.3430 - accuracy: 0.8496 - val_loss: -0.9796 - val_accuracy: 0.1402\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3603 - accuracy: 0.8340 - val_loss: -0.6876 - val_accuracy: 0.1585\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3085 - accuracy: 0.8730 - val_loss: -1.4094 - val_accuracy: 0.1159\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3245 - accuracy: 0.8574 - val_loss: -1.4168 - val_accuracy: 0.1220\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3087 - accuracy: 0.8672 - val_loss: -1.4751 - val_accuracy: 0.1220\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2913 - accuracy: 0.8809 - val_loss: -1.4448 - val_accuracy: 0.1159\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2918 - accuracy: 0.8828 - val_loss: -1.6373 - val_accuracy: 0.1159\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2751 - accuracy: 0.8965 - val_loss: -2.1039 - val_accuracy: 0.0976\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2783 - accuracy: 0.8906 - val_loss: -1.5605 - val_accuracy: 0.1159\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2709 - accuracy: 0.8945 - val_loss: -1.8209 - val_accuracy: 0.1220\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2557 - accuracy: 0.9043 - val_loss: -1.4057 - val_accuracy: 0.1220\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2572 - accuracy: 0.8945 - val_loss: -1.3974 - val_accuracy: 0.1402\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2755 - accuracy: 0.8926 - val_loss: -2.0485 - val_accuracy: 0.1159\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2530 - accuracy: 0.9102 - val_loss: -2.4125 - val_accuracy: 0.1098\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2369 - accuracy: 0.9043 - val_loss: -2.4122 - val_accuracy: 0.1098\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2384 - accuracy: 0.9102 - val_loss: -2.2363 - val_accuracy: 0.1159\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3125 - accuracy: 0.8555 - val_loss: -2.7415 - val_accuracy: 0.0671\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.8320 - val_loss: -1.9924 - val_accuracy: 0.1159\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3111 - accuracy: 0.8652 - val_loss: -1.2554 - val_accuracy: 0.1402\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2755 - accuracy: 0.8887 - val_loss: -1.2837 - val_accuracy: 0.1463\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2626 - accuracy: 0.8926 - val_loss: -1.9874 - val_accuracy: 0.1098\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2280 - accuracy: 0.9160 - val_loss: -1.7839 - val_accuracy: 0.1280\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2039 - accuracy: 0.9238 - val_loss: -2.5057 - val_accuracy: 0.1098\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1921 - accuracy: 0.9277 - val_loss: -2.5059 - val_accuracy: 0.1037\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1810 - accuracy: 0.9395 - val_loss: -2.5445 - val_accuracy: 0.1098\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.1723 - accuracy: 0.9414 - val_loss: -2.6634 - val_accuracy: 0.1098\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1898 - accuracy: 0.9297 - val_loss: -2.4257 - val_accuracy: 0.1159\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1679 - accuracy: 0.9414 - val_loss: -2.4667 - val_accuracy: 0.1159\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1776 - accuracy: 0.9453 - val_loss: -1.9579 - val_accuracy: 0.1402\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1920 - accuracy: 0.9258 - val_loss: -2.4434 - val_accuracy: 0.1159\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1753 - accuracy: 0.9258 - val_loss: -2.3217 - val_accuracy: 0.1159\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1812 - accuracy: 0.9375 - val_loss: -2.6785 - val_accuracy: 0.1159\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1519 - accuracy: 0.9492 - val_loss: -3.3828 - val_accuracy: 0.0915\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1408 - accuracy: 0.9531 - val_loss: -3.5453 - val_accuracy: 0.0793\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1372 - accuracy: 0.9512 - val_loss: -3.8296 - val_accuracy: 0.0671\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1332 - accuracy: 0.9570 - val_loss: -3.2864 - val_accuracy: 0.0915\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.9629 - val_loss: -3.1800 - val_accuracy: 0.1098\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1323 - accuracy: 0.9551 - val_loss: -2.6584 - val_accuracy: 0.1280\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1445 - accuracy: 0.9395 - val_loss: -2.3564 - val_accuracy: 0.1402\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1689 - accuracy: 0.9316 - val_loss: -2.7039 - val_accuracy: 0.1159\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1586 - accuracy: 0.9355 - val_loss: -2.8225 - val_accuracy: 0.1098\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1665 - accuracy: 0.9336 - val_loss: -3.3982 - val_accuracy: 0.1037\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1444 - accuracy: 0.9492 - val_loss: -2.8836 - val_accuracy: 0.1098\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1465 - accuracy: 0.9414 - val_loss: -3.1325 - val_accuracy: 0.1098\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1399 - accuracy: 0.9570 - val_loss: -3.1507 - val_accuracy: 0.0976\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1180 - accuracy: 0.9551 - val_loss: -3.5366 - val_accuracy: 0.1159\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1052 - accuracy: 0.9590 - val_loss: -3.7104 - val_accuracy: 0.0915\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1143 - accuracy: 0.9531 - val_loss: -3.9730 - val_accuracy: 0.0976\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1010 - accuracy: 0.9688 - val_loss: -4.0814 - val_accuracy: 0.0915\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0937 - accuracy: 0.9707 - val_loss: -4.4589 - val_accuracy: 0.0793\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0936 - accuracy: 0.9668 - val_loss: -4.4223 - val_accuracy: 0.0732\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0843 - accuracy: 0.9746 - val_loss: -4.3079 - val_accuracy: 0.0854\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0812 - accuracy: 0.9805 - val_loss: -3.9256 - val_accuracy: 0.1098\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0814 - accuracy: 0.9688 - val_loss: -3.7817 - val_accuracy: 0.1037\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0795 - accuracy: 0.9707 - val_loss: -4.4516 - val_accuracy: 0.0793\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0745 - accuracy: 0.9707 - val_loss: -3.6577 - val_accuracy: 0.1098\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0766 - accuracy: 0.9746 - val_loss: -4.2977 - val_accuracy: 0.1037\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0734 - accuracy: 0.9785 - val_loss: -3.9028 - val_accuracy: 0.1098\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0822 - accuracy: 0.9785 - val_loss: -3.9012 - val_accuracy: 0.1098\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1605 - accuracy: 0.9258 - val_loss: -5.6438 - val_accuracy: 0.0488\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1054 - accuracy: 0.9570 - val_loss: -5.6595 - val_accuracy: 0.0488\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1351 - accuracy: 0.9570 - val_loss: -4.8592 - val_accuracy: 0.0732\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0905 - accuracy: 0.9727 - val_loss: -4.8629 - val_accuracy: 0.0854\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0819 - accuracy: 0.9805 - val_loss: -4.9919 - val_accuracy: 0.0793\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0701 - accuracy: 0.9727 - val_loss: -4.6753 - val_accuracy: 0.0854\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0609 - accuracy: 0.9766 - val_loss: -4.6435 - val_accuracy: 0.0915\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9707 - val_loss: -4.1248 - val_accuracy: 0.1037\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0677 - accuracy: 0.9727 - val_loss: -4.3727 - val_accuracy: 0.0854\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0723 - accuracy: 0.9785 - val_loss: -4.3658 - val_accuracy: 0.0976\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0662 - accuracy: 0.9746 - val_loss: -4.7347 - val_accuracy: 0.0976\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0662 - accuracy: 0.9746 - val_loss: -4.0950 - val_accuracy: 0.1098\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0457 - accuracy: 0.9922 - val_loss: -4.5064 - val_accuracy: 0.0915\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0526 - accuracy: 0.9805 - val_loss: -5.0947 - val_accuracy: 0.0854\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: -5.3753 - val_accuracy: 0.0793\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0463 - accuracy: 0.9883 - val_loss: -5.1181 - val_accuracy: 0.0854\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: -5.1293 - val_accuracy: 0.0976\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0329 - accuracy: 0.9941 - val_loss: -5.5766 - val_accuracy: 0.0793\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0287 - accuracy: 0.9941 - val_loss: -5.1806 - val_accuracy: 0.0915\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0278 - accuracy: 0.9961 - val_loss: -5.6993 - val_accuracy: 0.0793\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0263 - accuracy: 0.9941 - val_loss: -5.5549 - val_accuracy: 0.0854\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0249 - accuracy: 0.9980 - val_loss: -4.8769 - val_accuracy: 0.0976\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: -5.0309 - val_accuracy: 0.0976\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: -5.3057 - val_accuracy: 0.0915\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0268 - accuracy: 0.9961 - val_loss: -5.3943 - val_accuracy: 0.0854\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0254 - accuracy: 0.9980 - val_loss: -5.4504 - val_accuracy: 0.0976\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0214 - accuracy: 0.9980 - val_loss: -5.8603 - val_accuracy: 0.0854\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: -5.9092 - val_accuracy: 0.0793\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0269 - accuracy: 0.9961 - val_loss: -6.0499 - val_accuracy: 0.0793\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9980 - val_loss: -5.9990 - val_accuracy: 0.0854\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: -6.0682 - val_accuracy: 0.0793\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0194 - accuracy: 0.9980 - val_loss: -6.9817 - val_accuracy: 0.0793\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9980 - val_loss: -7.1134 - val_accuracy: 0.0671\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9922 - val_loss: -6.6862 - val_accuracy: 0.0793\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: -6.2404 - val_accuracy: 0.0793\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0245 - accuracy: 0.9961 - val_loss: -5.7966 - val_accuracy: 0.0915\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: -5.8968 - val_accuracy: 0.0915\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0214 - accuracy: 0.9980 - val_loss: -6.3538 - val_accuracy: 0.0793\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: -6.7147 - val_accuracy: 0.0793\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9980 - val_loss: -6.1809 - val_accuracy: 0.0854\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: -6.4707 - val_accuracy: 0.0793\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: -6.7043 - val_accuracy: 0.0793\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 0.9980 - val_loss: -7.1982 - val_accuracy: 0.0793\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: -7.1653 - val_accuracy: 0.0793\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0176 - accuracy: 0.9980 - val_loss: -7.1020 - val_accuracy: 0.0793\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: -6.8346 - val_accuracy: 0.0793\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: -6.3720 - val_accuracy: 0.0915\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: -6.6685 - val_accuracy: 0.0854\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: -6.8157 - val_accuracy: 0.0793\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: -6.6653 - val_accuracy: 0.0793\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: -7.0536 - val_accuracy: 0.0793\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: -6.7137 - val_accuracy: 0.0793\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: -6.6584 - val_accuracy: 0.0793\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: -7.7865 - val_accuracy: 0.0793\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: -7.8065 - val_accuracy: 0.0793\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: -7.0492 - val_accuracy: 0.0793\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: -6.5376 - val_accuracy: 0.0854\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: -5.6318 - val_accuracy: 0.1098\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9961 - val_loss: -6.0812 - val_accuracy: 0.0976\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: -5.6817 - val_accuracy: 0.1037\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: -6.4192 - val_accuracy: 0.0915\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: -6.2479 - val_accuracy: 0.1037\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0214 - accuracy: 0.9961 - val_loss: -7.4358 - val_accuracy: 0.0854\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9961 - val_loss: -7.7212 - val_accuracy: 0.0732\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0126 - accuracy: 0.9941 - val_loss: -7.0641 - val_accuracy: 0.0854\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: -7.1182 - val_accuracy: 0.0915\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: -6.6712 - val_accuracy: 0.0854\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: -7.7255 - val_accuracy: 0.0793\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: -7.0379 - val_accuracy: 0.0854\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: -7.4147 - val_accuracy: 0.0793\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -7.6029 - val_accuracy: 0.0793\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -7.3879 - val_accuracy: 0.0854\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -7.6066 - val_accuracy: 0.0793\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -7.3154 - val_accuracy: 0.0793\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -8.1292 - val_accuracy: 0.0793\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -7.1837 - val_accuracy: 0.0854\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -8.0603 - val_accuracy: 0.0793\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.4396 - val_accuracy: 0.0793\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -7.9619 - val_accuracy: 0.0793\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.7640 - val_accuracy: 0.0793\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.6624 - val_accuracy: 0.0793\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -7.9791 - val_accuracy: 0.0793\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -7.6880 - val_accuracy: 0.0793\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -7.9800 - val_accuracy: 0.0793\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -7.8783 - val_accuracy: 0.0793\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -8.1330 - val_accuracy: 0.0793\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.7238 - val_accuracy: 0.0793\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -8.2035 - val_accuracy: 0.0793\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -8.2214 - val_accuracy: 0.0793\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.7968 - val_accuracy: 0.0793\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -8.1666 - val_accuracy: 0.0793\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.0793 - val_accuracy: 0.0793\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.2734 - val_accuracy: 0.0793\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.9018 - val_accuracy: 0.0793\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.2520 - val_accuracy: 0.0793\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.1022 - val_accuracy: 0.0793\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -8.1311 - val_accuracy: 0.0793\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.0489 - val_accuracy: 0.0793\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.0628 - val_accuracy: 0.0793\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.4104 - val_accuracy: 0.0793\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.0676 - val_accuracy: 0.0793\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.6373 - val_accuracy: 0.0793\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -8.0968 - val_accuracy: 0.0793\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.3854 - val_accuracy: 0.0793\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.2842 - val_accuracy: 0.0793\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.3091 - val_accuracy: 0.0793\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.2013 - val_accuracy: 0.0793\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.3941 - val_accuracy: 0.0793\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.3141 - val_accuracy: 0.0793\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.5297 - val_accuracy: 0.0793\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.3223 - val_accuracy: 0.0793\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.5581 - val_accuracy: 0.0793\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.3404 - val_accuracy: 0.0793\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.7290 - val_accuracy: 0.0793\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.3284 - val_accuracy: 0.0793\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.4869 - val_accuracy: 0.0793\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.4980 - val_accuracy: 0.0793\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.4964 - val_accuracy: 0.0793\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.5974 - val_accuracy: 0.0793\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.5314 - val_accuracy: 0.0793\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.6590 - val_accuracy: 0.0793\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.4899 - val_accuracy: 0.0793\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.6493 - val_accuracy: 0.0793\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.6508 - val_accuracy: 0.0793\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.6647 - val_accuracy: 0.0793\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.5024 - val_accuracy: 0.0793\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.7994 - val_accuracy: 0.0793\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.6530 - val_accuracy: 0.0793\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.8164 - val_accuracy: 0.0793\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.6638 - val_accuracy: 0.0793\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.9014 - val_accuracy: 0.0793\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.6800 - val_accuracy: 0.0793\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.8547 - val_accuracy: 0.0793\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.7162 - val_accuracy: 0.0793\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.7986 - val_accuracy: 0.0793\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.7575 - val_accuracy: 0.0793\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.9463 - val_accuracy: 0.0793\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.8515 - val_accuracy: 0.0793\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.5933e-04 - accuracy: 1.0000 - val_loss: -8.9126 - val_accuracy: 0.0793\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.5475e-04 - accuracy: 1.0000 - val_loss: -8.8530 - val_accuracy: 0.0793\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.4221e-04 - accuracy: 1.0000 - val_loss: -8.9160 - val_accuracy: 0.0793\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.0863e-04 - accuracy: 1.0000 - val_loss: -9.0213 - val_accuracy: 0.0793\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.1885e-04 - accuracy: 1.0000 - val_loss: -8.8011 - val_accuracy: 0.0793\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.2074e-04 - accuracy: 1.0000 - val_loss: -8.9824 - val_accuracy: 0.0793\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.9902e-04 - accuracy: 1.0000 - val_loss: -8.8705 - val_accuracy: 0.0793\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 8.8633e-04 - accuracy: 1.0000 - val_loss: -9.0738 - val_accuracy: 0.0793\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 8.5497e-04 - accuracy: 1.0000 - val_loss: -8.8354 - val_accuracy: 0.0793\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.7402e-04 - accuracy: 1.0000 - val_loss: -9.1265 - val_accuracy: 0.0793\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 8.4791e-04 - accuracy: 1.0000 - val_loss: -8.9779 - val_accuracy: 0.0793\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.3869e-04 - accuracy: 1.0000 - val_loss: -9.0385 - val_accuracy: 0.0793\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 8.3042e-04 - accuracy: 1.0000 - val_loss: -9.1180 - val_accuracy: 0.0793\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.9511e-04 - accuracy: 1.0000 - val_loss: -8.9490 - val_accuracy: 0.0793\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.4325e-04 - accuracy: 1.0000 - val_loss: -9.1331 - val_accuracy: 0.0793\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.9691e-04 - accuracy: 1.0000 - val_loss: -9.0555 - val_accuracy: 0.0793\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.9332e-04 - accuracy: 1.0000 - val_loss: -9.0740 - val_accuracy: 0.0793\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 8.2040e-04 - accuracy: 1.0000 - val_loss: -9.1482 - val_accuracy: 0.0793\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.6087e-04 - accuracy: 1.0000 - val_loss: -9.0328 - val_accuracy: 0.0793\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.6481e-04 - accuracy: 1.0000 - val_loss: -9.2578 - val_accuracy: 0.0793\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.4592e-04 - accuracy: 1.0000 - val_loss: -9.1090 - val_accuracy: 0.0793\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.4395e-04 - accuracy: 1.0000 - val_loss: -9.2402 - val_accuracy: 0.0793\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.6458e-04 - accuracy: 1.0000 - val_loss: -9.1600 - val_accuracy: 0.0793\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.4507e-04 - accuracy: 1.0000 - val_loss: -9.1209 - val_accuracy: 0.0793\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 7.0806e-04 - accuracy: 1.0000 - val_loss: -9.2420 - val_accuracy: 0.0793\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.8970e-04 - accuracy: 1.0000 - val_loss: -9.2507 - val_accuracy: 0.0793\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 6.8314e-04 - accuracy: 1.0000 - val_loss: -9.2501 - val_accuracy: 0.0793\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.8444e-04 - accuracy: 1.0000 - val_loss: -9.2110 - val_accuracy: 0.0793\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.7061e-04 - accuracy: 1.0000 - val_loss: -9.3700 - val_accuracy: 0.0793\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 7.0601e-04 - accuracy: 1.0000 - val_loss: -9.2743 - val_accuracy: 0.0793\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 6.7377e-04 - accuracy: 1.0000 - val_loss: -9.3757 - val_accuracy: 0.0793\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.9051e-04 - accuracy: 1.0000 - val_loss: -9.2318 - val_accuracy: 0.0793\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.5242e-04 - accuracy: 1.0000 - val_loss: -9.3834 - val_accuracy: 0.0793\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 6.3674e-04 - accuracy: 1.0000 - val_loss: -9.2153 - val_accuracy: 0.0793\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.2675e-04 - accuracy: 1.0000 - val_loss: -9.4239 - val_accuracy: 0.0793\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 6.1863e-04 - accuracy: 1.0000 - val_loss: -9.3399 - val_accuracy: 0.0793\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.0989e-04 - accuracy: 1.0000 - val_loss: -9.3246 - val_accuracy: 0.0793\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.9637e-04 - accuracy: 1.0000 - val_loss: -9.4399 - val_accuracy: 0.0793\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.8725e-04 - accuracy: 1.0000 - val_loss: -9.3787 - val_accuracy: 0.0793\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.8945e-04 - accuracy: 1.0000 - val_loss: -9.4317 - val_accuracy: 0.0793\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.9103e-04 - accuracy: 1.0000 - val_loss: -9.4744 - val_accuracy: 0.0793\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.7783e-04 - accuracy: 1.0000 - val_loss: -9.3262 - val_accuracy: 0.0793\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 5.6555e-04 - accuracy: 1.0000 - val_loss: -9.5353 - val_accuracy: 0.0793\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.5973e-04 - accuracy: 1.0000 - val_loss: -9.4228 - val_accuracy: 0.0793\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.5306e-04 - accuracy: 1.0000 - val_loss: -9.4046 - val_accuracy: 0.0793\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.5293e-04 - accuracy: 1.0000 - val_loss: -9.5530 - val_accuracy: 0.0793\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.4566e-04 - accuracy: 1.0000 - val_loss: -9.4452 - val_accuracy: 0.0793\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.4227e-04 - accuracy: 1.0000 - val_loss: -9.4860 - val_accuracy: 0.0793\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.3727e-04 - accuracy: 1.0000 - val_loss: -9.5553 - val_accuracy: 0.0793\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.1615e-04 - accuracy: 1.0000 - val_loss: -9.4034 - val_accuracy: 0.0793\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.2722e-04 - accuracy: 1.0000 - val_loss: -9.6381 - val_accuracy: 0.0793\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.1332e-04 - accuracy: 1.0000 - val_loss: -9.4629 - val_accuracy: 0.0793\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.0659e-04 - accuracy: 1.0000 - val_loss: -9.5884 - val_accuracy: 0.0793\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.0180e-04 - accuracy: 1.0000 - val_loss: -9.5505 - val_accuracy: 0.0793\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.0186e-04 - accuracy: 1.0000 - val_loss: -9.6400 - val_accuracy: 0.0793\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 4.9312e-04 - accuracy: 1.0000 - val_loss: -9.5914 - val_accuracy: 0.0793\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.8896e-04 - accuracy: 1.0000 - val_loss: -9.5694 - val_accuracy: 0.0793\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.9087e-04 - accuracy: 1.0000 - val_loss: -9.6809 - val_accuracy: 0.0793\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.8785e-04 - accuracy: 1.0000 - val_loss: -9.5686 - val_accuracy: 0.0793\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.7679e-04 - accuracy: 1.0000 - val_loss: -9.7652 - val_accuracy: 0.0793\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.8174e-04 - accuracy: 1.0000 - val_loss: -9.5324 - val_accuracy: 0.0793\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.7307e-04 - accuracy: 1.0000 - val_loss: -9.7372 - val_accuracy: 0.0793\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.6183e-04 - accuracy: 1.0000 - val_loss: -9.5788 - val_accuracy: 0.0793\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.7080e-04 - accuracy: 1.0000 - val_loss: -9.6847 - val_accuracy: 0.0793\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.4573e-04 - accuracy: 1.0000 - val_loss: -9.6170 - val_accuracy: 0.0793\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.4250e-04 - accuracy: 1.0000 - val_loss: -9.7419 - val_accuracy: 0.0793\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3301e-04 - accuracy: 1.0000 - val_loss: -9.7371 - val_accuracy: 0.0793\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 4.3440e-04 - accuracy: 1.0000 - val_loss: -9.7581 - val_accuracy: 0.0793\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3341e-04 - accuracy: 1.0000 - val_loss: -9.7077 - val_accuracy: 0.0793\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.2332e-04 - accuracy: 1.0000 - val_loss: -9.8064 - val_accuracy: 0.0793\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.4098e-04 - accuracy: 1.0000 - val_loss: -9.7283 - val_accuracy: 0.0793\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.2139e-04 - accuracy: 1.0000 - val_loss: -9.8229 - val_accuracy: 0.0793\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3465e-04 - accuracy: 1.0000 - val_loss: -9.7234 - val_accuracy: 0.0793\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.0797e-04 - accuracy: 1.0000 - val_loss: -9.8839 - val_accuracy: 0.0793\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.0603e-04 - accuracy: 1.0000 - val_loss: -9.7404 - val_accuracy: 0.0793\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 4.0195e-04 - accuracy: 1.0000 - val_loss: -9.8506 - val_accuracy: 0.0793\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.9814e-04 - accuracy: 1.0000 - val_loss: -9.7566 - val_accuracy: 0.0793\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.8939e-04 - accuracy: 1.0000 - val_loss: -9.8906 - val_accuracy: 0.0793\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.8984e-04 - accuracy: 1.0000 - val_loss: -9.7817 - val_accuracy: 0.0793\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 3.7987e-04 - accuracy: 1.0000 - val_loss: -9.9107 - val_accuracy: 0.0793\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.7789e-04 - accuracy: 1.0000 - val_loss: -9.7879 - val_accuracy: 0.0793\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.6979e-04 - accuracy: 1.0000 - val_loss: -9.9207 - val_accuracy: 0.0793\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/300\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 0.6883 - accuracy: 0.5293 - val_loss: 0.6958 - val_accuracy: 0.1646\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6677 - accuracy: 0.5840 - val_loss: 0.4042 - val_accuracy: 0.0976\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6499 - accuracy: 0.6270 - val_loss: 0.6220 - val_accuracy: 0.1585\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6363 - accuracy: 0.6621 - val_loss: 0.1428 - val_accuracy: 0.1159\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6145 - accuracy: 0.6738 - val_loss: 0.5423 - val_accuracy: 0.1707\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5861 - accuracy: 0.7207 - val_loss: 0.1963 - val_accuracy: 0.1524\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.5641 - accuracy: 0.6934 - val_loss: 0.0767 - val_accuracy: 0.1524\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5485 - accuracy: 0.7168 - val_loss: 0.0400 - val_accuracy: 0.1524\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5306 - accuracy: 0.7266 - val_loss: -0.2492 - val_accuracy: 0.1402\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5199 - accuracy: 0.7344 - val_loss: -0.3732 - val_accuracy: 0.1585\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5046 - accuracy: 0.7559 - val_loss: -0.6004 - val_accuracy: 0.1402\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4890 - accuracy: 0.7656 - val_loss: -0.3195 - val_accuracy: 0.1768\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4782 - accuracy: 0.7793 - val_loss: 0.1597 - val_accuracy: 0.2012\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4849 - accuracy: 0.7559 - val_loss: -0.2027 - val_accuracy: 0.1829\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4922 - accuracy: 0.7578 - val_loss: -0.4820 - val_accuracy: 0.1768\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4539 - accuracy: 0.7676 - val_loss: -0.2451 - val_accuracy: 0.1890\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.4637 - accuracy: 0.7871 - val_loss: -0.2539 - val_accuracy: 0.1890\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4782 - accuracy: 0.7578 - val_loss: -0.5985 - val_accuracy: 0.1707\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4537 - accuracy: 0.7949 - val_loss: -0.8031 - val_accuracy: 0.1280\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4557 - accuracy: 0.7715 - val_loss: -0.6645 - val_accuracy: 0.1646\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4387 - accuracy: 0.7910 - val_loss: -0.0983 - val_accuracy: 0.1890\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4161 - accuracy: 0.8105 - val_loss: -1.3488 - val_accuracy: 0.1037\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: -0.6527 - val_accuracy: 0.1768\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3979 - accuracy: 0.8262 - val_loss: -0.6795 - val_accuracy: 0.1707\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3816 - accuracy: 0.8438 - val_loss: -0.9394 - val_accuracy: 0.1524\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3746 - accuracy: 0.8438 - val_loss: -0.9925 - val_accuracy: 0.1524\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3748 - accuracy: 0.8223 - val_loss: -1.3083 - val_accuracy: 0.1341\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3526 - accuracy: 0.8477 - val_loss: -1.7840 - val_accuracy: 0.0915\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3756 - accuracy: 0.8340 - val_loss: -1.6695 - val_accuracy: 0.0854\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.3696 - accuracy: 0.8340 - val_loss: -2.2589 - val_accuracy: 0.0549\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3770 - accuracy: 0.8281 - val_loss: -0.9489 - val_accuracy: 0.1524\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3689 - accuracy: 0.8301 - val_loss: -1.2332 - val_accuracy: 0.1402\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3305 - accuracy: 0.8574 - val_loss: -0.5024 - val_accuracy: 0.1890\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3711 - accuracy: 0.8398 - val_loss: -1.2105 - val_accuracy: 0.1402\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.3082 - accuracy: 0.8750 - val_loss: -1.4477 - val_accuracy: 0.1341\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2917 - accuracy: 0.8867 - val_loss: -1.2885 - val_accuracy: 0.1402\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2864 - accuracy: 0.8887 - val_loss: -1.9077 - val_accuracy: 0.1098\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2838 - accuracy: 0.8926 - val_loss: -1.5843 - val_accuracy: 0.1220\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2804 - accuracy: 0.8867 - val_loss: -1.7004 - val_accuracy: 0.1280\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2626 - accuracy: 0.8984 - val_loss: -1.4580 - val_accuracy: 0.1341\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2534 - accuracy: 0.9023 - val_loss: -1.7109 - val_accuracy: 0.1280\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2510 - accuracy: 0.9062 - val_loss: -1.8987 - val_accuracy: 0.1220\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2362 - accuracy: 0.9199 - val_loss: -1.8604 - val_accuracy: 0.1280\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2472 - accuracy: 0.8984 - val_loss: -1.9226 - val_accuracy: 0.1220\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2490 - accuracy: 0.9141 - val_loss: -0.8588 - val_accuracy: 0.1463\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2584 - accuracy: 0.9082 - val_loss: -2.1359 - val_accuracy: 0.1280\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2240 - accuracy: 0.9199 - val_loss: -2.3410 - val_accuracy: 0.1037\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1998 - accuracy: 0.9355 - val_loss: -2.4107 - val_accuracy: 0.0976\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1960 - accuracy: 0.9375 - val_loss: -2.5831 - val_accuracy: 0.1037\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2083 - accuracy: 0.9199 - val_loss: -1.2661 - val_accuracy: 0.1524\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1948 - accuracy: 0.9277 - val_loss: -2.0267 - val_accuracy: 0.1159\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1932 - accuracy: 0.9297 - val_loss: -2.8621 - val_accuracy: 0.0976\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1744 - accuracy: 0.9414 - val_loss: -2.7583 - val_accuracy: 0.1037\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1841 - accuracy: 0.9316 - val_loss: -2.8054 - val_accuracy: 0.1098\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1697 - accuracy: 0.9453 - val_loss: -3.0516 - val_accuracy: 0.1037\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1580 - accuracy: 0.9414 - val_loss: -2.7734 - val_accuracy: 0.1037\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1561 - accuracy: 0.9453 - val_loss: -3.4935 - val_accuracy: 0.0854\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1551 - accuracy: 0.9395 - val_loss: -2.1634 - val_accuracy: 0.1159\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1452 - accuracy: 0.9512 - val_loss: -2.4389 - val_accuracy: 0.1159\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1282 - accuracy: 0.9551 - val_loss: -3.3415 - val_accuracy: 0.0976\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.1391 - accuracy: 0.9609 - val_loss: -3.2122 - val_accuracy: 0.0915\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1308 - accuracy: 0.9570 - val_loss: -3.0607 - val_accuracy: 0.1159\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1233 - accuracy: 0.9551 - val_loss: -3.1154 - val_accuracy: 0.1098\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1182 - accuracy: 0.9629 - val_loss: -3.7397 - val_accuracy: 0.0915\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1346 - accuracy: 0.9609 - val_loss: -4.0876 - val_accuracy: 0.0976\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1226 - accuracy: 0.9512 - val_loss: -2.1215 - val_accuracy: 0.1280\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1254 - accuracy: 0.9570 - val_loss: -1.3219 - val_accuracy: 0.1585\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1544 - accuracy: 0.9375 - val_loss: -1.9922 - val_accuracy: 0.1524\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1459 - accuracy: 0.9453 - val_loss: -2.1381 - val_accuracy: 0.1159\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1211 - accuracy: 0.9609 - val_loss: -1.4622 - val_accuracy: 0.1402\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.1415 - accuracy: 0.9453 - val_loss: -2.2967 - val_accuracy: 0.1280\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1091 - accuracy: 0.9629 - val_loss: -3.2153 - val_accuracy: 0.1098\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1006 - accuracy: 0.9688 - val_loss: -2.6548 - val_accuracy: 0.1341\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0998 - accuracy: 0.9707 - val_loss: -2.7818 - val_accuracy: 0.1098\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0971 - accuracy: 0.9648 - val_loss: -3.6805 - val_accuracy: 0.1159\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9805 - val_loss: -3.8179 - val_accuracy: 0.0976\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0756 - accuracy: 0.9844 - val_loss: -3.3960 - val_accuracy: 0.1280\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: -3.1090 - val_accuracy: 0.1098\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0736 - accuracy: 0.9844 - val_loss: -3.4508 - val_accuracy: 0.1220\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0942 - accuracy: 0.9648 - val_loss: -3.4168 - val_accuracy: 0.1098\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0774 - accuracy: 0.9746 - val_loss: -3.8181 - val_accuracy: 0.1037\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0684 - accuracy: 0.9883 - val_loss: -4.4336 - val_accuracy: 0.0976\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0610 - accuracy: 0.9883 - val_loss: -3.5973 - val_accuracy: 0.1098\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0581 - accuracy: 0.9863 - val_loss: -3.9686 - val_accuracy: 0.1037\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0569 - accuracy: 0.9902 - val_loss: -4.3591 - val_accuracy: 0.1037\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0509 - accuracy: 0.9922 - val_loss: -4.4505 - val_accuracy: 0.1037\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0471 - accuracy: 0.9902 - val_loss: -4.7962 - val_accuracy: 0.0976\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0573 - accuracy: 0.9844 - val_loss: -5.4637 - val_accuracy: 0.0671\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0569 - accuracy: 0.9844 - val_loss: -4.5915 - val_accuracy: 0.0976\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0567 - accuracy: 0.9805 - val_loss: -4.9855 - val_accuracy: 0.0915\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: -4.7924 - val_accuracy: 0.0915\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0522 - accuracy: 0.9844 - val_loss: -4.4272 - val_accuracy: 0.0976\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0426 - accuracy: 0.9883 - val_loss: -4.5448 - val_accuracy: 0.1037\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0384 - accuracy: 0.9961 - val_loss: -4.5282 - val_accuracy: 0.1037\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0452 - accuracy: 0.9863 - val_loss: -4.5697 - val_accuracy: 0.1037\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0414 - accuracy: 0.9902 - val_loss: -4.9022 - val_accuracy: 0.0976\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0403 - accuracy: 0.9941 - val_loss: -4.6480 - val_accuracy: 0.0976\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0339 - accuracy: 0.9980 - val_loss: -5.5629 - val_accuracy: 0.0854\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9961 - val_loss: -3.8298 - val_accuracy: 0.1098\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9961 - val_loss: -4.9420 - val_accuracy: 0.1159\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0308 - accuracy: 0.9980 - val_loss: -5.0873 - val_accuracy: 0.1098\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 0.9961 - val_loss: -4.6904 - val_accuracy: 0.1037\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9980 - val_loss: -5.4203 - val_accuracy: 0.1037\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: -5.6477 - val_accuracy: 0.0915\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: -5.6600 - val_accuracy: 0.0976\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 0.9961 - val_loss: -5.1216 - val_accuracy: 0.1098\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9961 - val_loss: -5.1432 - val_accuracy: 0.1098\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.9961 - val_loss: -5.3597 - val_accuracy: 0.1037\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: -5.5292 - val_accuracy: 0.1037\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: -5.1924 - val_accuracy: 0.1037\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: -5.8746 - val_accuracy: 0.1037\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0176 - accuracy: 0.9980 - val_loss: -5.6271 - val_accuracy: 0.1037\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0162 - accuracy: 0.9980 - val_loss: -6.1836 - val_accuracy: 0.0976\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9980 - val_loss: -5.8821 - val_accuracy: 0.1037\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: -5.3637 - val_accuracy: 0.1098\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: -5.4552 - val_accuracy: 0.1037\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: -5.7570 - val_accuracy: 0.1037\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: -6.0484 - val_accuracy: 0.1037\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: -6.4647 - val_accuracy: 0.0976\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: -6.5825 - val_accuracy: 0.0854\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0150 - accuracy: 0.9980 - val_loss: -6.9199 - val_accuracy: 0.0854\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: -6.5215 - val_accuracy: 0.0976\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9980 - val_loss: -5.5869 - val_accuracy: 0.1159\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: -5.4433 - val_accuracy: 0.1098\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: -5.5358 - val_accuracy: 0.1159\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: -5.9639 - val_accuracy: 0.1037\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: -6.3767 - val_accuracy: 0.1098\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: -6.6567 - val_accuracy: 0.0854\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: -6.6312 - val_accuracy: 0.0976\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -6.2132 - val_accuracy: 0.1037\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: -6.7604 - val_accuracy: 0.1037\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: -6.7438 - val_accuracy: 0.0976\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: -6.5466 - val_accuracy: 0.1037\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: -7.2738 - val_accuracy: 0.0915\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: -6.4720 - val_accuracy: 0.1037\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: -6.4949 - val_accuracy: 0.1098\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: -7.0935 - val_accuracy: 0.1037\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: -6.7146 - val_accuracy: 0.1037\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -6.9069 - val_accuracy: 0.1037\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -6.5548 - val_accuracy: 0.1098\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: -7.2639 - val_accuracy: 0.1037\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: -7.2284 - val_accuracy: 0.1037\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -6.1419 - val_accuracy: 0.1098\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: -7.2005 - val_accuracy: 0.1037\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: -7.1916 - val_accuracy: 0.1037\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -6.7425 - val_accuracy: 0.1098\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -7.3857 - val_accuracy: 0.0976\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -6.9279 - val_accuracy: 0.1037\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -7.0109 - val_accuracy: 0.1037\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: -7.4406 - val_accuracy: 0.1037\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -7.1623 - val_accuracy: 0.1098\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -7.0393 - val_accuracy: 0.1037\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -7.3708 - val_accuracy: 0.1037\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -7.3840 - val_accuracy: 0.1037\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -6.9076 - val_accuracy: 0.1037\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -7.5657 - val_accuracy: 0.1037\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -7.4957 - val_accuracy: 0.1037\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -7.1393 - val_accuracy: 0.1098\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.5021 - val_accuracy: 0.1037\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.1972 - val_accuracy: 0.1037\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -7.7517 - val_accuracy: 0.1037\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -6.6885 - val_accuracy: 0.1159\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -7.9418 - val_accuracy: 0.0976\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -7.5576 - val_accuracy: 0.1037\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -7.1736 - val_accuracy: 0.1098\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -8.2669 - val_accuracy: 0.0915\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -7.0930 - val_accuracy: 0.1037\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -6.6414 - val_accuracy: 0.1159\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: -8.3262 - val_accuracy: 0.0915\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.3593 - val_accuracy: 0.1098\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -7.7100 - val_accuracy: 0.1037\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.5106 - val_accuracy: 0.1037\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.7856 - val_accuracy: 0.1037\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -7.8618 - val_accuracy: 0.1037\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.8637 - val_accuracy: 0.1037\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.6880 - val_accuracy: 0.1037\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.6480 - val_accuracy: 0.1037\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.0225 - val_accuracy: 0.1037\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.7167 - val_accuracy: 0.1037\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.7896 - val_accuracy: 0.1098\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.2621 - val_accuracy: 0.0976\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -7.6424 - val_accuracy: 0.1098\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -7.8246 - val_accuracy: 0.1037\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.0687 - val_accuracy: 0.1037\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.8690 - val_accuracy: 0.1098\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -8.1997 - val_accuracy: 0.1037\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -7.7981 - val_accuracy: 0.1098\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.3238 - val_accuracy: 0.0976\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.6297 - val_accuracy: 0.1098\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.2404 - val_accuracy: 0.1037\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.0267 - val_accuracy: 0.1098\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.1310 - val_accuracy: 0.1037\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -7.7852 - val_accuracy: 0.1098\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.6804 - val_accuracy: 0.0915\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -7.8706 - val_accuracy: 0.1098\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.2490 - val_accuracy: 0.1037\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.1084 - val_accuracy: 0.1037\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.2969 - val_accuracy: 0.1037\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.2796 - val_accuracy: 0.1037\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.0554 - val_accuracy: 0.1037\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.3917 - val_accuracy: 0.1037\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.2618 - val_accuracy: 0.1037\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.3542 - val_accuracy: 0.1037\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.2402 - val_accuracy: 0.1037\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.4153 - val_accuracy: 0.1037\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.2592 - val_accuracy: 0.1037\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.4032 - val_accuracy: 0.1037\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.2273 - val_accuracy: 0.1037\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.5042 - val_accuracy: 0.1037\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.4241 - val_accuracy: 0.1037\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.3324 - val_accuracy: 0.1037\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.3733 - val_accuracy: 0.1098\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.3260 - val_accuracy: 0.1098\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.5276 - val_accuracy: 0.1037\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.5357 - val_accuracy: 0.1037\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.3779 - val_accuracy: 0.1098\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.6081 - val_accuracy: 0.1037\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.4987 - val_accuracy: 0.1037\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.5969 - val_accuracy: 0.1037\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 9.8858e-04 - accuracy: 1.0000 - val_loss: -8.5579 - val_accuracy: 0.1037\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.4118 - val_accuracy: 0.1098\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.6016e-04 - accuracy: 1.0000 - val_loss: -8.5852 - val_accuracy: 0.1037\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.4635e-04 - accuracy: 1.0000 - val_loss: -8.6062 - val_accuracy: 0.1037\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.7034e-04 - accuracy: 1.0000 - val_loss: -8.7388 - val_accuracy: 0.1037\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.5418e-04 - accuracy: 1.0000 - val_loss: -8.5183 - val_accuracy: 0.1098\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.5493e-04 - accuracy: 1.0000 - val_loss: -8.6365 - val_accuracy: 0.1098\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.1045e-04 - accuracy: 1.0000 - val_loss: -8.6786 - val_accuracy: 0.1037\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.7527e-04 - accuracy: 1.0000 - val_loss: -8.5605 - val_accuracy: 0.1098\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.7024e-04 - accuracy: 1.0000 - val_loss: -8.8361 - val_accuracy: 0.1037\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.5657e-04 - accuracy: 1.0000 - val_loss: -8.5872 - val_accuracy: 0.1037\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.8446e-04 - accuracy: 1.0000 - val_loss: -8.9739 - val_accuracy: 0.1037\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 8.7615e-04 - accuracy: 1.0000 - val_loss: -8.7808 - val_accuracy: 0.1037\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 8.4015e-04 - accuracy: 1.0000 - val_loss: -8.6850 - val_accuracy: 0.1037\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.3156e-04 - accuracy: 1.0000 - val_loss: -8.7902 - val_accuracy: 0.1098\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 8.3433e-04 - accuracy: 1.0000 - val_loss: -8.6696 - val_accuracy: 0.1037\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.1000e-04 - accuracy: 1.0000 - val_loss: -8.8802 - val_accuracy: 0.1037\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.7051e-04 - accuracy: 1.0000 - val_loss: -8.5734 - val_accuracy: 0.1098\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.6055e-04 - accuracy: 1.0000 - val_loss: -8.9484 - val_accuracy: 0.1037\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.1565e-04 - accuracy: 1.0000 - val_loss: -8.6447 - val_accuracy: 0.1098\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.7193e-04 - accuracy: 1.0000 - val_loss: -8.9101 - val_accuracy: 0.1037\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.5395e-04 - accuracy: 1.0000 - val_loss: -8.8715 - val_accuracy: 0.1037\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.3110e-04 - accuracy: 1.0000 - val_loss: -8.7597 - val_accuracy: 0.1037\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.2319e-04 - accuracy: 1.0000 - val_loss: -8.9845 - val_accuracy: 0.1037\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.1855e-04 - accuracy: 1.0000 - val_loss: -8.9094 - val_accuracy: 0.1098\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 7.2534e-04 - accuracy: 1.0000 - val_loss: -9.0429 - val_accuracy: 0.1037\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.9536e-04 - accuracy: 1.0000 - val_loss: -8.8258 - val_accuracy: 0.1098\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.0170e-04 - accuracy: 1.0000 - val_loss: -9.1383 - val_accuracy: 0.1037\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.8796e-04 - accuracy: 1.0000 - val_loss: -8.8735 - val_accuracy: 0.1098\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.8602e-04 - accuracy: 1.0000 - val_loss: -8.9555 - val_accuracy: 0.1037\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.5909e-04 - accuracy: 1.0000 - val_loss: -9.0613 - val_accuracy: 0.1037\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.5677e-04 - accuracy: 1.0000 - val_loss: -8.8562 - val_accuracy: 0.1098\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.5517e-04 - accuracy: 1.0000 - val_loss: -9.0114 - val_accuracy: 0.1037\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.4597e-04 - accuracy: 1.0000 - val_loss: -9.0589 - val_accuracy: 0.1037\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.2972e-04 - accuracy: 1.0000 - val_loss: -9.0299 - val_accuracy: 0.1037\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.2822e-04 - accuracy: 1.0000 - val_loss: -9.0168 - val_accuracy: 0.1037\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6.2870e-04 - accuracy: 1.0000 - val_loss: -9.0987 - val_accuracy: 0.1037\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 6.1121e-04 - accuracy: 1.0000 - val_loss: -9.0967 - val_accuracy: 0.1037\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.0206e-04 - accuracy: 1.0000 - val_loss: -9.0438 - val_accuracy: 0.1098\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.1229e-04 - accuracy: 1.0000 - val_loss: -9.1981 - val_accuracy: 0.1098\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6.0760e-04 - accuracy: 1.0000 - val_loss: -9.1184 - val_accuracy: 0.1037\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.9229e-04 - accuracy: 1.0000 - val_loss: -9.0155 - val_accuracy: 0.1037\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.8007e-04 - accuracy: 1.0000 - val_loss: -9.1752 - val_accuracy: 0.1037\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.8351e-04 - accuracy: 1.0000 - val_loss: -9.2278 - val_accuracy: 0.1037\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.6836e-04 - accuracy: 1.0000 - val_loss: -9.1164 - val_accuracy: 0.1037\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.6064e-04 - accuracy: 1.0000 - val_loss: -9.1888 - val_accuracy: 0.1098\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.5185e-04 - accuracy: 1.0000 - val_loss: -9.1751 - val_accuracy: 0.1037\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.5573e-04 - accuracy: 1.0000 - val_loss: -9.2151 - val_accuracy: 0.1037\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.6545e-04 - accuracy: 1.0000 - val_loss: -9.1251 - val_accuracy: 0.1098\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.4309e-04 - accuracy: 1.0000 - val_loss: -9.2653 - val_accuracy: 0.1098\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 5.2287e-04 - accuracy: 1.0000 - val_loss: -9.3716 - val_accuracy: 0.1037\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.2058e-04 - accuracy: 1.0000 - val_loss: -9.1844 - val_accuracy: 0.1098\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.1136e-04 - accuracy: 1.0000 - val_loss: -9.2562 - val_accuracy: 0.1037\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.1336e-04 - accuracy: 1.0000 - val_loss: -9.3816 - val_accuracy: 0.1037\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.0158e-04 - accuracy: 1.0000 - val_loss: -9.2623 - val_accuracy: 0.1098\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.9503e-04 - accuracy: 1.0000 - val_loss: -9.3096 - val_accuracy: 0.1037\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.9988e-04 - accuracy: 1.0000 - val_loss: -9.3644 - val_accuracy: 0.1098\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.9488e-04 - accuracy: 1.0000 - val_loss: -9.2828 - val_accuracy: 0.1098\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.8006e-04 - accuracy: 1.0000 - val_loss: -9.2664 - val_accuracy: 0.1098\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.7963e-04 - accuracy: 1.0000 - val_loss: -9.4470 - val_accuracy: 0.1037\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.6711e-04 - accuracy: 1.0000 - val_loss: -9.3246 - val_accuracy: 0.1037\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.6731e-04 - accuracy: 1.0000 - val_loss: -9.3435 - val_accuracy: 0.1098\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 4.5852e-04 - accuracy: 1.0000 - val_loss: -9.3575 - val_accuracy: 0.1098\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.5797e-04 - accuracy: 1.0000 - val_loss: -9.4141 - val_accuracy: 0.1037\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.7053e-04 - accuracy: 1.0000 - val_loss: -9.4911 - val_accuracy: 0.1098\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.4653e-04 - accuracy: 1.0000 - val_loss: -9.4641 - val_accuracy: 0.1037\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.5865e-04 - accuracy: 1.0000 - val_loss: -9.3665 - val_accuracy: 0.1098\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.7917e-04 - accuracy: 1.0000 - val_loss: -9.4427 - val_accuracy: 0.1037\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.6682e-04 - accuracy: 1.0000 - val_loss: -9.3954 - val_accuracy: 0.1098\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.2394e-04 - accuracy: 1.0000 - val_loss: -9.5791 - val_accuracy: 0.1037\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.2096e-04 - accuracy: 1.0000 - val_loss: -9.3453 - val_accuracy: 0.1098\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.1812e-04 - accuracy: 1.0000 - val_loss: -9.4981 - val_accuracy: 0.1098\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.0777e-04 - accuracy: 1.0000 - val_loss: -9.6793 - val_accuracy: 0.1037\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.1427e-04 - accuracy: 1.0000 - val_loss: -9.4591 - val_accuracy: 0.1098\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.9486e-04 - accuracy: 1.0000 - val_loss: -9.6172 - val_accuracy: 0.1037\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.0561e-04 - accuracy: 1.0000 - val_loss: -9.4799 - val_accuracy: 0.1098\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.0891e-04 - accuracy: 1.0000 - val_loss: -9.5255 - val_accuracy: 0.1098\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.9487e-04 - accuracy: 1.0000 - val_loss: -9.6870 - val_accuracy: 0.1037\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 3.9924e-04 - accuracy: 1.0000 - val_loss: -9.4937 - val_accuracy: 0.1098\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.8846e-04 - accuracy: 1.0000 - val_loss: -9.6117 - val_accuracy: 0.1037\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.7872e-04 - accuracy: 1.0000 - val_loss: -9.4769 - val_accuracy: 0.1098\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 0.6932 - accuracy: 0.5449 - val_loss: 0.9016 - val_accuracy: 0.2195\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6760 - accuracy: 0.5723 - val_loss: 0.5687 - val_accuracy: 0.1280\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6517 - accuracy: 0.6875 - val_loss: 0.5494 - val_accuracy: 0.1524\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6384 - accuracy: 0.6699 - val_loss: 0.2294 - val_accuracy: 0.0793\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6047 - accuracy: 0.7246 - val_loss: 0.6283 - val_accuracy: 0.1768\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5908 - accuracy: 0.7070 - val_loss: 0.3809 - val_accuracy: 0.1829\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5721 - accuracy: 0.6973 - val_loss: -0.1062 - val_accuracy: 0.1280\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5363 - accuracy: 0.7578 - val_loss: -0.0572 - val_accuracy: 0.1646\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5035 - accuracy: 0.7734 - val_loss: 0.4296 - val_accuracy: 0.1951\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4992 - accuracy: 0.7832 - val_loss: -0.4453 - val_accuracy: 0.1646\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4889 - accuracy: 0.7637 - val_loss: -0.8315 - val_accuracy: 0.1220\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4640 - accuracy: 0.7832 - val_loss: -0.6130 - val_accuracy: 0.1707\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4495 - accuracy: 0.8086 - val_loss: -0.7632 - val_accuracy: 0.1585\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4384 - accuracy: 0.8164 - val_loss: -0.8070 - val_accuracy: 0.1646\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4230 - accuracy: 0.8223 - val_loss: -0.8851 - val_accuracy: 0.1646\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4277 - accuracy: 0.8164 - val_loss: -0.8784 - val_accuracy: 0.1707\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4051 - accuracy: 0.8340 - val_loss: -0.6132 - val_accuracy: 0.1768\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3932 - accuracy: 0.8398 - val_loss: -1.2287 - val_accuracy: 0.1524\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8340 - val_loss: -1.3577 - val_accuracy: 0.1463\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3750 - accuracy: 0.8379 - val_loss: -1.7535 - val_accuracy: 0.1159\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3769 - accuracy: 0.8457 - val_loss: -1.5841 - val_accuracy: 0.1280\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3641 - accuracy: 0.8359 - val_loss: -0.7752 - val_accuracy: 0.1829\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3617 - accuracy: 0.8477 - val_loss: -0.7280 - val_accuracy: 0.1768\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.8398 - val_loss: -0.7169 - val_accuracy: 0.1829\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4034 - accuracy: 0.8125 - val_loss: -0.9901 - val_accuracy: 0.1829\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3487 - accuracy: 0.8613 - val_loss: -1.7850 - val_accuracy: 0.1402\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3263 - accuracy: 0.8711 - val_loss: -2.0096 - val_accuracy: 0.1098\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3233 - accuracy: 0.8730 - val_loss: -2.2289 - val_accuracy: 0.0915\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.8555 - val_loss: -2.4234 - val_accuracy: 0.0854\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3100 - accuracy: 0.8750 - val_loss: -2.3360 - val_accuracy: 0.0976\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3222 - accuracy: 0.8535 - val_loss: -2.2606 - val_accuracy: 0.1220\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4046 - accuracy: 0.8145 - val_loss: -3.0136 - val_accuracy: 0.0732\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3507 - accuracy: 0.8398 - val_loss: -2.3013 - val_accuracy: 0.0976\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3185 - accuracy: 0.8711 - val_loss: -1.9741 - val_accuracy: 0.1524\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2919 - accuracy: 0.8848 - val_loss: -1.4413 - val_accuracy: 0.1707\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2756 - accuracy: 0.8887 - val_loss: -1.7531 - val_accuracy: 0.1707\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2641 - accuracy: 0.9043 - val_loss: -2.4310 - val_accuracy: 0.1220\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2617 - accuracy: 0.9004 - val_loss: -2.4309 - val_accuracy: 0.1220\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2551 - accuracy: 0.9004 - val_loss: -1.3556 - val_accuracy: 0.1768\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2673 - accuracy: 0.8965 - val_loss: -2.2610 - val_accuracy: 0.1280\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9043 - val_loss: -3.6756 - val_accuracy: 0.0549\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2753 - accuracy: 0.8906 - val_loss: -2.6107 - val_accuracy: 0.0915\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2478 - accuracy: 0.9023 - val_loss: -3.6168 - val_accuracy: 0.0610\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2458 - accuracy: 0.8965 - val_loss: -3.0427 - val_accuracy: 0.0793\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2339 - accuracy: 0.9043 - val_loss: -3.6474 - val_accuracy: 0.0549\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2313 - accuracy: 0.9062 - val_loss: -2.9749 - val_accuracy: 0.0854\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2075 - accuracy: 0.9355 - val_loss: -2.5033 - val_accuracy: 0.1402\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2193 - accuracy: 0.9121 - val_loss: -1.9505 - val_accuracy: 0.1463\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2062 - accuracy: 0.9336 - val_loss: -2.8531 - val_accuracy: 0.1341\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1836 - accuracy: 0.9395 - val_loss: -2.7822 - val_accuracy: 0.1220\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1928 - accuracy: 0.9355 - val_loss: -3.0452 - val_accuracy: 0.1220\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1692 - accuracy: 0.9434 - val_loss: -3.7206 - val_accuracy: 0.0671\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.9375 - val_loss: -3.4428 - val_accuracy: 0.0854\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1720 - accuracy: 0.9395 - val_loss: -3.7635 - val_accuracy: 0.0915\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1687 - accuracy: 0.9375 - val_loss: -4.2214 - val_accuracy: 0.0488\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1957 - accuracy: 0.9258 - val_loss: -4.5545 - val_accuracy: 0.0610\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2068 - accuracy: 0.9180 - val_loss: -4.4778 - val_accuracy: 0.0610\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1909 - accuracy: 0.9297 - val_loss: -4.3256 - val_accuracy: 0.0671\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1476 - accuracy: 0.9570 - val_loss: -3.5755 - val_accuracy: 0.1220\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1357 - accuracy: 0.9570 - val_loss: -3.0207 - val_accuracy: 0.1220\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1270 - accuracy: 0.9609 - val_loss: -3.0484 - val_accuracy: 0.1280\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1246 - accuracy: 0.9570 - val_loss: -3.7003 - val_accuracy: 0.0915\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1221 - accuracy: 0.9648 - val_loss: -4.1512 - val_accuracy: 0.0854\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1294 - accuracy: 0.9570 - val_loss: -4.0429 - val_accuracy: 0.0976\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1257 - accuracy: 0.9648 - val_loss: -4.1112 - val_accuracy: 0.0976\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1085 - accuracy: 0.9590 - val_loss: -4.1510 - val_accuracy: 0.0915\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1029 - accuracy: 0.9707 - val_loss: -3.7003 - val_accuracy: 0.1159\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0958 - accuracy: 0.9746 - val_loss: -2.8705 - val_accuracy: 0.1402\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1271 - accuracy: 0.9531 - val_loss: -3.7586 - val_accuracy: 0.1220\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0971 - accuracy: 0.9688 - val_loss: -4.1553 - val_accuracy: 0.0915\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0876 - accuracy: 0.9766 - val_loss: -4.0803 - val_accuracy: 0.1280\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0891 - accuracy: 0.9746 - val_loss: -3.0358 - val_accuracy: 0.1524\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0912 - accuracy: 0.9707 - val_loss: -3.9980 - val_accuracy: 0.1098\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0774 - accuracy: 0.9805 - val_loss: -4.1097 - val_accuracy: 0.1220\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.0722 - accuracy: 0.9785 - val_loss: -3.9291 - val_accuracy: 0.1402\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0655 - accuracy: 0.9844 - val_loss: -4.8689 - val_accuracy: 0.1037\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0587 - accuracy: 0.9863 - val_loss: -4.9525 - val_accuracy: 0.1037\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0647 - accuracy: 0.9805 - val_loss: -5.8745 - val_accuracy: 0.0610\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0973 - accuracy: 0.9688 - val_loss: -6.5772 - val_accuracy: 0.0671\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1435 - accuracy: 0.9395 - val_loss: -5.3503 - val_accuracy: 0.0732\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0875 - accuracy: 0.9785 - val_loss: -6.2294 - val_accuracy: 0.0427\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0952 - accuracy: 0.9727 - val_loss: -5.4713 - val_accuracy: 0.0671\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0848 - accuracy: 0.9746 - val_loss: -5.3677 - val_accuracy: 0.0854\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0697 - accuracy: 0.9844 - val_loss: -4.7003 - val_accuracy: 0.1220\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0602 - accuracy: 0.9824 - val_loss: -4.6220 - val_accuracy: 0.1220\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0612 - accuracy: 0.9785 - val_loss: -4.2273 - val_accuracy: 0.1280\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.9785 - val_loss: -4.7555 - val_accuracy: 0.1220\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0505 - accuracy: 0.9883 - val_loss: -5.0522 - val_accuracy: 0.1098\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0435 - accuracy: 0.9883 - val_loss: -5.9412 - val_accuracy: 0.0915\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0344 - accuracy: 0.9941 - val_loss: -6.0060 - val_accuracy: 0.0793\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0416 - accuracy: 0.9902 - val_loss: -5.7616 - val_accuracy: 0.1037\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: -5.8178 - val_accuracy: 0.1098\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: -5.5034 - val_accuracy: 0.1098\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: -5.1997 - val_accuracy: 0.1220\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9961 - val_loss: -5.4605 - val_accuracy: 0.1159\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: -5.5675 - val_accuracy: 0.1037\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.0210 - accuracy: 0.9980 - val_loss: -5.7793 - val_accuracy: 0.1159\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9980 - val_loss: -6.3814 - val_accuracy: 0.0854\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9980 - val_loss: -5.9421 - val_accuracy: 0.1159\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: -5.9057 - val_accuracy: 0.1159\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9980 - val_loss: -6.7722 - val_accuracy: 0.0915\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9941 - val_loss: -7.0564 - val_accuracy: 0.0732\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0229 - accuracy: 0.9980 - val_loss: -6.6046 - val_accuracy: 0.0915\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: -5.9263 - val_accuracy: 0.1220\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: -5.7453 - val_accuracy: 0.1220\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9961 - val_loss: -6.6033 - val_accuracy: 0.1037\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: -7.0288 - val_accuracy: 0.0854\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9980 - val_loss: -7.2002 - val_accuracy: 0.0854\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: -6.2989 - val_accuracy: 0.1220\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: -6.6558 - val_accuracy: 0.1098\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: -7.6769 - val_accuracy: 0.0732\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: -6.6096 - val_accuracy: 0.1159\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: -6.2036 - val_accuracy: 0.1159\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: -6.6824 - val_accuracy: 0.1159\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: -6.7217 - val_accuracy: 0.1159\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: -6.4504 - val_accuracy: 0.1159\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: -7.3008 - val_accuracy: 0.1037\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: -7.2290 - val_accuracy: 0.1098\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: -5.8382 - val_accuracy: 0.1220\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: -6.7838 - val_accuracy: 0.1159\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: -7.1349 - val_accuracy: 0.1159\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: -6.9916 - val_accuracy: 0.1037\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: -6.7577 - val_accuracy: 0.1098\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: -6.1344 - val_accuracy: 0.1220\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: -7.9702 - val_accuracy: 0.0915\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: -7.7320 - val_accuracy: 0.1098\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: -6.0379 - val_accuracy: 0.1280\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -7.3173 - val_accuracy: 0.1159\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: -7.7650 - val_accuracy: 0.0976\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: -6.9589 - val_accuracy: 0.1159\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: -7.3998 - val_accuracy: 0.1159\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -7.4876 - val_accuracy: 0.1037\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -7.5362 - val_accuracy: 0.1159\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -7.5612 - val_accuracy: 0.1159\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -7.5484 - val_accuracy: 0.1098\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -7.2335 - val_accuracy: 0.1159\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -7.8108 - val_accuracy: 0.1159\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -7.2493 - val_accuracy: 0.1159\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -8.2907 - val_accuracy: 0.0915\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -7.1599 - val_accuracy: 0.1159\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -7.4691 - val_accuracy: 0.1159\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -8.1282 - val_accuracy: 0.1159\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -7.4321 - val_accuracy: 0.1159\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -8.0246 - val_accuracy: 0.1098\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -7.3586 - val_accuracy: 0.1159\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -7.8758 - val_accuracy: 0.1037\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -7.9287 - val_accuracy: 0.1159\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -7.9547 - val_accuracy: 0.1159\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -7.7611 - val_accuracy: 0.1159\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -7.7418 - val_accuracy: 0.1159\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.2162 - val_accuracy: 0.1159\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -7.7922 - val_accuracy: 0.1159\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -8.0212 - val_accuracy: 0.1159\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -7.9623 - val_accuracy: 0.1159\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.8872 - val_accuracy: 0.1159\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.3317 - val_accuracy: 0.1159\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -7.5417 - val_accuracy: 0.1159\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -8.1288 - val_accuracy: 0.1159\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.0932 - val_accuracy: 0.1159\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.0724 - val_accuracy: 0.1159\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.2567 - val_accuracy: 0.1159\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -7.9491 - val_accuracy: 0.1159\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.2075 - val_accuracy: 0.1159\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.0535 - val_accuracy: 0.1159\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.4610 - val_accuracy: 0.1159\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -8.1061 - val_accuracy: 0.1159\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.2674 - val_accuracy: 0.1159\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.1440 - val_accuracy: 0.1159\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.2492 - val_accuracy: 0.1159\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.2874 - val_accuracy: 0.1159\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.3559 - val_accuracy: 0.1159\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.3255 - val_accuracy: 0.1159\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.4029 - val_accuracy: 0.1159\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.0193 - val_accuracy: 0.1159\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.7747 - val_accuracy: 0.1098\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.1519 - val_accuracy: 0.1159\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.5784 - val_accuracy: 0.1159\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.2164 - val_accuracy: 0.1159\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.5835 - val_accuracy: 0.1159\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.5064 - val_accuracy: 0.1159\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.6319 - val_accuracy: 0.1159\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.5657 - val_accuracy: 0.1159\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.5118 - val_accuracy: 0.1159\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.5301 - val_accuracy: 0.1159\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.4776 - val_accuracy: 0.1159\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.5321 - val_accuracy: 0.1159\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.6769 - val_accuracy: 0.1159\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.5169 - val_accuracy: 0.1159\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.6738 - val_accuracy: 0.1159\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.4580 - val_accuracy: 0.1159\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.7118 - val_accuracy: 0.1159\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.5866 - val_accuracy: 0.1159\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.8453 - val_accuracy: 0.1159\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -8.6821 - val_accuracy: 0.1159\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 9.9367e-04 - accuracy: 1.0000 - val_loss: -8.7011 - val_accuracy: 0.1159\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.7028e-04 - accuracy: 1.0000 - val_loss: -8.7642 - val_accuracy: 0.1159\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.5681e-04 - accuracy: 1.0000 - val_loss: -8.6678 - val_accuracy: 0.1159\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.1538e-04 - accuracy: 1.0000 - val_loss: -8.6698 - val_accuracy: 0.1159\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.4490e-04 - accuracy: 1.0000 - val_loss: -8.9489 - val_accuracy: 0.1159\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.7501e-04 - accuracy: 1.0000 - val_loss: -8.6510 - val_accuracy: 0.1159\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.1180e-04 - accuracy: 1.0000 - val_loss: -8.9180 - val_accuracy: 0.1159\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.6059e-04 - accuracy: 1.0000 - val_loss: -8.7873 - val_accuracy: 0.1159\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8.5034e-04 - accuracy: 1.0000 - val_loss: -8.9099 - val_accuracy: 0.1159\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.5926e-04 - accuracy: 1.0000 - val_loss: -8.7287 - val_accuracy: 0.1159\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.3234e-04 - accuracy: 1.0000 - val_loss: -8.9020 - val_accuracy: 0.1159\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.0257e-04 - accuracy: 1.0000 - val_loss: -8.7507 - val_accuracy: 0.1159\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 9.2818e-04 - accuracy: 1.0000 - val_loss: -9.0868 - val_accuracy: 0.1159\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.8559e-04 - accuracy: 1.0000 - val_loss: -8.7855 - val_accuracy: 0.1159\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.7670e-04 - accuracy: 1.0000 - val_loss: -8.9474 - val_accuracy: 0.1159\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.8904e-04 - accuracy: 1.0000 - val_loss: -9.0393 - val_accuracy: 0.1159\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.4808e-04 - accuracy: 1.0000 - val_loss: -8.9102 - val_accuracy: 0.1159\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.3098e-04 - accuracy: 1.0000 - val_loss: -9.1012 - val_accuracy: 0.1159\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 7.0460e-04 - accuracy: 1.0000 - val_loss: -8.9190 - val_accuracy: 0.1159\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.1311e-04 - accuracy: 1.0000 - val_loss: -9.0378 - val_accuracy: 0.1159\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.2102e-04 - accuracy: 1.0000 - val_loss: -9.1576 - val_accuracy: 0.1159\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.9577e-04 - accuracy: 1.0000 - val_loss: -8.8425 - val_accuracy: 0.1159\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.6454e-04 - accuracy: 1.0000 - val_loss: -9.1034 - val_accuracy: 0.1159\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.7571e-04 - accuracy: 1.0000 - val_loss: -9.0995 - val_accuracy: 0.1159\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 6.5621e-04 - accuracy: 1.0000 - val_loss: -9.0743 - val_accuracy: 0.1159\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.6779e-04 - accuracy: 1.0000 - val_loss: -9.0670 - val_accuracy: 0.1159\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 6.6258e-04 - accuracy: 1.0000 - val_loss: -9.2027 - val_accuracy: 0.1159\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.6838e-04 - accuracy: 1.0000 - val_loss: -9.0477 - val_accuracy: 0.1159\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.1679e-04 - accuracy: 1.0000 - val_loss: -9.2552 - val_accuracy: 0.1159\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.0244e-04 - accuracy: 1.0000 - val_loss: -9.0785 - val_accuracy: 0.1159\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 6.1286e-04 - accuracy: 1.0000 - val_loss: -9.1463 - val_accuracy: 0.1159\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.8571e-04 - accuracy: 1.0000 - val_loss: -9.1138 - val_accuracy: 0.1159\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 5.8279e-04 - accuracy: 1.0000 - val_loss: -9.1507 - val_accuracy: 0.1159\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 5.7613e-04 - accuracy: 1.0000 - val_loss: -9.1915 - val_accuracy: 0.1159\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 5.8042e-04 - accuracy: 1.0000 - val_loss: -9.1486 - val_accuracy: 0.1159\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 5.6656e-04 - accuracy: 1.0000 - val_loss: -9.2506 - val_accuracy: 0.1159\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.5038e-04 - accuracy: 1.0000 - val_loss: -9.2202 - val_accuracy: 0.1159\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.4045e-04 - accuracy: 1.0000 - val_loss: -9.2992 - val_accuracy: 0.1159\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.3104e-04 - accuracy: 1.0000 - val_loss: -9.1108 - val_accuracy: 0.1159\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 5.2668e-04 - accuracy: 1.0000 - val_loss: -9.3014 - val_accuracy: 0.1159\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 5.1307e-04 - accuracy: 1.0000 - val_loss: -9.4491 - val_accuracy: 0.1159\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 5.2132e-04 - accuracy: 1.0000 - val_loss: -9.1763 - val_accuracy: 0.1159\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.9900e-04 - accuracy: 1.0000 - val_loss: -9.4343 - val_accuracy: 0.1159\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.0161e-04 - accuracy: 1.0000 - val_loss: -9.2640 - val_accuracy: 0.1159\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 4.9059e-04 - accuracy: 1.0000 - val_loss: -9.2665 - val_accuracy: 0.1159\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.8805e-04 - accuracy: 1.0000 - val_loss: -9.3289 - val_accuracy: 0.1159\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.7615e-04 - accuracy: 1.0000 - val_loss: -9.3025 - val_accuracy: 0.1159\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 4.7188e-04 - accuracy: 1.0000 - val_loss: -9.4164 - val_accuracy: 0.1159\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 4.6563e-04 - accuracy: 1.0000 - val_loss: -9.4130 - val_accuracy: 0.1159\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 4.6510e-04 - accuracy: 1.0000 - val_loss: -9.3465 - val_accuracy: 0.1159\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.5085e-04 - accuracy: 1.0000 - val_loss: -9.3530 - val_accuracy: 0.1159\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.4064e-04 - accuracy: 1.0000 - val_loss: -9.4569 - val_accuracy: 0.1159\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.3807e-04 - accuracy: 1.0000 - val_loss: -9.4099 - val_accuracy: 0.1159\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.3373e-04 - accuracy: 1.0000 - val_loss: -9.4754 - val_accuracy: 0.1159\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.3074e-04 - accuracy: 1.0000 - val_loss: -9.4643 - val_accuracy: 0.1159\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.3008e-04 - accuracy: 1.0000 - val_loss: -9.3731 - val_accuracy: 0.1159\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.1365e-04 - accuracy: 1.0000 - val_loss: -9.5654 - val_accuracy: 0.1159\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 4.0486e-04 - accuracy: 1.0000 - val_loss: -9.4416 - val_accuracy: 0.1159\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.0572e-04 - accuracy: 1.0000 - val_loss: -9.4898 - val_accuracy: 0.1159\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.0687e-04 - accuracy: 1.0000 - val_loss: -9.4461 - val_accuracy: 0.1159\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.0934e-04 - accuracy: 1.0000 - val_loss: -9.5922 - val_accuracy: 0.1159\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.8719e-04 - accuracy: 1.0000 - val_loss: -9.4844 - val_accuracy: 0.1159\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 3.8763e-04 - accuracy: 1.0000 - val_loss: -9.6389 - val_accuracy: 0.1159\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.7875e-04 - accuracy: 1.0000 - val_loss: -9.5310 - val_accuracy: 0.1159\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 3.7830e-04 - accuracy: 1.0000 - val_loss: -9.5917 - val_accuracy: 0.1159\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.7046e-04 - accuracy: 1.0000 - val_loss: -9.5243 - val_accuracy: 0.1159\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.6640e-04 - accuracy: 1.0000 - val_loss: -9.7012 - val_accuracy: 0.1159\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 3.6221e-04 - accuracy: 1.0000 - val_loss: -9.6883 - val_accuracy: 0.1159\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 3.5858e-04 - accuracy: 1.0000 - val_loss: -9.5293 - val_accuracy: 0.1159\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 3.4698e-04 - accuracy: 1.0000 - val_loss: -9.6900 - val_accuracy: 0.1159\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.4949e-04 - accuracy: 1.0000 - val_loss: -9.5690 - val_accuracy: 0.1159\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.6029e-04 - accuracy: 1.0000 - val_loss: -9.6422 - val_accuracy: 0.1159\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.4313e-04 - accuracy: 1.0000 - val_loss: -9.6916 - val_accuracy: 0.1159\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.3604e-04 - accuracy: 1.0000 - val_loss: -9.6143 - val_accuracy: 0.1159\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.2676e-04 - accuracy: 1.0000 - val_loss: -9.7454 - val_accuracy: 0.1159\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.2600e-04 - accuracy: 1.0000 - val_loss: -9.6006 - val_accuracy: 0.1159\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.1989e-04 - accuracy: 1.0000 - val_loss: -9.7440 - val_accuracy: 0.1159\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.1831e-04 - accuracy: 1.0000 - val_loss: -9.6789 - val_accuracy: 0.1159\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 3.2738e-04 - accuracy: 1.0000 - val_loss: -9.6383 - val_accuracy: 0.1159\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.0391e-04 - accuracy: 1.0000 - val_loss: -9.8813 - val_accuracy: 0.1159\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.0720e-04 - accuracy: 1.0000 - val_loss: -9.7356 - val_accuracy: 0.1159\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 3.0997e-04 - accuracy: 1.0000 - val_loss: -9.7014 - val_accuracy: 0.1159\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.0965e-04 - accuracy: 1.0000 - val_loss: -9.7738 - val_accuracy: 0.1159\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.0022e-04 - accuracy: 1.0000 - val_loss: -9.6404 - val_accuracy: 0.1159\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.9388e-04 - accuracy: 1.0000 - val_loss: -9.9787 - val_accuracy: 0.1159\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8355e-04 - accuracy: 1.0000 - val_loss: -9.6856 - val_accuracy: 0.1159\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.8666e-04 - accuracy: 1.0000 - val_loss: -9.8743 - val_accuracy: 0.1159\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.7889e-04 - accuracy: 1.0000 - val_loss: -9.8176 - val_accuracy: 0.1159\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.7433e-04 - accuracy: 1.0000 - val_loss: -9.7753 - val_accuracy: 0.1159\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.7192e-04 - accuracy: 1.0000 - val_loss: -9.9355 - val_accuracy: 0.1159\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: -9.7181 - val_accuracy: 0.1159\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6914e-04 - accuracy: 1.0000 - val_loss: -10.0186 - val_accuracy: 0.1159\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.6159e-04 - accuracy: 1.0000 - val_loss: -9.7458 - val_accuracy: 0.1159\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.6037e-04 - accuracy: 1.0000 - val_loss: -9.9313 - val_accuracy: 0.1159\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5941e-04 - accuracy: 1.0000 - val_loss: -9.8541 - val_accuracy: 0.1159\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6481e-04 - accuracy: 1.0000 - val_loss: -9.7095 - val_accuracy: 0.1159\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6893e-04 - accuracy: 1.0000 - val_loss: -10.0413 - val_accuracy: 0.1159\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.4862e-04 - accuracy: 1.0000 - val_loss: -9.7712 - val_accuracy: 0.1159\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.4436e-04 - accuracy: 1.0000 - val_loss: -10.0822 - val_accuracy: 0.1159\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4477e-04 - accuracy: 1.0000 - val_loss: -9.9292 - val_accuracy: 0.1159\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.3672e-04 - accuracy: 1.0000 - val_loss: -9.8341 - val_accuracy: 0.1159\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.3437e-04 - accuracy: 1.0000 - val_loss: -10.0265 - val_accuracy: 0.1159\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.3581e-04 - accuracy: 1.0000 - val_loss: -9.8594 - val_accuracy: 0.1159\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.3117e-04 - accuracy: 1.0000 - val_loss: -10.0528 - val_accuracy: 0.1159\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.2953e-04 - accuracy: 1.0000 - val_loss: -9.9298 - val_accuracy: 0.1159\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.2201e-04 - accuracy: 1.0000 - val_loss: -10.0694 - val_accuracy: 0.1159\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 2s 25ms/step - loss: 0.6815 - accuracy: 0.5404 - val_loss: 0.2408 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6606 - accuracy: 0.6133 - val_loss: 0.4985 - val_accuracy: 0.1463\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6354 - accuracy: 0.6888 - val_loss: 0.2333 - val_accuracy: 0.1098\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6110 - accuracy: 0.6901 - val_loss: -0.0998 - val_accuracy: 0.0488\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5895 - accuracy: 0.6849 - val_loss: -0.0799 - val_accuracy: 0.1220\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7383 - val_loss: 0.0455 - val_accuracy: 0.1402\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5249 - accuracy: 0.7513 - val_loss: 0.4963 - val_accuracy: 0.1829\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5114 - accuracy: 0.7539 - val_loss: 0.8079 - val_accuracy: 0.1951\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.5025 - accuracy: 0.7539 - val_loss: 0.0652 - val_accuracy: 0.1829\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: -0.0468 - val_accuracy: 0.1768\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4582 - accuracy: 0.8047 - val_loss: -0.5653 - val_accuracy: 0.1585\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.7995 - val_loss: -0.3851 - val_accuracy: 0.1707\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4221 - accuracy: 0.8099 - val_loss: -1.0140 - val_accuracy: 0.1220\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7995 - val_loss: -1.4157 - val_accuracy: 0.0610\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: -1.0740 - val_accuracy: 0.1037\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8242 - val_loss: -1.0660 - val_accuracy: 0.1402\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3860 - accuracy: 0.8281 - val_loss: -1.1624 - val_accuracy: 0.1220\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8359 - val_loss: -1.1546 - val_accuracy: 0.1524\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3721 - accuracy: 0.8333 - val_loss: -1.5110 - val_accuracy: 0.1098\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3639 - accuracy: 0.8438 - val_loss: -1.6677 - val_accuracy: 0.1159\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.3534 - accuracy: 0.8464 - val_loss: -1.1838 - val_accuracy: 0.1524\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.8581 - val_loss: -1.4968 - val_accuracy: 0.1220\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.8555 - val_loss: -2.2417 - val_accuracy: 0.0915\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3174 - accuracy: 0.8594 - val_loss: -1.2752 - val_accuracy: 0.1585\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3419 - accuracy: 0.8490 - val_loss: -1.6953 - val_accuracy: 0.1220\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8372 - val_loss: -1.5906 - val_accuracy: 0.1098\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8438 - val_loss: -1.7333 - val_accuracy: 0.1159\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3060 - accuracy: 0.8685 - val_loss: -2.1289 - val_accuracy: 0.1037\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2748 - accuracy: 0.8984 - val_loss: -1.8169 - val_accuracy: 0.1220\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2859 - accuracy: 0.8880 - val_loss: -2.6175 - val_accuracy: 0.0793\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2701 - accuracy: 0.8984 - val_loss: -1.8753 - val_accuracy: 0.1280\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2623 - accuracy: 0.8945 - val_loss: -2.1142 - val_accuracy: 0.1220\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2650 - accuracy: 0.8906 - val_loss: -2.6723 - val_accuracy: 0.0976\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2352 - accuracy: 0.9141 - val_loss: -2.2776 - val_accuracy: 0.1037\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2233 - accuracy: 0.9206 - val_loss: -2.3635 - val_accuracy: 0.1280\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2224 - accuracy: 0.9167 - val_loss: -3.2118 - val_accuracy: 0.0793\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2098 - accuracy: 0.9206 - val_loss: -3.0498 - val_accuracy: 0.0976\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2096 - accuracy: 0.9258 - val_loss: -2.9258 - val_accuracy: 0.1037\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2310 - accuracy: 0.9049 - val_loss: -3.3187 - val_accuracy: 0.1037\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2501 - accuracy: 0.8984 - val_loss: -2.8359 - val_accuracy: 0.1098\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2008 - accuracy: 0.9245 - val_loss: -2.9639 - val_accuracy: 0.1280\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1998 - accuracy: 0.9297 - val_loss: -2.7033 - val_accuracy: 0.1159\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2075 - accuracy: 0.9167 - val_loss: -3.2118 - val_accuracy: 0.1098\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1774 - accuracy: 0.9440 - val_loss: -3.1604 - val_accuracy: 0.1220\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9427 - val_loss: -3.9145 - val_accuracy: 0.0671\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1541 - accuracy: 0.9518 - val_loss: -3.8949 - val_accuracy: 0.0854\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1480 - accuracy: 0.9570 - val_loss: -3.9071 - val_accuracy: 0.0793\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1456 - accuracy: 0.9531 - val_loss: -3.4957 - val_accuracy: 0.1220\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1339 - accuracy: 0.9622 - val_loss: -4.0491 - val_accuracy: 0.0976\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1201 - accuracy: 0.9648 - val_loss: -4.1753 - val_accuracy: 0.0793\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1464 - accuracy: 0.9505 - val_loss: -4.2716 - val_accuracy: 0.0915\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9440 - val_loss: -2.9793 - val_accuracy: 0.1585\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1872 - accuracy: 0.9258 - val_loss: -4.8847 - val_accuracy: 0.0610\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1599 - accuracy: 0.9505 - val_loss: -4.3953 - val_accuracy: 0.0854\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.9688 - val_loss: -3.8805 - val_accuracy: 0.1037\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1098 - accuracy: 0.9753 - val_loss: -3.7104 - val_accuracy: 0.1220\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1326 - accuracy: 0.9505 - val_loss: -5.0562 - val_accuracy: 0.0610\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 0.9635 - val_loss: -4.0700 - val_accuracy: 0.1098\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1118 - accuracy: 0.9609 - val_loss: -5.0569 - val_accuracy: 0.0610\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1372 - accuracy: 0.9479 - val_loss: -3.2698 - val_accuracy: 0.1646\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.9414 - val_loss: -4.1009 - val_accuracy: 0.0915\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1196 - accuracy: 0.9570 - val_loss: -3.8960 - val_accuracy: 0.1402\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1203 - accuracy: 0.9648 - val_loss: -5.3857 - val_accuracy: 0.0610\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0908 - accuracy: 0.9779 - val_loss: -5.3590 - val_accuracy: 0.0549\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0799 - accuracy: 0.9766 - val_loss: -4.3853 - val_accuracy: 0.1098\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9818 - val_loss: -5.4482 - val_accuracy: 0.0793\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0676 - accuracy: 0.9883 - val_loss: -4.8201 - val_accuracy: 0.0854\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.9831 - val_loss: -5.5544 - val_accuracy: 0.0915\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0690 - accuracy: 0.9831 - val_loss: -5.3045 - val_accuracy: 0.0976\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: -5.6740 - val_accuracy: 0.0671\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: -6.4764 - val_accuracy: 0.0671\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: -5.8736 - val_accuracy: 0.0793\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9805 - val_loss: -7.0019 - val_accuracy: 0.0427\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0702 - accuracy: 0.9805 - val_loss: -5.5407 - val_accuracy: 0.0976\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0614 - accuracy: 0.9779 - val_loss: -6.2598 - val_accuracy: 0.0671\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0591 - accuracy: 0.9831 - val_loss: -5.3019 - val_accuracy: 0.0976\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0695 - accuracy: 0.9818 - val_loss: -4.9860 - val_accuracy: 0.1159\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0738 - accuracy: 0.9818 - val_loss: -6.6000 - val_accuracy: 0.0610\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9779 - val_loss: -6.1483 - val_accuracy: 0.0732\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0518 - accuracy: 0.9883 - val_loss: -6.3414 - val_accuracy: 0.0732\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.9857 - val_loss: -6.5770 - val_accuracy: 0.0732\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0474 - accuracy: 0.9870 - val_loss: -7.4929 - val_accuracy: 0.0427\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: -5.6543 - val_accuracy: 0.1159\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9883 - val_loss: -6.1600 - val_accuracy: 0.0793\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0427 - accuracy: 0.9896 - val_loss: -6.6889 - val_accuracy: 0.0793\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: -7.6062 - val_accuracy: 0.0549\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: -7.0970 - val_accuracy: 0.0610\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0411 - accuracy: 0.9857 - val_loss: -6.8713 - val_accuracy: 0.0854\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9909 - val_loss: -8.2342 - val_accuracy: 0.0427\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0367 - accuracy: 0.9935 - val_loss: -6.6590 - val_accuracy: 0.0915\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0366 - accuracy: 0.9896 - val_loss: -7.2300 - val_accuracy: 0.0610\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0396 - accuracy: 0.9922 - val_loss: -8.5572 - val_accuracy: 0.0427\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9935 - val_loss: -7.7880 - val_accuracy: 0.0549\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: -7.7571 - val_accuracy: 0.0610\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0293 - accuracy: 0.9935 - val_loss: -8.2273 - val_accuracy: 0.0488\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9792 - val_loss: -8.2805 - val_accuracy: 0.0427\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0590 - accuracy: 0.9818 - val_loss: -6.7682 - val_accuracy: 0.1037\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: -7.8231 - val_accuracy: 0.0793\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9883 - val_loss: -6.9185 - val_accuracy: 0.0854\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9948 - val_loss: -7.1341 - val_accuracy: 0.0915\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: -8.5883 - val_accuracy: 0.0549\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9935 - val_loss: -7.3595 - val_accuracy: 0.1098\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: -7.2300 - val_accuracy: 0.0793\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9935 - val_loss: -7.7360 - val_accuracy: 0.0610\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9857 - val_loss: -8.3953 - val_accuracy: 0.0610\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: -7.3670 - val_accuracy: 0.0976\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 0.9766 - val_loss: -8.6188 - val_accuracy: 0.0610\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0636 - accuracy: 0.9753 - val_loss: -7.4550 - val_accuracy: 0.0854\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9818 - val_loss: -7.7264 - val_accuracy: 0.1098\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: -7.7928 - val_accuracy: 0.0610\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: -8.2161 - val_accuracy: 0.0671\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: -8.2188 - val_accuracy: 0.0732\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: -8.5945 - val_accuracy: 0.0671\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: -8.3399 - val_accuracy: 0.0854\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: -8.4020 - val_accuracy: 0.0793\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: -8.7450 - val_accuracy: 0.0732\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: -8.8653 - val_accuracy: 0.0610\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: -8.4837 - val_accuracy: 0.0976\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: -9.0780 - val_accuracy: 0.0610\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: -9.1979 - val_accuracy: 0.0610\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: -9.0319 - val_accuracy: 0.0549\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: -8.4687 - val_accuracy: 0.1037\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: -8.8846 - val_accuracy: 0.0793\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: -8.5119 - val_accuracy: 0.0976\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -8.6534 - val_accuracy: 0.0915\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: -9.3181 - val_accuracy: 0.0610\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -9.5481 - val_accuracy: 0.0549\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: -9.5179 - val_accuracy: 0.0549\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -8.5217 - val_accuracy: 0.1098\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: -9.4387 - val_accuracy: 0.0671\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -9.7436 - val_accuracy: 0.0610\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: -9.4913 - val_accuracy: 0.0671\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -9.4326 - val_accuracy: 0.0671\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -9.6874 - val_accuracy: 0.0671\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -9.8039 - val_accuracy: 0.0671\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -9.1633 - val_accuracy: 0.0976\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -9.5394 - val_accuracy: 0.0732\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: -9.5137 - val_accuracy: 0.0671\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -9.9484 - val_accuracy: 0.0671\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -9.8271 - val_accuracy: 0.0732\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -9.7397 - val_accuracy: 0.0793\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -9.7497 - val_accuracy: 0.0732\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -9.7336 - val_accuracy: 0.0793\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -10.0809 - val_accuracy: 0.0549\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: -9.8789 - val_accuracy: 0.0671\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -9.7807 - val_accuracy: 0.0793\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -10.0002 - val_accuracy: 0.0610\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: -10.7395 - val_accuracy: 0.0549\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: -9.4668 - val_accuracy: 0.0976\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: -9.3821 - val_accuracy: 0.0915\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: -9.9474 - val_accuracy: 0.0732\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -10.3063 - val_accuracy: 0.0549\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -9.8393 - val_accuracy: 0.0854\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -10.3182 - val_accuracy: 0.0610\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -10.2540 - val_accuracy: 0.0671\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -10.3167 - val_accuracy: 0.0610\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -9.9816 - val_accuracy: 0.0854\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -10.2179 - val_accuracy: 0.0732\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -10.6221 - val_accuracy: 0.0549\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -10.1915 - val_accuracy: 0.0793\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -10.4136 - val_accuracy: 0.0671\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -10.6833 - val_accuracy: 0.0549\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -10.4165 - val_accuracy: 0.0610\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.6281 - val_accuracy: 0.0610\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.4489 - val_accuracy: 0.0671\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.6553 - val_accuracy: 0.0549\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.5134 - val_accuracy: 0.0610\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -10.4450 - val_accuracy: 0.0671\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.6035 - val_accuracy: 0.0610\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -10.8732 - val_accuracy: 0.0549\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.5333 - val_accuracy: 0.0732\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -11.0585 - val_accuracy: 0.0549\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.0522 - val_accuracy: 0.0976\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -11.2553 - val_accuracy: 0.0549\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -10.3032 - val_accuracy: 0.0854\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.6777 - val_accuracy: 0.0610\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -10.9587 - val_accuracy: 0.0549\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -10.8793 - val_accuracy: 0.0610\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.7298 - val_accuracy: 0.0671\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -10.9435 - val_accuracy: 0.0610\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -11.0275 - val_accuracy: 0.0610\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -10.7373 - val_accuracy: 0.0732\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -10.9086 - val_accuracy: 0.0732\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -10.9638 - val_accuracy: 0.0610\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.7717e-04 - accuracy: 1.0000 - val_loss: -10.9638 - val_accuracy: 0.0610\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.7643e-04 - accuracy: 1.0000 - val_loss: -11.0338 - val_accuracy: 0.0610\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.6231e-04 - accuracy: 1.0000 - val_loss: -11.0379 - val_accuracy: 0.0549\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.3663e-04 - accuracy: 1.0000 - val_loss: -10.8859 - val_accuracy: 0.0732\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -11.1799 - val_accuracy: 0.0549\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -11.3426 - val_accuracy: 0.0549\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.8148e-04 - accuracy: 1.0000 - val_loss: -10.7476 - val_accuracy: 0.0732\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 9.1570e-04 - accuracy: 1.0000 - val_loss: -11.2559 - val_accuracy: 0.0549\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.0477e-04 - accuracy: 1.0000 - val_loss: -11.1602 - val_accuracy: 0.0671\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.4922e-04 - accuracy: 1.0000 - val_loss: -10.9841 - val_accuracy: 0.0732\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.7186e-04 - accuracy: 1.0000 - val_loss: -11.3858 - val_accuracy: 0.0549\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.8695e-04 - accuracy: 1.0000 - val_loss: -11.0026 - val_accuracy: 0.0671\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.1427e-04 - accuracy: 1.0000 - val_loss: -11.3375 - val_accuracy: 0.0610\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.1893e-04 - accuracy: 1.0000 - val_loss: -11.1896 - val_accuracy: 0.0671\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.1896e-04 - accuracy: 1.0000 - val_loss: -11.1459 - val_accuracy: 0.0793\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.7967e-04 - accuracy: 1.0000 - val_loss: -11.2626 - val_accuracy: 0.0610\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 7.8338e-04 - accuracy: 1.0000 - val_loss: -11.2501 - val_accuracy: 0.0610\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.7761e-04 - accuracy: 1.0000 - val_loss: -11.5205 - val_accuracy: 0.0549\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.5615e-04 - accuracy: 1.0000 - val_loss: -11.1100 - val_accuracy: 0.0793\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.7690e-04 - accuracy: 1.0000 - val_loss: -11.2587 - val_accuracy: 0.0732\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.7652e-04 - accuracy: 1.0000 - val_loss: -11.5624 - val_accuracy: 0.0610\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 7.3398e-04 - accuracy: 1.0000 - val_loss: -11.2290 - val_accuracy: 0.0732\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.0996e-04 - accuracy: 1.0000 - val_loss: -11.5878 - val_accuracy: 0.0549\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.0022e-04 - accuracy: 1.0000 - val_loss: -11.1933 - val_accuracy: 0.0732\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.1409e-04 - accuracy: 1.0000 - val_loss: -11.5027 - val_accuracy: 0.0610\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.5662e-04 - accuracy: 1.0000 - val_loss: -11.4063 - val_accuracy: 0.0671\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.3859e-04 - accuracy: 1.0000 - val_loss: -11.4397 - val_accuracy: 0.0671\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 6.3439e-04 - accuracy: 1.0000 - val_loss: -11.5223 - val_accuracy: 0.0549\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.1299e-04 - accuracy: 1.0000 - val_loss: -11.4391 - val_accuracy: 0.0671\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.2911e-04 - accuracy: 1.0000 - val_loss: -11.4881 - val_accuracy: 0.0610\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.8631e-04 - accuracy: 1.0000 - val_loss: -11.4584 - val_accuracy: 0.0671\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.0602e-04 - accuracy: 1.0000 - val_loss: -11.6061 - val_accuracy: 0.0549\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.8064e-04 - accuracy: 1.0000 - val_loss: -11.5673 - val_accuracy: 0.0610\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.7777e-04 - accuracy: 1.0000 - val_loss: -11.5799 - val_accuracy: 0.0610\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.6528e-04 - accuracy: 1.0000 - val_loss: -11.5702 - val_accuracy: 0.0671\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 5.5575e-04 - accuracy: 1.0000 - val_loss: -11.6746 - val_accuracy: 0.0549\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.5360e-04 - accuracy: 1.0000 - val_loss: -11.5857 - val_accuracy: 0.0732\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.5484e-04 - accuracy: 1.0000 - val_loss: -11.6014 - val_accuracy: 0.0732\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 5.2537e-04 - accuracy: 1.0000 - val_loss: -11.7607 - val_accuracy: 0.0549\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.2643e-04 - accuracy: 1.0000 - val_loss: -11.5975 - val_accuracy: 0.0732\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.3721e-04 - accuracy: 1.0000 - val_loss: -11.5917 - val_accuracy: 0.0671\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.2083e-04 - accuracy: 1.0000 - val_loss: -11.6908 - val_accuracy: 0.0610\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.1225e-04 - accuracy: 1.0000 - val_loss: -11.7329 - val_accuracy: 0.0610\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.1199e-04 - accuracy: 1.0000 - val_loss: -11.8004 - val_accuracy: 0.0610\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.9988e-04 - accuracy: 1.0000 - val_loss: -11.7332 - val_accuracy: 0.0671\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.8156e-04 - accuracy: 1.0000 - val_loss: -11.8313 - val_accuracy: 0.0610\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 4.8112e-04 - accuracy: 1.0000 - val_loss: -11.7435 - val_accuracy: 0.0732\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.8190e-04 - accuracy: 1.0000 - val_loss: -11.7394 - val_accuracy: 0.0732\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.6900e-04 - accuracy: 1.0000 - val_loss: -11.8882 - val_accuracy: 0.0671\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 4.6131e-04 - accuracy: 1.0000 - val_loss: -11.8084 - val_accuracy: 0.0610\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.6567e-04 - accuracy: 1.0000 - val_loss: -11.9978 - val_accuracy: 0.0549\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 4.6911e-04 - accuracy: 1.0000 - val_loss: -11.7910 - val_accuracy: 0.0793\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.3899e-04 - accuracy: 1.0000 - val_loss: -12.0404 - val_accuracy: 0.0549\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 4.6270e-04 - accuracy: 1.0000 - val_loss: -11.7128 - val_accuracy: 0.0793\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.7254e-04 - accuracy: 1.0000 - val_loss: -11.9767 - val_accuracy: 0.0671\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 4.4431e-04 - accuracy: 1.0000 - val_loss: -11.9525 - val_accuracy: 0.0549\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.2392e-04 - accuracy: 1.0000 - val_loss: -11.9402 - val_accuracy: 0.0732\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 4.1801e-04 - accuracy: 1.0000 - val_loss: -12.0029 - val_accuracy: 0.0610\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.1326e-04 - accuracy: 1.0000 - val_loss: -11.9369 - val_accuracy: 0.0671\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 3.9941e-04 - accuracy: 1.0000 - val_loss: -12.0303 - val_accuracy: 0.0671\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.0361e-04 - accuracy: 1.0000 - val_loss: -11.8856 - val_accuracy: 0.0732\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 3.9710e-04 - accuracy: 1.0000 - val_loss: -12.1723 - val_accuracy: 0.0549\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 4.1140e-04 - accuracy: 1.0000 - val_loss: -12.1194 - val_accuracy: 0.0610\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.7203e-04 - accuracy: 1.0000 - val_loss: -11.9378 - val_accuracy: 0.0732\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 3.9943e-04 - accuracy: 1.0000 - val_loss: -12.2217 - val_accuracy: 0.0549\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.8705e-04 - accuracy: 1.0000 - val_loss: -12.0807 - val_accuracy: 0.0732\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.7600e-04 - accuracy: 1.0000 - val_loss: -12.1159 - val_accuracy: 0.0732\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.8232e-04 - accuracy: 1.0000 - val_loss: -11.9958 - val_accuracy: 0.0732\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.8062e-04 - accuracy: 1.0000 - val_loss: -12.0638 - val_accuracy: 0.0793\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 3.5299e-04 - accuracy: 1.0000 - val_loss: -12.1057 - val_accuracy: 0.0671\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.4996e-04 - accuracy: 1.0000 - val_loss: -12.2547 - val_accuracy: 0.0549\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.6417e-04 - accuracy: 1.0000 - val_loss: -12.1374 - val_accuracy: 0.0610\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.8020e-04 - accuracy: 1.0000 - val_loss: -12.0228 - val_accuracy: 0.0732\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.4416e-04 - accuracy: 1.0000 - val_loss: -12.2132 - val_accuracy: 0.0671\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.4819e-04 - accuracy: 1.0000 - val_loss: -12.2382 - val_accuracy: 0.0549\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.2765e-04 - accuracy: 1.0000 - val_loss: -12.1958 - val_accuracy: 0.0732\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.3352e-04 - accuracy: 1.0000 - val_loss: -12.1583 - val_accuracy: 0.0732\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.2289e-04 - accuracy: 1.0000 - val_loss: -12.3809 - val_accuracy: 0.0549\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 3.1684e-04 - accuracy: 1.0000 - val_loss: -12.1231 - val_accuracy: 0.0732\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.1645e-04 - accuracy: 1.0000 - val_loss: -12.2420 - val_accuracy: 0.0610\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.1625e-04 - accuracy: 1.0000 - val_loss: -12.2423 - val_accuracy: 0.0732\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.0931e-04 - accuracy: 1.0000 - val_loss: -12.3204 - val_accuracy: 0.0549\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.0764e-04 - accuracy: 1.0000 - val_loss: -12.3082 - val_accuracy: 0.0671\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.1051e-04 - accuracy: 1.0000 - val_loss: -12.4920 - val_accuracy: 0.0549\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1130e-04 - accuracy: 1.0000 - val_loss: -12.1944 - val_accuracy: 0.0732\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.9082e-04 - accuracy: 1.0000 - val_loss: -12.4550 - val_accuracy: 0.0610\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.8406e-04 - accuracy: 1.0000 - val_loss: -12.2864 - val_accuracy: 0.0732\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 2.8628e-04 - accuracy: 1.0000 - val_loss: -12.5200 - val_accuracy: 0.0549\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 2.8074e-04 - accuracy: 1.0000 - val_loss: -12.3128 - val_accuracy: 0.0732\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.9380e-04 - accuracy: 1.0000 - val_loss: -12.5148 - val_accuracy: 0.0671\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 2.8046e-04 - accuracy: 1.0000 - val_loss: -12.4397 - val_accuracy: 0.0671\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7694e-04 - accuracy: 1.0000 - val_loss: -12.3746 - val_accuracy: 0.0671\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.9649e-04 - accuracy: 1.0000 - val_loss: -12.6223 - val_accuracy: 0.0549\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.6940e-04 - accuracy: 1.0000 - val_loss: -12.2990 - val_accuracy: 0.0793\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.8104e-04 - accuracy: 1.0000 - val_loss: -12.5794 - val_accuracy: 0.0549\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.6631e-04 - accuracy: 1.0000 - val_loss: -12.3971 - val_accuracy: 0.0732\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.6334e-04 - accuracy: 1.0000 - val_loss: -12.5089 - val_accuracy: 0.0671\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 2.5919e-04 - accuracy: 1.0000 - val_loss: -12.5605 - val_accuracy: 0.0671\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.4948e-04 - accuracy: 1.0000 - val_loss: -12.5339 - val_accuracy: 0.0671\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.5055e-04 - accuracy: 1.0000 - val_loss: -12.4355 - val_accuracy: 0.0732\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.5867e-04 - accuracy: 1.0000 - val_loss: -12.7326 - val_accuracy: 0.0610\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.6808e-04 - accuracy: 1.0000 - val_loss: -12.6489 - val_accuracy: 0.0610\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4697e-04 - accuracy: 1.0000 - val_loss: -12.4980 - val_accuracy: 0.0732\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.4150e-04 - accuracy: 1.0000 - val_loss: -12.6608 - val_accuracy: 0.0610\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.3107e-04 - accuracy: 1.0000 - val_loss: -12.5154 - val_accuracy: 0.0732\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3384e-04 - accuracy: 1.0000 - val_loss: -12.6526 - val_accuracy: 0.0671\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 2.2655e-04 - accuracy: 1.0000 - val_loss: -12.5629 - val_accuracy: 0.0732\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.2464e-04 - accuracy: 1.0000 - val_loss: -12.7072 - val_accuracy: 0.0610\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3600e-04 - accuracy: 1.0000 - val_loss: -12.7092 - val_accuracy: 0.0671\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.2916e-04 - accuracy: 1.0000 - val_loss: -12.5410 - val_accuracy: 0.0732\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.1838e-04 - accuracy: 1.0000 - val_loss: -12.7899 - val_accuracy: 0.0549\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1362e-04 - accuracy: 1.0000 - val_loss: -12.5716 - val_accuracy: 0.0793\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.1766e-04 - accuracy: 1.0000 - val_loss: -12.7680 - val_accuracy: 0.0732\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.0989e-04 - accuracy: 1.0000 - val_loss: -12.6655 - val_accuracy: 0.0732\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1118e-04 - accuracy: 1.0000 - val_loss: -12.7846 - val_accuracy: 0.0549\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.0939e-04 - accuracy: 1.0000 - val_loss: -12.6825 - val_accuracy: 0.0732\n"
     ]
    }
   ],
   "source": [
    "# grid = GridSearchCV(estimator, param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# mean_scores = grid_result.cv_results_['mean_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "\n",
    "# epochs = [param['epochs'] for param in params]\n",
    "# batch_sizes = [param['batch_size'] for param in params]\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# axs[0].scatter(epochs, mean_scores)\n",
    "# axs[0].set_xlabel('Epochs')\n",
    "# axs[0].set_ylabel('Mean Validation Score')\n",
    "# axs[0].set_title('Mean Validation Score vs Epochs')\n",
    "\n",
    "# axs[1].scatter(batch_sizes, mean_scores)\n",
    "# axs[1].set_xlabel('Batch Size')\n",
    "# axs[1].set_ylabel('Mean Validation Score')\n",
    "# axs[1].set_title('Mean Validation Score vs Batch Size')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.902344 using {'batch_size': 64, 'epochs': 300}\n",
      "0.899740 (0.015733) with: {'batch_size': 8, 'epochs': 100}\n",
      "0.899740 (0.014731) with: {'batch_size': 8, 'epochs': 200}\n",
      "0.890625 (0.019401) with: {'batch_size': 8, 'epochs': 300}\n",
      "0.890625 (0.016877) with: {'batch_size': 16, 'epochs': 100}\n",
      "0.877604 (0.013279) with: {'batch_size': 16, 'epochs': 200}\n",
      "0.891927 (0.012075) with: {'batch_size': 16, 'epochs': 300}\n",
      "0.886719 (0.016877) with: {'batch_size': 32, 'epochs': 100}\n",
      "0.873698 (0.021710) with: {'batch_size': 32, 'epochs': 200}\n",
      "0.884115 (0.020256) with: {'batch_size': 32, 'epochs': 300}\n",
      "0.873698 (0.058492) with: {'batch_size': 64, 'epochs': 100}\n",
      "0.901042 (0.016367) with: {'batch_size': 64, 'epochs': 200}\n",
      "0.902344 (0.011500) with: {'batch_size': 64, 'epochs': 300}\n"
     ]
    }
   ],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mean_scores = grid_result.cv_results_['mean_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "\n",
    "# epochs = np.array([param['epochs'] for param in params])\n",
    "# batch_sizes = np.array([param['batch_size'] for param in params])\n",
    "# accuracy = mean_scores * 100  \n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# scatter = plt.scatter(batch_sizes, epochs, c=accuracy, cmap='viridis', marker='o', zorder=2)\n",
    "\n",
    "# cbar = plt.colorbar(scatter)\n",
    "# cbar.set_label('Training Accuracy (%)')\n",
    "# plt.xlabel('Batch Size')\n",
    "# plt.ylabel('Number of Epochs')\n",
    "# plt.title('Accuracy vs Batch Size and Number of Epochs')\n",
    "\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = grid_result.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_baseline, epochs=300, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 18ms/step - loss: 0.6813 - accuracy: 0.5755 - val_loss: 0.7246 - val_accuracy: 0.1768\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.6615 - val_loss: 0.6334 - val_accuracy: 0.1524\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6237 - accuracy: 0.6576 - val_loss: 0.0687 - val_accuracy: 0.0854\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5867 - accuracy: 0.7253 - val_loss: 0.2097 - val_accuracy: 0.1341\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5528 - accuracy: 0.7188 - val_loss: 0.3688 - val_accuracy: 0.1707\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7396 - val_loss: 0.3653 - val_accuracy: 0.1707\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7617 - val_loss: -0.2903 - val_accuracy: 0.1524\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.7682 - val_loss: -0.1873 - val_accuracy: 0.1707\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4828 - accuracy: 0.7695 - val_loss: 0.2613 - val_accuracy: 0.1890\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.7669 - val_loss: -0.0076 - val_accuracy: 0.1768\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.7826 - val_loss: -0.4882 - val_accuracy: 0.1524\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.8021 - val_loss: -0.3790 - val_accuracy: 0.1829\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8190 - val_loss: -0.3603 - val_accuracy: 0.1890\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8138 - val_loss: -0.6858 - val_accuracy: 0.1646\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8359 - val_loss: -0.9017 - val_accuracy: 0.1585\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8424 - val_loss: -1.0870 - val_accuracy: 0.1463\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8503 - val_loss: -0.9071 - val_accuracy: 0.1585\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8411 - val_loss: -0.7293 - val_accuracy: 0.1646\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8503 - val_loss: -1.7410 - val_accuracy: 0.1037\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8659 - val_loss: -1.7314 - val_accuracy: 0.0976\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8776 - val_loss: -1.3381 - val_accuracy: 0.1463\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8620 - val_loss: -1.7666 - val_accuracy: 0.1220\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2951 - accuracy: 0.8763 - val_loss: -1.5963 - val_accuracy: 0.1402\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.8854 - val_loss: -2.1337 - val_accuracy: 0.1037\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.9010 - val_loss: -1.7558 - val_accuracy: 0.1280\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2742 - accuracy: 0.8919 - val_loss: -1.9537 - val_accuracy: 0.1220\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.8932 - val_loss: -2.3700 - val_accuracy: 0.0976\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9049 - val_loss: -2.2347 - val_accuracy: 0.0854\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.8789 - val_loss: -2.3044 - val_accuracy: 0.1037\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9154 - val_loss: -2.7553 - val_accuracy: 0.0854\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.8945 - val_loss: -1.7139 - val_accuracy: 0.1159\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9115 - val_loss: -2.0816 - val_accuracy: 0.1220\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2179 - accuracy: 0.9206 - val_loss: -2.5650 - val_accuracy: 0.1098\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.9206 - val_loss: -2.7022 - val_accuracy: 0.1098\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9141 - val_loss: -2.9739 - val_accuracy: 0.1037\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9414 - val_loss: -2.6961 - val_accuracy: 0.1220\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9427 - val_loss: -2.9055 - val_accuracy: 0.1098\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9427 - val_loss: -2.5150 - val_accuracy: 0.1220\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9492 - val_loss: -3.8220 - val_accuracy: 0.0854\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9375 - val_loss: -3.6128 - val_accuracy: 0.0793\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1648 - accuracy: 0.9453 - val_loss: -3.1418 - val_accuracy: 0.1159\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9388 - val_loss: -4.1321 - val_accuracy: 0.0671\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9479 - val_loss: -2.8434 - val_accuracy: 0.1220\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9583 - val_loss: -4.9703 - val_accuracy: 0.0549\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9323 - val_loss: -3.0364 - val_accuracy: 0.1341\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9570 - val_loss: -4.0809 - val_accuracy: 0.0854\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9583 - val_loss: -2.9591 - val_accuracy: 0.1159\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9531 - val_loss: -4.2257 - val_accuracy: 0.0793\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9518 - val_loss: -3.6134 - val_accuracy: 0.1098\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9622 - val_loss: -3.8740 - val_accuracy: 0.1098\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9753 - val_loss: -3.7838 - val_accuracy: 0.1037\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9701 - val_loss: -4.6618 - val_accuracy: 0.0793\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9648 - val_loss: -2.6091 - val_accuracy: 0.1402\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9401 - val_loss: -4.3088 - val_accuracy: 0.0915\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9661 - val_loss: -4.7850 - val_accuracy: 0.0671\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9753 - val_loss: -4.4329 - val_accuracy: 0.1098\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9701 - val_loss: -4.8773 - val_accuracy: 0.0793\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9792 - val_loss: -5.1521 - val_accuracy: 0.0732\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9857 - val_loss: -4.4026 - val_accuracy: 0.1159\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9792 - val_loss: -5.2355 - val_accuracy: 0.0671\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9844 - val_loss: -5.0670 - val_accuracy: 0.0793\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9844 - val_loss: -5.1967 - val_accuracy: 0.0793\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9831 - val_loss: -5.0872 - val_accuracy: 0.0854\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9870 - val_loss: -3.8644 - val_accuracy: 0.1098\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9714 - val_loss: -7.0339 - val_accuracy: 0.0244\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9544 - val_loss: -4.2263 - val_accuracy: 0.1037\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9766 - val_loss: -5.8701 - val_accuracy: 0.0671\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9779 - val_loss: -5.9295 - val_accuracy: 0.0610\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9818 - val_loss: -4.3916 - val_accuracy: 0.0915\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: -5.5928 - val_accuracy: 0.0671\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9870 - val_loss: -5.2748 - val_accuracy: 0.0793\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9896 - val_loss: -5.4414 - val_accuracy: 0.0854\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9883 - val_loss: -6.1242 - val_accuracy: 0.0610\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9922 - val_loss: -5.2445 - val_accuracy: 0.0854\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9896 - val_loss: -6.0527 - val_accuracy: 0.0732\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9948 - val_loss: -5.6234 - val_accuracy: 0.0854\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9961 - val_loss: -6.1184 - val_accuracy: 0.0732\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9935 - val_loss: -6.3467 - val_accuracy: 0.0793\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9961 - val_loss: -6.4087 - val_accuracy: 0.0732\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9974 - val_loss: -6.0047 - val_accuracy: 0.0793\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9948 - val_loss: -6.8315 - val_accuracy: 0.0610\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: -4.9204 - val_accuracy: 0.1037\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9883 - val_loss: -6.7410 - val_accuracy: 0.0793\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9909 - val_loss: -5.7344 - val_accuracy: 0.0793\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: -5.7392 - val_accuracy: 0.0854\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: -7.9666 - val_accuracy: 0.0488\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: -4.6781 - val_accuracy: 0.1280\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9909 - val_loss: -5.6591 - val_accuracy: 0.0793\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9987 - val_loss: -6.6222 - val_accuracy: 0.0732\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9987 - val_loss: -6.1096 - val_accuracy: 0.0793\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9974 - val_loss: -6.5685 - val_accuracy: 0.0732\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: -6.7294 - val_accuracy: 0.0732\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: -6.8401 - val_accuracy: 0.0732\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: -6.7803 - val_accuracy: 0.0732\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: -7.0902 - val_accuracy: 0.0732\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: -7.0404 - val_accuracy: 0.0732\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9987 - val_loss: -6.9523 - val_accuracy: 0.0732\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: -6.1922 - val_accuracy: 0.0915\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: -6.9261 - val_accuracy: 0.0793\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: -7.2092 - val_accuracy: 0.0732\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: -7.2845 - val_accuracy: 0.0671\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: -6.6894 - val_accuracy: 0.0854\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9987 - val_loss: -6.9310 - val_accuracy: 0.0854\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: -6.8184 - val_accuracy: 0.0793\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: -7.0258 - val_accuracy: 0.0793\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: -6.8805 - val_accuracy: 0.0854\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: -7.7038 - val_accuracy: 0.0732\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: -7.3749 - val_accuracy: 0.0732\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: -7.6408 - val_accuracy: 0.0671\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: -7.4479 - val_accuracy: 0.0732\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: -7.2320 - val_accuracy: 0.0793\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -7.3086 - val_accuracy: 0.0854\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: -7.8306 - val_accuracy: 0.0732\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: -8.0299 - val_accuracy: 0.0671\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: -7.9326 - val_accuracy: 0.0732\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: -8.0516 - val_accuracy: 0.0671\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: -8.4199 - val_accuracy: 0.0671\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: -8.1690 - val_accuracy: 0.0671\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: -7.7507 - val_accuracy: 0.0793\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: -7.9780 - val_accuracy: 0.0732\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -7.8272 - val_accuracy: 0.0793\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: -8.0272 - val_accuracy: 0.0732\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: -8.2359 - val_accuracy: 0.0732\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: -8.3091 - val_accuracy: 0.0671\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: -7.8432 - val_accuracy: 0.0793\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: -8.0526 - val_accuracy: 0.0732\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: -8.0253 - val_accuracy: 0.0793\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -8.3015 - val_accuracy: 0.0732\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: -8.2928 - val_accuracy: 0.0732\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.2936 - val_accuracy: 0.0732\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -7.9844 - val_accuracy: 0.0732\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: -8.1910 - val_accuracy: 0.0793\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: -8.5673 - val_accuracy: 0.0732\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -8.3109 - val_accuracy: 0.0732\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -8.2344 - val_accuracy: 0.0732\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: -8.6158 - val_accuracy: 0.0671\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: -8.4331 - val_accuracy: 0.0732\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: -8.4562 - val_accuracy: 0.0732\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.5069 - val_accuracy: 0.0732\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.6095 - val_accuracy: 0.0732\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.6228 - val_accuracy: 0.0671\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.6368 - val_accuracy: 0.0732\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.9063 - val_accuracy: 0.0732\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: -8.9051 - val_accuracy: 0.0671\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: -8.4190 - val_accuracy: 0.0732\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.7687 - val_accuracy: 0.0732\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.6955 - val_accuracy: 0.0732\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -8.3843 - val_accuracy: 0.0854\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: -9.1097 - val_accuracy: 0.0671\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: -8.8472 - val_accuracy: 0.0732\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: -8.4971 - val_accuracy: 0.0793\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: -8.6520 - val_accuracy: 0.0732\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -9.1288 - val_accuracy: 0.0671\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: -8.8747 - val_accuracy: 0.0732\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: -8.7876 - val_accuracy: 0.0732\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.7948 - val_accuracy: 0.0732\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: -8.8703 - val_accuracy: 0.0732\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.9170 - val_accuracy: 0.0732\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -9.1568 - val_accuracy: 0.0732\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: -8.9229 - val_accuracy: 0.0732\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.0326 - val_accuracy: 0.0732\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -8.9394 - val_accuracy: 0.0732\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.0100 - val_accuracy: 0.0732\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.1972 - val_accuracy: 0.0732\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: -9.2529 - val_accuracy: 0.0671\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: -9.1343 - val_accuracy: 0.0732\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.9240e-04 - accuracy: 1.0000 - val_loss: -9.1863 - val_accuracy: 0.0732\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.7670e-04 - accuracy: 1.0000 - val_loss: -9.3577 - val_accuracy: 0.0671\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.5211e-04 - accuracy: 1.0000 - val_loss: -9.1426 - val_accuracy: 0.0732\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.6624e-04 - accuracy: 1.0000 - val_loss: -9.1827 - val_accuracy: 0.0732\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.3386e-04 - accuracy: 1.0000 - val_loss: -9.2519 - val_accuracy: 0.0671\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.9435e-04 - accuracy: 1.0000 - val_loss: -9.1583 - val_accuracy: 0.0732\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.6488e-04 - accuracy: 1.0000 - val_loss: -9.3163 - val_accuracy: 0.0732\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.4884e-04 - accuracy: 1.0000 - val_loss: -9.4152 - val_accuracy: 0.0732\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.3719e-04 - accuracy: 1.0000 - val_loss: -9.2730 - val_accuracy: 0.0732\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.9564e-04 - accuracy: 1.0000 - val_loss: -9.3149 - val_accuracy: 0.0732\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.3709e-04 - accuracy: 1.0000 - val_loss: -9.6346 - val_accuracy: 0.0671\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.0692e-04 - accuracy: 1.0000 - val_loss: -9.1236 - val_accuracy: 0.0732\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.5605e-04 - accuracy: 1.0000 - val_loss: -9.6465 - val_accuracy: 0.0671\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.4818e-04 - accuracy: 1.0000 - val_loss: -9.4045 - val_accuracy: 0.0671\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0694e-04 - accuracy: 1.0000 - val_loss: -9.4391 - val_accuracy: 0.0732\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0160e-04 - accuracy: 1.0000 - val_loss: -9.5229 - val_accuracy: 0.0732\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0063e-04 - accuracy: 1.0000 - val_loss: -9.3336 - val_accuracy: 0.0732\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0106e-04 - accuracy: 1.0000 - val_loss: -9.6270 - val_accuracy: 0.0671\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.6158e-04 - accuracy: 1.0000 - val_loss: -9.3830 - val_accuracy: 0.0732\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.5036e-04 - accuracy: 1.0000 - val_loss: -9.5930 - val_accuracy: 0.0671\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.3715e-04 - accuracy: 1.0000 - val_loss: -9.4732 - val_accuracy: 0.0732\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.7984e-04 - accuracy: 1.0000 - val_loss: -9.3290 - val_accuracy: 0.0732\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.4980e-04 - accuracy: 1.0000 - val_loss: -9.6281 - val_accuracy: 0.0732\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.3560e-04 - accuracy: 1.0000 - val_loss: -9.7436 - val_accuracy: 0.0671\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.2380e-04 - accuracy: 1.0000 - val_loss: -9.5235 - val_accuracy: 0.0732\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.6890e-04 - accuracy: 1.0000 - val_loss: -9.5820 - val_accuracy: 0.0732\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.5658e-04 - accuracy: 1.0000 - val_loss: -9.7136 - val_accuracy: 0.0671\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.7647e-04 - accuracy: 1.0000 - val_loss: -9.4329 - val_accuracy: 0.0732\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.5192e-04 - accuracy: 1.0000 - val_loss: -9.8285 - val_accuracy: 0.0671\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.4210e-04 - accuracy: 1.0000 - val_loss: -9.6084 - val_accuracy: 0.0671\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.1859e-04 - accuracy: 1.0000 - val_loss: -9.6094 - val_accuracy: 0.0732\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.2091e-04 - accuracy: 1.0000 - val_loss: -9.7877 - val_accuracy: 0.0671\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.0029e-04 - accuracy: 1.0000 - val_loss: -9.6825 - val_accuracy: 0.0732\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.8057e-04 - accuracy: 1.0000 - val_loss: -9.7705 - val_accuracy: 0.0671\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.7179e-04 - accuracy: 1.0000 - val_loss: -9.7076 - val_accuracy: 0.0732\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.6008e-04 - accuracy: 1.0000 - val_loss: -9.7785 - val_accuracy: 0.0671\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.5644e-04 - accuracy: 1.0000 - val_loss: -9.7463 - val_accuracy: 0.0732\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.5643e-04 - accuracy: 1.0000 - val_loss: -9.8015 - val_accuracy: 0.0671\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.3591e-04 - accuracy: 1.0000 - val_loss: -9.8276 - val_accuracy: 0.0671\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.3423e-04 - accuracy: 1.0000 - val_loss: -9.8036 - val_accuracy: 0.0732\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1890e-04 - accuracy: 1.0000 - val_loss: -9.8338 - val_accuracy: 0.0732\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.1938e-04 - accuracy: 1.0000 - val_loss: -9.9274 - val_accuracy: 0.0671\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.1603e-04 - accuracy: 1.0000 - val_loss: -9.7749 - val_accuracy: 0.0732\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2515e-04 - accuracy: 1.0000 - val_loss: -10.0324 - val_accuracy: 0.0671\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.0850e-04 - accuracy: 1.0000 - val_loss: -9.9074 - val_accuracy: 0.0671\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9650e-04 - accuracy: 1.0000 - val_loss: -9.7174 - val_accuracy: 0.0732\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8699e-04 - accuracy: 1.0000 - val_loss: -10.1595 - val_accuracy: 0.0671\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.1853e-04 - accuracy: 1.0000 - val_loss: -9.7045 - val_accuracy: 0.0732\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.7022e-04 - accuracy: 1.0000 - val_loss: -10.1170 - val_accuracy: 0.0671\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7898e-04 - accuracy: 1.0000 - val_loss: -9.9303 - val_accuracy: 0.0671\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5413e-04 - accuracy: 1.0000 - val_loss: -9.9886 - val_accuracy: 0.0671\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5066e-04 - accuracy: 1.0000 - val_loss: -9.9610 - val_accuracy: 0.0671\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4511e-04 - accuracy: 1.0000 - val_loss: -9.8955 - val_accuracy: 0.0732\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.3865e-04 - accuracy: 1.0000 - val_loss: -10.0788 - val_accuracy: 0.0671\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.3099e-04 - accuracy: 1.0000 - val_loss: -10.1041 - val_accuracy: 0.0671\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2441e-04 - accuracy: 1.0000 - val_loss: -9.9744 - val_accuracy: 0.0671\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.1135e-04 - accuracy: 1.0000 - val_loss: -10.0717 - val_accuracy: 0.0671\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.1483e-04 - accuracy: 1.0000 - val_loss: -9.9858 - val_accuracy: 0.0671\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0886e-04 - accuracy: 1.0000 - val_loss: -10.1723 - val_accuracy: 0.0671\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.1467e-04 - accuracy: 1.0000 - val_loss: -9.8743 - val_accuracy: 0.0732\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.1169e-04 - accuracy: 1.0000 - val_loss: -10.1725 - val_accuracy: 0.0671\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0426e-04 - accuracy: 1.0000 - val_loss: -10.0911 - val_accuracy: 0.0671\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0201e-04 - accuracy: 1.0000 - val_loss: -10.0121 - val_accuracy: 0.0732\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9122e-04 - accuracy: 1.0000 - val_loss: -10.2179 - val_accuracy: 0.0671\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8661e-04 - accuracy: 1.0000 - val_loss: -10.0031 - val_accuracy: 0.0732\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7604e-04 - accuracy: 1.0000 - val_loss: -10.3220 - val_accuracy: 0.0671\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7664e-04 - accuracy: 1.0000 - val_loss: -10.0810 - val_accuracy: 0.0671\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6135e-04 - accuracy: 1.0000 - val_loss: -10.1990 - val_accuracy: 0.0671\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6362e-04 - accuracy: 1.0000 - val_loss: -10.1043 - val_accuracy: 0.0671\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6078e-04 - accuracy: 1.0000 - val_loss: -10.2499 - val_accuracy: 0.0671\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5353e-04 - accuracy: 1.0000 - val_loss: -10.1545 - val_accuracy: 0.0671\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5384e-04 - accuracy: 1.0000 - val_loss: -10.3018 - val_accuracy: 0.0671\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5256e-04 - accuracy: 1.0000 - val_loss: -10.1520 - val_accuracy: 0.0732\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4784e-04 - accuracy: 1.0000 - val_loss: -10.2085 - val_accuracy: 0.0671\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3752e-04 - accuracy: 1.0000 - val_loss: -10.2452 - val_accuracy: 0.0671\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3490e-04 - accuracy: 1.0000 - val_loss: -10.2757 - val_accuracy: 0.0671\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3402e-04 - accuracy: 1.0000 - val_loss: -10.1777 - val_accuracy: 0.0671\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2992e-04 - accuracy: 1.0000 - val_loss: -10.3490 - val_accuracy: 0.0671\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1970e-04 - accuracy: 1.0000 - val_loss: -10.2669 - val_accuracy: 0.0671\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1516e-04 - accuracy: 1.0000 - val_loss: -10.3603 - val_accuracy: 0.0671\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.1744e-04 - accuracy: 1.0000 - val_loss: -10.2389 - val_accuracy: 0.0671\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1545e-04 - accuracy: 1.0000 - val_loss: -10.3864 - val_accuracy: 0.0671\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0573e-04 - accuracy: 1.0000 - val_loss: -10.3293 - val_accuracy: 0.0671\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.0375e-04 - accuracy: 1.0000 - val_loss: -10.3009 - val_accuracy: 0.0671\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.0199e-04 - accuracy: 1.0000 - val_loss: -10.4696 - val_accuracy: 0.0671\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.9930e-04 - accuracy: 1.0000 - val_loss: -10.3292 - val_accuracy: 0.0671\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.9914e-04 - accuracy: 1.0000 - val_loss: -10.3828 - val_accuracy: 0.0671\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.9245e-04 - accuracy: 1.0000 - val_loss: -10.3968 - val_accuracy: 0.0671\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.9349e-04 - accuracy: 1.0000 - val_loss: -10.3690 - val_accuracy: 0.0671\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.9435e-04 - accuracy: 1.0000 - val_loss: -10.5348 - val_accuracy: 0.0671\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.8413e-04 - accuracy: 1.0000 - val_loss: -10.3426 - val_accuracy: 0.0671\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.8294e-04 - accuracy: 1.0000 - val_loss: -10.4804 - val_accuracy: 0.0671\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7653e-04 - accuracy: 1.0000 - val_loss: -10.3997 - val_accuracy: 0.0671\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7845e-04 - accuracy: 1.0000 - val_loss: -10.4822 - val_accuracy: 0.0671\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7413e-04 - accuracy: 1.0000 - val_loss: -10.4418 - val_accuracy: 0.0671\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7256e-04 - accuracy: 1.0000 - val_loss: -10.4636 - val_accuracy: 0.0671\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7016e-04 - accuracy: 1.0000 - val_loss: -10.5126 - val_accuracy: 0.0671\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6596e-04 - accuracy: 1.0000 - val_loss: -10.4489 - val_accuracy: 0.0671\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6216e-04 - accuracy: 1.0000 - val_loss: -10.5526 - val_accuracy: 0.0671\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6211e-04 - accuracy: 1.0000 - val_loss: -10.4592 - val_accuracy: 0.0671\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6114e-04 - accuracy: 1.0000 - val_loss: -10.5999 - val_accuracy: 0.0671\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6193e-04 - accuracy: 1.0000 - val_loss: -10.4570 - val_accuracy: 0.0671\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.5859e-04 - accuracy: 1.0000 - val_loss: -10.6643 - val_accuracy: 0.0671\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.6031e-04 - accuracy: 1.0000 - val_loss: -10.4644 - val_accuracy: 0.0671\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.5267e-04 - accuracy: 1.0000 - val_loss: -10.6208 - val_accuracy: 0.0671\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.5077e-04 - accuracy: 1.0000 - val_loss: -10.5644 - val_accuracy: 0.0671\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4649e-04 - accuracy: 1.0000 - val_loss: -10.6237 - val_accuracy: 0.0671\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4479e-04 - accuracy: 1.0000 - val_loss: -10.5156 - val_accuracy: 0.0671\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4161e-04 - accuracy: 1.0000 - val_loss: -10.6728 - val_accuracy: 0.0671\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4024e-04 - accuracy: 1.0000 - val_loss: -10.5349 - val_accuracy: 0.0671\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.3942e-04 - accuracy: 1.0000 - val_loss: -10.6709 - val_accuracy: 0.0671\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3741e-04 - accuracy: 1.0000 - val_loss: -10.5880 - val_accuracy: 0.0671\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3530e-04 - accuracy: 1.0000 - val_loss: -10.6686 - val_accuracy: 0.0671\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3418e-04 - accuracy: 1.0000 - val_loss: -10.6594 - val_accuracy: 0.0671\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3124e-04 - accuracy: 1.0000 - val_loss: -10.6043 - val_accuracy: 0.0671\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3016e-04 - accuracy: 1.0000 - val_loss: -10.6486 - val_accuracy: 0.0671\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2771e-04 - accuracy: 1.0000 - val_loss: -10.7124 - val_accuracy: 0.0671\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2728e-04 - accuracy: 1.0000 - val_loss: -10.7200 - val_accuracy: 0.0671\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2459e-04 - accuracy: 1.0000 - val_loss: -10.6699 - val_accuracy: 0.0671\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2624e-04 - accuracy: 1.0000 - val_loss: -10.7772 - val_accuracy: 0.0671\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2267e-04 - accuracy: 1.0000 - val_loss: -10.6775 - val_accuracy: 0.0671\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1972e-04 - accuracy: 1.0000 - val_loss: -10.7086 - val_accuracy: 0.0671\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2166e-04 - accuracy: 1.0000 - val_loss: -10.6613 - val_accuracy: 0.0671\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1903e-04 - accuracy: 1.0000 - val_loss: -10.7168 - val_accuracy: 0.0671\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1548e-04 - accuracy: 1.0000 - val_loss: -10.6700 - val_accuracy: 0.0671\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1382e-04 - accuracy: 1.0000 - val_loss: -10.8015 - val_accuracy: 0.0671\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1333e-04 - accuracy: 1.0000 - val_loss: -10.7370 - val_accuracy: 0.0671\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.1109e-04 - accuracy: 1.0000 - val_loss: -10.7975 - val_accuracy: 0.0671\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1051e-04 - accuracy: 1.0000 - val_loss: -10.6694 - val_accuracy: 0.0671\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1101e-04 - accuracy: 1.0000 - val_loss: -10.8648 - val_accuracy: 0.0671\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0865e-04 - accuracy: 1.0000 - val_loss: -10.7289 - val_accuracy: 0.0671\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0548e-04 - accuracy: 1.0000 - val_loss: -10.8200 - val_accuracy: 0.0671\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.0773e-04 - accuracy: 1.0000 - val_loss: -10.7784 - val_accuracy: 0.0671\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0444e-04 - accuracy: 1.0000 - val_loss: -10.7792 - val_accuracy: 0.0671\n"
     ]
    }
   ],
   "source": [
    "best_model = model.fit(X_train, y_train, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.7682926829268293\n",
      "F1 Score: 0.36666666666666664\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.85      0.86       135\n",
      "           1       0.35      0.38      0.37        29\n",
      "\n",
      "    accuracy                           0.77       164\n",
      "   macro avg       0.61      0.62      0.61       164\n",
      "weighted avg       0.77      0.77      0.77       164\n",
      "\n",
      "Confusion Matrix:\n",
      "[[115  20]\n",
      " [ 18  11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "classes = ['Not Upset', 'Upset']  \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
