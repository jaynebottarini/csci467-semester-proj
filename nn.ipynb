{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"matchups_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TEAM NO</th>\n",
       "      <th>DUNKS FG%</th>\n",
       "      <th>DUNKS SHARE</th>\n",
       "      <th>DUNKS FG%D</th>\n",
       "      <th>DUNKS D SHARE</th>\n",
       "      <th>CLOSE TWOS FG%</th>\n",
       "      <th>BADJ EM_x</th>\n",
       "      <th>BADJ O_x</th>\n",
       "      <th>BADJ D_x</th>\n",
       "      <th>...</th>\n",
       "      <th>BARTHAG_x_o</th>\n",
       "      <th>BADJ EM_y_o</th>\n",
       "      <th>BADJ O_y_o</th>\n",
       "      <th>BADJ D_y_o</th>\n",
       "      <th>BARTHAG_y_o</th>\n",
       "      <th>YEAR_o</th>\n",
       "      <th>SEED_o</th>\n",
       "      <th>CURRENT ROUND_o</th>\n",
       "      <th>GAME ID_o</th>\n",
       "      <th>UPSET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1011</td>\n",
       "      <td>88.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>85.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>60.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>121.6</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>102.4</td>\n",
       "      <td>104.4</td>\n",
       "      <td>0.445</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>979</td>\n",
       "      <td>80.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>86.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>59.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>118.1</td>\n",
       "      <td>97.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914</td>\n",
       "      <td>17.6</td>\n",
       "      <td>114.8</td>\n",
       "      <td>97.2</td>\n",
       "      <td>0.871</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>961</td>\n",
       "      <td>87.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>61.5</td>\n",
       "      <td>25.7</td>\n",
       "      <td>113.8</td>\n",
       "      <td>88.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819</td>\n",
       "      <td>9.4</td>\n",
       "      <td>108.1</td>\n",
       "      <td>98.7</td>\n",
       "      <td>0.740</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>76</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>946</td>\n",
       "      <td>89.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>81.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>60.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>110.8</td>\n",
       "      <td>91.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640</td>\n",
       "      <td>9.5</td>\n",
       "      <td>112.6</td>\n",
       "      <td>103.1</td>\n",
       "      <td>0.734</td>\n",
       "      <td>2023</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001</td>\n",
       "      <td>94.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>63.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>115.7</td>\n",
       "      <td>89.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840</td>\n",
       "      <td>15.2</td>\n",
       "      <td>113.0</td>\n",
       "      <td>97.8</td>\n",
       "      <td>0.840</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  TEAM NO  DUNKS FG%  DUNKS SHARE  DUNKS FG%D  DUNKS D SHARE  \\\n",
       "0           0     1011       88.7         13.0        85.2            5.3   \n",
       "1           1      979       80.2          6.7        86.7            5.8   \n",
       "2           2      961       87.5          7.8        75.0            5.4   \n",
       "3           3      946       89.7          9.4        81.5            5.2   \n",
       "4           4     1001       94.7         10.4        78.9            4.3   \n",
       "\n",
       "   CLOSE TWOS FG%  BADJ EM_x  BADJ O_x  BADJ D_x  ...  BARTHAG_x_o  \\\n",
       "0            60.7       33.0     121.6      88.6  ...        0.468   \n",
       "1            59.9       20.8     118.1      97.3  ...        0.914   \n",
       "2            61.5       25.7     113.8      88.1  ...        0.819   \n",
       "3            60.6       19.3     110.8      91.5  ...        0.640   \n",
       "4            63.6       26.3     115.7      89.4  ...        0.840   \n",
       "\n",
       "   BADJ EM_y_o  BADJ O_y_o  BADJ D_y_o  BARTHAG_y_o  YEAR_o  SEED_o  \\\n",
       "0         -2.0       102.4       104.4        0.445    2023      16   \n",
       "1         17.6       114.8        97.2        0.871    2023       9   \n",
       "2          9.4       108.1        98.7        0.740    2023      12   \n",
       "3          9.5       112.6       103.1        0.734    2023      13   \n",
       "4         15.2       113.0        97.8        0.840    2023      11   \n",
       "\n",
       "   CURRENT ROUND_o GAME ID_o  UPSET  \n",
       "0               64        74     -1  \n",
       "1               64        75     -1  \n",
       "2               64        76     -1  \n",
       "3               64        77      1  \n",
       "4               64        78     -1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [TEAM NO, DUNKS FG%, DUNKS SHARE, DUNKS FG%D, DUNKS D SHARE, CLOSE TWOS FG%, BADJ EM_x, BADJ O_x, BADJ D_x, BARTHAG_x, BADJ EM_y, BADJ O_y, BADJ D_y, BARTHAG_y, YEAR, BY YEAR NO, BY ROUND NO, TEAM, SEED, ROUND, CURRENT ROUND, SCORE, GAME ID, OUTCOME, TEAM NO_o, DUNKS FG%_o, DUNKS SHARE_o, DUNKS FG%D_o, DUNKS D SHARE_o, CLOSE TWOS FG%_o, BADJ EM_x_o, BADJ O_x_o, BADJ D_x_o, BARTHAG_x_o, BADJ EM_y_o, BADJ O_y_o, BADJ D_y_o, BARTHAG_y_o, YEAR_o, SEED_o, CURRENT ROUND_o, GAME ID_o, UPSET]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "rows_with_nan = matchups[matchups.isna().any(axis=1)]\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matchups.drop(columns=['OUTCOME', \"TEAM\", \"ROUND\", \"BY YEAR NO\", \"BY ROUND NO\", \"SCORE\", \"UPSET\", \"TEAM NO\", \"CURRENT ROUND_o\", \"TEAM NO_o\", \"GAME ID\", \"GAME ID_o\", \"YEAR_o\"])\n",
    "y = matchups['UPSET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_baseline at 0x000001370F95B060&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=400\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KerasClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_baseline at 0x000001370F95B060&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=400\n",
       "\tclass_weight=None\n",
       ")</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function create_baseline at 0x000001370F95B060>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=400\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(30,), activation='relu'))\n",
    "    model.add(Dense(128, input_shape=(128,), activation='relu'))\n",
    "    model.add(Dense(64, input_shape=(128,), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(model=create_baseline, epochs=400, batch_size=10, verbose=0)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7621951219512195\n"
     ]
    }
   ],
   "source": [
    "results = estimator.score(X_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeLayerMLP(hidden_dim=128,\n",
    "                              dropout_prob=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(0, slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(0, slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, X_train, y_train, X_dev, y_dev, lr, batch_size, num_epochs)\u001b[0m\n\u001b[0;32m     34\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)  \u001b[38;5;66;03m# (QUESTION 4a: line 2)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m                 \u001b[38;5;66;03m# Stochastic gradient descent optimizer\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Prepare the training dataset\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Pytorch DataLoader expects a dataset to be a list of (x, y) pairs\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# (QUESTION 4a: line 3)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Simple version of early stopping: save the best model checkpoint based on dev accuracy\u001b[39;00m\n\u001b[0;32m     42\u001b[0m best_dev_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# (QUESTION 4a: line 4)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     34\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)  \u001b[38;5;66;03m# (QUESTION 4a: line 2)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m                 \u001b[38;5;66;03m# Stochastic gradient descent optimizer\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Prepare the training dataset\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Pytorch DataLoader expects a dataset to be a list of (x, y) pairs\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m [(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, y_train[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_train))] \u001b[38;5;66;03m# (QUESTION 4a: line 3)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Simple version of early stopping: save the best model checkpoint based on dev accuracy\u001b[39;00m\n\u001b[0;32m     42\u001b[0m best_dev_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# (QUESTION 4a: line 4)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (0, slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "train(model, X_train, y_train, X_val, y_val, lr=0.0001,\n",
    "          batch_size=16, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=5, scoring='accuracy', verbose=1)\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sign(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN(model, criterion, optimizer, X_train, y_train, num_epochs=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        inputs = torch.from_numpy(X_train).float()\n",
    "        targets = torch.from_numpy(y_train).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 3.1358\n",
      "Epoch [20/100], Loss: 3.1358\n",
      "Epoch [30/100], Loss: 3.1358\n",
      "Epoch [40/100], Loss: 3.1358\n",
      "Epoch [50/100], Loss: 3.1358\n",
      "Epoch [60/100], Loss: 3.1358\n",
      "Epoch [70/100], Loss: 3.1358\n",
      "Epoch [80/100], Loss: 3.1358\n",
      "Epoch [90/100], Loss: 3.1358\n",
      "Epoch [100/100], Loss: 3.1358\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "input_size = 30\n",
    "hidden_size = 5\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "y_train = y_train.values.reshape(-1, 1)\n",
    "\n",
    "train_NN(model, criterion, optimizer, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(test_inputs)\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:87\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     85\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m     86\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_pred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:316\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:171\u001b[0m, in \u001b[0;36mis_multilabel\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    169\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:951\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    949\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 951\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    955\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "test_inputs = torch.from_numpy(X_test).float()\n",
    "y_pred = model(test_inputs)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00951641]\n",
      " [0.00609006]\n",
      " [0.00696848]\n",
      " [0.0102385 ]\n",
      " [0.01221258]\n",
      " [0.00624028]\n",
      " [0.01551387]\n",
      " [0.01120417]\n",
      " [0.01255063]\n",
      " [0.01107905]\n",
      " [0.00798607]\n",
      " [0.01258259]\n",
      " [0.00660738]\n",
      " [0.00830946]\n",
      " [0.00697922]\n",
      " [0.02008639]\n",
      " [0.00730779]\n",
      " [0.00812393]\n",
      " [0.00750722]\n",
      " [0.01016658]\n",
      " [0.01010038]\n",
      " [0.01309676]\n",
      " [0.01128656]\n",
      " [0.00921994]\n",
      " [0.00685391]\n",
      " [0.01338949]\n",
      " [0.00690694]\n",
      " [0.01225213]\n",
      " [0.00766718]\n",
      " [0.00884771]\n",
      " [0.00701987]\n",
      " [0.00628808]\n",
      " [0.0083915 ]\n",
      " [0.01038788]\n",
      " [0.00891119]\n",
      " [0.01355849]\n",
      " [0.01155873]\n",
      " [0.00798309]\n",
      " [0.0081931 ]\n",
      " [0.00990274]\n",
      " [0.00995898]\n",
      " [0.00889685]\n",
      " [0.00851073]\n",
      " [0.01117069]\n",
      " [0.01378911]\n",
      " [0.01342402]\n",
      " [0.01110784]\n",
      " [0.01750607]\n",
      " [0.0082528 ]\n",
      " [0.0098368 ]\n",
      " [0.00984471]\n",
      " [0.00614973]\n",
      " [0.01081772]\n",
      " [0.00706888]\n",
      " [0.01166881]\n",
      " [0.00654483]\n",
      " [0.00621019]\n",
      " [0.00893396]\n",
      " [0.00621351]\n",
      " [0.00885075]\n",
      " [0.01131735]\n",
      " [0.01249632]\n",
      " [0.01027555]\n",
      " [0.00896223]\n",
      " [0.01373771]\n",
      " [0.00715913]\n",
      " [0.00834258]\n",
      " [0.01061673]\n",
      " [0.01441155]\n",
      " [0.01117294]\n",
      " [0.01333233]\n",
      " [0.00522253]\n",
      " [0.00716616]\n",
      " [0.01191185]\n",
      " [0.01013607]\n",
      " [0.01051188]\n",
      " [0.01112787]\n",
      " [0.01089342]\n",
      " [0.01376736]\n",
      " [0.01092204]\n",
      " [0.00735025]\n",
      " [0.01058549]\n",
      " [0.01400485]\n",
      " [0.00769398]\n",
      " [0.00539565]\n",
      " [0.00704047]\n",
      " [0.01116274]\n",
      " [0.01832244]\n",
      " [0.01383184]\n",
      " [0.01188827]\n",
      " [0.01827009]\n",
      " [0.0093079 ]\n",
      " [0.00699609]\n",
      " [0.01488714]\n",
      " [0.01312789]\n",
      " [0.01432244]\n",
      " [0.00741146]\n",
      " [0.00932468]\n",
      " [0.01127106]\n",
      " [0.0147763 ]\n",
      " [0.00953561]\n",
      " [0.00674476]\n",
      " [0.00762358]\n",
      " [0.01142296]\n",
      " [0.0110214 ]\n",
      " [0.00797486]\n",
      " [0.0078876 ]\n",
      " [0.00994338]\n",
      " [0.01487468]\n",
      " [0.01109984]\n",
      " [0.00842109]\n",
      " [0.01275613]\n",
      " [0.0105464 ]\n",
      " [0.00848788]\n",
      " [0.01349078]\n",
      " [0.01430834]\n",
      " [0.01196926]\n",
      " [0.00957419]\n",
      " [0.00859939]\n",
      " [0.0089921 ]\n",
      " [0.00899745]\n",
      " [0.01107699]\n",
      " [0.00948416]\n",
      " [0.00908013]\n",
      " [0.00706212]\n",
      " [0.00921887]\n",
      " [0.01068259]\n",
      " [0.00635144]\n",
      " [0.00769864]\n",
      " [0.00777588]\n",
      " [0.00765456]\n",
      " [0.01039079]\n",
      " [0.01022419]\n",
      " [0.00765828]\n",
      " [0.00551323]\n",
      " [0.00893084]\n",
      " [0.00822276]\n",
      " [0.0093712 ]\n",
      " [0.00830884]\n",
      " [0.00452131]\n",
      " [0.01457815]\n",
      " [0.00797945]\n",
      " [0.00772166]\n",
      " [0.00910489]\n",
      " [0.01226621]\n",
      " [0.01003815]\n",
      " [0.00744875]\n",
      " [0.0071504 ]\n",
      " [0.01302814]\n",
      " [0.00896435]\n",
      " [0.00689715]\n",
      " [0.00935035]\n",
      " [0.01118567]\n",
      " [0.00886414]\n",
      " [0.01409639]\n",
      " [0.00944551]\n",
      " [0.00638221]\n",
      " [0.00845314]\n",
      " [0.01046972]\n",
      " [0.00746244]\n",
      " [0.01320568]\n",
      " [0.00580345]\n",
      " [0.01344587]\n",
      " [0.00833383]]\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, average, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75862069, 0.7388535 , 0.19256757, ..., 0.48701299, 0.54342105,\n",
       "        0.8       ],\n",
       "       [0.77155172, 0.46496815, 0.42567568, ..., 0.33766234, 0.82631579,\n",
       "        0.46666667],\n",
       "       [0.85344828, 0.68789809, 0.25337838, ..., 0.37012987, 0.83026316,\n",
       "        0.46666667],\n",
       "       ...,\n",
       "       [0.77301484, 0.49781433, 0.46743152, ..., 0.33656025, 0.84725906,\n",
       "        0.31020942],\n",
       "       [0.63362069, 0.78343949, 0.53378378, ..., 0.38961039, 0.82894737,\n",
       "        0.46666667],\n",
       "       [0.83189655, 0.17834395, 0.57094595, ..., 0.50974026, 0.83289474,\n",
       "        0.6       ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 30)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.625     , 0.2611465 , 0.65540541, ..., 0.69480519, 0.45789474,\n",
       "        0.93333333],\n",
       "       [0.93103448, 0.50318471, 0.61148649, ..., 0.3538961 , 0.78421053,\n",
       "        0.53333333],\n",
       "       [0.81034483, 0.56687898, 0.80405405, ..., 0.31818182, 0.90657895,\n",
       "        0.2       ],\n",
       "       ...,\n",
       "       [0.76724138, 0.64968153, 0.61824324, ..., 0.47727273, 0.89342105,\n",
       "        0.06666667],\n",
       "       [0.43103448, 0.23566879, 0.68581081, ..., 0.20454545, 0.93947368,\n",
       "        0.06666667],\n",
       "       [0.83189655, 0.40764331, 0.52364865, ..., 0.2987013 , 0.88552632,\n",
       "        0.53333333]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137   -1\n",
       "377    1\n",
       "388   -1\n",
       "824    1\n",
       "767    1\n",
       "      ..\n",
       "106   -1\n",
       "270    1\n",
       "860    1\n",
       "435    1\n",
       "102   -1\n",
       "Name: UPSET, Length: 819, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86     1\n",
       "431   -1\n",
       "798   -1\n",
       "497   -1\n",
       "805   -1\n",
       "      ..\n",
       "209   -1\n",
       "445   -1\n",
       "762   -1\n",
       "522   -1\n",
       "519   -1\n",
       "Name: UPSET, Length: 164, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.count of 86     1\n",
      "431   -1\n",
      "798   -1\n",
      "497   -1\n",
      "805   -1\n",
      "      ..\n",
      "209   -1\n",
      "445   -1\n",
      "762   -1\n",
      "522   -1\n",
      "519   -1\n",
      "Name: UPSET, Length: 164, dtype: int64>\n"
     ]
    }
   ],
   "source": [
    "print(y_test.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(neurons_per_layer, lr, reg_rate, num_hidden_layers):\n",
    "    inputs = Input(shape=(30,))\n",
    "    hidden = inputs\n",
    "    for i in range(num_hidden_layers):\n",
    "        hidden = Dense(neurons_per_layer, activation='relu', kernel_regularizer=l2(reg_rate))(hidden)\n",
    "    outputs = Dense(1, activation='sigmoid')(hidden)\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 5ms/step - loss: 2.1307 - accuracy: 0.0000e+00 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.8135 - accuracy: 0.0000e+00 - val_loss: 1.6848 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.6257 - accuracy: 0.0000e+00 - val_loss: 1.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.4989 - accuracy: 0.0000e+00 - val_loss: 1.4031 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.3839 - accuracy: 0.0000e+00 - val_loss: 1.3099 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2926 - accuracy: 0.0000e+00 - val_loss: 1.2142 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2110 - accuracy: 0.0000e+00 - val_loss: 1.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1383 - accuracy: 0.0000e+00 - val_loss: 1.0648 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0686 - accuracy: 0.0000e+00 - val_loss: 0.9923 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0008 - accuracy: 0.0000e+00 - val_loss: 0.9301 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.0000e+00 - val_loss: 0.8685 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8812 - accuracy: 0.0000e+00 - val_loss: 0.8083 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.0000e+00 - val_loss: 0.7551 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7754 - accuracy: 0.0000e+00 - val_loss: 0.7035 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.0000e+00 - val_loss: 0.6483 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.0000e+00 - val_loss: 0.6045 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.0000e+00 - val_loss: 0.5605 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.0000e+00 - val_loss: 0.5143 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.0000e+00 - val_loss: 0.4733 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.0000e+00 - val_loss: 0.4367 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.0000e+00 - val_loss: 0.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.0000e+00 - val_loss: 0.3541 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.0000e+00 - val_loss: 0.3209 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.0000e+00 - val_loss: 0.2777 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.0000e+00 - val_loss: 0.2394 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.0000e+00 - val_loss: 0.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.0000e+00 - val_loss: 0.1604 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.0000e+00 - val_loss: 0.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.0000e+00 - val_loss: 0.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.0000e+00 - val_loss: 0.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.0000e+00 - val_loss: -0.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.0000e+00 - val_loss: -0.0568 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: -0.1042 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.0053 - accuracy: 0.0000e+00 - val_loss: -0.1544 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.0432 - accuracy: 0.0000e+00 - val_loss: -0.2140 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.1191 - accuracy: 0.0000e+00 - val_loss: -0.2732 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.1738 - accuracy: 0.0000e+00 - val_loss: -0.3331 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.2280 - accuracy: 0.0000e+00 - val_loss: -0.3969 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.2918 - accuracy: 0.0000e+00 - val_loss: -0.4720 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.3577 - accuracy: 0.0000e+00 - val_loss: -0.5419 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.4267 - accuracy: 0.0000e+00 - val_loss: -0.6207 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.4760 - accuracy: 0.0000e+00 - val_loss: -0.7050 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.5663 - accuracy: 0.0000e+00 - val_loss: -0.7945 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.6506 - accuracy: 0.0000e+00 - val_loss: -0.8797 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.7462 - accuracy: 0.0000e+00 - val_loss: -0.9926 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -0.8225 - accuracy: 0.0000e+00 - val_loss: -1.0920 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: -0.9035 - accuracy: 0.0000e+00 - val_loss: -1.2352 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -1.0114 - accuracy: 0.0000e+00 - val_loss: -1.3291 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -1.1430 - accuracy: 0.0000e+00 - val_loss: -1.4385 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -1.2505 - accuracy: 0.0000e+00 - val_loss: -1.5825 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -1.3859 - accuracy: 0.0000e+00 - val_loss: -1.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -1.5017 - accuracy: 0.0000e+00 - val_loss: -1.8692 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -1.6432 - accuracy: 0.0012 - val_loss: -2.0393 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -1.7862 - accuracy: 0.0000e+00 - val_loss: -2.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: -1.9539 - accuracy: 0.0061 - val_loss: -2.3795 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -2.1321 - accuracy: 0.0049 - val_loss: -2.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -2.2649 - accuracy: 0.0024 - val_loss: -2.7744 - val_accuracy: 0.0049\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -2.4749 - accuracy: 0.0024 - val_loss: -2.9782 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -2.6636 - accuracy: 0.0037 - val_loss: -3.1880 - val_accuracy: 0.0049\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -2.8614 - accuracy: 0.0073 - val_loss: -3.4223 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -3.0552 - accuracy: 0.0049 - val_loss: -3.6419 - val_accuracy: 0.0049\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -3.2874 - accuracy: 0.0085 - val_loss: -3.9210 - val_accuracy: 0.0049\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -3.5207 - accuracy: 0.0085 - val_loss: -4.1736 - val_accuracy: 0.0049\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -3.7457 - accuracy: 0.0134 - val_loss: -4.4431 - val_accuracy: 0.0049\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -3.9917 - accuracy: 0.0159 - val_loss: -4.6953 - val_accuracy: 0.0049\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: -4.2820 - accuracy: 0.0061 - val_loss: -4.9978 - val_accuracy: 0.0049\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -4.5427 - accuracy: 0.0061 - val_loss: -5.3045 - val_accuracy: 0.0049\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -4.8044 - accuracy: 0.0110 - val_loss: -5.6104 - val_accuracy: 0.0049\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -5.0667 - accuracy: 0.0110 - val_loss: -5.9547 - val_accuracy: 0.0049\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -5.4150 - accuracy: 0.0061 - val_loss: -6.3052 - val_accuracy: 0.0049\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -5.7153 - accuracy: 0.0134 - val_loss: -6.6559 - val_accuracy: 0.0049\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -6.0497 - accuracy: 0.0061 - val_loss: -7.0394 - val_accuracy: 0.0049\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -6.3855 - accuracy: 0.0085 - val_loss: -7.4328 - val_accuracy: 0.0049\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -6.7333 - accuracy: 0.0134 - val_loss: -7.7886 - val_accuracy: 0.0195\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -7.1136 - accuracy: 0.0122 - val_loss: -8.2152 - val_accuracy: 0.0049\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -7.4043 - accuracy: 0.0037 - val_loss: -8.6763 - val_accuracy: 0.0049\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -7.7892 - accuracy: 0.0195 - val_loss: -9.0528 - val_accuracy: 0.0244\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -8.2569 - accuracy: 0.0269 - val_loss: -9.4855 - val_accuracy: 0.0049\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -8.6340 - accuracy: 0.0110 - val_loss: -9.9364 - val_accuracy: 0.0098\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: -9.0167 - accuracy: 0.0122 - val_loss: -10.3978 - val_accuracy: 0.0146\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -9.4540 - accuracy: 0.0171 - val_loss: -10.8724 - val_accuracy: 0.0098\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -9.9027 - accuracy: 0.0085 - val_loss: -11.3665 - val_accuracy: 0.0098\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -10.3401 - accuracy: 0.0269 - val_loss: -11.8488 - val_accuracy: 0.0146\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: -10.7741 - accuracy: 0.0061 - val_loss: -12.3767 - val_accuracy: 0.0049\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -11.2470 - accuracy: 0.0171 - val_loss: -12.8823 - val_accuracy: 0.0195\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -11.7303 - accuracy: 0.0256 - val_loss: -13.3964 - val_accuracy: 0.0195\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -12.1705 - accuracy: 0.0159 - val_loss: -13.9226 - val_accuracy: 0.0049\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -12.6878 - accuracy: 0.0085 - val_loss: -14.5085 - val_accuracy: 0.0049\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -13.1734 - accuracy: 0.0085 - val_loss: -15.1700 - val_accuracy: 0.0098\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -13.8040 - accuracy: 0.0147 - val_loss: -15.6856 - val_accuracy: 0.0146\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -14.3257 - accuracy: 0.0122 - val_loss: -16.3288 - val_accuracy: 0.0098\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -14.8605 - accuracy: 0.0256 - val_loss: -16.9299 - val_accuracy: 0.0098\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -15.2968 - accuracy: 0.0183 - val_loss: -17.5262 - val_accuracy: 0.0049\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -15.9585 - accuracy: 0.0049 - val_loss: -18.2800 - val_accuracy: 0.0049\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: -16.6631 - accuracy: 0.0073 - val_loss: -18.9582 - val_accuracy: 0.0098\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -17.2124 - accuracy: 0.0293 - val_loss: -19.6111 - val_accuracy: 0.0146\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -17.8892 - accuracy: 0.0098 - val_loss: -20.3595 - val_accuracy: 0.0098\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -18.5080 - accuracy: 0.0134 - val_loss: -21.0401 - val_accuracy: 0.0049\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -19.0977 - accuracy: 0.0159 - val_loss: -21.7586 - val_accuracy: 0.0098\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: -19.8016 - accuracy: 0.0147 - val_loss: -22.5189 - val_accuracy: 0.0195\n",
      "6/6 [==============================] - 0s 3ms/step - loss: -63.7097 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = NN(128, 0.0001, 0.01, 2)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_val, y_val))\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: -132987486157668352.0000 - accuracy: 0.1768\n",
      "Test Loss: -1.3298748615766835e+17, Test Accuracy: 0.1768292635679245\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 2ms/step - loss: 2.2728 - accuracy: 9.7656e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7073170731707317\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train)\n",
    "\n",
    "loss_values = history.history['loss']\n",
    "\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7378048780487805\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.82      0.84       135\n",
      "           1       0.29      0.34      0.32        29\n",
      "\n",
      "    accuracy                           0.74       164\n",
      "   macro avg       0.57      0.58      0.58       164\n",
      "weighted avg       0.75      0.74      0.75       164\n",
      "\n",
      "Confusion Matrix:\n",
      "[[111  24]\n",
      " [ 19  10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X_train, y_train, X_val, y_val, params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(torch.unique(y_train))\n",
    "\n",
    "    model = NN(input_dim, params['hidden_dim'], output_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(predicted.numpy(), y_val.numpy())\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_dim': [5, 10, 20],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'num_epochs': [50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mtrain_nn, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(y_train))\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=train_nn, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_accuracy = train_nn(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train),\n",
    "                         torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val),\n",
    "                         best_params)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Validation accuracy with best hyperparameters:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=train_nn, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter lr for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(lr=0.001)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:878\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    871\u001b[0m score_params_test \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mscore_params, indices\u001b[38;5;241m=\u001b[39mtest)\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# here we clone the parameters, since sometimes the parameters\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# themselves might be estimators, e.g. when we search over different\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;66;03m# estimators in a pipeline.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# ref: https://github.com/scikit-learn/scikit-learn/pull/26786\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    882\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py:1165\u001b[0m, in \u001b[0;36mBaseWrapper.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m   1161\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{param: value})\n\u001b[0;32m   1162\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1163\u001b[0m             \u001b[38;5;66;03m# Give a SciKeras specific user message to aid\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;66;03m# in moving from the Keras wrappers\u001b[39;00m\n\u001b[1;32m-> 1165\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1166\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1167\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis issue can likely be resolved by setting this parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1168\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1169\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1170\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheck the list of available parameters with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1171\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `estimator.get_params().keys()`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1172\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter lr for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(lr=0.001)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'class_weight'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = KerasClassifier(build_fn=nn_classifier, epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'neurons_per_layer': [32, 64, 128],\n",
    "    'lr': [0.001, 0.01, 0.1],\n",
    "    'reg_rate': [0.001, 0.01, 0.1],\n",
    "    'num_hidden_layers': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter lr for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(lr=0.001)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mkeras_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:878\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    871\u001b[0m score_params_test \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mscore_params, indices\u001b[38;5;241m=\u001b[39mtest)\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# here we clone the parameters, since sometimes the parameters\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# themselves might be estimators, e.g. when we search over different\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;66;03m# estimators in a pipeline.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# ref: https://github.com/scikit-learn/scikit-learn/pull/26786\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    882\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32mc:\\Users\\17735\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py:1165\u001b[0m, in \u001b[0;36mBaseWrapper.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m   1161\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{param: value})\n\u001b[0;32m   1162\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1163\u001b[0m             \u001b[38;5;66;03m# Give a SciKeras specific user message to aid\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;66;03m# in moving from the Keras wrappers\u001b[39;00m\n\u001b[1;32m-> 1165\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1166\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1167\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis issue can likely be resolved by setting this parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1168\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1169\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1170\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheck the list of available parameters with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1171\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `estimator.get_params().keys()`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1172\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter lr for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(lr=0.001)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters found:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = KerasClassifier(build_fn=nn_classifier, epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_classifier(neurons_per_layer=64, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
